{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from spektral.data.utils import to_tf_signature, prepend_none\n",
    "from spektral.data import DisjointLoader, Dataset\n",
    "from spektral.transforms import GCNFilter, NormalizeAdj\n",
    "from spektral.layers import GlobalMaxPool, GlobalAvgPool, GCSConv\n",
    "import scipy.sparse\n",
    "from spektral.data.graph import Graph\n",
    "from keras.layers import Dense, concatenate, Dropout, Concatenate\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('thingi10k_data.csv', index_col=0)\n",
    "adjpath = '../Data/stl/adjacency_stl_simplified/'\n",
    "cloudpath = '../Data/stl/nodefeatures_stl_simplified/'\n",
    "edgepath = '../Data/stl/edgefeaturesmatrix_stl_simplified/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom disjointloader\n",
    "def getFeatures(batch):\n",
    "    feats = []\n",
    "    for graph in batch:\n",
    "        feats.append(graph.__getattribute__('feats'))\n",
    "    return np.array(feats)\n",
    "\n",
    "class MyDisjointLoader(DisjointLoader):\n",
    "    def __init__(\n",
    "        self, dataset, node_level=False, batch_size=1, epochs=None, shuffle=True\n",
    "    ):\n",
    "        self.node_level = node_level\n",
    "        super().__init__(dataset, batch_size=batch_size, epochs=epochs, shuffle=shuffle)\n",
    "\n",
    "    def __next__(self):\n",
    "        nxt = self._generator.__next__()\n",
    "        feats = getFeatures(nxt)\n",
    "        #feats = nxt[0].__getattribute__('feats')\n",
    "        output, y = self.collate(nxt)\n",
    "        feats = (feats,)\n",
    "        output = output + feats\n",
    "        return   output, y\n",
    "    \n",
    "    def tf_signature(self):\n",
    "    \n",
    "        signature = self.dataset.signature\n",
    "        if \"y\" in signature:\n",
    "            signature[\"y\"][\"shape\"] = prepend_none(signature[\"y\"][\"shape\"])\n",
    "        if \"a\" in signature:\n",
    "            signature[\"a\"][\"spec\"] = tf.SparseTensorSpec\n",
    "\n",
    "        signature[\"i\"] = dict()\n",
    "        signature[\"i\"][\"spec\"] = tf.TensorSpec\n",
    "        signature[\"i\"][\"shape\"] = (None,)\n",
    "        signature[\"i\"][\"dtype\"] = tf.as_dtype(tf.int64)\n",
    "\n",
    "        sig = (tf.TensorSpec(shape=[None,12]),)\n",
    "        input = to_tf_signature(signature)\n",
    "        sig = input[0] + sig\n",
    "        return (sig, input[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data, drop unnecessary\n",
    "data = pd.read_csv('thingi10k_data.csv', index_col=0)\n",
    "\n",
    "df = data.copy()\n",
    "df.drop(\"source\", axis=1, inplace=True)\n",
    "df.drop(\"model_name\", axis=1, inplace=True)\n",
    "df.drop(\"support_material\", axis=1, inplace=True)\n",
    "\n",
    "#Extract build times\n",
    "build_times = df[\"build_time\"]\n",
    "df.drop(\"build_time\", axis=1,inplace=True)\n",
    "\n",
    "#Make pipeline\n",
    "def log_transform(x):\n",
    "    return np.log(x + 1)\n",
    "\n",
    "def inv_log_transform(x):\n",
    "    return np.exp(x) - 1 \n",
    "\n",
    "logtransformer = FunctionTransformer(func=log_transform, inverse_func=inv_log_transform, check_inverse=False)\n",
    "pipe = Pipeline(steps=[ ('logtransformer', logtransformer)])\n",
    "\n",
    "#Log transform\n",
    "transformed = pipe.fit_transform(df)\n",
    "df = np.asarray(transformed)\n",
    "build_times = np.asarray(build_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, centroids, dev, index, **kwargs):\n",
    "        self.centroids = centroids\n",
    "        self.dev = dev\n",
    "        self.index = index\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        output = []\n",
    "        for i in self.index:\n",
    "            if(os.path.isfile(adjpath + f'{features[\"model_name\"][i]}.npz')):\n",
    "                point_cloud = np.load(cloudpath + f'{features[\"model_name\"][i]}.npy').reshape(-1,3)\n",
    "                edgefeat = scipy.sparse.load_npz(edgepath + f'{features[\"model_name\"][i]}.npz')\n",
    "                output.append(\n",
    "                    Graph(x=((point_cloud-self.centroids)/self.dev), a=edgefeat, y=features[\"build_time\"][i], feats=df[i])\n",
    "                )\n",
    "            else:\n",
    "                print(f'object {i} missing!')\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_graphs(trainindex, testindex):\n",
    "    print(\"Getting split...\")\n",
    "    coords = np.empty((1,3))\n",
    "\n",
    "    for i in trainindex:\n",
    "        if(os.path.isfile(adjpath + f'{features[\"model_name\"][i]}.npz')):\n",
    "            point_cloud = np.load(cloudpath + f'{features[\"model_name\"][i]}.npy').reshape(-1,3)\n",
    "            coords = np.concatenate((coords,point_cloud))\n",
    "            \n",
    "\n",
    "    coords = np.delete(coords,0,0)\n",
    "    centroids = np.mean(coords,0)\n",
    "    coordscentered = coords - centroids\n",
    "    dev = np.max(np.sqrt(np.sum(coordscentered**2,axis=-1) / (trainindex.shape[0] - 1)))\n",
    "\n",
    "    train = MyDataset(centroids, dev, trainindex)\n",
    "    test = MyDataset(centroids, dev, testindex)\n",
    "    validation = MyDataset(centroids, dev, range(3478,3661))\n",
    "    train.apply(NormalizeAdj())\n",
    "    test.apply(NormalizeAdj())\n",
    "    validation.apply(NormalizeAdj())\n",
    "    train = MyDisjointLoader(train, batch_size=32)\n",
    "    test = MyDisjointLoader(test, batch_size=32)\n",
    "    validation = MyDisjointLoader(validation, batch_size=32)\n",
    "    \n",
    "    return train, test, validation\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define callbacks\n",
    "def get_callbacks(weights_file, patience, lr_factor):\n",
    "  return [\n",
    "      # Only save the weights that correspond to the minimum mape.\n",
    "      ModelCheckpoint(filepath= weights_file,\n",
    "                      monitor=\"val_mape\", \n",
    "                      mode=\"min\",\n",
    "                      save_best_only=True, \n",
    "                      save_weights_only=False),\n",
    "      # If val_loss doesn't improve for a number of epochs set with 'patience' var \n",
    "      # training will stop to avoid overfitting.    \n",
    "      EarlyStopping(monitor=\"val_loss\",\n",
    "                    mode=\"min\",\n",
    "                    patience = patience,\n",
    "                    verbose=1),\n",
    "      # Learning rate is reduced by 'lr_factor' if val_loss stagnates\n",
    "      # for a number of epochs set with 'patience/2' var.     \n",
    "      ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\",\n",
    "                        factor=lr_factor, min_lr=1e-8, patience=patience//2, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util\n",
    "def reset_model(model):\n",
    "    import keras.backend as K\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel.initializer') and layer.trainable: \n",
    "            layer.kernel.initializer.run(session=session)\n",
    "        if hasattr(layer, 'bias.initializer') and layer.trainable:\n",
    "            layer.bias.initializer.run(session=session)\n",
    "\n",
    "def make_trainable(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "def cross_validate(model, dir):\n",
    "    loss_per_fold = []\n",
    "    mae_per_fold = []\n",
    "    mape_per_fold = []\n",
    "    validation_per_fold = []\n",
    "    batch_size = 32\n",
    "    verbosity = 1\n",
    "    no_epochs = 1000\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    basemodel = model\n",
    "\n",
    "    if len(model.inputs) == 1:\n",
    "        print('Baselinemodel')\n",
    "\n",
    "        fold_no = 1\n",
    "        for train, test in kfold.split(df[0:3478], build_times[0:3478]):\n",
    "\n",
    "            reset_model(model)\n",
    "\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "            model.compile(loss='mape',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                metrics=['mae','mape']\n",
    "            )\n",
    "\n",
    "            history = model.fit(df[train], build_times[train], validation_data=(df[test], build_times[test]),\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity,\n",
    "              callbacks=get_callbacks(f'{dir}_{fold_no}',\n",
    "                                            patience=60,\n",
    "                                            lr_factor=0.3))\n",
    "            model = keras.models.load_model(f\"{dir}_{fold_no}\")\n",
    "\n",
    "            # Generate generalization metrics\n",
    "            valscores = model.evaluate(df[3478:3661], build_times[3478:3661], batch_size=32, verbose=0)\n",
    "            validation_per_fold.append(valscores)\n",
    "            scores = model.evaluate(df[test], build_times[test], verbose=0)\n",
    "            print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}%;')\n",
    "            loss_per_fold.append(scores[0])\n",
    "            mae_per_fold.append(scores[1])\n",
    "            mape_per_fold.append(scores[2])\n",
    "\n",
    "            # Increase fold number\n",
    "            fold_no = fold_no + 1\n",
    "    else:\n",
    "        print('multi-input')\n",
    "        fold_no = 1\n",
    "        for train, test in kfold.split(df[0:3478], build_times[0:3478]):\n",
    "\n",
    "            reset_model(model) #wegcommenten voor additional training\n",
    "            #model = basemodel\n",
    "            #model = keras.models.load_model(\"crossvalidationmodels/Hybrid_nosupp_freeze_4/\")\n",
    "            #make_trainable(model)\n",
    "\n",
    "            trainloader, testloader, validationloader = get_split_graphs(train, test)\n",
    "\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "            model.compile(loss='mape',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), #0.001\n",
    "                metrics=['mae','mape']\n",
    "            )\n",
    "            history = model.fit(trainloader.load(), validation_data=testloader.load(), validation_steps=testloader.steps_per_epoch, steps_per_epoch=trainloader.steps_per_epoch,\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity,\n",
    "              callbacks=get_callbacks(f'{dir}_{fold_no}',\n",
    "                                            patience=60,\n",
    "                                            lr_factor=0.3))\n",
    "            model = keras.models.load_model(f\"{dir}_{fold_no}\")\n",
    "        \n",
    "            # Generate generalization metrics\n",
    "            valscores = model.evaluate(validationloader.load(), steps=validationloader.steps_per_epoch, batch_size=32, verbose=0)\n",
    "            validation_per_fold.append(valscores)\n",
    "            scores = model.evaluate(testloader.load(), steps=testloader.steps_per_epoch, batch_size=32, verbose=0)\n",
    "            print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}%;')\n",
    "            loss_per_fold.append(scores[0])\n",
    "            mae_per_fold.append(scores[1])\n",
    "            mape_per_fold.append(scores[2])\n",
    "\n",
    "            # Increase fold number\n",
    "            fold_no = fold_no + 1\n",
    "    return loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print scores\n",
    "def print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, len(loss_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Mean average error: {mae_per_fold[i]}% - Mean percentage error: {mape_per_fold[i]}%')\n",
    "        print(f'    Score on unseen data: Loss: {validation_per_fold[i][0]} - Mean average error: {validation_per_fold[i][1]}% - Mean percentage error: {validation_per_fold[i][2]}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print(f'> Mean average error: {np.mean(mae_per_fold)}')\n",
    "    print(f'> Mean percentage error: {np.mean(mape_per_fold)}')\n",
    "    print(f'> Unseen Loss: {np.mean(np.asarray(validation_per_fold)[:,0])}')\n",
    "    print(f'> Unseen Mean average error: {np.mean(np.asarray(validation_per_fold)[:,1])}')\n",
    "    print(f'> Unseen Mean percentage error: {np.mean(np.asarray(validation_per_fold)[:,2])}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\initializers\\initializers_v2.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values  each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 35.9018 - mae: 85.6307 - mape: 35.9018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 95ms/step - loss: 35.9018 - mae: 85.6307 - mape: 35.9018 - val_loss: 21.8615 - val_mae: 38.8569 - val_mape: 21.8615 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 22.4467 - mae: 52.4783 - mape: 22.4467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 95ms/step - loss: 22.4467 - mae: 52.4783 - mape: 22.4467 - val_loss: 17.4268 - val_mae: 37.2727 - val_mape: 17.4268 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 21.2655 - mae: 48.6465 - mape: 21.2655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 95ms/step - loss: 21.2655 - mae: 48.6465 - mape: 21.2655 - val_loss: 17.3372 - val_mae: 34.5460 - val_mape: 17.3372 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      " 1/87 [..............................] - ETA: 5s - loss: 18.0169 - mae: 52.2808 - mape: 18.0169"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 78ms/step - loss: 18.9574 - mae: 44.1017 - mape: 18.9574 - val_loss: 19.9149 - val_mae: 31.4315 - val_mape: 19.9149 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 19.0000 - mae: 51.3099 - mape: 19.0000 - val_loss: 20.8099 - val_mae: 27.5746 - val_mape: 20.8099 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 18.5695 - mae: 49.8814 - mape: 18.5695"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 95ms/step - loss: 18.5691 - mae: 49.5170 - mape: 18.5691 - val_loss: 17.2241 - val_mae: 32.4921 - val_mape: 17.2241 - lr: 0.0010\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 18.1283 - mae: 41.3434 - mape: 18.1283"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 95ms/step - loss: 18.1283 - mae: 41.3434 - mape: 18.1283 - val_loss: 15.5750 - val_mae: 29.2101 - val_mape: 15.5750 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      " 1/87 [..............................] - ETA: 5s - loss: 16.4059 - mae: 14.3825 - mape: 16.4059"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 17.7822 - mae: 48.7166 - mape: 17.7822"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 105ms/step - loss: 17.7905 - mae: 48.3051 - mape: 17.7905 - val_loss: 14.7165 - val_mae: 29.9797 - val_mape: 14.7165 - lr: 0.0010\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 79ms/step - loss: 19.7579 - mae: 47.2650 - mape: 19.7579 - val_loss: 15.0581 - val_mae: 51.2594 - val_mape: 15.0581 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 18.0861 - mae: 46.2383 - mape: 18.0861 - val_loss: 14.7325 - val_mae: 41.2827 - val_mape: 14.7325 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.0553 - mae: 47.6392 - mape: 17.0553 - val_loss: 15.9126 - val_mae: 29.0301 - val_mape: 15.9126 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 18.1610 - mae: 47.2295 - mape: 18.1610 - val_loss: 16.8503 - val_mae: 35.5594 - val_mape: 16.8503 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 17.7716 - mae: 44.3415 - mape: 17.7716 - val_loss: 15.8731 - val_mae: 28.8646 - val_mape: 15.8731 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 18.6797 - mae: 55.2281 - mape: 18.6797 - val_loss: 17.2259 - val_mae: 33.9366 - val_mape: 17.2259 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 6s 75ms/step - loss: 17.8285 - mae: 42.8813 - mape: 17.8285 - val_loss: 15.1040 - val_mae: 33.6768 - val_mape: 15.1040 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 16.7910 - mae: 40.8904 - mape: 16.7910 - val_loss: 15.0846 - val_mae: 32.3834 - val_mape: 15.0846 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 16.6382 - mae: 48.8560 - mape: 16.6382 - val_loss: 17.7141 - val_mae: 35.0329 - val_mape: 17.7141 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.6544 - mae: 48.1825 - mape: 17.6544 - val_loss: 24.6848 - val_mae: 49.0179 - val_mape: 24.6848 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 19.2805 - mae: 47.3211 - mape: 19.2805 - val_loss: 15.0308 - val_mae: 30.8742 - val_mape: 15.0308 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7685 - mae: 43.1182 - mape: 16.7685 - val_loss: 21.5597 - val_mae: 38.2725 - val_mape: 21.5597 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.9510 - mae: 45.5791 - mape: 16.9510 - val_loss: 15.1233 - val_mae: 26.6229 - val_mape: 15.1233 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 17.5058 - mae: 45.9583 - mape: 17.5058 - val_loss: 15.2056 - val_mae: 50.5175 - val_mape: 15.2056 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.6434 - mae: 40.3278 - mape: 16.6434"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 94ms/step - loss: 16.6434 - mae: 40.3278 - mape: 16.6434 - val_loss: 14.5459 - val_mae: 31.8124 - val_mape: 14.5459 - lr: 0.0010\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8593 - mae: 41.7594 - mape: 16.8593 - val_loss: 14.7035 - val_mae: 31.7605 - val_mape: 14.7035 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.5006 - mae: 43.1145 - mape: 16.5006 - val_loss: 16.7319 - val_mae: 46.4467 - val_mape: 16.7319 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.4352 - mae: 42.9013 - mape: 16.4352 - val_loss: 19.7255 - val_mae: 54.7137 - val_mape: 19.7255 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.6387 - mae: 49.2093 - mape: 16.6387 - val_loss: 20.7195 - val_mae: 50.1779 - val_mape: 20.7195 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.3406 - mae: 40.0557 - mape: 16.3406 - val_loss: 14.7152 - val_mae: 32.2438 - val_mape: 14.7152 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.6832 - mae: 40.7781 - mape: 17.6832 - val_loss: 19.9102 - val_mae: 43.7103 - val_mape: 19.9102 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.6568 - mae: 40.0881 - mape: 16.6568"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 93ms/step - loss: 16.6568 - mae: 40.0881 - mape: 16.6568 - val_loss: 14.2080 - val_mae: 31.4420 - val_mape: 14.2080 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      " 1/87 [..............................] - ETA: 7s - loss: 10.9908 - mae: 36.8958 - mape: 10.9908"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\engine\\functional.py:1563: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  layer_config = serialize_layer_fn(layer)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\keras\\saving\\saved_model\\layer_serialization.py:134: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  return generic_utils.serialize_keras_object(obj)\n",
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 81ms/step - loss: 17.1967 - mae: 45.8654 - mape: 17.1967 - val_loss: 18.7383 - val_mae: 35.4850 - val_mape: 18.7383 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 17.0542 - mae: 43.8773 - mape: 17.0542 - val_loss: 16.4313 - val_mae: 35.8148 - val_mape: 16.4313 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 17.0832 - mae: 43.8830 - mape: 17.0832 - val_loss: 16.6707 - val_mae: 33.9232 - val_mape: 16.6707 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 16.1387 - mae: 41.6342 - mape: 16.1387 - val_loss: 22.3254 - val_mae: 61.2144 - val_mape: 22.3254 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.1953 - mae: 42.9534 - mape: 17.1953 - val_loss: 16.8630 - val_mae: 47.0273 - val_mape: 16.8630 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 15.6896 - mae: 44.6412 - mape: 15.6896 - val_loss: 16.6598 - val_mae: 37.5581 - val_mape: 16.6598 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.9848 - mae: 39.5722 - mape: 14.9848 - val_loss: 14.7288 - val_mae: 36.0966 - val_mape: 14.7288 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 16.7031 - mae: 41.4578 - mape: 16.7031 - val_loss: 16.4157 - val_mae: 38.1543 - val_mape: 16.4157 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.7016 - mae: 40.8538 - mape: 15.7016 - val_loss: 15.0297 - val_mae: 32.3289 - val_mape: 15.0297 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.1137 - mae: 41.0128 - mape: 16.1137 - val_loss: 15.2855 - val_mae: 33.1231 - val_mape: 15.2855 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.5710 - mae: 41.9022 - mape: 16.5710 - val_loss: 19.7006 - val_mae: 50.1571 - val_mape: 19.7006 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.8899 - mae: 48.5277 - mape: 16.8899 - val_loss: 19.4716 - val_mae: 46.6131 - val_mape: 19.4716 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.8311 - mae: 42.3523 - mape: 15.8311 - val_loss: 14.9574 - val_mae: 41.7016 - val_mape: 14.9574 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 16.1181 - mae: 41.2566 - mape: 16.1181 - val_loss: 14.5671 - val_mae: 33.2247 - val_mape: 14.5671 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 16.5371 - mae: 43.6918 - mape: 16.5371 - val_loss: 18.1126 - val_mae: 64.9000 - val_mape: 18.1126 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.5474 - mae: 50.6645 - mape: 15.5474 - val_loss: 16.3889 - val_mae: 47.6230 - val_mape: 16.3889 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.9353 - mae: 42.1297 - mape: 15.9353 - val_loss: 26.2164 - val_mae: 43.8685 - val_mape: 26.2164 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.3499 - mae: 56.5033 - mape: 17.3499 - val_loss: 17.5643 - val_mae: 59.4082 - val_mape: 17.5643 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.1869 - mae: 41.1481 - mape: 16.1869 - val_loss: 17.5161 - val_mae: 32.9548 - val_mape: 17.5161 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 15.5221 - mae: 39.7565 - mape: 15.5221 - val_loss: 18.2044 - val_mae: 38.7969 - val_mape: 18.2044 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.2686 - mae: 47.3465 - mape: 17.2686 - val_loss: 17.5801 - val_mae: 38.3255 - val_mape: 17.5801 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.6229 - mae: 46.7088 - mape: 16.6229 - val_loss: 15.1279 - val_mae: 44.7634 - val_mape: 15.1279 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.1408 - mae: 43.5478 - mape: 17.1408 - val_loss: 23.6122 - val_mae: 44.8156 - val_mape: 23.6122 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.6126 - mae: 39.3843 - mape: 15.6126 - val_loss: 20.2550 - val_mae: 48.2988 - val_mape: 20.2550 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 16.2313 - mae: 46.7850 - mape: 16.2313 - val_loss: 19.0017 - val_mae: 40.0911 - val_mape: 19.0017 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.1687 - mae: 45.1846 - mape: 15.1687 - val_loss: 18.6113 - val_mae: 54.6699 - val_mape: 18.6113 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.5431 - mae: 39.2343 - mape: 15.5431 - val_loss: 21.1203 - val_mae: 41.7849 - val_mape: 21.1203 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 15.4129 - mae: 39.5420 - mape: 15.4129 - val_loss: 18.4656 - val_mae: 56.7995 - val_mape: 18.4656 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 15.6013 - mae: 41.2399 - mape: 15.6013 - val_loss: 18.2384 - val_mae: 61.7960 - val_mape: 18.2384 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.9194 - mae: 40.1774 - mape: 14.9194\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 14.9194 - mae: 40.1774 - mape: 14.9194 - val_loss: 16.3802 - val_mae: 49.7243 - val_mape: 16.3802 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.9982 - mae: 36.5996 - mape: 13.9982 - val_loss: 17.5966 - val_mae: 46.8927 - val_mape: 17.5966 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.3437 - mae: 32.7929 - mape: 13.3437 - val_loss: 18.4301 - val_mae: 44.2633 - val_mape: 18.4301 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9122 - mae: 33.5654 - mape: 13.9122 - val_loss: 14.7087 - val_mae: 41.0355 - val_mape: 14.7087 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.8798 - mae: 35.7089 - mape: 13.8798 - val_loss: 17.2647 - val_mae: 39.1685 - val_mape: 17.2647 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.6295 - mae: 33.5200 - mape: 13.6295 - val_loss: 15.9077 - val_mae: 37.4832 - val_mape: 15.9077 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.5487 - mae: 35.3564 - mape: 13.5487 - val_loss: 19.3338 - val_mae: 46.4510 - val_mape: 19.3338 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 13.2881 - mae: 35.0030 - mape: 13.2881 - val_loss: 20.8247 - val_mae: 51.2638 - val_mape: 20.8247 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0583 - mae: 32.3123 - mape: 13.0583 - val_loss: 16.8992 - val_mae: 39.5708 - val_mape: 16.8992 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.6558 - mae: 33.4066 - mape: 13.6558 - val_loss: 22.2275 - val_mae: 66.1364 - val_mape: 22.2275 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.2546 - mae: 33.0691 - mape: 13.2546 - val_loss: 18.0243 - val_mae: 40.4117 - val_mape: 18.0243 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 13.2091 - mae: 32.5357 - mape: 13.2091 - val_loss: 20.8335 - val_mae: 61.9690 - val_mape: 20.8335 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.2289 - mae: 32.9663 - mape: 13.2289 - val_loss: 18.2613 - val_mae: 49.7450 - val_mape: 18.2613 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0416 - mae: 35.6563 - mape: 13.0416 - val_loss: 17.1674 - val_mae: 46.7332 - val_mape: 17.1674 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 14.4710 - mae: 36.4450 - mape: 14.4710 - val_loss: 17.7416 - val_mae: 58.2353 - val_mape: 17.7416 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.6798 - mae: 34.6368 - mape: 13.6798 - val_loss: 19.7043 - val_mae: 47.9682 - val_mape: 19.7043 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.0771 - mae: 34.8028 - mape: 13.0771 - val_loss: 18.9370 - val_mae: 55.0741 - val_mape: 18.9370 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.1885 - mae: 33.6937 - mape: 13.1885 - val_loss: 20.2436 - val_mae: 60.5501 - val_mape: 20.2436 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 75ms/step - loss: 13.9820 - mae: 35.3605 - mape: 13.9820 - val_loss: 21.9131 - val_mae: 56.3044 - val_mape: 21.9131 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.2475 - mae: 32.2671 - mape: 13.2475 - val_loss: 16.6950 - val_mae: 51.8303 - val_mape: 16.6950 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 13.7868 - mae: 33.9960 - mape: 13.7868 - val_loss: 20.5046 - val_mae: 61.8220 - val_mape: 20.5046 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.2254 - mae: 35.9990 - mape: 13.2254 - val_loss: 18.7880 - val_mae: 56.3665 - val_mape: 18.7880 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.5811 - mae: 32.7389 - mape: 13.5811 - val_loss: 22.3790 - val_mae: 59.9355 - val_mape: 22.3790 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.3704 - mae: 34.4323 - mape: 13.3704 - val_loss: 22.4999 - val_mae: 65.4598 - val_mape: 22.4999 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 13.5486 - mae: 33.7335 - mape: 13.5486 - val_loss: 25.4407 - val_mae: 63.3639 - val_mape: 25.4407 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.1209 - mae: 33.8255 - mape: 13.1209 - val_loss: 24.7845 - val_mae: 72.7791 - val_mape: 24.7845 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0752 - mae: 32.3517 - mape: 13.0752 - val_loss: 19.9896 - val_mae: 65.9108 - val_mape: 19.9896 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9205 - mae: 32.1567 - mape: 12.9205 - val_loss: 20.3499 - val_mae: 50.4291 - val_mape: 20.3499 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.8832 - mae: 34.3966 - mape: 12.8832 - val_loss: 24.8438 - val_mae: 62.5421 - val_mape: 24.8438 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 12.9946 - mae: 35.4562 - mape: 12.9946 - val_loss: 26.6568 - val_mae: 82.1201 - val_mape: 26.6568 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 13.4880 - mae: 36.2530 - mape: 13.4880\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 6s 73ms/step - loss: 13.4845 - mae: 35.9269 - mape: 13.4845 - val_loss: 23.4386 - val_mae: 61.3291 - val_mape: 23.4386 - lr: 3.0000e-04\n",
      "Epoch 90: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 14.207966804504395; mae of 31.442018508911133; mape of 14.207966804504395%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 18.1505 - mae: 46.1707 - mape: 18.1505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 92ms/step - loss: 18.1505 - mae: 46.1707 - mape: 18.1505 - val_loss: 12.4407 - val_mae: 43.8793 - val_mape: 12.4407 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 78ms/step - loss: 17.4831 - mae: 47.0653 - mape: 17.4831 - val_loss: 25.7698 - val_mae: 95.6462 - val_mape: 25.7698 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 17.1365 - mae: 42.8774 - mape: 17.1365 - val_loss: 14.9349 - val_mae: 58.9203 - val_mape: 14.9349 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 16.8712 - mae: 41.7425 - mape: 16.8712 - val_loss: 15.2112 - val_mae: 75.5485 - val_mape: 15.2112 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7505 - mae: 42.2343 - mape: 16.7505 - val_loss: 18.7955 - val_mae: 86.0089 - val_mape: 18.7955 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7770 - mae: 42.8059 - mape: 16.7770 - val_loss: 29.7390 - val_mae: 85.7146 - val_mape: 29.7390 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.1363 - mae: 39.0623 - mape: 17.1363 - val_loss: 13.5024 - val_mae: 59.0532 - val_mape: 13.5024 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7519 - mae: 39.5277 - mape: 16.7519 - val_loss: 13.6591 - val_mae: 34.0131 - val_mape: 13.6591 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.9081 - mae: 40.0453 - mape: 15.9081 - val_loss: 12.8948 - val_mae: 36.6456 - val_mape: 12.8948 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.7272 - mae: 42.4872 - mape: 16.7272 - val_loss: 12.7122 - val_mae: 34.5599 - val_mape: 12.7122 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 15.9145 - mae: 42.4226 - mape: 15.9145 - val_loss: 15.0610 - val_mae: 54.1886 - val_mape: 15.0610 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8207 - mae: 45.4246 - mape: 16.8207 - val_loss: 23.1225 - val_mae: 74.7974 - val_mape: 23.1225 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.2639 - mae: 42.2451 - mape: 17.2639 - val_loss: 14.5681 - val_mae: 35.3252 - val_mape: 14.5681 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.8390 - mae: 41.0070 - mape: 16.8390 - val_loss: 15.4145 - val_mae: 54.9764 - val_mape: 15.4145 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.4559 - mae: 48.6160 - mape: 17.4559 - val_loss: 19.0850 - val_mae: 73.7607 - val_mape: 19.0850 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.8830 - mae: 35.9429 - mape: 15.8830 - val_loss: 16.0532 - val_mae: 62.2247 - val_mape: 16.0532 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.0508 - mae: 41.9205 - mape: 16.0508 - val_loss: 17.8722 - val_mae: 44.8247 - val_mape: 17.8722 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.9851 - mae: 41.7572 - mape: 17.9851 - val_loss: 16.6470 - val_mae: 45.0798 - val_mape: 16.6470 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.6552 - mae: 40.0396 - mape: 16.6552 - val_loss: 15.4045 - val_mae: 54.5995 - val_mape: 15.4045 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.0512 - mae: 37.8605 - mape: 16.0512 - val_loss: 14.8020 - val_mae: 42.6658 - val_mape: 14.8020 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.9100 - mae: 40.9043 - mape: 15.9100 - val_loss: 20.0501 - val_mae: 74.7022 - val_mape: 20.0501 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5719 - mae: 42.4989 - mape: 16.5719 - val_loss: 26.6545 - val_mae: 54.2168 - val_mape: 26.6545 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.0252 - mae: 43.1691 - mape: 17.0252 - val_loss: 24.1321 - val_mae: 46.5667 - val_mape: 24.1321 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.3131 - mae: 38.1342 - mape: 16.3131 - val_loss: 15.6916 - val_mae: 41.0984 - val_mape: 15.6916 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.8971 - mae: 36.1866 - mape: 15.8971 - val_loss: 20.3064 - val_mae: 47.4524 - val_mape: 20.3064 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.6722 - mae: 37.3752 - mape: 15.6722 - val_loss: 13.9698 - val_mae: 47.7160 - val_mape: 13.9698 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.6890 - mae: 39.6248 - mape: 15.6890 - val_loss: 15.3625 - val_mae: 44.7128 - val_mape: 15.3625 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.5764 - mae: 38.2231 - mape: 16.5764 - val_loss: 22.6151 - val_mae: 69.1150 - val_mape: 22.6151 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.5938 - mae: 46.5846 - mape: 17.5938 - val_loss: 21.2823 - val_mae: 65.4655 - val_mape: 21.2823 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.1295 - mae: 36.3447 - mape: 15.1295 - val_loss: 21.5132 - val_mae: 64.8400 - val_mape: 21.5132 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.3158 - mae: 41.5464 - mape: 16.3158\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.3158 - mae: 41.5464 - mape: 16.3158 - val_loss: 15.7532 - val_mae: 67.9625 - val_mape: 15.7532 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.5241 - mae: 38.1291 - mape: 14.5241 - val_loss: 16.1145 - val_mae: 51.4046 - val_mape: 16.1145 - lr: 3.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.7194 - mae: 31.3923 - mape: 13.7194 - val_loss: 16.2310 - val_mae: 49.5258 - val_mape: 16.2310 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.8079 - mae: 32.8511 - mape: 13.8079 - val_loss: 16.1590 - val_mae: 69.1315 - val_mape: 16.1590 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.6947 - mae: 37.1234 - mape: 13.6947 - val_loss: 20.5495 - val_mae: 76.0196 - val_mape: 20.5495 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.5524 - mae: 32.5498 - mape: 13.5524 - val_loss: 18.4332 - val_mae: 60.0873 - val_mape: 18.4332 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4523 - mae: 33.6779 - mape: 13.4523 - val_loss: 21.1370 - val_mae: 78.1569 - val_mape: 21.1370 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.6568 - mae: 33.6474 - mape: 13.6568 - val_loss: 19.3430 - val_mae: 72.0380 - val_mape: 19.3430 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2930 - mae: 31.2292 - mape: 13.2930 - val_loss: 16.7337 - val_mae: 74.3512 - val_mape: 16.7337 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.0784 - mae: 32.4516 - mape: 14.0784 - val_loss: 16.9585 - val_mae: 69.6139 - val_mape: 16.9585 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3960 - mae: 33.6140 - mape: 13.3960 - val_loss: 17.7977 - val_mae: 55.3614 - val_mape: 17.7977 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.7647 - mae: 37.0135 - mape: 13.7647 - val_loss: 18.7225 - val_mae: 81.5166 - val_mape: 18.7225 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.5863 - mae: 34.0815 - mape: 13.5863 - val_loss: 22.0750 - val_mae: 56.0814 - val_mape: 22.0750 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7734 - mae: 34.1320 - mape: 13.7734 - val_loss: 16.4624 - val_mae: 58.4698 - val_mape: 16.4624 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.1535 - mae: 35.4205 - mape: 14.1535 - val_loss: 21.9946 - val_mae: 82.8911 - val_mape: 21.9946 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.7174 - mae: 33.8132 - mape: 13.7174 - val_loss: 17.4817 - val_mae: 69.8686 - val_mape: 17.4817 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.1295 - mae: 35.1517 - mape: 14.1295 - val_loss: 21.0469 - val_mae: 73.7994 - val_mape: 21.0469 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.3424 - mae: 33.6897 - mape: 13.3424 - val_loss: 17.6899 - val_mae: 65.5724 - val_mape: 17.6899 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.4718 - mae: 35.2878 - mape: 13.4718 - val_loss: 19.7743 - val_mae: 70.3690 - val_mape: 19.7743 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.5546 - mae: 30.8355 - mape: 13.5546 - val_loss: 19.7065 - val_mae: 77.7393 - val_mape: 19.7065 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2427 - mae: 30.8360 - mape: 13.2427 - val_loss: 19.2754 - val_mae: 75.6183 - val_mape: 19.2754 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.6425 - mae: 30.7061 - mape: 13.6425 - val_loss: 25.5405 - val_mae: 77.1864 - val_mape: 25.5405 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3223 - mae: 34.0621 - mape: 13.3223 - val_loss: 17.8800 - val_mae: 72.2023 - val_mape: 17.8800 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1134 - mae: 31.0290 - mape: 13.1134 - val_loss: 23.3115 - val_mae: 81.3170 - val_mape: 23.3115 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.0805 - mae: 30.3310 - mape: 13.0805 - val_loss: 23.7700 - val_mae: 80.9854 - val_mape: 23.7700 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1660 - mae: 31.5107 - mape: 13.1660 - val_loss: 22.8130 - val_mae: 74.3913 - val_mape: 22.8130 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.3011 - mae: 28.8017 - mape: 13.3011 - val_loss: 23.5185 - val_mae: 82.6188 - val_mape: 23.5185 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.5340 - mae: 31.8096 - mape: 13.5340 - val_loss: 24.2033 - val_mae: 83.2935 - val_mape: 24.2033 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.9137 - mae: 31.0282 - mape: 12.9137 - val_loss: 23.6572 - val_mae: 76.9774 - val_mape: 23.6572 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 12.9837 - mae: 32.0649 - mape: 12.9837 - val_loss: 26.7883 - val_mae: 75.9811 - val_mape: 26.7883 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.4011 - mae: 33.3443 - mape: 13.4011\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4011 - mae: 33.3443 - mape: 13.4011 - val_loss: 16.4541 - val_mae: 67.7668 - val_mape: 16.4541 - lr: 3.0000e-04\n",
      "Epoch 61: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 12.440661430358887; mae of 43.87931442260742; mape of 12.440661430358887%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n",
      " 1/87 [..............................] - ETA: 1:13 - loss: 15.5925 - mae: 68.4738 - mape: 15.5925"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 17.1681 - mae: 44.0649 - mape: 17.1681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 17.1681 - mae: 44.0649 - mape: 17.1681 - val_loss: 13.2489 - val_mae: 51.6679 - val_mape: 13.2489 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      " 1/87 [..............................] - ETA: 7s - loss: 14.8559 - mae: 48.0651 - mape: 14.8559"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 85ms/step - loss: 16.8604 - mae: 40.7363 - mape: 16.8604 - val_loss: 14.4542 - val_mae: 49.0628 - val_mape: 14.4542 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.5985 - mae: 50.3731 - mape: 17.5985 - val_loss: 15.3987 - val_mae: 56.7773 - val_mape: 15.3987 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 16.3659 - mae: 39.6179 - mape: 16.3659 - val_loss: 15.2521 - val_mae: 40.0937 - val_mape: 15.2521 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 16.3398 - mae: 42.6936 - mape: 16.3398 - val_loss: 18.9630 - val_mae: 58.9904 - val_mape: 18.9630 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 18.4742 - mae: 46.7318 - mape: 18.4742 - val_loss: 13.5734 - val_mae: 55.2488 - val_mape: 13.5734 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.8324 - mae: 44.6325 - mape: 16.8324 - val_loss: 22.4540 - val_mae: 44.1897 - val_mape: 22.4540 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.9123 - mae: 45.5537 - mape: 17.9123"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 17.9123 - mae: 45.5537 - mape: 17.9123 - val_loss: 13.0935 - val_mae: 38.5710 - val_mape: 13.0935 - lr: 0.0010\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4874 - mae: 48.6673 - mape: 19.4874 - val_loss: 13.6652 - val_mae: 50.1414 - val_mape: 13.6652 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.5686 - mae: 41.1934 - mape: 16.5686 - val_loss: 15.3418 - val_mae: 34.8828 - val_mape: 15.3418 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 16.9213 - mae: 45.1404 - mape: 16.9213"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 94ms/step - loss: 16.9111 - mae: 45.1593 - mape: 16.9111 - val_loss: 12.3522 - val_mae: 31.7137 - val_mape: 12.3522 - lr: 0.0010\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 16.1042 - mae: 37.1612 - mape: 16.1042 - val_loss: 15.6564 - val_mae: 47.9693 - val_mape: 15.6564 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.3099 - mae: 42.7023 - mape: 16.3099 - val_loss: 12.9499 - val_mae: 41.4555 - val_mape: 12.9499 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.3722 - mae: 40.2101 - mape: 16.3722 - val_loss: 16.4424 - val_mae: 54.6621 - val_mape: 16.4424 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8126 - mae: 41.5725 - mape: 16.8126 - val_loss: 21.6747 - val_mae: 58.5250 - val_mape: 21.6747 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8369 - mae: 41.2496 - mape: 16.8369 - val_loss: 13.9449 - val_mae: 46.3559 - val_mape: 13.9449 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.0689 - mae: 42.1737 - mape: 18.0689 - val_loss: 14.2001 - val_mae: 55.1637 - val_mape: 14.2001 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.8707 - mae: 41.2541 - mape: 15.8707 - val_loss: 15.1726 - val_mae: 46.4950 - val_mape: 15.1726 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.3788 - mae: 41.6107 - mape: 15.3788 - val_loss: 13.7806 - val_mae: 39.9640 - val_mape: 13.7806 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.1577 - mae: 41.5138 - mape: 17.1577 - val_loss: 15.8352 - val_mae: 56.7551 - val_mape: 15.8352 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.7795 - mae: 43.2831 - mape: 15.7795 - val_loss: 13.3095 - val_mae: 34.3264 - val_mape: 13.3095 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.2127 - mae: 42.2341 - mape: 16.2127 - val_loss: 16.1195 - val_mae: 72.6218 - val_mape: 16.1195 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.9106 - mae: 46.3431 - mape: 17.9106 - val_loss: 15.4271 - val_mae: 37.1330 - val_mape: 15.4271 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.5130 - mae: 39.8931 - mape: 15.5130 - val_loss: 20.8585 - val_mae: 42.9234 - val_mape: 20.8585 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.3551 - mae: 38.4070 - mape: 16.3551 - val_loss: 15.6660 - val_mae: 53.0134 - val_mape: 15.6660 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5980 - mae: 40.3096 - mape: 16.5980 - val_loss: 15.8074 - val_mae: 48.7327 - val_mape: 15.8074 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 15.7685 - mae: 40.3628 - mape: 15.7685 - val_loss: 14.5426 - val_mae: 40.2830 - val_mape: 14.5426 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7719 - mae: 40.3103 - mape: 16.7719 - val_loss: 27.6656 - val_mae: 69.0420 - val_mape: 27.6656 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.7748 - mae: 41.0564 - mape: 17.7748 - val_loss: 13.6760 - val_mae: 42.5313 - val_mape: 13.6760 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.5279 - mae: 42.1898 - mape: 16.5279 - val_loss: 13.3399 - val_mae: 41.0868 - val_mape: 13.3399 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.5307 - mae: 38.8309 - mape: 15.5307 - val_loss: 20.0861 - val_mae: 46.1919 - val_mape: 20.0861 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 15.5811 - mae: 39.9582 - mape: 15.5811 - val_loss: 17.7885 - val_mae: 40.0336 - val_mape: 17.7885 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.6467 - mae: 39.7216 - mape: 15.6467 - val_loss: 15.2244 - val_mae: 45.3456 - val_mape: 15.2244 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.6388 - mae: 40.7877 - mape: 15.6388 - val_loss: 22.8270 - val_mae: 60.9458 - val_mape: 22.8270 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.4468 - mae: 40.9692 - mape: 16.4468 - val_loss: 20.9545 - val_mae: 43.0680 - val_mape: 20.9545 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.6334 - mae: 40.1501 - mape: 15.6334 - val_loss: 21.8389 - val_mae: 64.0476 - val_mape: 21.8389 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.7051 - mae: 46.7045 - mape: 17.7051 - val_loss: 22.0322 - val_mae: 48.2655 - val_mape: 22.0322 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.1042 - mae: 38.2697 - mape: 16.1042 - val_loss: 20.1761 - val_mae: 41.6243 - val_mape: 20.1761 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.3138 - mae: 44.0029 - mape: 16.3138 - val_loss: 22.2748 - val_mae: 47.1884 - val_mape: 22.2748 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.3670 - mae: 42.2012 - mape: 16.3670 - val_loss: 19.1385 - val_mae: 44.8709 - val_mape: 19.1385 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 15.8970 - mae: 42.5444 - mape: 15.8970\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 15.9422 - mae: 42.3664 - mape: 15.9422 - val_loss: 14.1876 - val_mae: 51.0314 - val_mape: 14.1876 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.8695 - mae: 35.0879 - mape: 14.8695 - val_loss: 17.5727 - val_mae: 60.1364 - val_mape: 17.5727 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.8213 - mae: 34.1009 - mape: 13.8213 - val_loss: 17.0543 - val_mae: 54.6205 - val_mape: 17.0543 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.6794 - mae: 34.3806 - mape: 13.6794 - val_loss: 15.5161 - val_mae: 42.2348 - val_mape: 15.5161 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.5461 - mae: 34.5160 - mape: 13.5461 - val_loss: 19.2822 - val_mae: 46.0290 - val_mape: 19.2822 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.9523 - mae: 35.6924 - mape: 13.9523 - val_loss: 14.7743 - val_mae: 49.9375 - val_mape: 14.7743 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.6592 - mae: 35.8499 - mape: 13.6592 - val_loss: 17.4926 - val_mae: 60.4043 - val_mape: 17.4926 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.8419 - mae: 35.2377 - mape: 13.8419 - val_loss: 16.2427 - val_mae: 56.6108 - val_mape: 16.2427 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.5422 - mae: 32.9977 - mape: 13.5422 - val_loss: 22.6176 - val_mae: 64.0210 - val_mape: 22.6176 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.4795 - mae: 32.4497 - mape: 13.4795 - val_loss: 18.8584 - val_mae: 62.1380 - val_mape: 18.8584 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.2525 - mae: 33.4699 - mape: 13.2525 - val_loss: 18.5401 - val_mae: 61.5236 - val_mape: 18.5401 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.8072 - mae: 35.9049 - mape: 13.8072 - val_loss: 15.6453 - val_mae: 42.8122 - val_mape: 15.6453 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 13.4083 - mae: 31.9012 - mape: 13.4083 - val_loss: 21.4329 - val_mae: 76.3276 - val_mape: 21.4329 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.2724 - mae: 35.1033 - mape: 13.2724 - val_loss: 19.6288 - val_mae: 55.6201 - val_mape: 19.6288 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.3112 - mae: 35.6122 - mape: 13.3112 - val_loss: 16.3170 - val_mae: 65.4260 - val_mape: 16.3170 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 13.9781 - mae: 36.5997 - mape: 13.9781 - val_loss: 21.6022 - val_mae: 65.9895 - val_mape: 21.6022 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.8935 - mae: 34.5071 - mape: 13.8935 - val_loss: 20.6467 - val_mae: 64.2934 - val_mape: 20.6467 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.4471 - mae: 35.0693 - mape: 13.4471 - val_loss: 19.7859 - val_mae: 73.8768 - val_mape: 19.7859 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 12.9370 - mae: 30.2034 - mape: 12.9370 - val_loss: 16.7997 - val_mae: 59.2548 - val_mape: 16.7997 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.3378 - mae: 31.7113 - mape: 13.3378 - val_loss: 19.5705 - val_mae: 58.4766 - val_mape: 19.5705 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.2807 - mae: 34.9368 - mape: 13.2807 - val_loss: 18.5900 - val_mae: 69.5749 - val_mape: 18.5900 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.0651 - mae: 33.2286 - mape: 14.0651 - val_loss: 17.5719 - val_mae: 62.1163 - val_mape: 17.5719 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.2327 - mae: 31.1491 - mape: 13.2327 - val_loss: 20.3422 - val_mae: 64.5896 - val_mape: 20.3422 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.6490 - mae: 33.4196 - mape: 13.6490 - val_loss: 17.9360 - val_mae: 62.2669 - val_mape: 17.9360 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.0826 - mae: 35.5945 - mape: 13.0826 - val_loss: 20.1905 - val_mae: 65.9554 - val_mape: 20.1905 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.3847 - mae: 33.5278 - mape: 13.3847 - val_loss: 15.7501 - val_mae: 64.6833 - val_mape: 15.7501 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.3085 - mae: 33.8684 - mape: 13.3085 - val_loss: 17.2114 - val_mae: 50.6974 - val_mape: 17.2114 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.0032 - mae: 32.6544 - mape: 13.0032 - val_loss: 21.8871 - val_mae: 68.7491 - val_mape: 21.8871 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.9318 - mae: 31.4624 - mape: 12.9318 - val_loss: 18.2476 - val_mae: 60.3836 - val_mape: 18.2476 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.6136 - mae: 34.0386 - mape: 13.6136 - val_loss: 19.6768 - val_mae: 72.9678 - val_mape: 19.6768 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.1446 - mae: 34.0222 - mape: 13.1446\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.1446 - mae: 34.0222 - mape: 13.1446 - val_loss: 22.2583 - val_mae: 61.8469 - val_mape: 22.2583 - lr: 3.0000e-04\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 12.35222339630127; mae of 31.713748931884766; mape of 12.35222339630127%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 17.3883 - mae: 44.2089 - mape: 17.3883"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 17.3883 - mae: 44.2089 - mape: 17.3883 - val_loss: 12.6368 - val_mae: 39.1336 - val_mape: 12.6368 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      " 1/87 [..............................] - ETA: 5s - loss: 14.1269 - mae: 8.3538 - mape: 14.1269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.7774 - mae: 39.7983 - mape: 16.7774"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 101ms/step - loss: 16.7774 - mae: 39.7983 - mape: 16.7774 - val_loss: 12.1317 - val_mae: 24.6535 - val_mape: 12.1317 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      " 1/87 [..............................] - ETA: 6s - loss: 17.7380 - mae: 42.3424 - mape: 17.7380"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.2403 - mae: 44.3435 - mape: 16.2403"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 16.2403 - mae: 44.3435 - mape: 16.2403 - val_loss: 11.9511 - val_mae: 23.1840 - val_mape: 11.9511 - lr: 0.0010\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 88ms/step - loss: 17.6487 - mae: 49.4676 - mape: 17.6487 - val_loss: 17.8188 - val_mae: 76.1936 - val_mape: 17.8188 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.2341 - mae: 44.0907 - mape: 17.2341 - val_loss: 12.9479 - val_mae: 41.3419 - val_mape: 12.9479 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.1011 - mae: 41.7147 - mape: 17.1011 - val_loss: 22.2708 - val_mae: 49.8282 - val_mape: 22.2708 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.7907 - mae: 41.5194 - mape: 16.7907 - val_loss: 20.8272 - val_mae: 54.8755 - val_mape: 20.8272 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.5875 - mae: 45.6325 - mape: 16.5875 - val_loss: 18.5845 - val_mae: 37.6589 - val_mape: 18.5845 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.6612 - mae: 36.4151 - mape: 15.6612 - val_loss: 18.3819 - val_mae: 35.7758 - val_mape: 18.3819 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.9093 - mae: 43.1674 - mape: 17.9093 - val_loss: 15.8240 - val_mae: 27.5864 - val_mape: 15.8240 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.4504 - mae: 41.3620 - mape: 16.4504 - val_loss: 17.2613 - val_mae: 48.0390 - val_mape: 17.2613 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.6368 - mae: 49.5392 - mape: 16.6368 - val_loss: 13.5720 - val_mae: 44.2003 - val_mape: 13.5720 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.1458 - mae: 42.1324 - mape: 16.1458 - val_loss: 16.4405 - val_mae: 47.4681 - val_mape: 16.4405 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 16.3675 - mae: 41.0534 - mape: 16.3675 - val_loss: 13.6111 - val_mae: 38.5550 - val_mape: 13.6111 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.3705 - mae: 41.9303 - mape: 16.3705 - val_loss: 15.5751 - val_mae: 40.9854 - val_mape: 15.5751 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.2269 - mae: 47.4972 - mape: 16.2269 - val_loss: 14.3681 - val_mae: 31.6532 - val_mape: 14.3681 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.4593 - mae: 42.3058 - mape: 16.4593 - val_loss: 19.6004 - val_mae: 49.7151 - val_mape: 19.6004 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.0792 - mae: 42.0562 - mape: 16.0792 - val_loss: 19.2104 - val_mae: 39.9407 - val_mape: 19.2104 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.6580 - mae: 42.0659 - mape: 16.6580 - val_loss: 12.2471 - val_mae: 38.1939 - val_mape: 12.2471 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.3142 - mae: 49.7360 - mape: 17.3142 - val_loss: 14.4164 - val_mae: 37.4908 - val_mape: 14.4164 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.2157 - mae: 47.3236 - mape: 17.2157 - val_loss: 23.3522 - val_mae: 52.1062 - val_mape: 23.3522 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.4317 - mae: 44.6496 - mape: 16.4317 - val_loss: 17.5203 - val_mae: 48.3520 - val_mape: 17.5203 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.8806 - mae: 40.7974 - mape: 15.8806 - val_loss: 16.1548 - val_mae: 43.8231 - val_mape: 16.1548 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.8371 - mae: 47.0654 - mape: 16.8371 - val_loss: 20.6982 - val_mae: 80.9808 - val_mape: 20.6982 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.1595 - mae: 44.0886 - mape: 16.1595 - val_loss: 15.6207 - val_mae: 34.7122 - val_mape: 15.6207 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.2705 - mae: 40.8826 - mape: 16.2705 - val_loss: 18.2855 - val_mae: 47.1639 - val_mape: 18.2855 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.6122 - mae: 44.4225 - mape: 16.6122 - val_loss: 19.9063 - val_mae: 64.5870 - val_mape: 19.9063 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.9399 - mae: 39.3820 - mape: 15.9399 - val_loss: 17.1037 - val_mae: 54.4259 - val_mape: 17.1037 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.1004 - mae: 40.0740 - mape: 15.1004 - val_loss: 20.9597 - val_mae: 57.5524 - val_mape: 20.9597 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.4583 - mae: 47.9382 - mape: 17.4583 - val_loss: 20.1184 - val_mae: 68.2871 - val_mape: 20.1184 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 16.3244 - mae: 39.2714 - mape: 16.3244 - val_loss: 13.9819 - val_mae: 38.6925 - val_mape: 13.9819 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.8035 - mae: 42.4317 - mape: 15.8035 - val_loss: 14.1785 - val_mae: 28.7599 - val_mape: 14.1785 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 15.7401 - mae: 40.6367 - mape: 15.7401\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.7401 - mae: 40.6367 - mape: 15.7401 - val_loss: 16.8225 - val_mae: 29.6431 - val_mape: 16.8225 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.0312 - mae: 38.5649 - mape: 14.0312 - val_loss: 15.5817 - val_mae: 34.7207 - val_mape: 15.5817 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.7085 - mae: 35.7871 - mape: 13.7085 - val_loss: 15.4959 - val_mae: 38.7743 - val_mape: 15.4959 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.6256 - mae: 34.8789 - mape: 13.6256 - val_loss: 16.5368 - val_mae: 54.7899 - val_mape: 16.5368 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.3365 - mae: 37.5585 - mape: 14.3365 - val_loss: 19.4396 - val_mae: 42.9277 - val_mape: 19.4396 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.4998 - mae: 31.3450 - mape: 13.4998 - val_loss: 16.5882 - val_mae: 50.7665 - val_mape: 16.5882 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.5577 - mae: 35.3129 - mape: 13.5577 - val_loss: 19.4153 - val_mae: 43.7754 - val_mape: 19.4153 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.2916 - mae: 36.0894 - mape: 13.2916 - val_loss: 19.3117 - val_mae: 57.0848 - val_mape: 19.3117 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1232 - mae: 33.4584 - mape: 13.1232 - val_loss: 22.3628 - val_mae: 57.5293 - val_mape: 22.3628 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.7248 - mae: 34.2532 - mape: 13.7248 - val_loss: 20.6250 - val_mae: 59.4932 - val_mape: 20.6250 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3969 - mae: 33.7106 - mape: 13.3969 - val_loss: 20.4265 - val_mae: 66.9190 - val_mape: 20.4265 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.8133 - mae: 35.6155 - mape: 13.8133 - val_loss: 16.5883 - val_mae: 52.8674 - val_mape: 16.5883 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.9614 - mae: 33.3180 - mape: 13.9614 - val_loss: 17.9355 - val_mae: 46.4047 - val_mape: 17.9355 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.2881 - mae: 33.4738 - mape: 13.2881 - val_loss: 18.0691 - val_mae: 46.5338 - val_mape: 18.0691 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1233 - mae: 33.3853 - mape: 13.1233 - val_loss: 19.2634 - val_mae: 53.5308 - val_mape: 19.2634 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.0554 - mae: 37.8689 - mape: 13.0554 - val_loss: 21.1079 - val_mae: 50.8077 - val_mape: 21.1079 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1929 - mae: 33.8496 - mape: 13.1929 - val_loss: 17.8633 - val_mae: 51.2159 - val_mape: 17.8633 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.1657 - mae: 33.3221 - mape: 13.1657 - val_loss: 21.0512 - val_mae: 59.8667 - val_mape: 21.0512 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.8021 - mae: 33.0327 - mape: 12.8021 - val_loss: 21.0010 - val_mae: 54.0561 - val_mape: 21.0010 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.3255 - mae: 34.3834 - mape: 13.3255 - val_loss: 18.1653 - val_mae: 55.6286 - val_mape: 18.1653 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.0708 - mae: 35.5385 - mape: 13.0708 - val_loss: 22.8948 - val_mae: 64.6581 - val_mape: 22.8948 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.3286 - mae: 34.6383 - mape: 13.3286 - val_loss: 21.9821 - val_mae: 62.2089 - val_mape: 21.9821 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.3471 - mae: 34.3896 - mape: 13.3471 - val_loss: 23.3636 - val_mae: 55.6148 - val_mape: 23.3636 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.6175 - mae: 33.5171 - mape: 13.6175 - val_loss: 22.3672 - val_mae: 59.6929 - val_mape: 22.3672 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.0188 - mae: 34.8741 - mape: 13.0188 - val_loss: 23.5377 - val_mae: 66.9651 - val_mape: 23.5377 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.9071 - mae: 33.4482 - mape: 12.9071 - val_loss: 23.7359 - val_mae: 64.4877 - val_mape: 23.7359 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.8826 - mae: 32.5801 - mape: 12.8826 - val_loss: 22.6186 - val_mae: 65.2451 - val_mape: 22.6186 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6744 - mae: 35.6464 - mape: 12.6744 - val_loss: 20.7568 - val_mae: 67.3985 - val_mape: 20.7568 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.8366 - mae: 34.0710 - mape: 12.8366 - val_loss: 20.1954 - val_mae: 63.3669 - val_mape: 20.1954 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.9090 - mae: 34.1924 - mape: 12.9090 - val_loss: 25.1555 - val_mae: 59.8145 - val_mape: 25.1555 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.2944 - mae: 32.3244 - mape: 13.2944\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.2944 - mae: 32.3244 - mape: 13.2944 - val_loss: 24.0609 - val_mae: 68.2273 - val_mape: 24.0609 - lr: 3.0000e-04\n",
      "Epoch 63: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 11.951065063476562; mae of 23.18400764465332; mape of 11.951065063476562%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 18.5100 - mae: 43.9553 - mape: 18.5100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 93ms/step - loss: 18.5100 - mae: 43.9553 - mape: 18.5100 - val_loss: 20.8545 - val_mae: 39.7019 - val_mape: 20.8545 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      " 1/87 [..............................] - ETA: 5s - loss: 19.2486 - mae: 52.6901 - mape: 19.2486"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.7201 - mae: 41.0482 - mape: 16.7201"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 97ms/step - loss: 16.7201 - mae: 41.0482 - mape: 16.7201 - val_loss: 14.2507 - val_mae: 37.9930 - val_mape: 14.2507 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      " 1/87 [..............................] - ETA: 5s - loss: 18.0360 - mae: 15.6343 - mape: 18.0360"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 82ms/step - loss: 15.7768 - mae: 44.1091 - mape: 15.7768 - val_loss: 14.5674 - val_mae: 43.0220 - val_mape: 14.5674 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.3954 - mae: 39.8747 - mape: 16.3954"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 96ms/step - loss: 16.3954 - mae: 39.8747 - mape: 16.3954 - val_loss: 13.8567 - val_mae: 47.3757 - val_mape: 13.8567 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      " 1/87 [..............................] - ETA: 7s - loss: 15.2318 - mae: 75.1090 - mape: 15.2318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4551 - mae: 41.1808 - mape: 16.4551 - val_loss: 15.1009 - val_mae: 40.7788 - val_mape: 15.1009 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.3435 - mae: 42.6897 - mape: 16.3435 - val_loss: 15.5495 - val_mae: 37.4369 - val_mape: 15.5495 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.5815 - mae: 45.8979 - mape: 17.5815 - val_loss: 16.4681 - val_mae: 56.2301 - val_mape: 16.4681 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.3183 - mae: 41.8640 - mape: 17.3183 - val_loss: 18.7123 - val_mae: 33.2441 - val_mape: 18.7123 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.0543 - mae: 47.6359 - mape: 17.0543 - val_loss: 15.2634 - val_mae: 72.2201 - val_mape: 15.2634 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.9346 - mae: 44.6312 - mape: 16.9346 - val_loss: 15.2223 - val_mae: 58.0933 - val_mape: 15.2223 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.0659 - mae: 41.7493 - mape: 16.0659 - val_loss: 18.4493 - val_mae: 56.0112 - val_mape: 18.4493 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.2937 - mae: 42.0698 - mape: 17.2937 - val_loss: 19.5448 - val_mae: 36.4265 - val_mape: 19.5448 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.3890 - mae: 45.5119 - mape: 17.3890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 17.3890 - mae: 45.5119 - mape: 17.3890 - val_loss: 13.7369 - val_mae: 39.0422 - val_mape: 13.7369 - lr: 0.0010\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 86ms/step - loss: 16.5336 - mae: 41.1440 - mape: 16.5336 - val_loss: 19.7110 - val_mae: 63.3042 - val_mape: 19.7110 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.2342 - mae: 46.4744 - mape: 17.2342 - val_loss: 15.9315 - val_mae: 36.7174 - val_mape: 15.9315 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.8338 - mae: 61.9966 - mape: 18.8338 - val_loss: 13.7835 - val_mae: 55.1343 - val_mape: 13.7835 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.4960 - mae: 39.9584 - mape: 16.4960 - val_loss: 14.3670 - val_mae: 39.4120 - val_mape: 14.3670 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.0293 - mae: 40.1074 - mape: 18.0293 - val_loss: 13.8074 - val_mae: 41.8132 - val_mape: 13.8074 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 15.2738 - mae: 38.9666 - mape: 15.2738 - val_loss: 18.4923 - val_mae: 59.3411 - val_mape: 18.4923 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.1420 - mae: 41.7575 - mape: 16.1420 - val_loss: 17.3031 - val_mae: 30.5263 - val_mape: 17.3031 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.5481 - mae: 38.8897 - mape: 15.5481 - val_loss: 19.7454 - val_mae: 50.6697 - val_mape: 19.7454 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.5625 - mae: 46.0593 - mape: 16.5625 - val_loss: 19.3135 - val_mae: 41.2407 - val_mape: 19.3135 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.9400 - mae: 41.0557 - mape: 15.9400 - val_loss: 15.2625 - val_mae: 42.4122 - val_mape: 15.2625 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.1748 - mae: 42.9717 - mape: 16.1748 - val_loss: 20.7322 - val_mae: 63.0469 - val_mape: 20.7322 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.5977 - mae: 36.9768 - mape: 15.5977 - val_loss: 16.3700 - val_mae: 36.1866 - val_mape: 16.3700 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.0731 - mae: 41.9347 - mape: 16.0731 - val_loss: 14.0282 - val_mae: 53.7393 - val_mape: 14.0282 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.5042 - mae: 41.3560 - mape: 15.5042 - val_loss: 20.2246 - val_mae: 63.7521 - val_mape: 20.2246 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 15.6990 - mae: 38.1183 - mape: 15.6990 - val_loss: 24.1069 - val_mae: 44.8243 - val_mape: 24.1069 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.3395 - mae: 43.1538 - mape: 16.3395 - val_loss: 19.2142 - val_mae: 64.7915 - val_mape: 19.2142 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.8837 - mae: 43.8489 - mape: 15.8837 - val_loss: 18.3287 - val_mae: 43.4951 - val_mape: 18.3287 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.0384 - mae: 43.4798 - mape: 16.0384 - val_loss: 18.1571 - val_mae: 53.8058 - val_mape: 18.1571 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 15.6032 - mae: 43.7118 - mape: 15.6032 - val_loss: 22.5567 - val_mae: 51.9563 - val_mape: 22.5567 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.9241 - mae: 38.0980 - mape: 15.9241 - val_loss: 21.2679 - val_mae: 66.5820 - val_mape: 21.2679 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.7118 - mae: 39.0253 - mape: 15.7118 - val_loss: 16.9865 - val_mae: 54.8546 - val_mape: 16.9865 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 15.9706 - mae: 38.1814 - mape: 15.9706 - val_loss: 28.9184 - val_mae: 65.8750 - val_mape: 28.9184 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.0498 - mae: 44.0799 - mape: 16.0498 - val_loss: 25.3853 - val_mae: 54.2659 - val_mape: 25.3853 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.0001 - mae: 46.7752 - mape: 17.0001 - val_loss: 20.6509 - val_mae: 51.8489 - val_mape: 20.6509 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.4889 - mae: 40.8247 - mape: 15.4889 - val_loss: 14.2959 - val_mae: 37.1796 - val_mape: 14.2959 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.0265 - mae: 37.5415 - mape: 15.0265 - val_loss: 27.1900 - val_mae: 70.6578 - val_mape: 27.1900 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.6735 - mae: 38.9623 - mape: 15.6735 - val_loss: 15.8883 - val_mae: 45.4312 - val_mape: 15.8883 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 15.8254 - mae: 44.0787 - mape: 15.8254"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_short_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 101ms/step - loss: 15.8508 - mae: 43.9935 - mape: 15.8508 - val_loss: 13.5703 - val_mae: 36.0149 - val_mape: 13.5703 - lr: 0.0010\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 87ms/step - loss: 17.3002 - mae: 44.3022 - mape: 17.3002 - val_loss: 17.5515 - val_mae: 37.7270 - val_mape: 17.5515 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.8808 - mae: 42.4282 - mape: 15.8808 - val_loss: 18.8819 - val_mae: 34.3036 - val_mape: 18.8819 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.0277 - mae: 40.4641 - mape: 15.0277 - val_loss: 19.1599 - val_mae: 66.9996 - val_mape: 19.1599 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.4273 - mae: 42.5391 - mape: 15.4273 - val_loss: 13.9641 - val_mae: 26.1784 - val_mape: 13.9641 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 16.3325 - mae: 42.8974 - mape: 16.3325 - val_loss: 17.6090 - val_mae: 52.9028 - val_mape: 17.6090 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.5969 - mae: 45.1227 - mape: 16.5969 - val_loss: 22.3262 - val_mae: 78.5056 - val_mape: 22.3262 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.1140 - mae: 38.4115 - mape: 15.1140 - val_loss: 18.0378 - val_mae: 43.1927 - val_mape: 18.0378 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.4145 - mae: 37.5894 - mape: 15.4145 - val_loss: 20.4624 - val_mae: 66.4151 - val_mape: 20.4624 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.5998 - mae: 41.9258 - mape: 16.5998 - val_loss: 14.5773 - val_mae: 44.9142 - val_mape: 14.5773 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.3768 - mae: 41.6204 - mape: 15.3768 - val_loss: 23.1457 - val_mae: 48.2414 - val_mape: 23.1457 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.1413 - mae: 44.0397 - mape: 17.1413 - val_loss: 17.7867 - val_mae: 47.7638 - val_mape: 17.7867 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.0663 - mae: 39.3640 - mape: 15.0663 - val_loss: 14.5257 - val_mae: 33.9949 - val_mape: 14.5257 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.3767 - mae: 41.6798 - mape: 15.3767 - val_loss: 14.5828 - val_mae: 52.1242 - val_mape: 14.5828 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.3557 - mae: 38.5175 - mape: 15.3557 - val_loss: 16.6366 - val_mae: 60.2875 - val_mape: 16.6366 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.5681 - mae: 38.1839 - mape: 15.5681 - val_loss: 25.6179 - val_mae: 56.1408 - val_mape: 25.6179 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.4626 - mae: 38.7337 - mape: 15.4626 - val_loss: 22.9766 - val_mae: 41.7374 - val_mape: 22.9766 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.8328 - mae: 41.2879 - mape: 15.8328 - val_loss: 16.9685 - val_mae: 63.6577 - val_mape: 16.9685 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.3247 - mae: 42.4550 - mape: 15.3247 - val_loss: 16.5061 - val_mae: 61.5994 - val_mape: 16.5061 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.8067 - mae: 38.3525 - mape: 14.8067 - val_loss: 23.2271 - val_mae: 79.3976 - val_mape: 23.2271 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.3830 - mae: 41.1163 - mape: 15.3830 - val_loss: 18.4781 - val_mae: 74.1538 - val_mape: 18.4781 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.0748 - mae: 39.0589 - mape: 15.0748 - val_loss: 17.7456 - val_mae: 54.3193 - val_mape: 17.7456 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.6684 - mae: 41.0428 - mape: 14.6684 - val_loss: 17.0637 - val_mae: 56.0750 - val_mape: 17.0637 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.9512 - mae: 41.8845 - mape: 15.9512 - val_loss: 16.7957 - val_mae: 67.1640 - val_mape: 16.7957 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.3394 - mae: 46.0250 - mape: 15.3394 - val_loss: 19.0146 - val_mae: 70.7799 - val_mape: 19.0146 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.1303 - mae: 39.8736 - mape: 15.1303 - val_loss: 18.7823 - val_mae: 54.3094 - val_mape: 18.7823 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.6314 - mae: 38.2549 - mape: 15.6314 - val_loss: 19.3951 - val_mae: 74.4784 - val_mape: 19.3951 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.5104 - mae: 40.5698 - mape: 15.5104 - val_loss: 17.3369 - val_mae: 37.6650 - val_mape: 17.3369 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.6315 - mae: 37.5753 - mape: 14.6315 - val_loss: 16.6925 - val_mae: 48.5539 - val_mape: 16.6925 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.2284 - mae: 41.6039 - mape: 15.2284 - val_loss: 18.6358 - val_mae: 53.8282 - val_mape: 18.6358 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 15.5535 - mae: 41.3896 - mape: 15.5535\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.5535 - mae: 41.3896 - mape: 15.5535 - val_loss: 22.2994 - val_mae: 59.3133 - val_mape: 22.2994 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.8333 - mae: 34.8689 - mape: 13.8333 - val_loss: 18.1133 - val_mae: 46.0419 - val_mape: 18.1133 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.3561 - mae: 36.9144 - mape: 13.3561 - val_loss: 18.9442 - val_mae: 62.0157 - val_mape: 18.9442 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.7226 - mae: 34.2904 - mape: 12.7226 - val_loss: 15.0077 - val_mae: 40.4803 - val_mape: 15.0077 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.2824 - mae: 34.8279 - mape: 13.2824 - val_loss: 21.7077 - val_mae: 62.4948 - val_mape: 21.7077 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 12.7424 - mae: 33.2275 - mape: 12.7424 - val_loss: 20.5719 - val_mae: 58.2207 - val_mape: 20.5719 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.0875 - mae: 32.3945 - mape: 13.0875 - val_loss: 17.9850 - val_mae: 51.1055 - val_mape: 17.9850 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.8570 - mae: 33.7267 - mape: 12.8570 - val_loss: 22.3639 - val_mae: 69.8314 - val_mape: 22.3639 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 12.8985 - mae: 34.0959 - mape: 12.8985 - val_loss: 19.0691 - val_mae: 65.3404 - val_mape: 19.0691 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 12.9225 - mae: 31.9638 - mape: 12.9225 - val_loss: 19.4229 - val_mae: 54.9731 - val_mape: 19.4229 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.7910 - mae: 31.8512 - mape: 12.7910 - val_loss: 26.1328 - val_mae: 69.1971 - val_mape: 26.1328 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.9113 - mae: 33.0241 - mape: 12.9113 - val_loss: 22.6408 - val_mae: 67.0084 - val_mape: 22.6408 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.4581 - mae: 31.1244 - mape: 12.4581 - val_loss: 22.0289 - val_mae: 67.9408 - val_mape: 22.0289 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 12.7705 - mae: 32.6112 - mape: 12.7705 - val_loss: 25.6119 - val_mae: 74.9726 - val_mape: 25.6119 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.8273 - mae: 34.4571 - mape: 12.8273 - val_loss: 20.4995 - val_mae: 68.0600 - val_mape: 20.4995 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.9824 - mae: 33.2602 - mape: 12.9824 - val_loss: 26.4584 - val_mae: 74.4370 - val_mape: 26.4584 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.6187 - mae: 29.9526 - mape: 12.6187 - val_loss: 20.3006 - val_mae: 69.9543 - val_mape: 20.3006 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.8524 - mae: 31.7432 - mape: 12.8524 - val_loss: 24.8527 - val_mae: 84.3332 - val_mape: 24.8527 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.4352 - mae: 33.0762 - mape: 12.4352 - val_loss: 21.9170 - val_mae: 62.8223 - val_mape: 21.9170 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.6257 - mae: 30.7706 - mape: 12.6257 - val_loss: 22.8841 - val_mae: 68.5053 - val_mape: 22.8841 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.7921 - mae: 34.6247 - mape: 12.7921 - val_loss: 27.0028 - val_mae: 72.9706 - val_mape: 27.0028 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.6445 - mae: 30.9410 - mape: 12.6445 - val_loss: 21.7879 - val_mae: 68.1869 - val_mape: 21.7879 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.6211 - mae: 32.9975 - mape: 12.6211 - val_loss: 23.4928 - val_mae: 61.8352 - val_mape: 23.4928 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.8937 - mae: 31.1803 - mape: 12.8937 - val_loss: 25.2520 - val_mae: 79.9829 - val_mape: 25.2520 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.1279 - mae: 33.0750 - mape: 13.1279 - val_loss: 23.2549 - val_mae: 80.2655 - val_mape: 23.2549 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 12.3587 - mae: 31.9995 - mape: 12.3587 - val_loss: 22.2072 - val_mae: 75.5914 - val_mape: 22.2072 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.2760 - mae: 30.8965 - mape: 12.2760 - val_loss: 19.9335 - val_mae: 50.0158 - val_mape: 19.9335 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.2536 - mae: 31.8588 - mape: 12.2536 - val_loss: 22.5917 - val_mae: 82.6245 - val_mape: 22.5917 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.6750 - mae: 33.7838 - mape: 12.6750 - val_loss: 27.1656 - val_mae: 68.4576 - val_mape: 27.1656 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.5453 - mae: 34.0630 - mape: 12.5453 - val_loss: 20.2589 - val_mae: 64.5565 - val_mape: 20.2589 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.4960 - mae: 33.5570 - mape: 12.4960\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.4960 - mae: 33.5570 - mape: 12.4960 - val_loss: 22.6391 - val_mae: 65.3937 - val_mape: 22.6391 - lr: 3.0000e-04\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 13.570323944091797; mae of 36.01487350463867; mape of 13.570323944091797%;\n"
     ]
    }
   ],
   "source": [
    "nnmodel = keras.models.load_model('savedmodels/Baseline_nosupp_final')\n",
    "\n",
    "xi = keras.layers.Input( name= 'Input_x', type_spec=tf.TensorSpec(shape=[None,3]))\n",
    "ai = keras.layers.Input( name= 'Input_a', type_spec=tf.SparseTensorSpec(shape=[None,None]))\n",
    "ii = keras.layers.Input( name= 'Input_i', type_spec=tf.TensorSpec(shape=[None,], dtype='int32'))\n",
    "\n",
    "x1 = GCSConv(64, 'relu')([xi,ai]) \n",
    "x2 = GCSConv(128, 'relu')([x1,ai])\n",
    "x = Concatenate()([x1,x2])\n",
    "x= GlobalMaxPool()([x,ii])\n",
    "\n",
    "\n",
    "combined = concatenate([nnmodel.get_layer('dropbaseline').output, x], name='join')\n",
    "z = Dense(128,'relu', name='dense1')(combined)\n",
    "z = Dense(64,'relu', name='dense4')(z)\n",
    "z = Dropout(0.2, name='finaldrop')(z)\n",
    "z = Dense(1, 'linear', name='Output')(z)\n",
    "\n",
    "model = Model(inputs=[xi,ai,ii,nnmodel.input], outputs=z)\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, \"crossvalidationmodels/Hybrid_short\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 14.207966804504395 - Mean average error: 31.442018508911133% - Mean percentage error: 14.207966804504395%\n",
      "    Score on unseen data: Loss: 16.107515335083008 - Mean average error: 57.532039642333984% - Mean percentage error: 16.107515335083008%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 12.440661430358887 - Mean average error: 43.87931442260742% - Mean percentage error: 12.440661430358887%\n",
      "    Score on unseen data: Loss: 15.614555358886719 - Mean average error: 65.85304260253906% - Mean percentage error: 15.614555358886719%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 12.35222339630127 - Mean average error: 31.713748931884766% - Mean percentage error: 12.35222339630127%\n",
      "    Score on unseen data: Loss: 14.505189895629883 - Mean average error: 45.51414108276367% - Mean percentage error: 14.505189895629883%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 11.951065063476562 - Mean average error: 23.18400764465332% - Mean percentage error: 11.951065063476562%\n",
      "    Score on unseen data: Loss: 15.428691864013672 - Mean average error: 41.45392608642578% - Mean percentage error: 15.428691864013672%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 13.570323944091797 - Mean average error: 36.01487350463867% - Mean percentage error: 13.570323944091797%\n",
      "    Score on unseen data: Loss: 17.385353088378906 - Mean average error: 71.27188873291016% - Mean percentage error: 17.385353088378906%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 12.904448127746582\n",
      "> Mean average error: 33.24679260253906\n",
      "> Mean percentage error: 12.904448127746582\n",
      "> Unseen Loss: 15.808261108398437\n",
      "> Unseen Mean average error: 56.325007629394534\n",
      "> Unseen Mean percentage error: 15.808261108398437\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baselinemodel\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 15.4036 - mae: 36.5333 - mape: 15.4036INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 4s 22ms/step - loss: 15.4057 - mae: 36.3860 - mape: 15.4057 - val_loss: 12.1133 - val_mae: 47.6623 - val_mape: 12.1133 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 16.5145 - mae: 43.9791 - mape: 16.5145 - val_loss: 12.2071 - val_mae: 28.3546 - val_mape: 12.2071 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.7913 - mae: 36.9353 - mape: 15.7913 - val_loss: 14.6180 - val_mae: 56.0801 - val_mape: 14.6180 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.3789 - mae: 36.5430 - mape: 15.3789 - val_loss: 15.2541 - val_mae: 41.9828 - val_mape: 15.2541 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 16.3335 - mae: 45.2888 - mape: 16.3335 - val_loss: 15.0575 - val_mae: 46.9723 - val_mape: 15.0575 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.0429 - mae: 35.4398 - mape: 15.0429 - val_loss: 12.2803 - val_mae: 50.4556 - val_mape: 12.2803 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 15.0437 - mae: 38.7177 - mape: 15.0437 - val_loss: 13.0255 - val_mae: 40.3196 - val_mape: 13.0255 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 15.0513 - mae: 37.7921 - mape: 15.0513 - val_loss: 12.6069 - val_mae: 31.0003 - val_mape: 12.6069 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 16.2801 - mae: 43.7989 - mape: 16.2801 - val_loss: 19.0324 - val_mae: 45.7773 - val_mape: 19.0324 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 16.5763 - mae: 43.0059 - mape: 16.5763 - val_loss: 12.4130 - val_mae: 43.3486 - val_mape: 12.4130 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.3947 - mae: 38.2943 - mape: 15.3947 - val_loss: 12.6682 - val_mae: 34.4415 - val_mape: 12.6682 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.7850 - mae: 39.4352 - mape: 14.7850 - val_loss: 13.5280 - val_mae: 54.1507 - val_mape: 13.5280 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.9970 - mae: 41.0133 - mape: 14.9970 - val_loss: 19.8786 - val_mae: 43.4815 - val_mape: 19.8786 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 15.5727 - mae: 38.2102 - mape: 15.5727 - val_loss: 15.3360 - val_mae: 35.8104 - val_mape: 15.3360 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.5028 - mae: 35.3474 - mape: 14.5028 - val_loss: 12.9457 - val_mae: 44.9014 - val_mape: 12.9457 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 16.1902 - mae: 44.3773 - mape: 16.1902 - val_loss: 18.2516 - val_mae: 34.0555 - val_mape: 18.2516 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 15.2484 - mae: 35.2179 - mape: 15.2484 - val_loss: 17.3995 - val_mae: 53.8041 - val_mape: 17.3995 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 15.1268 - mae: 38.2842 - mape: 15.1268 - val_loss: 17.2162 - val_mae: 35.8272 - val_mape: 17.2162 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 16.2139 - mae: 44.3750 - mape: 16.2139 - val_loss: 17.5466 - val_mae: 61.8636 - val_mape: 17.5466 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 16.1371 - mae: 37.6801 - mape: 16.1371 - val_loss: 13.8579 - val_mae: 43.8350 - val_mape: 13.8579 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 14.1522 - mae: 38.7217 - mape: 14.1522INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 14.0988 - mae: 38.5205 - mape: 14.0988 - val_loss: 12.1104 - val_mae: 32.4505 - val_mape: 12.1104 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 14.2064 - mae: 33.5162 - mape: 14.2064 - val_loss: 14.5223 - val_mae: 37.5666 - val_mape: 14.5223 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.2566 - mae: 39.3327 - mape: 15.2566 - val_loss: 13.3286 - val_mae: 31.1009 - val_mape: 13.3286 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.5557 - mae: 35.5510 - mape: 14.5557 - val_loss: 16.0415 - val_mae: 37.6035 - val_mape: 16.0415 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.9891 - mae: 35.2038 - mape: 14.9891 - val_loss: 19.2076 - val_mae: 58.6804 - val_mape: 19.2076 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.5401 - mae: 41.7345 - mape: 15.5401 - val_loss: 15.2727 - val_mae: 44.2859 - val_mape: 15.2727 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.8569 - mae: 39.7533 - mape: 14.8569 - val_loss: 12.9350 - val_mae: 34.8073 - val_mape: 12.9350 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 15.3723 - mae: 36.0030 - mape: 15.3723 - val_loss: 17.9187 - val_mae: 50.3828 - val_mape: 17.9187 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 17.3858 - mae: 43.4582 - mape: 17.3858 - val_loss: 13.2910 - val_mae: 35.0985 - val_mape: 13.2910 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 15.2808 - mae: 36.6110 - mape: 15.2808 - val_loss: 13.6915 - val_mae: 32.6356 - val_mape: 13.6915 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 15.0729 - mae: 36.7287 - mape: 15.0729 - val_loss: 15.5699 - val_mae: 52.4952 - val_mape: 15.5699 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.4394 - mae: 38.1816 - mape: 14.4394 - val_loss: 17.1085 - val_mae: 36.9279 - val_mape: 17.1085 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.5603 - mae: 34.7250 - mape: 14.5603 - val_loss: 12.8469 - val_mae: 30.1520 - val_mape: 12.8469 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.8729 - mae: 36.8025 - mape: 14.8729 - val_loss: 14.8090 - val_mae: 58.5624 - val_mape: 14.8090 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.9746 - mae: 37.1549 - mape: 14.9746 - val_loss: 13.7215 - val_mae: 35.4833 - val_mape: 13.7215 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.5949 - mae: 35.8510 - mape: 14.5949 - val_loss: 12.7130 - val_mae: 34.6032 - val_mape: 12.7130 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.2014 - mae: 33.8629 - mape: 14.2014 - val_loss: 12.9297 - val_mae: 38.9026 - val_mape: 12.9297 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.4642 - mae: 35.5245 - mape: 14.4642 - val_loss: 13.6654 - val_mae: 41.5106 - val_mape: 13.6654 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 15.2620 - mae: 40.4752 - mape: 15.2620 - val_loss: 13.8299 - val_mae: 43.7042 - val_mape: 13.8299 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 15.1126 - mae: 38.1344 - mape: 15.1126 - val_loss: 13.3858 - val_mae: 47.5230 - val_mape: 13.3858 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.2514 - mae: 37.1135 - mape: 15.2514 - val_loss: 15.0070 - val_mae: 41.3676 - val_mape: 15.0070 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.1311 - mae: 31.6064 - mape: 14.1311 - val_loss: 12.6894 - val_mae: 34.0872 - val_mape: 12.6894 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.0479 - mae: 32.0745 - mape: 14.0479 - val_loss: 13.7075 - val_mae: 37.1252 - val_mape: 13.7075 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.5654 - mae: 38.8023 - mape: 14.5654 - val_loss: 18.0774 - val_mae: 57.0445 - val_mape: 18.0774 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.4994 - mae: 40.6607 - mape: 14.4994 - val_loss: 20.4054 - val_mae: 56.1795 - val_mape: 20.4054 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.7218 - mae: 35.0610 - mape: 15.7218 - val_loss: 16.7863 - val_mae: 38.7223 - val_mape: 16.7863 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.6323 - mae: 37.8240 - mape: 15.6323 - val_loss: 14.1289 - val_mae: 36.1037 - val_mape: 14.1289 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.8007 - mae: 34.3726 - mape: 13.8007 - val_loss: 13.1989 - val_mae: 38.9074 - val_mape: 13.1989 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.5112 - mae: 37.8986 - mape: 14.5112 - val_loss: 21.5386 - val_mae: 50.8931 - val_mape: 21.5386 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.6754 - mae: 38.7770 - mape: 15.6754 - val_loss: 13.3019 - val_mae: 42.0429 - val_mape: 13.3019 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 15.9887 - mae: 37.8326 - mape: 15.9887\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.9599 - mae: 39.2034 - mape: 15.9599 - val_loss: 16.2898 - val_mae: 37.9903 - val_mape: 16.2898 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.1228 - mae: 31.3473 - mape: 13.1228 - val_loss: 12.9525 - val_mae: 32.5969 - val_mape: 12.9525 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 12.3575 - mae: 32.3870 - mape: 12.3575INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 12.3564 - mae: 32.4610 - mape: 12.3564 - val_loss: 12.0256 - val_mae: 30.7937 - val_mape: 12.0256 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6748 - mae: 29.8790 - mape: 12.6748 - val_loss: 12.1267 - val_mae: 36.4111 - val_mape: 12.1267 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6395 - mae: 29.3035 - mape: 12.6395 - val_loss: 12.4391 - val_mae: 29.8429 - val_mape: 12.4391 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.7743 - mae: 30.5428 - mape: 12.7743 - val_loss: 12.1009 - val_mae: 35.0657 - val_mape: 12.1009 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.5122 - mae: 31.1487 - mape: 12.5122 - val_loss: 12.4297 - val_mae: 42.8867 - val_mape: 12.4297 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3057 - mae: 29.2849 - mape: 12.3057 - val_loss: 12.1941 - val_mae: 29.7971 - val_mape: 12.1941 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3399 - mae: 31.7143 - mape: 12.3399 - val_loss: 12.1197 - val_mae: 30.5007 - val_mape: 12.1197 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6202 - mae: 32.8820 - mape: 12.6202 - val_loss: 12.5555 - val_mae: 34.6612 - val_mape: 12.5555 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3639 - mae: 31.3883 - mape: 12.3639 - val_loss: 12.4387 - val_mae: 39.6700 - val_mape: 12.4387 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.8050 - mae: 29.3772 - mape: 12.8050 - val_loss: 12.2927 - val_mae: 35.3046 - val_mape: 12.2927 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 12.3424 - mae: 29.0711 - mape: 12.3424INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 20ms/step - loss: 12.3547 - mae: 30.1198 - mape: 12.3547 - val_loss: 11.9112 - val_mae: 32.1602 - val_mape: 11.9112 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.4156 - mae: 27.8765 - mape: 12.4156 - val_loss: 13.5326 - val_mae: 37.0461 - val_mape: 13.5326 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.5179 - mae: 31.2897 - mape: 12.5179 - val_loss: 12.2621 - val_mae: 35.2527 - val_mape: 12.2621 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0555 - mae: 29.1608 - mape: 12.0555 - val_loss: 12.3966 - val_mae: 29.5186 - val_mape: 12.3966 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.2167 - mae: 30.0016 - mape: 12.2167 - val_loss: 14.3419 - val_mae: 46.7493 - val_mape: 14.3419 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3979 - mae: 30.3766 - mape: 12.3979 - val_loss: 13.2125 - val_mae: 33.1920 - val_mape: 13.2125 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0946 - mae: 28.9424 - mape: 12.0946 - val_loss: 12.0108 - val_mae: 30.8653 - val_mape: 12.0108 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.1269 - mae: 28.9750 - mape: 12.1269 - val_loss: 12.6171 - val_mae: 30.2610 - val_mape: 12.6171 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.1463 - mae: 30.3001 - mape: 12.1463 - val_loss: 12.7902 - val_mae: 29.8563 - val_mape: 12.7902 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 12.2569 - mae: 31.4354 - mape: 12.2569INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 20ms/step - loss: 12.1798 - mae: 31.6317 - mape: 12.1798 - val_loss: 11.8857 - val_mae: 28.6552 - val_mape: 11.8857 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.2474 - mae: 29.0658 - mape: 12.2474INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 12.2474 - mae: 29.0658 - mape: 12.2474 - val_loss: 11.8669 - val_mae: 28.8848 - val_mape: 11.8669 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.4110 - mae: 28.8556 - mape: 12.4110 - val_loss: 12.3812 - val_mae: 30.9677 - val_mape: 12.3812 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3719 - mae: 31.5596 - mape: 12.3719 - val_loss: 12.5914 - val_mae: 31.8360 - val_mape: 12.5914 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3149 - mae: 29.2955 - mape: 12.3149 - val_loss: 12.0035 - val_mae: 28.4074 - val_mape: 12.0035 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3617 - mae: 30.4230 - mape: 12.3617 - val_loss: 12.0144 - val_mae: 28.5098 - val_mape: 12.0144 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6995 - mae: 32.4283 - mape: 12.6995 - val_loss: 12.3872 - val_mae: 41.5625 - val_mape: 12.3872 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.7965 - mae: 30.2910 - mape: 12.7965 - val_loss: 13.0952 - val_mae: 33.1115 - val_mape: 13.0952 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.4543 - mae: 30.8228 - mape: 12.4543 - val_loss: 11.9577 - val_mae: 33.8697 - val_mape: 11.9577 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0797 - mae: 29.0052 - mape: 12.0797 - val_loss: 12.4491 - val_mae: 36.0457 - val_mape: 12.4491 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.7885 - mae: 30.1467 - mape: 12.7885 - val_loss: 16.9521 - val_mae: 40.9951 - val_mape: 16.9521 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6962 - mae: 29.6425 - mape: 12.6962 - val_loss: 12.5630 - val_mae: 34.1123 - val_mape: 12.5630 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.1600 - mae: 29.4249 - mape: 12.1600 - val_loss: 12.0675 - val_mae: 34.2328 - val_mape: 12.0675 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.1560 - mae: 30.0255 - mape: 13.1560 - val_loss: 12.6100 - val_mae: 29.7715 - val_mape: 12.6100 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.8307 - mae: 28.7602 - mape: 11.8307 - val_loss: 11.9130 - val_mae: 28.0258 - val_mape: 11.9130 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3508 - mae: 32.5407 - mape: 12.3508 - val_loss: 12.6241 - val_mae: 34.4012 - val_mape: 12.6241 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3448 - mae: 30.6932 - mape: 12.3448 - val_loss: 12.6432 - val_mae: 36.9893 - val_mape: 12.6432 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 12.2845 - mae: 31.9809 - mape: 12.2845INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 12.2556 - mae: 31.5024 - mape: 12.2556 - val_loss: 11.8543 - val_mae: 34.9262 - val_mape: 11.8543 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.2450 - mae: 28.6024 - mape: 12.2450 - val_loss: 12.2902 - val_mae: 31.6251 - val_mape: 12.2902 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0274 - mae: 29.5151 - mape: 12.0274 - val_loss: 12.5335 - val_mae: 30.3855 - val_mape: 12.5335 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9142 - mae: 30.0920 - mape: 11.9142 - val_loss: 12.0578 - val_mae: 30.2501 - val_mape: 12.0578 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.2234 - mae: 28.0989 - mape: 12.2234 - val_loss: 12.4180 - val_mae: 31.4946 - val_mape: 12.4180 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.5276 - mae: 31.2293 - mape: 12.5276 - val_loss: 11.9598 - val_mae: 29.9587 - val_mape: 11.9598 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9533 - mae: 28.3026 - mape: 11.9533 - val_loss: 12.0970 - val_mae: 40.1969 - val_mape: 12.0970 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.7812 - mae: 29.8774 - mape: 11.7812 - val_loss: 13.4468 - val_mae: 31.3230 - val_mape: 13.4468 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.4140 - mae: 30.2028 - mape: 12.4140 - val_loss: 13.2528 - val_mae: 32.0799 - val_mape: 13.2528 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0798 - mae: 29.6195 - mape: 12.0798 - val_loss: 12.2187 - val_mae: 34.8441 - val_mape: 12.2187 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6138 - mae: 30.5249 - mape: 12.6138 - val_loss: 12.9922 - val_mae: 33.6509 - val_mape: 12.9922 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.3052 - mae: 28.9991 - mape: 12.3052 - val_loss: 12.4223 - val_mae: 29.6855 - val_mape: 12.4223 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0723 - mae: 30.0787 - mape: 12.0723 - val_loss: 12.2133 - val_mae: 31.6354 - val_mape: 12.2133 - lr: 3.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0633 - mae: 28.7203 - mape: 12.0633 - val_loss: 14.3885 - val_mae: 31.2598 - val_mape: 14.3885 - lr: 3.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0077 - mae: 29.4528 - mape: 12.0077 - val_loss: 12.0167 - val_mae: 27.8819 - val_mape: 12.0167 - lr: 3.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9524 - mae: 30.6851 - mape: 11.9524 - val_loss: 12.9561 - val_mae: 32.9912 - val_mape: 12.9561 - lr: 3.0000e-04\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9806 - mae: 30.1860 - mape: 11.9806 - val_loss: 12.2907 - val_mae: 30.8532 - val_mape: 12.2907 - lr: 3.0000e-04\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.2111 - mae: 30.0843 - mape: 12.2111 - val_loss: 12.4615 - val_mae: 33.7155 - val_mape: 12.4615 - lr: 3.0000e-04\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9873 - mae: 28.9005 - mape: 11.9873 - val_loss: 13.2583 - val_mae: 31.0052 - val_mape: 13.2583 - lr: 3.0000e-04\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0488 - mae: 31.1167 - mape: 12.0488 - val_loss: 12.6359 - val_mae: 32.0648 - val_mape: 12.6359 - lr: 3.0000e-04\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0153 - mae: 27.4966 - mape: 12.0153 - val_loss: 12.7455 - val_mae: 29.9553 - val_mape: 12.7455 - lr: 3.0000e-04\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.8996 - mae: 30.1306 - mape: 11.8996 - val_loss: 12.1530 - val_mae: 29.3841 - val_mape: 12.1530 - lr: 3.0000e-04\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.5381 - mae: 29.9608 - mape: 12.5381 - val_loss: 11.8724 - val_mae: 33.0227 - val_mape: 11.8724 - lr: 3.0000e-04\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.7118 - mae: 29.3913 - mape: 12.7118 - val_loss: 12.9533 - val_mae: 45.5002 - val_mape: 12.9533 - lr: 3.0000e-04\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.1217 - mae: 28.4950 - mape: 12.1217 - val_loss: 12.6286 - val_mae: 29.5132 - val_mape: 12.6286 - lr: 3.0000e-04\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.1509 - mae: 32.5693 - mape: 12.1509 - val_loss: 12.7213 - val_mae: 29.7623 - val_mape: 12.7213 - lr: 3.0000e-04\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.8516 - mae: 28.5402 - mape: 11.8516 - val_loss: 12.9279 - val_mae: 30.7709 - val_mape: 12.9279 - lr: 3.0000e-04\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9233 - mae: 27.8194 - mape: 11.9233 - val_loss: 12.4376 - val_mae: 30.0224 - val_mape: 12.4376 - lr: 3.0000e-04\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9220 - mae: 28.3427 - mape: 11.9220 - val_loss: 13.3092 - val_mae: 30.0060 - val_mape: 13.3092 - lr: 3.0000e-04\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.7981 - mae: 29.9950 - mape: 11.7981 - val_loss: 12.8219 - val_mae: 30.0920 - val_mape: 12.8219 - lr: 3.0000e-04\n",
      "Epoch 119/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 12.1172 - mae: 30.8009 - mape: 12.1172\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.1254 - mae: 30.2928 - mape: 12.1254 - val_loss: 15.0892 - val_mae: 33.4795 - val_mape: 15.0892 - lr: 3.0000e-04\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5476 - mae: 28.9820 - mape: 11.5476 - val_loss: 11.9029 - val_mae: 27.6148 - val_mape: 11.9029 - lr: 9.0000e-05\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5454 - mae: 25.6288 - mape: 11.5454 - val_loss: 12.2301 - val_mae: 31.8088 - val_mape: 12.2301 - lr: 9.0000e-05\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2261 - mae: 28.1511 - mape: 11.2261 - val_loss: 12.1733 - val_mae: 28.2631 - val_mape: 12.1733 - lr: 9.0000e-05\n",
      "Epoch 123/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 11.1062 - mae: 27.1009 - mape: 11.1062INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 19ms/step - loss: 11.2468 - mae: 26.6298 - mape: 11.2468 - val_loss: 11.8042 - val_mae: 28.4668 - val_mape: 11.8042 - lr: 9.0000e-05\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4958 - mae: 30.0727 - mape: 11.4958 - val_loss: 12.0610 - val_mae: 29.2578 - val_mape: 12.0610 - lr: 9.0000e-05\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2464 - mae: 26.6405 - mape: 11.2464 - val_loss: 12.1252 - val_mae: 30.7217 - val_mape: 12.1252 - lr: 9.0000e-05\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3390 - mae: 28.4144 - mape: 11.3390 - val_loss: 11.9276 - val_mae: 33.6182 - val_mape: 11.9276 - lr: 9.0000e-05\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3671 - mae: 29.0391 - mape: 11.3671 - val_loss: 12.0936 - val_mae: 28.3803 - val_mape: 12.0936 - lr: 9.0000e-05\n",
      "Epoch 128/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 11.0614 - mae: 25.9532 - mape: 11.0614INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 22ms/step - loss: 11.0331 - mae: 26.1479 - mape: 11.0331 - val_loss: 11.7795 - val_mae: 28.3425 - val_mape: 11.7795 - lr: 9.0000e-05\n",
      "Epoch 129/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 11.1118 - mae: 27.4155 - mape: 11.1118INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 17ms/step - loss: 11.1483 - mae: 27.5591 - mape: 11.1483 - val_loss: 11.7486 - val_mae: 30.1128 - val_mape: 11.7486 - lr: 9.0000e-05\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5110 - mae: 30.4502 - mape: 11.5110 - val_loss: 11.8458 - val_mae: 32.1444 - val_mape: 11.8458 - lr: 9.0000e-05\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.6159 - mae: 29.1342 - mape: 11.6159 - val_loss: 11.8095 - val_mae: 27.5610 - val_mape: 11.8095 - lr: 9.0000e-05\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2148 - mae: 27.4836 - mape: 11.2148 - val_loss: 11.8669 - val_mae: 27.6909 - val_mape: 11.8669 - lr: 9.0000e-05\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5540 - mae: 29.3257 - mape: 11.5540 - val_loss: 11.9463 - val_mae: 33.5434 - val_mape: 11.9463 - lr: 9.0000e-05\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1233 - mae: 27.7881 - mape: 11.1233 - val_loss: 11.9419 - val_mae: 30.9472 - val_mape: 11.9419 - lr: 9.0000e-05\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2135 - mae: 25.2359 - mape: 11.2135 - val_loss: 11.7877 - val_mae: 27.6854 - val_mape: 11.7877 - lr: 9.0000e-05\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3673 - mae: 28.3423 - mape: 11.3673 - val_loss: 11.8211 - val_mae: 30.8810 - val_mape: 11.8211 - lr: 9.0000e-05\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1718 - mae: 27.7603 - mape: 11.1718 - val_loss: 11.7824 - val_mae: 27.8685 - val_mape: 11.7824 - lr: 9.0000e-05\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1274 - mae: 25.4640 - mape: 11.1274 - val_loss: 12.0917 - val_mae: 27.3599 - val_mape: 12.0917 - lr: 9.0000e-05\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3658 - mae: 26.0398 - mape: 11.3658 - val_loss: 11.8277 - val_mae: 28.5182 - val_mape: 11.8277 - lr: 9.0000e-05\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3131 - mae: 28.9737 - mape: 11.3131 - val_loss: 11.9346 - val_mae: 28.5922 - val_mape: 11.9346 - lr: 9.0000e-05\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5403 - mae: 27.8515 - mape: 11.5403 - val_loss: 12.6004 - val_mae: 33.5822 - val_mape: 12.6004 - lr: 9.0000e-05\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.1509 - mae: 28.4587 - mape: 11.1509 - val_loss: 11.7854 - val_mae: 30.7257 - val_mape: 11.7854 - lr: 9.0000e-05\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4579 - mae: 27.3960 - mape: 11.4579 - val_loss: 11.7948 - val_mae: 28.0098 - val_mape: 11.7948 - lr: 9.0000e-05\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.0929 - mae: 26.3888 - mape: 11.0929 - val_loss: 11.7553 - val_mae: 27.6422 - val_mape: 11.7553 - lr: 9.0000e-05\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3391 - mae: 26.0434 - mape: 11.3391 - val_loss: 11.9043 - val_mae: 28.6744 - val_mape: 11.9043 - lr: 9.0000e-05\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5689 - mae: 28.1371 - mape: 11.5689 - val_loss: 11.9506 - val_mae: 28.3422 - val_mape: 11.9506 - lr: 9.0000e-05\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1319 - mae: 25.1486 - mape: 11.1319 - val_loss: 12.1401 - val_mae: 28.6813 - val_mape: 12.1401 - lr: 9.0000e-05\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2467 - mae: 25.8036 - mape: 11.2467 - val_loss: 11.7753 - val_mae: 29.5915 - val_mape: 11.7753 - lr: 9.0000e-05\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1475 - mae: 28.4014 - mape: 11.1475 - val_loss: 11.8043 - val_mae: 31.1654 - val_mape: 11.8043 - lr: 9.0000e-05\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2586 - mae: 28.2721 - mape: 11.2586 - val_loss: 11.8540 - val_mae: 33.3946 - val_mape: 11.8540 - lr: 9.0000e-05\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0771 - mae: 27.0030 - mape: 11.0771 - val_loss: 11.9955 - val_mae: 28.1139 - val_mape: 11.9955 - lr: 9.0000e-05\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9470 - mae: 26.0812 - mape: 10.9470 - val_loss: 12.2573 - val_mae: 35.8610 - val_mape: 12.2573 - lr: 9.0000e-05\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2846 - mae: 28.4581 - mape: 11.2846 - val_loss: 11.8482 - val_mae: 31.0150 - val_mape: 11.8482 - lr: 9.0000e-05\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1439 - mae: 27.2401 - mape: 11.1439 - val_loss: 11.8979 - val_mae: 32.4919 - val_mape: 11.8979 - lr: 9.0000e-05\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1986 - mae: 29.1012 - mape: 11.1986 - val_loss: 12.1092 - val_mae: 29.9126 - val_mape: 12.1092 - lr: 9.0000e-05\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1265 - mae: 27.9493 - mape: 11.1265 - val_loss: 12.3236 - val_mae: 30.2133 - val_mape: 12.3236 - lr: 9.0000e-05\n",
      "Epoch 157/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 11.2117 - mae: 26.6435 - mape: 11.2117INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 11.2387 - mae: 26.5618 - mape: 11.2387 - val_loss: 11.7451 - val_mae: 26.6033 - val_mape: 11.7451 - lr: 9.0000e-05\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0774 - mae: 27.9509 - mape: 11.0774 - val_loss: 11.7719 - val_mae: 29.9366 - val_mape: 11.7719 - lr: 9.0000e-05\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2544 - mae: 26.8012 - mape: 11.2544 - val_loss: 12.2647 - val_mae: 28.6284 - val_mape: 12.2647 - lr: 9.0000e-05\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3338 - mae: 25.5344 - mape: 11.3338 - val_loss: 13.4630 - val_mae: 29.5048 - val_mape: 13.4630 - lr: 9.0000e-05\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3243 - mae: 29.7077 - mape: 11.3243 - val_loss: 11.8652 - val_mae: 28.9449 - val_mape: 11.8652 - lr: 9.0000e-05\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1482 - mae: 26.0452 - mape: 11.1482 - val_loss: 12.0006 - val_mae: 29.6759 - val_mape: 12.0006 - lr: 9.0000e-05\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2255 - mae: 26.7358 - mape: 11.2255 - val_loss: 12.1367 - val_mae: 28.1893 - val_mape: 12.1367 - lr: 9.0000e-05\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1826 - mae: 28.7555 - mape: 11.1826 - val_loss: 11.7752 - val_mae: 28.2274 - val_mape: 11.7752 - lr: 9.0000e-05\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3551 - mae: 28.6073 - mape: 11.3551 - val_loss: 12.0689 - val_mae: 28.8245 - val_mape: 12.0689 - lr: 9.0000e-05\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3527 - mae: 30.1566 - mape: 11.3527 - val_loss: 11.7756 - val_mae: 29.0932 - val_mape: 11.7756 - lr: 9.0000e-05\n",
      "Epoch 167/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 11.0908 - mae: 27.0510 - mape: 11.0908INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 11.0894 - mae: 26.6723 - mape: 11.0894 - val_loss: 11.7384 - val_mae: 27.0846 - val_mape: 11.7384 - lr: 9.0000e-05\n",
      "Epoch 168/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 11.0384 - mae: 27.0918 - mape: 11.0384INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 11.0849 - mae: 27.2756 - mape: 11.0849 - val_loss: 11.7295 - val_mae: 29.4330 - val_mape: 11.7295 - lr: 9.0000e-05\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0767 - mae: 26.6850 - mape: 11.0767 - val_loss: 11.8543 - val_mae: 30.1654 - val_mape: 11.8543 - lr: 9.0000e-05\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1232 - mae: 27.0197 - mape: 11.1232 - val_loss: 11.8038 - val_mae: 27.3622 - val_mape: 11.8038 - lr: 9.0000e-05\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4663 - mae: 27.3887 - mape: 11.4663 - val_loss: 11.8016 - val_mae: 29.9052 - val_mape: 11.8016 - lr: 9.0000e-05\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4376 - mae: 28.4538 - mape: 11.4376 - val_loss: 12.1118 - val_mae: 32.1699 - val_mape: 12.1118 - lr: 9.0000e-05\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1832 - mae: 28.5203 - mape: 11.1832 - val_loss: 11.7301 - val_mae: 26.8327 - val_mape: 11.7301 - lr: 9.0000e-05\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1168 - mae: 26.9343 - mape: 11.1168 - val_loss: 11.8638 - val_mae: 27.7460 - val_mape: 11.8638 - lr: 9.0000e-05\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4410 - mae: 26.6111 - mape: 11.4410 - val_loss: 11.7984 - val_mae: 26.6872 - val_mape: 11.7984 - lr: 9.0000e-05\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1440 - mae: 25.5075 - mape: 11.1440 - val_loss: 11.8859 - val_mae: 27.0667 - val_mape: 11.8859 - lr: 9.0000e-05\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4092 - mae: 28.3947 - mape: 11.4092 - val_loss: 12.1627 - val_mae: 27.7938 - val_mape: 12.1627 - lr: 9.0000e-05\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4079 - mae: 28.7392 - mape: 11.4079 - val_loss: 11.8261 - val_mae: 29.4981 - val_mape: 11.8261 - lr: 9.0000e-05\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2759 - mae: 26.8326 - mape: 11.2759 - val_loss: 11.7728 - val_mae: 27.1475 - val_mape: 11.7728 - lr: 9.0000e-05\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9831 - mae: 27.8505 - mape: 10.9831 - val_loss: 11.8980 - val_mae: 31.4811 - val_mape: 11.8980 - lr: 9.0000e-05\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0689 - mae: 27.6461 - mape: 11.0689 - val_loss: 12.0634 - val_mae: 27.3665 - val_mape: 12.0634 - lr: 9.0000e-05\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2822 - mae: 28.2802 - mape: 11.2822 - val_loss: 12.0838 - val_mae: 30.3280 - val_mape: 12.0838 - lr: 9.0000e-05\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0263 - mae: 25.5802 - mape: 11.0263 - val_loss: 11.7391 - val_mae: 30.0634 - val_mape: 11.7391 - lr: 9.0000e-05\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9242 - mae: 27.3616 - mape: 10.9242 - val_loss: 12.6090 - val_mae: 28.4620 - val_mape: 12.6090 - lr: 9.0000e-05\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1702 - mae: 26.8980 - mape: 11.1702 - val_loss: 11.8089 - val_mae: 27.7932 - val_mape: 11.8089 - lr: 9.0000e-05\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1780 - mae: 27.4506 - mape: 11.1780 - val_loss: 11.7649 - val_mae: 27.5223 - val_mape: 11.7649 - lr: 9.0000e-05\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3754 - mae: 29.1583 - mape: 11.3754 - val_loss: 12.0331 - val_mae: 29.9216 - val_mape: 12.0331 - lr: 9.0000e-05\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2063 - mae: 26.7979 - mape: 11.2063 - val_loss: 12.2231 - val_mae: 29.3409 - val_mape: 12.2231 - lr: 9.0000e-05\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0846 - mae: 26.1742 - mape: 11.0846 - val_loss: 12.2093 - val_mae: 28.2705 - val_mape: 12.2093 - lr: 9.0000e-05\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1002 - mae: 28.5472 - mape: 11.1002 - val_loss: 12.0315 - val_mae: 31.5916 - val_mape: 12.0315 - lr: 9.0000e-05\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0344 - mae: 25.4158 - mape: 11.0344 - val_loss: 11.9199 - val_mae: 32.3613 - val_mape: 11.9199 - lr: 9.0000e-05\n",
      "Epoch 192/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2000 - mae: 29.4744 - mape: 11.2000 - val_loss: 11.9727 - val_mae: 26.8803 - val_mape: 11.9727 - lr: 9.0000e-05\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0255 - mae: 28.2243 - mape: 11.0255 - val_loss: 11.9241 - val_mae: 28.3819 - val_mape: 11.9241 - lr: 9.0000e-05\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0877 - mae: 27.6438 - mape: 11.0877 - val_loss: 11.9449 - val_mae: 27.9181 - val_mape: 11.9449 - lr: 9.0000e-05\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1311 - mae: 25.3924 - mape: 11.1311 - val_loss: 12.4202 - val_mae: 28.0644 - val_mape: 12.4202 - lr: 9.0000e-05\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1798 - mae: 26.5532 - mape: 11.1798 - val_loss: 11.7694 - val_mae: 27.1108 - val_mape: 11.7694 - lr: 9.0000e-05\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3536 - mae: 27.1502 - mape: 11.3536 - val_loss: 12.3404 - val_mae: 30.2461 - val_mape: 12.3404 - lr: 9.0000e-05\n",
      "Epoch 198/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 11.0007 - mae: 27.4808 - mape: 11.0007\n",
      "Epoch 198: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9121 - mae: 27.3570 - mape: 10.9121 - val_loss: 11.8580 - val_mae: 26.7677 - val_mape: 11.8580 - lr: 9.0000e-05\n",
      "Epoch 199/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 10.8991 - mae: 27.0754 - mape: 10.8991INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 19ms/step - loss: 10.8770 - mae: 26.7736 - mape: 10.8770 - val_loss: 11.7039 - val_mae: 28.0634 - val_mape: 11.7039 - lr: 2.7000e-05\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.8017 - mae: 24.7643 - mape: 10.8017 - val_loss: 11.7756 - val_mae: 29.0119 - val_mape: 11.7756 - lr: 2.7000e-05\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6887 - mae: 24.8168 - mape: 10.6887 - val_loss: 11.7701 - val_mae: 30.0373 - val_mape: 11.7701 - lr: 2.7000e-05\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8506 - mae: 26.5309 - mape: 10.8506 - val_loss: 11.8043 - val_mae: 28.9142 - val_mape: 11.8043 - lr: 2.7000e-05\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8719 - mae: 25.8124 - mape: 10.8719 - val_loss: 11.8750 - val_mae: 29.9088 - val_mape: 11.8750 - lr: 2.7000e-05\n",
      "Epoch 204/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 10.8969 - mae: 27.3334 - mape: 10.8969INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 28ms/step - loss: 10.9279 - mae: 27.5207 - mape: 10.9279 - val_loss: 11.6932 - val_mae: 27.1845 - val_mape: 11.6932 - lr: 2.7000e-05\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9351 - mae: 26.3491 - mape: 10.9351 - val_loss: 11.9913 - val_mae: 29.3968 - val_mape: 11.9913 - lr: 2.7000e-05\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0329 - mae: 27.5398 - mape: 11.0329 - val_loss: 11.7559 - val_mae: 29.2308 - val_mape: 11.7559 - lr: 2.7000e-05\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9727 - mae: 27.3634 - mape: 10.9727 - val_loss: 11.7871 - val_mae: 28.0323 - val_mape: 11.7871 - lr: 2.7000e-05\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7371 - mae: 28.5352 - mape: 10.7371 - val_loss: 11.8375 - val_mae: 27.3106 - val_mape: 11.8375 - lr: 2.7000e-05\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6832 - mae: 25.2306 - mape: 10.6832 - val_loss: 11.7637 - val_mae: 27.7841 - val_mape: 11.7637 - lr: 2.7000e-05\n",
      "Epoch 210/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7161 - mae: 26.5145 - mape: 10.7161 - val_loss: 11.7995 - val_mae: 28.7241 - val_mape: 11.7995 - lr: 2.7000e-05\n",
      "Epoch 211/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8347 - mae: 25.8808 - mape: 10.8347 - val_loss: 11.7377 - val_mae: 27.8161 - val_mape: 11.7377 - lr: 2.7000e-05\n",
      "Epoch 212/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9338 - mae: 28.1162 - mape: 10.9338 - val_loss: 11.9039 - val_mae: 29.0695 - val_mape: 11.9039 - lr: 2.7000e-05\n",
      "Epoch 213/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8477 - mae: 26.3447 - mape: 10.8477 - val_loss: 11.7831 - val_mae: 28.6256 - val_mape: 11.7831 - lr: 2.7000e-05\n",
      "Epoch 214/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7975 - mae: 27.8208 - mape: 10.7975 - val_loss: 11.8602 - val_mae: 29.6636 - val_mape: 11.8602 - lr: 2.7000e-05\n",
      "Epoch 215/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 10.4376 - mae: 26.8191 - mape: 10.4376INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 10.5165 - mae: 26.4457 - mape: 10.5165 - val_loss: 11.6918 - val_mae: 27.5941 - val_mape: 11.6918 - lr: 2.7000e-05\n",
      "Epoch 216/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7742 - mae: 26.5794 - mape: 10.7742 - val_loss: 11.7094 - val_mae: 26.8467 - val_mape: 11.7094 - lr: 2.7000e-05\n",
      "Epoch 217/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9615 - mae: 25.9632 - mape: 10.9615 - val_loss: 11.7038 - val_mae: 27.8101 - val_mape: 11.7038 - lr: 2.7000e-05\n",
      "Epoch 218/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8819 - mae: 27.2107 - mape: 10.8819 - val_loss: 11.7216 - val_mae: 27.2648 - val_mape: 11.7216 - lr: 2.7000e-05\n",
      "Epoch 219/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8166 - mae: 24.8673 - mape: 10.8166 - val_loss: 11.7557 - val_mae: 28.9599 - val_mape: 11.7557 - lr: 2.7000e-05\n",
      "Epoch 220/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9695 - mae: 27.3194 - mape: 10.9695 - val_loss: 11.8492 - val_mae: 27.3091 - val_mape: 11.8492 - lr: 2.7000e-05\n",
      "Epoch 221/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7032 - mae: 25.3464 - mape: 10.7032 - val_loss: 11.8425 - val_mae: 28.9441 - val_mape: 11.8425 - lr: 2.7000e-05\n",
      "Epoch 222/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0155 - mae: 25.4055 - mape: 11.0155 - val_loss: 11.7386 - val_mae: 28.1546 - val_mape: 11.7386 - lr: 2.7000e-05\n",
      "Epoch 223/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3393 - mae: 26.8075 - mape: 11.3393 - val_loss: 11.9161 - val_mae: 28.2254 - val_mape: 11.9161 - lr: 2.7000e-05\n",
      "Epoch 224/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8778 - mae: 26.0745 - mape: 10.8778 - val_loss: 11.9302 - val_mae: 26.4983 - val_mape: 11.9302 - lr: 2.7000e-05\n",
      "Epoch 225/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8794 - mae: 27.9495 - mape: 10.8794 - val_loss: 11.7278 - val_mae: 28.4556 - val_mape: 11.7278 - lr: 2.7000e-05\n",
      "Epoch 226/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7112 - mae: 26.8576 - mape: 10.7112 - val_loss: 11.7949 - val_mae: 27.7790 - val_mape: 11.7949 - lr: 2.7000e-05\n",
      "Epoch 227/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7052 - mae: 25.7255 - mape: 10.7052 - val_loss: 11.7837 - val_mae: 27.9890 - val_mape: 11.7837 - lr: 2.7000e-05\n",
      "Epoch 228/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8830 - mae: 29.0018 - mape: 10.8830 - val_loss: 11.8439 - val_mae: 28.3155 - val_mape: 11.8439 - lr: 2.7000e-05\n",
      "Epoch 229/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0082 - mae: 26.3771 - mape: 11.0082 - val_loss: 11.7361 - val_mae: 27.3368 - val_mape: 11.7361 - lr: 2.7000e-05\n",
      "Epoch 230/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7819 - mae: 25.4453 - mape: 10.7819 - val_loss: 11.7107 - val_mae: 26.9488 - val_mape: 11.7107 - lr: 2.7000e-05\n",
      "Epoch 231/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8276 - mae: 29.5777 - mape: 10.8276 - val_loss: 11.8499 - val_mae: 26.9363 - val_mape: 11.8499 - lr: 2.7000e-05\n",
      "Epoch 232/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8859 - mae: 25.6541 - mape: 10.8859 - val_loss: 12.0887 - val_mae: 27.3978 - val_mape: 12.0887 - lr: 2.7000e-05\n",
      "Epoch 233/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8468 - mae: 26.7209 - mape: 10.8468 - val_loss: 11.8126 - val_mae: 29.9638 - val_mape: 11.8126 - lr: 2.7000e-05\n",
      "Epoch 234/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7741 - mae: 26.2925 - mape: 10.7741 - val_loss: 11.7457 - val_mae: 28.3127 - val_mape: 11.7457 - lr: 2.7000e-05\n",
      "Epoch 235/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8761 - mae: 26.5427 - mape: 10.8761 - val_loss: 11.7633 - val_mae: 29.1980 - val_mape: 11.7633 - lr: 2.7000e-05\n",
      "Epoch 236/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8850 - mae: 26.9545 - mape: 10.8850 - val_loss: 11.8202 - val_mae: 30.9106 - val_mape: 11.8202 - lr: 2.7000e-05\n",
      "Epoch 237/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0341 - mae: 28.1872 - mape: 11.0341 - val_loss: 11.7179 - val_mae: 28.3519 - val_mape: 11.7179 - lr: 2.7000e-05\n",
      "Epoch 238/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8174 - mae: 25.2634 - mape: 10.8174 - val_loss: 11.7653 - val_mae: 30.2584 - val_mape: 11.7653 - lr: 2.7000e-05\n",
      "Epoch 239/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5240 - mae: 26.9573 - mape: 10.5240 - val_loss: 11.7122 - val_mae: 28.7242 - val_mape: 11.7122 - lr: 2.7000e-05\n",
      "Epoch 240/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9474 - mae: 27.3155 - mape: 10.9474 - val_loss: 11.9876 - val_mae: 28.9328 - val_mape: 11.9876 - lr: 2.7000e-05\n",
      "Epoch 241/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8359 - mae: 27.4161 - mape: 10.8359 - val_loss: 11.7465 - val_mae: 27.0613 - val_mape: 11.7465 - lr: 2.7000e-05\n",
      "Epoch 242/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9882 - mae: 27.6578 - mape: 10.9882 - val_loss: 11.7486 - val_mae: 28.0114 - val_mape: 11.7486 - lr: 2.7000e-05\n",
      "Epoch 243/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7732 - mae: 26.3131 - mape: 10.7732 - val_loss: 11.7910 - val_mae: 28.1249 - val_mape: 11.7910 - lr: 2.7000e-05\n",
      "Epoch 244/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8496 - mae: 25.8216 - mape: 10.8496 - val_loss: 11.7814 - val_mae: 28.1868 - val_mape: 11.7814 - lr: 2.7000e-05\n",
      "Epoch 245/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 11.0411 - mae: 27.0784 - mape: 11.0411\n",
      "Epoch 245: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9795 - mae: 27.2656 - mape: 10.9795 - val_loss: 11.9010 - val_mae: 28.2384 - val_mape: 11.9010 - lr: 2.7000e-05\n",
      "Epoch 246/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6891 - mae: 26.9480 - mape: 10.6891 - val_loss: 11.7497 - val_mae: 27.4222 - val_mape: 11.7497 - lr: 8.1000e-06\n",
      "Epoch 247/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7711 - mae: 27.1690 - mape: 10.7711 - val_loss: 11.7195 - val_mae: 27.3895 - val_mape: 11.7195 - lr: 8.1000e-06\n",
      "Epoch 248/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7339 - mae: 26.2597 - mape: 10.7339 - val_loss: 11.7718 - val_mae: 28.3705 - val_mape: 11.7718 - lr: 8.1000e-06\n",
      "Epoch 249/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6906 - mae: 25.9325 - mape: 10.6906 - val_loss: 11.7794 - val_mae: 28.9353 - val_mape: 11.7794 - lr: 8.1000e-06\n",
      "Epoch 250/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5899 - mae: 26.4935 - mape: 10.5899 - val_loss: 11.7425 - val_mae: 27.8172 - val_mape: 11.7425 - lr: 8.1000e-06\n",
      "Epoch 251/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8171 - mae: 25.9745 - mape: 10.8171 - val_loss: 11.7287 - val_mae: 27.9618 - val_mape: 11.7287 - lr: 8.1000e-06\n",
      "Epoch 252/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6389 - mae: 26.8711 - mape: 10.6389 - val_loss: 11.7746 - val_mae: 27.5373 - val_mape: 11.7746 - lr: 8.1000e-06\n",
      "Epoch 253/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8632 - mae: 26.1747 - mape: 10.8632 - val_loss: 11.7275 - val_mae: 27.7561 - val_mape: 11.7275 - lr: 8.1000e-06\n",
      "Epoch 254/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8311 - mae: 26.5552 - mape: 10.8311 - val_loss: 11.7404 - val_mae: 27.9835 - val_mape: 11.7404 - lr: 8.1000e-06\n",
      "Epoch 255/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6399 - mae: 25.9731 - mape: 10.6399 - val_loss: 11.7357 - val_mae: 28.4267 - val_mape: 11.7357 - lr: 8.1000e-06\n",
      "Epoch 256/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7971 - mae: 26.0072 - mape: 10.7971 - val_loss: 11.7629 - val_mae: 28.9030 - val_mape: 11.7629 - lr: 8.1000e-06\n",
      "Epoch 257/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.5760 - mae: 26.0955 - mape: 10.5760 - val_loss: 11.7107 - val_mae: 27.7325 - val_mape: 11.7107 - lr: 8.1000e-06\n",
      "Epoch 258/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6268 - mae: 25.4891 - mape: 10.6268 - val_loss: 11.7329 - val_mae: 28.1297 - val_mape: 11.7329 - lr: 8.1000e-06\n",
      "Epoch 259/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6597 - mae: 25.0940 - mape: 10.6597 - val_loss: 11.7244 - val_mae: 28.1079 - val_mape: 11.7244 - lr: 8.1000e-06\n",
      "Epoch 260/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8593 - mae: 27.2369 - mape: 10.8593 - val_loss: 11.7665 - val_mae: 27.6444 - val_mape: 11.7665 - lr: 8.1000e-06\n",
      "Epoch 261/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7556 - mae: 24.0260 - mape: 10.7556 - val_loss: 11.7268 - val_mae: 28.3836 - val_mape: 11.7268 - lr: 8.1000e-06\n",
      "Epoch 262/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6787 - mae: 25.9453 - mape: 10.6787 - val_loss: 11.7088 - val_mae: 27.4445 - val_mape: 11.7088 - lr: 8.1000e-06\n",
      "Epoch 263/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7060 - mae: 26.0630 - mape: 10.7060 - val_loss: 11.7193 - val_mae: 28.2889 - val_mape: 11.7193 - lr: 8.1000e-06\n",
      "Epoch 264/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5912 - mae: 24.4315 - mape: 10.5912 - val_loss: 11.7751 - val_mae: 28.2297 - val_mape: 11.7751 - lr: 8.1000e-06\n",
      "Epoch 265/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8813 - mae: 25.7694 - mape: 10.8813 - val_loss: 11.8054 - val_mae: 28.4985 - val_mape: 11.8054 - lr: 8.1000e-06\n",
      "Epoch 266/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5839 - mae: 25.7675 - mape: 10.5839 - val_loss: 11.7377 - val_mae: 27.9790 - val_mape: 11.7377 - lr: 8.1000e-06\n",
      "Epoch 267/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8448 - mae: 27.7385 - mape: 10.8448 - val_loss: 11.7355 - val_mae: 27.8651 - val_mape: 11.7355 - lr: 8.1000e-06\n",
      "Epoch 268/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5610 - mae: 26.5830 - mape: 10.5610 - val_loss: 11.7553 - val_mae: 27.6213 - val_mape: 11.7553 - lr: 8.1000e-06\n",
      "Epoch 269/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7635 - mae: 25.0687 - mape: 10.7635 - val_loss: 11.7312 - val_mae: 27.9656 - val_mape: 11.7312 - lr: 8.1000e-06\n",
      "Epoch 270/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7221 - mae: 24.7546 - mape: 10.7221 - val_loss: 11.7460 - val_mae: 28.7153 - val_mape: 11.7460 - lr: 8.1000e-06\n",
      "Epoch 271/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5896 - mae: 26.8589 - mape: 10.5896 - val_loss: 11.8087 - val_mae: 28.0273 - val_mape: 11.8087 - lr: 8.1000e-06\n",
      "Epoch 272/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8673 - mae: 26.7834 - mape: 10.8673 - val_loss: 11.7431 - val_mae: 27.6293 - val_mape: 11.7431 - lr: 8.1000e-06\n",
      "Epoch 273/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7060 - mae: 25.5997 - mape: 10.7060 - val_loss: 11.7638 - val_mae: 27.7094 - val_mape: 11.7638 - lr: 8.1000e-06\n",
      "Epoch 274/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7577 - mae: 27.3441 - mape: 10.7577 - val_loss: 11.7305 - val_mae: 27.6597 - val_mape: 11.7305 - lr: 8.1000e-06\n",
      "Epoch 275/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 10.5940 - mae: 26.8164 - mape: 10.5940\n",
      "Epoch 275: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5829 - mae: 26.9076 - mape: 10.5829 - val_loss: 11.7521 - val_mae: 27.4570 - val_mape: 11.7521 - lr: 8.1000e-06\n",
      "Epoch 275: early stopping\n",
      "Score for fold 1: loss of 11.691810607910156; mae of 27.594125747680664; mape of 11.691810607910156%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.4153 - mae: 44.0566 - mape: 18.4153INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 17ms/step - loss: 18.4153 - mae: 44.0566 - mape: 18.4153 - val_loss: 17.1965 - val_mae: 25.9423 - val_mape: 17.1965 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 14.9088 - mae: 38.0842 - mape: 14.9088INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 15ms/step - loss: 14.9272 - mae: 38.6486 - mape: 14.9272 - val_loss: 12.1475 - val_mae: 32.7878 - val_mape: 12.1475 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 14.5315 - mae: 39.8988 - mape: 14.5315INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 14.5264 - mae: 39.8886 - mape: 14.5264 - val_loss: 12.0193 - val_mae: 34.6937 - val_mape: 12.0193 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.8128 - mae: 37.7924 - mape: 14.8128 - val_loss: 12.3604 - val_mae: 50.1671 - val_mape: 12.3604 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 14.9941 - mae: 43.6615 - mape: 14.9941INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 14.8715 - mae: 43.0129 - mape: 14.8715 - val_loss: 11.7758 - val_mae: 29.5302 - val_mape: 11.7758 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.9317 - mae: 42.3257 - mape: 15.9317 - val_loss: 12.5217 - val_mae: 57.2313 - val_mape: 12.5217 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.6817 - mae: 46.1313 - mape: 14.6817 - val_loss: 12.8318 - val_mae: 24.6171 - val_mape: 12.8318 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.1913 - mae: 34.7799 - mape: 14.1913 - val_loss: 14.0600 - val_mae: 30.1591 - val_mape: 14.0600 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.0316 - mae: 41.4782 - mape: 14.0316 - val_loss: 12.6256 - val_mae: 28.5869 - val_mape: 12.6256 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 13.9262 - mae: 35.8163 - mape: 13.9262INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 17ms/step - loss: 13.8808 - mae: 37.0178 - mape: 13.8808 - val_loss: 11.5388 - val_mae: 44.6055 - val_mape: 11.5388 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.2819 - mae: 36.7434 - mape: 14.2819 - val_loss: 14.8587 - val_mae: 21.6750 - val_mape: 14.8587 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.1350 - mae: 47.0105 - mape: 14.1350 - val_loss: 11.9082 - val_mae: 26.4946 - val_mape: 11.9082 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.1895 - mae: 36.7748 - mape: 14.1895 - val_loss: 13.4904 - val_mae: 38.1912 - val_mape: 13.4904 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.6191 - mae: 44.2632 - mape: 14.6191 - val_loss: 13.8966 - val_mae: 32.3161 - val_mape: 13.8966 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.6615 - mae: 36.7603 - mape: 14.6615 - val_loss: 13.0283 - val_mae: 25.1346 - val_mape: 13.0283 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.5679 - mae: 40.5944 - mape: 14.5679 - val_loss: 21.2389 - val_mae: 31.7541 - val_mape: 21.2389 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.0807 - mae: 37.7473 - mape: 14.0807 - val_loss: 14.1058 - val_mae: 49.8952 - val_mape: 14.1058 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.4582 - mae: 39.7127 - mape: 15.4582 - val_loss: 13.2067 - val_mae: 20.3976 - val_mape: 13.2067 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.9113 - mae: 43.1306 - mape: 14.9113 - val_loss: 13.9591 - val_mae: 41.8756 - val_mape: 13.9591 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.6101 - mae: 44.8291 - mape: 15.6101 - val_loss: 13.4486 - val_mae: 28.7437 - val_mape: 13.4486 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 13.8850 - mae: 39.0172 - mape: 13.8850INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 20ms/step - loss: 13.8659 - mae: 38.6572 - mape: 13.8659 - val_loss: 11.2139 - val_mae: 20.8527 - val_mape: 11.2139 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.6248 - mae: 33.2409 - mape: 13.6248 - val_loss: 14.7572 - val_mae: 33.3435 - val_mape: 14.7572 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.9767 - mae: 35.6563 - mape: 13.9767 - val_loss: 11.6031 - val_mae: 20.9625 - val_mape: 11.6031 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.3656 - mae: 44.6079 - mape: 14.3656 - val_loss: 11.5134 - val_mae: 21.2655 - val_mape: 11.5134 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.3619 - mae: 35.9311 - mape: 14.3619 - val_loss: 12.2061 - val_mae: 22.1458 - val_mape: 12.2061 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.2901 - mae: 35.6165 - mape: 13.2901 - val_loss: 13.8816 - val_mae: 22.2887 - val_mape: 13.8816 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.3349 - mae: 35.4050 - mape: 13.3349 - val_loss: 11.5220 - val_mae: 23.2222 - val_mape: 11.5220 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.4912 - mae: 36.6688 - mape: 13.4912 - val_loss: 11.6264 - val_mae: 22.9542 - val_mape: 11.6264 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.2221 - mae: 36.7192 - mape: 13.2221 - val_loss: 11.3970 - val_mae: 22.0626 - val_mape: 11.3970 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.3112 - mae: 47.4732 - mape: 14.3112 - val_loss: 14.8266 - val_mae: 23.0650 - val_mape: 14.8266 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.8453 - mae: 42.7067 - mape: 14.8453 - val_loss: 12.7052 - val_mae: 24.5689 - val_mape: 12.7052 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.5096 - mae: 34.1574 - mape: 13.5096 - val_loss: 13.0461 - val_mae: 26.8942 - val_mape: 13.0461 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.0498 - mae: 40.5188 - mape: 15.0498 - val_loss: 16.6217 - val_mae: 31.1922 - val_mape: 16.6217 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.6609 - mae: 41.8185 - mape: 14.6609 - val_loss: 11.9421 - val_mae: 24.0920 - val_mape: 11.9421 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.4262 - mae: 35.4052 - mape: 13.4262 - val_loss: 13.9373 - val_mae: 35.3871 - val_mape: 13.9373 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.6155 - mae: 34.0237 - mape: 13.6155 - val_loss: 12.0451 - val_mae: 27.6091 - val_mape: 12.0451 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.4827 - mae: 36.6878 - mape: 14.4827 - val_loss: 15.5381 - val_mae: 37.7786 - val_mape: 15.5381 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.4673 - mae: 37.2492 - mape: 13.4673 - val_loss: 13.7320 - val_mae: 28.2776 - val_mape: 13.7320 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.1040 - mae: 36.1599 - mape: 13.1040 - val_loss: 12.4190 - val_mae: 26.2081 - val_mape: 12.4190 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.6913 - mae: 39.3845 - mape: 13.6913 - val_loss: 12.4992 - val_mae: 23.0911 - val_mape: 12.4992 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.2630 - mae: 42.0326 - mape: 15.2630 - val_loss: 13.3417 - val_mae: 23.4124 - val_mape: 13.3417 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.6766 - mae: 38.7319 - mape: 13.6766 - val_loss: 11.8929 - val_mae: 22.3259 - val_mape: 11.8929 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.9187 - mae: 37.0336 - mape: 13.9187 - val_loss: 12.6731 - val_mae: 25.3763 - val_mape: 12.6731 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.8637 - mae: 34.0636 - mape: 12.8637 - val_loss: 12.7226 - val_mae: 36.4286 - val_mape: 12.7226 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.3933 - mae: 38.3731 - mape: 14.3933 - val_loss: 13.7737 - val_mae: 25.0967 - val_mape: 13.7737 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 16.1305 - mae: 35.4476 - mape: 16.1305 - val_loss: 14.9986 - val_mae: 30.5406 - val_mape: 14.9986 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.2626 - mae: 37.6877 - mape: 13.2626 - val_loss: 13.5689 - val_mae: 29.1651 - val_mape: 13.5689 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.6795 - mae: 38.9857 - mape: 14.6795 - val_loss: 14.1582 - val_mae: 23.7814 - val_mape: 14.1582 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.5073 - mae: 41.0053 - mape: 15.5073 - val_loss: 13.5854 - val_mae: 22.7240 - val_mape: 13.5854 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.0243 - mae: 36.9121 - mape: 14.0243 - val_loss: 14.3113 - val_mae: 44.8303 - val_mape: 14.3113 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 14.4713 - mae: 43.2488 - mape: 14.4713\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.3327 - mae: 41.6582 - mape: 14.3327 - val_loss: 16.1899 - val_mae: 23.1189 - val_mape: 16.1899 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.4898 - mae: 29.6550 - mape: 12.4898 - val_loss: 12.6902 - val_mae: 21.4766 - val_mape: 12.6902 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.9940 - mae: 31.3874 - mape: 11.9940 - val_loss: 12.2479 - val_mae: 20.7429 - val_mape: 12.2479 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9474 - mae: 30.4109 - mape: 11.9474 - val_loss: 13.5035 - val_mae: 21.6182 - val_mape: 13.5035 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.7638 - mae: 29.6760 - mape: 11.7638 - val_loss: 12.2378 - val_mae: 22.7439 - val_mape: 12.2378 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 12.0819 - mae: 32.4442 - mape: 12.0819INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 12.0993 - mae: 32.3963 - mape: 12.0993 - val_loss: 11.1591 - val_mae: 19.8031 - val_mape: 11.1591 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 11.5689 - mae: 30.7388 - mape: 11.5689INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 11.6381 - mae: 31.1551 - mape: 11.6381 - val_loss: 11.0970 - val_mae: 21.8319 - val_mape: 11.0970 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 12.0987 - mae: 31.8753 - mape: 12.0987 - val_loss: 12.0182 - val_mae: 20.3468 - val_mape: 12.0182 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.5832 - mae: 29.2756 - mape: 11.5832 - val_loss: 11.4370 - val_mae: 23.8484 - val_mape: 11.4370 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.5681 - mae: 30.1721 - mape: 11.5681 - val_loss: 11.3630 - val_mae: 23.6872 - val_mape: 11.3630 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.9896 - mae: 32.3347 - mape: 11.9896 - val_loss: 12.0525 - val_mae: 20.9128 - val_mape: 12.0525 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 12.1373 - mae: 31.4219 - mape: 12.1373 - val_loss: 11.5072 - val_mae: 20.2152 - val_mape: 11.5072 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.7391 - mae: 30.4205 - mape: 11.7391 - val_loss: 11.1554 - val_mae: 21.0701 - val_mape: 11.1554 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.6609 - mae: 29.9303 - mape: 11.6609 - val_loss: 11.1266 - val_mae: 20.9985 - val_mape: 11.1266 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.3202 - mae: 29.4790 - mape: 11.3202 - val_loss: 11.5770 - val_mae: 21.7910 - val_mape: 11.5770 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.8068 - mae: 31.7392 - mape: 11.8068 - val_loss: 11.2157 - val_mae: 19.8759 - val_mape: 11.2157 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.3124 - mae: 29.6722 - mape: 11.3124 - val_loss: 12.1115 - val_mae: 20.7799 - val_mape: 12.1115 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.5290 - mae: 32.1367 - mape: 11.5290 - val_loss: 11.1671 - val_mae: 20.1907 - val_mape: 11.1671 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 11.8022 - mae: 28.9054 - mape: 11.8022INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 18ms/step - loss: 11.7677 - mae: 28.9798 - mape: 11.7677 - val_loss: 10.9942 - val_mae: 20.1023 - val_mape: 10.9942 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.4262 - mae: 28.9541 - mape: 11.4262 - val_loss: 11.0475 - val_mae: 21.0723 - val_mape: 11.0475 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.8194 - mae: 29.2519 - mape: 11.8194 - val_loss: 11.7018 - val_mae: 22.9659 - val_mape: 11.7018 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 12.0022 - mae: 29.5150 - mape: 12.0022 - val_loss: 11.0338 - val_mae: 22.6217 - val_mape: 11.0338 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5942 - mae: 31.3485 - mape: 11.5942 - val_loss: 11.2437 - val_mae: 19.8231 - val_mape: 11.2437 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.6339 - mae: 31.5219 - mape: 11.6339 - val_loss: 11.2968 - val_mae: 19.8742 - val_mape: 11.2968 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 11.6641 - mae: 29.6180 - mape: 11.6641INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 20ms/step - loss: 11.6324 - mae: 30.2150 - mape: 11.6324 - val_loss: 10.9728 - val_mae: 20.2388 - val_mape: 10.9728 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 11.2202 - mae: 27.7945 - mape: 11.2202 - val_loss: 11.2006 - val_mae: 20.6437 - val_mape: 11.2006 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5028 - mae: 29.0337 - mape: 11.5028 - val_loss: 11.7876 - val_mae: 23.3999 - val_mape: 11.7876 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.3457 - mae: 30.0344 - mape: 11.3457 - val_loss: 12.4204 - val_mae: 21.6752 - val_mape: 12.4204 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.7658 - mae: 32.1629 - mape: 11.7658 - val_loss: 11.5725 - val_mae: 22.6970 - val_mape: 11.5725 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0758 - mae: 31.9590 - mape: 12.0758 - val_loss: 11.4956 - val_mae: 23.9695 - val_mape: 11.4956 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4502 - mae: 30.7291 - mape: 11.4502 - val_loss: 12.1555 - val_mae: 20.3254 - val_mape: 12.1555 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.8504 - mae: 28.7254 - mape: 11.8504 - val_loss: 11.3062 - val_mae: 20.8675 - val_mape: 11.3062 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.6161 - mae: 29.0952 - mape: 11.6161 - val_loss: 13.3190 - val_mae: 22.4624 - val_mape: 13.3190 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.9666 - mae: 33.1912 - mape: 11.9666 - val_loss: 11.9880 - val_mae: 19.8437 - val_mape: 11.9880 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.2455 - mae: 30.8476 - mape: 11.2455 - val_loss: 11.6251 - val_mae: 19.2829 - val_mape: 11.6251 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 12.1807 - mae: 26.9225 - mape: 12.1807 - val_loss: 12.1072 - val_mae: 21.2242 - val_mape: 12.1072 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4036 - mae: 31.0947 - mape: 11.4036 - val_loss: 11.7979 - val_mae: 20.8099 - val_mape: 11.7979 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.9056 - mae: 28.7889 - mape: 11.9056 - val_loss: 11.5174 - val_mae: 20.6055 - val_mape: 11.5174 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4087 - mae: 29.2173 - mape: 11.4087 - val_loss: 11.3972 - val_mae: 22.3263 - val_mape: 11.3972 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.6770 - mae: 29.7501 - mape: 11.6770 - val_loss: 11.0383 - val_mae: 22.5446 - val_mape: 11.0383 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9908 - mae: 28.3029 - mape: 10.9908 - val_loss: 12.0894 - val_mae: 24.6359 - val_mape: 12.0894 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3506 - mae: 31.0194 - mape: 11.3506 - val_loss: 12.2918 - val_mae: 20.7094 - val_mape: 12.2918 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.7581 - mae: 30.4954 - mape: 11.7581 - val_loss: 13.6249 - val_mae: 24.8719 - val_mape: 13.6249 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.4267 - mae: 30.9320 - mape: 11.4267 - val_loss: 11.7048 - val_mae: 19.5270 - val_mape: 11.7048 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2555 - mae: 30.6118 - mape: 11.2555 - val_loss: 11.7938 - val_mae: 24.7328 - val_mape: 11.7938 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5927 - mae: 30.1240 - mape: 11.5927 - val_loss: 11.4587 - val_mae: 23.4584 - val_mape: 11.4587 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5002 - mae: 31.8325 - mape: 11.5002 - val_loss: 13.6502 - val_mae: 28.9411 - val_mape: 13.6502 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.1831 - mae: 31.5196 - mape: 12.1831 - val_loss: 13.5410 - val_mae: 23.0736 - val_mape: 13.5410 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5240 - mae: 28.0565 - mape: 11.5240 - val_loss: 13.0115 - val_mae: 21.6441 - val_mape: 13.0115 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2591 - mae: 28.1508 - mape: 11.2591 - val_loss: 15.3240 - val_mae: 26.6310 - val_mape: 15.3240 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5700 - mae: 30.5338 - mape: 11.5700 - val_loss: 11.1183 - val_mae: 25.1962 - val_mape: 11.1183 - lr: 3.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 11.2642 - mae: 30.1796 - mape: 11.2642INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 11.2642 - mae: 30.1796 - mape: 11.2642 - val_loss: 10.9178 - val_mae: 21.2031 - val_mape: 10.9178 - lr: 3.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3037 - mae: 29.4518 - mape: 11.3037 - val_loss: 11.4582 - val_mae: 18.8946 - val_mape: 11.4582 - lr: 3.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.6751 - mae: 29.4632 - mape: 11.6751 - val_loss: 11.2926 - val_mae: 18.8836 - val_mape: 11.2926 - lr: 3.0000e-04\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4398 - mae: 29.4962 - mape: 11.4398 - val_loss: 12.3835 - val_mae: 21.7417 - val_mape: 12.3835 - lr: 3.0000e-04\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.9735 - mae: 31.7322 - mape: 11.9735 - val_loss: 11.0421 - val_mae: 19.2471 - val_mape: 11.0421 - lr: 3.0000e-04\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2275 - mae: 29.2622 - mape: 11.2275 - val_loss: 11.3199 - val_mae: 20.1556 - val_mape: 11.3199 - lr: 3.0000e-04\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.6764 - mae: 29.5911 - mape: 11.6764 - val_loss: 14.9161 - val_mae: 21.7819 - val_mape: 14.9161 - lr: 3.0000e-04\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4139 - mae: 28.1732 - mape: 11.4139 - val_loss: 11.5547 - val_mae: 21.6766 - val_mape: 11.5547 - lr: 3.0000e-04\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3816 - mae: 27.7312 - mape: 11.3816 - val_loss: 11.3428 - val_mae: 19.6308 - val_mape: 11.3428 - lr: 3.0000e-04\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3122 - mae: 29.4753 - mape: 11.3122 - val_loss: 11.7308 - val_mae: 19.8927 - val_mape: 11.7308 - lr: 3.0000e-04\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4812 - mae: 28.3478 - mape: 11.4812 - val_loss: 11.9565 - val_mae: 21.6265 - val_mape: 11.9565 - lr: 3.0000e-04\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.6224 - mae: 28.9536 - mape: 11.6224 - val_loss: 11.8753 - val_mae: 21.1122 - val_mape: 11.8753 - lr: 3.0000e-04\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2878 - mae: 31.6073 - mape: 11.2878 - val_loss: 12.0097 - val_mae: 27.2995 - val_mape: 12.0097 - lr: 3.0000e-04\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5778 - mae: 31.3920 - mape: 11.5778 - val_loss: 11.4818 - val_mae: 19.3286 - val_mape: 11.4818 - lr: 3.0000e-04\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5213 - mae: 31.8735 - mape: 11.5213 - val_loss: 11.5961 - val_mae: 19.0458 - val_mape: 11.5961 - lr: 3.0000e-04\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.9973 - mae: 27.0606 - mape: 10.9973 - val_loss: 11.5964 - val_mae: 20.8936 - val_mape: 11.5964 - lr: 3.0000e-04\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.1116 - mae: 29.0291 - mape: 11.1116 - val_loss: 11.2302 - val_mae: 19.1382 - val_mape: 11.2302 - lr: 3.0000e-04\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.9339 - mae: 29.5081 - mape: 10.9339 - val_loss: 11.3836 - val_mae: 21.8776 - val_mape: 11.3836 - lr: 3.0000e-04\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.1670 - mae: 27.7283 - mape: 11.1670 - val_loss: 11.0556 - val_mae: 19.6988 - val_mape: 11.0556 - lr: 3.0000e-04\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.0459 - mae: 28.5447 - mape: 11.0459 - val_loss: 11.3776 - val_mae: 20.7617 - val_mape: 11.3776 - lr: 3.0000e-04\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.2748 - mae: 28.2346 - mape: 11.2748 - val_loss: 11.1859 - val_mae: 20.3593 - val_mape: 11.1859 - lr: 3.0000e-04\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.5936 - mae: 29.1922 - mape: 11.5936 - val_loss: 12.2711 - val_mae: 20.7489 - val_mape: 12.2711 - lr: 3.0000e-04\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.1049 - mae: 30.6989 - mape: 11.1049 - val_loss: 11.3643 - val_mae: 22.7853 - val_mape: 11.3643 - lr: 3.0000e-04\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.4141 - mae: 29.2030 - mape: 11.4141 - val_loss: 12.1449 - val_mae: 22.9784 - val_mape: 12.1449 - lr: 3.0000e-04\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.2845 - mae: 28.9279 - mape: 11.2845 - val_loss: 11.2996 - val_mae: 19.6526 - val_mape: 11.2996 - lr: 3.0000e-04\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5452 - mae: 32.4370 - mape: 11.5452 - val_loss: 11.5400 - val_mae: 19.4866 - val_mape: 11.5400 - lr: 3.0000e-04\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.7745 - mae: 28.2429 - mape: 11.7745 - val_loss: 12.1004 - val_mae: 24.1174 - val_mape: 12.1004 - lr: 3.0000e-04\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 12.6588 - mae: 32.6486 - mape: 12.6588 - val_loss: 12.7109 - val_mae: 25.6095 - val_mape: 12.7109 - lr: 3.0000e-04\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.9951 - mae: 24.9053 - mape: 10.9951 - val_loss: 11.4896 - val_mae: 24.5967 - val_mape: 11.4896 - lr: 3.0000e-04\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.1441 - mae: 26.6574 - mape: 11.1441 - val_loss: 11.7407 - val_mae: 21.4525 - val_mape: 11.7407 - lr: 3.0000e-04\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 11.0850 - mae: 30.0034 - mape: 11.0850\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.0850 - mae: 30.0034 - mape: 11.0850 - val_loss: 11.5574 - val_mae: 19.5236 - val_mape: 11.5574 - lr: 3.0000e-04\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.8499 - mae: 26.5822 - mape: 10.8499 - val_loss: 11.2130 - val_mae: 22.7878 - val_mape: 11.2130 - lr: 9.0000e-05\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.6372 - mae: 29.0972 - mape: 10.6372 - val_loss: 11.0458 - val_mae: 20.5970 - val_mape: 11.0458 - lr: 9.0000e-05\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.6954 - mae: 27.2783 - mape: 10.6954 - val_loss: 11.7794 - val_mae: 20.0274 - val_mape: 11.7794 - lr: 9.0000e-05\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7875 - mae: 29.0888 - mape: 10.7875 - val_loss: 11.2030 - val_mae: 20.0071 - val_mape: 11.2030 - lr: 9.0000e-05\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4705 - mae: 28.4655 - mape: 10.4705 - val_loss: 11.1556 - val_mae: 21.9202 - val_mape: 11.1556 - lr: 9.0000e-05\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5544 - mae: 26.8058 - mape: 10.5544 - val_loss: 11.0107 - val_mae: 20.9535 - val_mape: 11.0107 - lr: 9.0000e-05\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.4966 - mae: 28.2172 - mape: 10.4966 - val_loss: 11.0191 - val_mae: 18.8455 - val_mape: 11.0191 - lr: 9.0000e-05\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3637 - mae: 27.9367 - mape: 10.3637 - val_loss: 11.5962 - val_mae: 20.1486 - val_mape: 11.5962 - lr: 9.0000e-05\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4797 - mae: 27.7243 - mape: 10.4797 - val_loss: 11.2393 - val_mae: 20.3889 - val_mape: 11.2393 - lr: 9.0000e-05\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6351 - mae: 25.2127 - mape: 10.6351 - val_loss: 11.1533 - val_mae: 20.0155 - val_mape: 11.1533 - lr: 9.0000e-05\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6159 - mae: 26.5988 - mape: 10.6159 - val_loss: 11.0730 - val_mae: 19.8095 - val_mape: 11.0730 - lr: 9.0000e-05\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3882 - mae: 24.4053 - mape: 10.3882 - val_loss: 11.1219 - val_mae: 19.9929 - val_mape: 11.1219 - lr: 9.0000e-05\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8177 - mae: 28.0310 - mape: 10.8177 - val_loss: 10.9957 - val_mae: 18.6574 - val_mape: 10.9957 - lr: 9.0000e-05\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4335 - mae: 27.0297 - mape: 10.4335 - val_loss: 11.1644 - val_mae: 19.0972 - val_mape: 11.1644 - lr: 9.0000e-05\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4126 - mae: 25.0802 - mape: 10.4126 - val_loss: 11.0807 - val_mae: 19.5091 - val_mape: 11.0807 - lr: 9.0000e-05\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6405 - mae: 26.8101 - mape: 10.6405 - val_loss: 11.0907 - val_mae: 19.1221 - val_mape: 11.0907 - lr: 9.0000e-05\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5635 - mae: 25.7218 - mape: 10.5635 - val_loss: 10.9601 - val_mae: 18.6745 - val_mape: 10.9601 - lr: 9.0000e-05\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4584 - mae: 27.9153 - mape: 10.4584 - val_loss: 11.6442 - val_mae: 20.7330 - val_mape: 11.6442 - lr: 9.0000e-05\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4312 - mae: 26.1573 - mape: 10.4312 - val_loss: 11.0860 - val_mae: 18.8649 - val_mape: 11.0860 - lr: 9.0000e-05\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3918 - mae: 29.8720 - mape: 10.3918 - val_loss: 10.9606 - val_mae: 19.2930 - val_mape: 10.9606 - lr: 9.0000e-05\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4405 - mae: 27.7574 - mape: 10.4405 - val_loss: 11.0697 - val_mae: 18.8364 - val_mape: 11.0697 - lr: 9.0000e-05\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7175 - mae: 28.1198 - mape: 10.7175 - val_loss: 11.4043 - val_mae: 19.3546 - val_mape: 11.4043 - lr: 9.0000e-05\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3542 - mae: 26.1434 - mape: 10.3542 - val_loss: 12.2370 - val_mae: 20.6545 - val_mape: 12.2370 - lr: 9.0000e-05\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5531 - mae: 27.0636 - mape: 10.5531 - val_loss: 11.1474 - val_mae: 20.0686 - val_mape: 11.1474 - lr: 9.0000e-05\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7751 - mae: 29.4827 - mape: 10.7751 - val_loss: 11.0084 - val_mae: 18.7631 - val_mape: 11.0084 - lr: 9.0000e-05\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.3111 - mae: 27.6486 - mape: 10.3111 - val_loss: 11.1521 - val_mae: 19.3077 - val_mape: 11.1521 - lr: 9.0000e-05\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.5538 - mae: 28.6725 - mape: 10.5538 - val_loss: 10.9603 - val_mae: 18.6814 - val_mape: 10.9603 - lr: 9.0000e-05\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.5778 - mae: 27.8386 - mape: 10.5778 - val_loss: 11.1853 - val_mae: 21.6985 - val_mape: 11.1853 - lr: 9.0000e-05\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.4834 - mae: 29.0749 - mape: 10.4834 - val_loss: 11.6098 - val_mae: 18.8786 - val_mape: 11.6098 - lr: 9.0000e-05\n",
      "Epoch 162/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 10.3793 - mae: 28.2294 - mape: 10.3793\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.4828 - mae: 29.3937 - mape: 10.4828 - val_loss: 11.0694 - val_mae: 19.3733 - val_mape: 11.0694 - lr: 9.0000e-05\n",
      "Epoch 162: early stopping\n",
      "Score for fold 2: loss of 10.917817115783691; mae of 21.2031307220459; mape of 10.917817115783691%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 15.9105 - mae: 38.3231 - mape: 15.9105INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 18ms/step - loss: 15.6825 - mae: 37.3715 - mape: 15.6825 - val_loss: 13.4122 - val_mae: 26.8769 - val_mape: 13.4122 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 14.7399 - mae: 38.8192 - mape: 14.7399INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 21ms/step - loss: 14.6837 - mae: 37.4071 - mape: 14.6837 - val_loss: 13.2053 - val_mae: 36.3769 - val_mape: 13.2053 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 14.4733 - mae: 38.5093 - mape: 14.4733INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 17ms/step - loss: 14.2003 - mae: 38.3129 - mape: 14.2003 - val_loss: 10.9782 - val_mae: 26.6938 - val_mape: 10.9782 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.9665 - mae: 37.7301 - mape: 13.9665 - val_loss: 12.9265 - val_mae: 22.1488 - val_mape: 12.9265 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.3632 - mae: 33.7478 - mape: 14.3632 - val_loss: 15.2548 - val_mae: 32.6522 - val_mape: 15.2548 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 13.9268 - mae: 38.6375 - mape: 13.9268INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 22ms/step - loss: 13.9468 - mae: 38.9482 - mape: 13.9468 - val_loss: 10.5706 - val_mae: 29.8580 - val_mape: 10.5706 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.0582 - mae: 39.2546 - mape: 15.0582 - val_loss: 15.7251 - val_mae: 35.1921 - val_mape: 15.7251 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.2222 - mae: 39.4513 - mape: 15.2222 - val_loss: 13.8788 - val_mae: 28.7788 - val_mape: 13.8788 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.1737 - mae: 39.4203 - mape: 14.1737 - val_loss: 18.0323 - val_mae: 35.9245 - val_mape: 18.0323 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.9725 - mae: 46.5643 - mape: 14.9725 - val_loss: 10.6852 - val_mae: 18.8576 - val_mape: 10.6852 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 13.0856 - mae: 34.4229 - mape: 13.0856 - val_loss: 14.2878 - val_mae: 26.9759 - val_mape: 14.2878 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 15.2549 - mae: 39.3197 - mape: 15.2549 - val_loss: 13.2148 - val_mae: 27.4518 - val_mape: 13.2148 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.1159 - mae: 37.0172 - mape: 14.1159 - val_loss: 10.9095 - val_mae: 21.7733 - val_mape: 10.9095 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.4955 - mae: 39.2317 - mape: 14.4955 - val_loss: 14.7076 - val_mae: 27.5015 - val_mape: 14.7076 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 16.1665 - mae: 39.6623 - mape: 16.1665 - val_loss: 13.8194 - val_mae: 28.3684 - val_mape: 13.8194 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.2025 - mae: 40.1161 - mape: 14.2025 - val_loss: 10.8748 - val_mae: 25.0921 - val_mape: 10.8748 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.2142 - mae: 37.9402 - mape: 14.2142 - val_loss: 12.2691 - val_mae: 22.2765 - val_mape: 12.2691 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 13.7231 - mae: 36.7790 - mape: 13.7231 - val_loss: 11.4704 - val_mae: 26.8948 - val_mape: 11.4704 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.2751 - mae: 38.0477 - mape: 14.2751 - val_loss: 13.6615 - val_mae: 29.2294 - val_mape: 13.6615 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.1751 - mae: 36.2574 - mape: 14.1751 - val_loss: 25.6946 - val_mae: 44.8975 - val_mape: 25.6946 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.8190 - mae: 37.3318 - mape: 14.8190INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 3s 29ms/step - loss: 14.8190 - mae: 37.3318 - mape: 14.8190 - val_loss: 10.4821 - val_mae: 25.0057 - val_mape: 10.4821 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 13.8096 - mae: 35.9384 - mape: 13.8096 - val_loss: 14.0082 - val_mae: 27.5614 - val_mape: 14.0082 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 15.0929 - mae: 39.1762 - mape: 15.0929 - val_loss: 18.7056 - val_mae: 31.4275 - val_mape: 18.7056 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 13.8863 - mae: 39.5045 - mape: 13.8863 - val_loss: 11.2453 - val_mae: 33.0473 - val_mape: 11.2453 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.0896 - mae: 36.6519 - mape: 14.0896 - val_loss: 10.8498 - val_mae: 22.6209 - val_mape: 10.8498 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.6534 - mae: 33.7101 - mape: 13.6534 - val_loss: 14.1298 - val_mae: 25.6466 - val_mape: 14.1298 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.2172 - mae: 32.5375 - mape: 13.2172 - val_loss: 10.8492 - val_mae: 18.1720 - val_mape: 10.8492 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.3803 - mae: 38.3790 - mape: 14.3803 - val_loss: 14.4206 - val_mae: 37.6182 - val_mape: 14.4206 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.3414 - mae: 39.5061 - mape: 14.3414 - val_loss: 10.6154 - val_mae: 21.1980 - val_mape: 10.6154 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.6712 - mae: 38.9622 - mape: 14.6712 - val_loss: 15.0386 - val_mae: 28.1581 - val_mape: 15.0386 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.0187 - mae: 37.1459 - mape: 14.0187 - val_loss: 11.7104 - val_mae: 29.2127 - val_mape: 11.7104 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.7807 - mae: 39.4703 - mape: 14.7807 - val_loss: 13.7573 - val_mae: 37.8051 - val_mape: 13.7573 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 13.5552 - mae: 37.3551 - mape: 13.5552 - val_loss: 12.1154 - val_mae: 24.4119 - val_mape: 12.1154 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 13.2557 - mae: 34.0187 - mape: 13.2557 - val_loss: 10.6063 - val_mae: 24.3126 - val_mape: 10.6063 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.5814 - mae: 37.9015 - mape: 14.5814 - val_loss: 13.0213 - val_mae: 38.2219 - val_mape: 13.0213 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.0340 - mae: 36.3288 - mape: 14.0340 - val_loss: 11.9631 - val_mae: 18.3090 - val_mape: 11.9631 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.3544 - mae: 41.9145 - mape: 14.3544 - val_loss: 12.9213 - val_mae: 22.7804 - val_mape: 12.9213 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.1175 - mae: 46.0366 - mape: 14.1175 - val_loss: 12.0343 - val_mae: 32.6022 - val_mape: 12.0343 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.2309 - mae: 37.1149 - mape: 13.2309 - val_loss: 12.9210 - val_mae: 23.2753 - val_mape: 12.9210 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.3843 - mae: 37.3675 - mape: 13.3843 - val_loss: 11.9645 - val_mae: 25.3345 - val_mape: 11.9645 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 13.0764 - mae: 36.9628 - mape: 13.0764 - val_loss: 12.2197 - val_mae: 26.7077 - val_mape: 12.2197 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.9307 - mae: 41.5263 - mape: 14.9307 - val_loss: 14.1681 - val_mae: 25.8481 - val_mape: 14.1681 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.0053 - mae: 42.0960 - mape: 15.0053 - val_loss: 11.3798 - val_mae: 22.9427 - val_mape: 11.3798 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.0218 - mae: 36.7841 - mape: 14.0218 - val_loss: 12.2858 - val_mae: 24.3697 - val_mape: 12.2858 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.8403 - mae: 35.6681 - mape: 12.8403 - val_loss: 14.7449 - val_mae: 37.1796 - val_mape: 14.7449 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.1089 - mae: 37.8096 - mape: 14.1089 - val_loss: 12.5448 - val_mae: 23.7897 - val_mape: 12.5448 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.5793 - mae: 37.7304 - mape: 13.5793 - val_loss: 12.6286 - val_mae: 21.5356 - val_mape: 12.6286 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.2263 - mae: 38.5188 - mape: 14.2263 - val_loss: 13.0241 - val_mae: 24.8260 - val_mape: 13.0241 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.8858 - mae: 32.7925 - mape: 12.8858 - val_loss: 11.0798 - val_mae: 22.6904 - val_mape: 11.0798 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 16.0010 - mae: 38.9373 - mape: 16.0010 - val_loss: 15.3229 - val_mae: 27.2389 - val_mape: 15.3229 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 14.0471 - mae: 38.3289 - mape: 14.0471\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 14.3889 - mae: 37.8305 - mape: 14.3889 - val_loss: 14.8905 - val_mae: 27.2722 - val_mape: 14.8905 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 12.2819 - mae: 32.3042 - mape: 12.2819 - val_loss: 10.8402 - val_mae: 18.1433 - val_mape: 10.8402 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.4176 - mae: 29.2006 - mape: 11.4176 - val_loss: 10.5397 - val_mae: 20.0132 - val_mape: 10.5397 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 11.8608 - mae: 31.1311 - mape: 11.8608INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 14ms/step - loss: 11.8761 - mae: 31.5844 - mape: 11.8761 - val_loss: 10.3879 - val_mae: 20.3435 - val_mape: 10.3879 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 12.4105 - mae: 29.0162 - mape: 12.4105 - val_loss: 10.6947 - val_mae: 18.6712 - val_mape: 10.6947 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.5237 - mae: 31.4934 - mape: 11.5237 - val_loss: 10.7773 - val_mae: 24.8076 - val_mape: 10.7773 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 11.5998 - mae: 32.9505 - mape: 11.5998INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 13ms/step - loss: 11.6296 - mae: 32.9711 - mape: 11.6296 - val_loss: 10.2070 - val_mae: 19.7597 - val_mape: 10.2070 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.8191 - mae: 32.6681 - mape: 11.8191 - val_loss: 13.9794 - val_mae: 22.5311 - val_mape: 13.9794 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 12.1096 - mae: 31.6413 - mape: 12.1096 - val_loss: 10.7746 - val_mae: 17.8027 - val_mape: 10.7746 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.3303 - mae: 28.1832 - mape: 11.3303 - val_loss: 10.2276 - val_mae: 18.0255 - val_mape: 10.2276 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.4268 - mae: 29.2640 - mape: 11.4268 - val_loss: 10.9063 - val_mae: 19.3596 - val_mape: 10.9063 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.4594 - mae: 29.2664 - mape: 11.4594 - val_loss: 10.7924 - val_mae: 20.3045 - val_mape: 10.7924 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.1284 - mae: 30.1341 - mape: 11.1284 - val_loss: 11.5685 - val_mae: 20.7537 - val_mape: 11.5685 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.3473 - mae: 32.5938 - mape: 11.3473 - val_loss: 10.2365 - val_mae: 17.8929 - val_mape: 10.2365 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 11.3960 - mae: 30.7413 - mape: 11.3960INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 22ms/step - loss: 11.3960 - mae: 30.7413 - mape: 11.3960 - val_loss: 10.1709 - val_mae: 19.4292 - val_mape: 10.1709 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5537 - mae: 30.5814 - mape: 11.5537 - val_loss: 10.2203 - val_mae: 18.6131 - val_mape: 10.2203 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4121 - mae: 30.2337 - mape: 11.4121 - val_loss: 12.0451 - val_mae: 25.1494 - val_mape: 12.0451 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3119 - mae: 30.8321 - mape: 11.3119 - val_loss: 11.8339 - val_mae: 18.6201 - val_mape: 11.8339 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5475 - mae: 30.1592 - mape: 11.5475 - val_loss: 10.4712 - val_mae: 16.7237 - val_mape: 10.4712 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.5281 - mae: 30.4418 - mape: 11.5281 - val_loss: 10.3335 - val_mae: 18.2659 - val_mape: 10.3335 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2809 - mae: 30.6235 - mape: 11.2809 - val_loss: 11.9414 - val_mae: 22.5101 - val_mape: 11.9414 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4342 - mae: 31.1929 - mape: 11.4342 - val_loss: 10.2281 - val_mae: 20.1967 - val_mape: 10.2281 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.0192 - mae: 31.7478 - mape: 12.0192 - val_loss: 10.3828 - val_mae: 19.4476 - val_mape: 10.3828 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7946 - mae: 28.0307 - mape: 10.7946 - val_loss: 10.9136 - val_mae: 17.8254 - val_mape: 10.9136 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 11.4097 - mae: 28.6468 - mape: 11.4097INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 19ms/step - loss: 11.2586 - mae: 27.8938 - mape: 11.2586 - val_loss: 10.0960 - val_mae: 18.2941 - val_mape: 10.0960 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2158 - mae: 30.5686 - mape: 11.2158 - val_loss: 10.7625 - val_mae: 18.2694 - val_mape: 10.7625 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3310 - mae: 31.0602 - mape: 11.3310 - val_loss: 10.9683 - val_mae: 21.4363 - val_mape: 10.9683 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3316 - mae: 29.0447 - mape: 11.3316 - val_loss: 10.3405 - val_mae: 17.7947 - val_mape: 10.3405 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2124 - mae: 29.4840 - mape: 11.2124 - val_loss: 10.5313 - val_mae: 19.8621 - val_mape: 10.5313 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2332 - mae: 30.9626 - mape: 11.2332 - val_loss: 10.5383 - val_mae: 28.6176 - val_mape: 10.5383 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.4052 - mae: 31.9383 - mape: 11.4052 - val_loss: 10.1363 - val_mae: 18.7699 - val_mape: 10.1363 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2588 - mae: 28.9329 - mape: 11.2588 - val_loss: 10.5998 - val_mae: 18.0480 - val_mape: 10.5998 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.3409 - mae: 28.6938 - mape: 11.3409 - val_loss: 12.6833 - val_mae: 20.9693 - val_mape: 12.6833 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.7194 - mae: 30.0398 - mape: 11.7194 - val_loss: 10.6131 - val_mae: 17.0666 - val_mape: 10.6131 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1541 - mae: 29.8249 - mape: 11.1541 - val_loss: 10.3899 - val_mae: 18.9265 - val_mape: 10.3899 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1483 - mae: 29.6085 - mape: 11.1483 - val_loss: 10.4367 - val_mae: 16.4026 - val_mape: 10.4367 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.0042 - mae: 27.9307 - mape: 11.0042 - val_loss: 10.6968 - val_mae: 17.8803 - val_mape: 10.6968 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.2596 - mae: 29.2074 - mape: 11.2596 - val_loss: 11.1116 - val_mae: 23.3171 - val_mape: 11.1116 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.1899 - mae: 31.5772 - mape: 11.1899 - val_loss: 10.3570 - val_mae: 22.3725 - val_mape: 10.3570 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.0051 - mae: 30.6391 - mape: 11.0051 - val_loss: 10.3275 - val_mae: 23.3813 - val_mape: 10.3275 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.1346 - mae: 30.1987 - mape: 11.1346 - val_loss: 10.3611 - val_mae: 21.6490 - val_mape: 10.3611 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.2694 - mae: 28.8276 - mape: 11.2694 - val_loss: 10.4592 - val_mae: 16.7514 - val_mape: 10.4592 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.1657 - mae: 28.9429 - mape: 11.1657 - val_loss: 10.4339 - val_mae: 21.3560 - val_mape: 10.4339 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.5917 - mae: 32.5034 - mape: 11.5917 - val_loss: 10.6813 - val_mae: 18.4583 - val_mape: 10.6813 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.8792 - mae: 29.8819 - mape: 10.8792 - val_loss: 11.4127 - val_mae: 18.3938 - val_mape: 11.4127 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.3737 - mae: 29.3603 - mape: 11.3737 - val_loss: 11.3690 - val_mae: 20.7709 - val_mape: 11.3690 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 11.4219 - mae: 30.0975 - mape: 11.4219 - val_loss: 12.1041 - val_mae: 19.5458 - val_mape: 12.1041 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.2935 - mae: 29.5991 - mape: 11.2935 - val_loss: 11.1754 - val_mae: 19.4628 - val_mape: 11.1754 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9776 - mae: 31.0956 - mape: 10.9776 - val_loss: 10.9252 - val_mae: 16.7237 - val_mape: 10.9252 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.1883 - mae: 31.7288 - mape: 11.1883 - val_loss: 10.4475 - val_mae: 23.4601 - val_mape: 10.4475 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.8964 - mae: 30.7719 - mape: 10.8964 - val_loss: 10.3646 - val_mae: 18.3021 - val_mape: 10.3646 - lr: 3.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.2024 - mae: 28.0396 - mape: 11.2024 - val_loss: 13.0349 - val_mae: 25.8442 - val_mape: 13.0349 - lr: 3.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.4224 - mae: 30.5653 - mape: 11.4224 - val_loss: 10.6026 - val_mae: 18.4595 - val_mape: 10.6026 - lr: 3.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.4242 - mae: 32.1922 - mape: 11.4242 - val_loss: 10.3759 - val_mae: 22.3377 - val_mape: 10.3759 - lr: 3.0000e-04\n",
      "Epoch 105/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 10.8022 - mae: 30.1170 - mape: 10.8022\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.8996 - mae: 29.9150 - mape: 10.8996 - val_loss: 13.0074 - val_mae: 20.5673 - val_mape: 13.0074 - lr: 3.0000e-04\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0483 - mae: 29.1334 - mape: 11.0483 - val_loss: 10.2428 - val_mae: 18.2004 - val_mape: 10.2428 - lr: 9.0000e-05\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.2034 - mae: 26.5401 - mape: 10.2034 - val_loss: 10.2324 - val_mae: 17.4902 - val_mape: 10.2324 - lr: 9.0000e-05\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.4672 - mae: 26.5044 - mape: 10.4672 - val_loss: 10.2801 - val_mae: 17.5636 - val_mape: 10.2801 - lr: 9.0000e-05\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.3606 - mae: 28.3948 - mape: 10.3606 - val_loss: 10.4131 - val_mae: 18.2696 - val_mape: 10.4131 - lr: 9.0000e-05\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.3279 - mae: 25.7695 - mape: 10.3279 - val_loss: 10.5856 - val_mae: 17.7429 - val_mape: 10.5856 - lr: 9.0000e-05\n",
      "Epoch 111/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 10.3824 - mae: 28.3090 - mape: 10.3824INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 19ms/step - loss: 10.4106 - mae: 29.2590 - mape: 10.4106 - val_loss: 10.0817 - val_mae: 16.3116 - val_mape: 10.0817 - lr: 9.0000e-05\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3942 - mae: 26.8912 - mape: 10.3942 - val_loss: 10.1522 - val_mae: 18.8069 - val_mape: 10.1522 - lr: 9.0000e-05\n",
      "Epoch 113/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 10.5317 - mae: 28.4047 - mape: 10.5317INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 15ms/step - loss: 10.5395 - mae: 28.7792 - mape: 10.5395 - val_loss: 10.0469 - val_mae: 17.1306 - val_mape: 10.0469 - lr: 9.0000e-05\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.3029 - mae: 27.8809 - mape: 10.3029 - val_loss: 10.1641 - val_mae: 19.8774 - val_mape: 10.1641 - lr: 9.0000e-05\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.3015 - mae: 26.1321 - mape: 10.3015 - val_loss: 10.4326 - val_mae: 19.2109 - val_mape: 10.4326 - lr: 9.0000e-05\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.3186 - mae: 25.9603 - mape: 10.3186 - val_loss: 10.0990 - val_mae: 17.9790 - val_mape: 10.0990 - lr: 9.0000e-05\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.3764 - mae: 27.1369 - mape: 10.3764 - val_loss: 10.1567 - val_mae: 16.6324 - val_mape: 10.1567 - lr: 9.0000e-05\n",
      "Epoch 118/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 10.3471 - mae: 25.8950 - mape: 10.3471INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 14ms/step - loss: 10.3526 - mae: 25.9832 - mape: 10.3526 - val_loss: 10.0455 - val_mae: 16.7237 - val_mape: 10.0455 - lr: 9.0000e-05\n",
      "Epoch 119/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 10.2245 - mae: 28.6880 - mape: 10.2245INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 14ms/step - loss: 10.2014 - mae: 28.4202 - mape: 10.2014 - val_loss: 10.0061 - val_mae: 15.9912 - val_mape: 10.0061 - lr: 9.0000e-05\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3436 - mae: 28.0420 - mape: 10.3436 - val_loss: 10.0521 - val_mae: 16.6451 - val_mape: 10.0521 - lr: 9.0000e-05\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5227 - mae: 27.0510 - mape: 10.5227 - val_loss: 10.1223 - val_mae: 19.2421 - val_mape: 10.1223 - lr: 9.0000e-05\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6688 - mae: 29.1744 - mape: 10.6688 - val_loss: 10.0095 - val_mae: 16.6696 - val_mape: 10.0095 - lr: 9.0000e-05\n",
      "Epoch 123/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 10.2787 - mae: 26.6776 - mape: 10.2787INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 15ms/step - loss: 10.3260 - mae: 27.0958 - mape: 10.3260 - val_loss: 9.9805 - val_mae: 16.1158 - val_mape: 9.9805 - lr: 9.0000e-05\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3244 - mae: 28.7792 - mape: 10.3244 - val_loss: 9.9929 - val_mae: 17.1996 - val_mape: 9.9929 - lr: 9.0000e-05\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4157 - mae: 27.0084 - mape: 10.4157 - val_loss: 9.9942 - val_mae: 16.5729 - val_mape: 9.9942 - lr: 9.0000e-05\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.1386 - mae: 27.0220 - mape: 10.1386 - val_loss: 10.1338 - val_mae: 16.2009 - val_mape: 10.1338 - lr: 9.0000e-05\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 10.2438 - mae: 27.1518 - mape: 10.2438 - val_loss: 10.0688 - val_mae: 16.6025 - val_mape: 10.0688 - lr: 9.0000e-05\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.1329 - mae: 26.1182 - mape: 10.1329 - val_loss: 10.4190 - val_mae: 17.3722 - val_mape: 10.4190 - lr: 9.0000e-05\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.5319 - mae: 26.3779 - mape: 10.5319 - val_loss: 10.9584 - val_mae: 20.3544 - val_mape: 10.9584 - lr: 9.0000e-05\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 10.5502 - mae: 27.4132 - mape: 10.5502 - val_loss: 10.8837 - val_mae: 20.1550 - val_mape: 10.8837 - lr: 9.0000e-05\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4604 - mae: 29.3205 - mape: 10.4604 - val_loss: 10.2905 - val_mae: 16.9075 - val_mape: 10.2905 - lr: 9.0000e-05\n",
      "Epoch 132/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 10.4265 - mae: 28.1277 - mape: 10.4265INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 18ms/step - loss: 10.2739 - mae: 27.2111 - mape: 10.2739 - val_loss: 9.9756 - val_mae: 17.9282 - val_mape: 9.9756 - lr: 9.0000e-05\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3488 - mae: 25.9497 - mape: 10.3488 - val_loss: 10.0990 - val_mae: 18.1853 - val_mape: 10.0990 - lr: 9.0000e-05\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4214 - mae: 25.9676 - mape: 10.4214 - val_loss: 9.9898 - val_mae: 16.7181 - val_mape: 9.9898 - lr: 9.0000e-05\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.1885 - mae: 28.6364 - mape: 10.1885 - val_loss: 10.2857 - val_mae: 18.8160 - val_mape: 10.2857 - lr: 9.0000e-05\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.3105 - mae: 25.1091 - mape: 10.3105 - val_loss: 10.1445 - val_mae: 16.4706 - val_mape: 10.1445 - lr: 9.0000e-05\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.2382 - mae: 27.9368 - mape: 10.2382 - val_loss: 10.1191 - val_mae: 20.1407 - val_mape: 10.1191 - lr: 9.0000e-05\n",
      "Epoch 138/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 10.2779 - mae: 26.4528 - mape: 10.2779INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 10.2865 - mae: 26.9157 - mape: 10.2865 - val_loss: 9.9604 - val_mae: 17.5251 - val_mape: 9.9604 - lr: 9.0000e-05\n",
      "Epoch 139/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 10.0328 - mae: 24.9287 - mape: 10.0328INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 17ms/step - loss: 10.0155 - mae: 24.8401 - mape: 10.0155 - val_loss: 9.9484 - val_mae: 16.0683 - val_mape: 9.9484 - lr: 9.0000e-05\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1825 - mae: 26.5873 - mape: 10.1825 - val_loss: 10.0088 - val_mae: 17.2532 - val_mape: 10.0088 - lr: 9.0000e-05\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.2502 - mae: 27.8278 - mape: 10.2502 - val_loss: 10.0636 - val_mae: 16.5511 - val_mape: 10.0636 - lr: 9.0000e-05\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.4028 - mae: 27.9564 - mape: 10.4028 - val_loss: 10.0425 - val_mae: 16.3017 - val_mape: 10.0425 - lr: 9.0000e-05\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.1416 - mae: 26.7286 - mape: 10.1416 - val_loss: 10.0587 - val_mae: 18.0045 - val_mape: 10.0587 - lr: 9.0000e-05\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4657 - mae: 28.5248 - mape: 10.4657 - val_loss: 10.8444 - val_mae: 17.7237 - val_mape: 10.8444 - lr: 9.0000e-05\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3780 - mae: 25.3946 - mape: 10.3780 - val_loss: 10.2897 - val_mae: 18.3807 - val_mape: 10.2897 - lr: 9.0000e-05\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.2770 - mae: 28.2518 - mape: 10.2770 - val_loss: 9.9837 - val_mae: 18.0357 - val_mape: 9.9837 - lr: 9.0000e-05\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.0768 - mae: 25.9124 - mape: 10.0768INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 10.0768 - mae: 25.9124 - mape: 10.0768 - val_loss: 9.9071 - val_mae: 17.5885 - val_mape: 9.9071 - lr: 9.0000e-05\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 1s 8ms/step - loss: 10.2745 - mae: 26.9284 - mape: 10.2745 - val_loss: 10.0672 - val_mae: 19.3018 - val_mape: 10.0672 - lr: 9.0000e-05\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.2719 - mae: 28.2419 - mape: 10.2719 - val_loss: 10.0739 - val_mae: 16.4969 - val_mape: 10.0739 - lr: 9.0000e-05\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.1605 - mae: 25.9886 - mape: 10.1605 - val_loss: 10.2276 - val_mae: 19.2344 - val_mape: 10.2276 - lr: 9.0000e-05\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.3137 - mae: 26.9878 - mape: 10.3137 - val_loss: 10.0312 - val_mae: 18.5402 - val_mape: 10.0312 - lr: 9.0000e-05\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2141 - mae: 27.7559 - mape: 10.2141 - val_loss: 10.8186 - val_mae: 19.0122 - val_mape: 10.8186 - lr: 9.0000e-05\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3605 - mae: 26.1143 - mape: 10.3605 - val_loss: 10.0744 - val_mae: 17.0831 - val_mape: 10.0744 - lr: 9.0000e-05\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2771 - mae: 28.2091 - mape: 10.2771 - val_loss: 10.1173 - val_mae: 17.0325 - val_mape: 10.1173 - lr: 9.0000e-05\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1779 - mae: 25.3225 - mape: 10.1779 - val_loss: 10.2531 - val_mae: 17.0336 - val_mape: 10.2531 - lr: 9.0000e-05\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4226 - mae: 26.4248 - mape: 10.4226 - val_loss: 10.5269 - val_mae: 20.0343 - val_mape: 10.5269 - lr: 9.0000e-05\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1972 - mae: 27.2755 - mape: 10.1972 - val_loss: 10.3147 - val_mae: 16.9787 - val_mape: 10.3147 - lr: 9.0000e-05\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3671 - mae: 26.4056 - mape: 10.3671 - val_loss: 9.9750 - val_mae: 20.5935 - val_mape: 9.9750 - lr: 9.0000e-05\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0722 - mae: 26.9745 - mape: 10.0722 - val_loss: 10.0284 - val_mae: 16.3800 - val_mape: 10.0284 - lr: 9.0000e-05\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1404 - mae: 26.8863 - mape: 10.1404 - val_loss: 10.5585 - val_mae: 17.4364 - val_mape: 10.5585 - lr: 9.0000e-05\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2923 - mae: 28.8330 - mape: 10.2923 - val_loss: 10.1241 - val_mae: 17.3835 - val_mape: 10.1241 - lr: 9.0000e-05\n",
      "Epoch 162/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 10.1538 - mae: 28.5197 - mape: 10.1538INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 22ms/step - loss: 10.2308 - mae: 28.0646 - mape: 10.2308 - val_loss: 9.8907 - val_mae: 16.4537 - val_mape: 9.8907 - lr: 9.0000e-05\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4082 - mae: 28.2755 - mape: 10.4082 - val_loss: 10.4039 - val_mae: 17.1981 - val_mape: 10.4039 - lr: 9.0000e-05\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.2871 - mae: 27.4166 - mape: 10.2871 - val_loss: 10.1742 - val_mae: 18.2419 - val_mape: 10.1742 - lr: 9.0000e-05\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.3893 - mae: 26.9739 - mape: 10.3893 - val_loss: 10.3256 - val_mae: 17.7313 - val_mape: 10.3256 - lr: 9.0000e-05\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.3509 - mae: 26.5363 - mape: 10.3509 - val_loss: 10.0683 - val_mae: 17.4593 - val_mape: 10.0683 - lr: 9.0000e-05\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6436 - mae: 29.4320 - mape: 10.6436 - val_loss: 10.1580 - val_mae: 17.6562 - val_mape: 10.1580 - lr: 9.0000e-05\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.2009 - mae: 27.0732 - mape: 10.2009 - val_loss: 10.3075 - val_mae: 17.7177 - val_mape: 10.3075 - lr: 9.0000e-05\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.0797 - mae: 29.0881 - mape: 10.0797 - val_loss: 11.1501 - val_mae: 19.8653 - val_mape: 11.1501 - lr: 9.0000e-05\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3087 - mae: 27.8948 - mape: 10.3087 - val_loss: 10.0640 - val_mae: 17.4830 - val_mape: 10.0640 - lr: 9.0000e-05\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1248 - mae: 27.6341 - mape: 10.1248 - val_loss: 10.0625 - val_mae: 16.4477 - val_mape: 10.0625 - lr: 9.0000e-05\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2329 - mae: 27.4026 - mape: 10.2329 - val_loss: 10.8525 - val_mae: 18.3210 - val_mape: 10.8525 - lr: 9.0000e-05\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0495 - mae: 26.2374 - mape: 10.0495 - val_loss: 10.4505 - val_mae: 17.7781 - val_mape: 10.4505 - lr: 9.0000e-05\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.2900 - mae: 27.9902 - mape: 10.2900 - val_loss: 10.0479 - val_mae: 17.7009 - val_mape: 10.0479 - lr: 9.0000e-05\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2834 - mae: 25.9708 - mape: 10.2834 - val_loss: 10.1190 - val_mae: 17.4645 - val_mape: 10.1190 - lr: 9.0000e-05\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0977 - mae: 26.0417 - mape: 10.0977 - val_loss: 10.1849 - val_mae: 19.7488 - val_mape: 10.1849 - lr: 9.0000e-05\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.5140 - mae: 27.8685 - mape: 10.5140 - val_loss: 10.1564 - val_mae: 16.4408 - val_mape: 10.1564 - lr: 9.0000e-05\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3433 - mae: 27.6263 - mape: 10.3433 - val_loss: 10.0480 - val_mae: 16.4246 - val_mape: 10.0480 - lr: 9.0000e-05\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1201 - mae: 26.5496 - mape: 10.1201 - val_loss: 10.4231 - val_mae: 21.6146 - val_mape: 10.4231 - lr: 9.0000e-05\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1656 - mae: 28.7169 - mape: 10.1656 - val_loss: 10.2204 - val_mae: 16.7142 - val_mape: 10.2204 - lr: 9.0000e-05\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3645 - mae: 26.4784 - mape: 10.3645 - val_loss: 10.0830 - val_mae: 16.9307 - val_mape: 10.0830 - lr: 9.0000e-05\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3825 - mae: 28.8075 - mape: 10.3825 - val_loss: 10.0745 - val_mae: 18.3231 - val_mape: 10.0745 - lr: 9.0000e-05\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0562 - mae: 28.2411 - mape: 10.0562 - val_loss: 10.1110 - val_mae: 17.1931 - val_mape: 10.1110 - lr: 9.0000e-05\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2835 - mae: 27.9501 - mape: 10.2835 - val_loss: 10.2098 - val_mae: 17.2317 - val_mape: 10.2098 - lr: 9.0000e-05\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0331 - mae: 26.5520 - mape: 10.0331 - val_loss: 10.1254 - val_mae: 16.8246 - val_mape: 10.1254 - lr: 9.0000e-05\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.9933 - mae: 26.6527 - mape: 9.9933 - val_loss: 10.1474 - val_mae: 18.5614 - val_mape: 10.1474 - lr: 9.0000e-05\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0254 - mae: 27.2565 - mape: 10.0254 - val_loss: 10.4276 - val_mae: 17.2676 - val_mape: 10.4276 - lr: 9.0000e-05\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1453 - mae: 27.0510 - mape: 10.1453 - val_loss: 10.1705 - val_mae: 17.0390 - val_mape: 10.1705 - lr: 9.0000e-05\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1677 - mae: 26.7426 - mape: 10.1677 - val_loss: 10.2628 - val_mae: 17.1968 - val_mape: 10.2628 - lr: 9.0000e-05\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2364 - mae: 26.1423 - mape: 10.2364 - val_loss: 10.1439 - val_mae: 16.6228 - val_mape: 10.1439 - lr: 9.0000e-05\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3807 - mae: 26.7139 - mape: 10.3807 - val_loss: 10.1143 - val_mae: 18.1620 - val_mape: 10.1143 - lr: 9.0000e-05\n",
      "Epoch 192/1000\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 10.0235 - mae: 25.6140 - mape: 10.0235\n",
      "Epoch 192: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0218 - mae: 25.4345 - mape: 10.0218 - val_loss: 10.1092 - val_mae: 16.2014 - val_mape: 10.1092 - lr: 9.0000e-05\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.9271 - mae: 26.8840 - mape: 9.9271 - val_loss: 10.0618 - val_mae: 16.2017 - val_mape: 10.0618 - lr: 2.7000e-05\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.8696 - mae: 27.1724 - mape: 9.8696 - val_loss: 10.0373 - val_mae: 16.1275 - val_mape: 10.0373 - lr: 2.7000e-05\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0170 - mae: 28.1117 - mape: 10.0170 - val_loss: 10.0693 - val_mae: 18.0117 - val_mape: 10.0693 - lr: 2.7000e-05\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0524 - mae: 26.1397 - mape: 10.0524 - val_loss: 10.0881 - val_mae: 17.7668 - val_mape: 10.0881 - lr: 2.7000e-05\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2881 - mae: 27.6166 - mape: 10.2881 - val_loss: 10.0600 - val_mae: 16.6832 - val_mape: 10.0600 - lr: 2.7000e-05\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8523 - mae: 26.9474 - mape: 9.8523 - val_loss: 10.2255 - val_mae: 17.3701 - val_mape: 10.2255 - lr: 2.7000e-05\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8638 - mae: 25.6715 - mape: 9.8638 - val_loss: 10.0639 - val_mae: 17.5975 - val_mape: 10.0639 - lr: 2.7000e-05\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.0757 - mae: 25.0637 - mape: 10.0757 - val_loss: 10.1538 - val_mae: 17.4964 - val_mape: 10.1538 - lr: 2.7000e-05\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0445 - mae: 26.1979 - mape: 10.0445 - val_loss: 10.1210 - val_mae: 17.0987 - val_mape: 10.1210 - lr: 2.7000e-05\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1849 - mae: 28.3265 - mape: 10.1849 - val_loss: 10.1226 - val_mae: 17.6118 - val_mape: 10.1226 - lr: 2.7000e-05\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.1737 - mae: 28.9458 - mape: 10.1737 - val_loss: 10.0291 - val_mae: 16.7633 - val_mape: 10.0291 - lr: 2.7000e-05\n",
      "Epoch 204/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.0675 - mae: 27.1142 - mape: 10.0675 - val_loss: 10.0269 - val_mae: 17.2740 - val_mape: 10.0269 - lr: 2.7000e-05\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.8113 - mae: 26.2811 - mape: 9.8113 - val_loss: 10.0222 - val_mae: 16.7503 - val_mape: 10.0222 - lr: 2.7000e-05\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8430 - mae: 25.5338 - mape: 9.8430 - val_loss: 10.0243 - val_mae: 16.3568 - val_mape: 10.0243 - lr: 2.7000e-05\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.9201 - mae: 26.2202 - mape: 9.9201 - val_loss: 10.0849 - val_mae: 17.3603 - val_mape: 10.0849 - lr: 2.7000e-05\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.9283 - mae: 27.9237 - mape: 9.9283 - val_loss: 10.1085 - val_mae: 16.6242 - val_mape: 10.1085 - lr: 2.7000e-05\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.9186 - mae: 23.8448 - mape: 9.9186 - val_loss: 10.0814 - val_mae: 16.7985 - val_mape: 10.0814 - lr: 2.7000e-05\n",
      "Epoch 210/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8789 - mae: 24.6494 - mape: 9.8789 - val_loss: 10.0220 - val_mae: 16.2311 - val_mape: 10.0220 - lr: 2.7000e-05\n",
      "Epoch 211/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.7419 - mae: 26.6928 - mape: 9.7419 - val_loss: 10.1393 - val_mae: 16.8271 - val_mape: 10.1393 - lr: 2.7000e-05\n",
      "Epoch 212/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8221 - mae: 23.9876 - mape: 9.8221 - val_loss: 10.0793 - val_mae: 16.5628 - val_mape: 10.0793 - lr: 2.7000e-05\n",
      "Epoch 213/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.7796 - mae: 24.0838 - mape: 9.7796 - val_loss: 10.0451 - val_mae: 17.8647 - val_mape: 10.0451 - lr: 2.7000e-05\n",
      "Epoch 214/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8461 - mae: 25.7997 - mape: 9.8461 - val_loss: 10.0102 - val_mae: 18.0045 - val_mape: 10.0102 - lr: 2.7000e-05\n",
      "Epoch 215/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.9426 - mae: 27.8268 - mape: 9.9426 - val_loss: 10.1175 - val_mae: 16.7211 - val_mape: 10.1175 - lr: 2.7000e-05\n",
      "Epoch 216/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8579 - mae: 25.9860 - mape: 9.8579 - val_loss: 10.0472 - val_mae: 17.1306 - val_mape: 10.0472 - lr: 2.7000e-05\n",
      "Epoch 217/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0725 - mae: 28.7526 - mape: 10.0725 - val_loss: 10.0372 - val_mae: 16.4060 - val_mape: 10.0372 - lr: 2.7000e-05\n",
      "Epoch 218/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0800 - mae: 27.9830 - mape: 10.0800 - val_loss: 10.1196 - val_mae: 16.5940 - val_mape: 10.1196 - lr: 2.7000e-05\n",
      "Epoch 219/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.8735 - mae: 24.1910 - mape: 9.8735 - val_loss: 10.1039 - val_mae: 16.2551 - val_mape: 10.1039 - lr: 2.7000e-05\n",
      "Epoch 220/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.7485 - mae: 24.6542 - mape: 9.7485 - val_loss: 10.0915 - val_mae: 16.2748 - val_mape: 10.0915 - lr: 2.7000e-05\n",
      "Epoch 221/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.0781 - mae: 24.9475 - mape: 10.0781 - val_loss: 10.1896 - val_mae: 16.7858 - val_mape: 10.1896 - lr: 2.7000e-05\n",
      "Epoch 222/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.8682 - mae: 25.6141 - mape: 9.8682\n",
      "Epoch 222: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8478 - mae: 25.6754 - mape: 9.8478 - val_loss: 10.1143 - val_mae: 16.8272 - val_mape: 10.1143 - lr: 2.7000e-05\n",
      "Epoch 222: early stopping\n",
      "Score for fold 3: loss of 9.890689849853516; mae of 16.45372200012207; mape of 9.890689849853516%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.1989 - mae: 34.1439 - mape: 14.1989INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 18ms/step - loss: 14.1989 - mae: 34.1439 - mape: 14.1989 - val_loss: 9.8322 - val_mae: 26.7207 - val_mape: 9.8322 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.9794 - mae: 31.4326 - mape: 12.9794 - val_loss: 10.2515 - val_mae: 24.1715 - val_mape: 10.2515 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.5398 - mae: 32.9494 - mape: 13.5398 - val_loss: 15.5947 - val_mae: 45.1827 - val_mape: 15.5947 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 14.3916 - mae: 32.1472 - mape: 14.3916INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 17ms/step - loss: 14.3926 - mae: 32.7002 - mape: 14.3926 - val_loss: 9.4178 - val_mae: 24.0805 - val_mape: 9.4178 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.0632 - mae: 37.4549 - mape: 14.0632 - val_loss: 10.4835 - val_mae: 52.7439 - val_mape: 10.4835 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.8517 - mae: 32.9873 - mape: 13.8517 - val_loss: 10.7219 - val_mae: 27.4272 - val_mape: 10.7219 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 13.9343 - mae: 32.9091 - mape: 13.9343 - val_loss: 19.1627 - val_mae: 40.5926 - val_mape: 19.1627 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.5774 - mae: 40.4008 - mape: 14.5774 - val_loss: 10.2421 - val_mae: 25.7413 - val_mape: 10.2421 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.1719 - mae: 32.5661 - mape: 13.1719 - val_loss: 9.6247 - val_mae: 27.6322 - val_mape: 9.6247 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 13.1623 - mae: 32.3597 - mape: 13.1623INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 21ms/step - loss: 13.1332 - mae: 32.2203 - mape: 13.1332 - val_loss: 9.0700 - val_mae: 25.2375 - val_mape: 9.0700 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.0400 - mae: 32.2703 - mape: 13.0400 - val_loss: 10.1672 - val_mae: 28.7997 - val_mape: 10.1672 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 12.9747 - mae: 37.0796 - mape: 12.9747 - val_loss: 11.5151 - val_mae: 64.6641 - val_mape: 11.5151 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.6793 - mae: 34.3733 - mape: 14.6793 - val_loss: 11.4017 - val_mae: 47.4837 - val_mape: 11.4017 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 13.2413 - mae: 36.0582 - mape: 13.2413 - val_loss: 9.8402 - val_mae: 30.3062 - val_mape: 9.8402 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.8266 - mae: 30.1512 - mape: 12.8266 - val_loss: 18.6023 - val_mae: 35.0534 - val_mape: 18.6023 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.8426 - mae: 35.0263 - mape: 13.8426 - val_loss: 9.5762 - val_mae: 33.6329 - val_mape: 9.5762 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6452 - mae: 31.2679 - mape: 12.6452 - val_loss: 11.0844 - val_mae: 38.8891 - val_mape: 11.0844 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.1887 - mae: 35.6317 - mape: 13.1887 - val_loss: 14.6314 - val_mae: 28.2743 - val_mape: 14.6314 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.7008 - mae: 35.4031 - mape: 12.7008 - val_loss: 11.2766 - val_mae: 28.0038 - val_mape: 11.2766 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.8790 - mae: 36.3554 - mape: 13.8790 - val_loss: 15.7555 - val_mae: 56.2220 - val_mape: 15.7555 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.7461 - mae: 33.1392 - mape: 13.7461 - val_loss: 9.8276 - val_mae: 39.3545 - val_mape: 9.8276 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.4185 - mae: 41.5598 - mape: 14.4185 - val_loss: 10.1170 - val_mae: 39.8954 - val_mape: 10.1170 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.5964 - mae: 34.1000 - mape: 13.5964 - val_loss: 10.8689 - val_mae: 28.4175 - val_mape: 10.8689 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.5658 - mae: 37.5772 - mape: 15.5658 - val_loss: 9.9630 - val_mae: 29.1794 - val_mape: 9.9630 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.4543 - mae: 35.4598 - mape: 13.4543 - val_loss: 12.3898 - val_mae: 39.4699 - val_mape: 12.3898 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.2763 - mae: 32.4851 - mape: 13.2763 - val_loss: 21.1114 - val_mae: 41.1564 - val_mape: 21.1114 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.2633 - mae: 35.4096 - mape: 14.2633 - val_loss: 12.2439 - val_mae: 60.2511 - val_mape: 12.2439 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.2586 - mae: 32.3376 - mape: 13.2586 - val_loss: 10.3110 - val_mae: 28.0870 - val_mape: 10.3110 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.1291 - mae: 31.3939 - mape: 13.1291 - val_loss: 10.2454 - val_mae: 44.8102 - val_mape: 10.2454 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.2993 - mae: 30.2802 - mape: 13.2993 - val_loss: 12.1237 - val_mae: 25.6703 - val_mape: 12.1237 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.0333 - mae: 33.0495 - mape: 13.0333 - val_loss: 10.1823 - val_mae: 32.4589 - val_mape: 10.1823 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.6799 - mae: 31.9856 - mape: 12.6799 - val_loss: 13.7500 - val_mae: 40.0026 - val_mape: 13.7500 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.5798 - mae: 32.7752 - mape: 13.5798 - val_loss: 10.9857 - val_mae: 26.5949 - val_mape: 10.9857 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.6616 - mae: 31.0468 - mape: 13.6616 - val_loss: 11.4685 - val_mae: 25.0809 - val_mape: 11.4685 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.1704 - mae: 39.2467 - mape: 13.1704 - val_loss: 10.8015 - val_mae: 27.3905 - val_mape: 10.8015 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.1830 - mae: 32.5328 - mape: 14.1830 - val_loss: 10.9376 - val_mae: 27.5284 - val_mape: 10.9376 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.8292 - mae: 31.4500 - mape: 12.8292 - val_loss: 11.6835 - val_mae: 30.6606 - val_mape: 11.6835 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.6631 - mae: 30.8478 - mape: 13.6631 - val_loss: 22.9342 - val_mae: 61.3515 - val_mape: 22.9342 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.5231 - mae: 40.2592 - mape: 14.5231 - val_loss: 12.6619 - val_mae: 62.8755 - val_mape: 12.6619 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 13.1524 - mae: 32.9344 - mape: 13.1524\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.1834 - mae: 34.1087 - mape: 13.1834 - val_loss: 12.8800 - val_mae: 28.0353 - val_mape: 12.8800 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.5014 - mae: 30.1267 - mape: 11.5014 - val_loss: 11.1352 - val_mae: 26.8741 - val_mape: 11.1352 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.0934 - mae: 26.5983 - mape: 11.0934 - val_loss: 10.2621 - val_mae: 26.6656 - val_mape: 10.2621 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.0846 - mae: 27.2584 - mape: 11.0846 - val_loss: 9.5759 - val_mae: 27.2887 - val_mape: 9.5759 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.9205 - mae: 24.8511 - mape: 10.9205 - val_loss: 9.4114 - val_mae: 27.6364 - val_mape: 9.4114 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.0213 - mae: 27.3754 - mape: 11.0213 - val_loss: 9.5483 - val_mae: 26.5189 - val_mape: 9.5483 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8563 - mae: 27.7428 - mape: 10.8563 - val_loss: 9.4904 - val_mae: 24.5876 - val_mape: 9.4904 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.8974 - mae: 26.5773 - mape: 10.8974 - val_loss: 9.3555 - val_mae: 24.7595 - val_mape: 9.3555 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.9732 - mae: 28.9773 - mape: 10.9732 - val_loss: 10.0323 - val_mae: 27.8107 - val_mape: 10.0323 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.2581 - mae: 27.8941 - mape: 11.2581 - val_loss: 9.7859 - val_mae: 35.2062 - val_mape: 9.7859 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.0276 - mae: 26.5338 - mape: 11.0276 - val_loss: 9.7577 - val_mae: 30.0518 - val_mape: 9.7577 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.8059 - mae: 27.6620 - mape: 10.8059 - val_loss: 9.6669 - val_mae: 24.2629 - val_mape: 9.6669 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.8565 - mae: 27.2781 - mape: 10.8565 - val_loss: 10.4731 - val_mae: 37.1398 - val_mape: 10.4731 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7235 - mae: 24.2702 - mape: 10.7235 - val_loss: 10.3242 - val_mae: 25.1351 - val_mape: 10.3242 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7658 - mae: 27.0515 - mape: 10.7658 - val_loss: 11.0815 - val_mae: 29.2259 - val_mape: 11.0815 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.8134 - mae: 28.2346 - mape: 11.8134 - val_loss: 9.8386 - val_mae: 32.1361 - val_mape: 9.8386 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.2398 - mae: 27.5625 - mape: 11.2398 - val_loss: 9.5256 - val_mae: 29.1502 - val_mape: 9.5256 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.0240 - mae: 26.5388 - mape: 11.0240 - val_loss: 9.3574 - val_mae: 23.2395 - val_mape: 9.3574 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.8561 - mae: 27.2041 - mape: 10.8561 - val_loss: 9.2944 - val_mae: 26.1282 - val_mape: 9.2944 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.9892 - mae: 26.8846 - mape: 10.9892 - val_loss: 9.2713 - val_mae: 25.5149 - val_mape: 9.2713 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7995 - mae: 25.1259 - mape: 10.7995 - val_loss: 9.4201 - val_mae: 25.4299 - val_mape: 9.4201 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.8386 - mae: 26.3015 - mape: 10.8386 - val_loss: 9.4309 - val_mae: 22.8440 - val_mape: 9.4309 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.1187 - mae: 27.9231 - mape: 11.1187 - val_loss: 9.6411 - val_mae: 26.7035 - val_mape: 9.6411 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6013 - mae: 25.3396 - mape: 10.6013 - val_loss: 11.4756 - val_mae: 32.0312 - val_mape: 11.4756 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.1911 - mae: 28.0289 - mape: 11.1911 - val_loss: 10.5772 - val_mae: 25.7757 - val_mape: 10.5772 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.5821 - mae: 24.8184 - mape: 10.5821 - val_loss: 10.0114 - val_mae: 41.8152 - val_mape: 10.0114 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6331 - mae: 27.3415 - mape: 10.6331 - val_loss: 9.4845 - val_mae: 23.7637 - val_mape: 9.4845 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7899 - mae: 27.9055 - mape: 10.7899 - val_loss: 9.5523 - val_mae: 32.8774 - val_mape: 9.5523 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6624 - mae: 28.1779 - mape: 10.6624 - val_loss: 9.2368 - val_mae: 24.5430 - val_mape: 9.2368 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8698 - mae: 29.0117 - mape: 10.8698 - val_loss: 10.0813 - val_mae: 22.9097 - val_mape: 10.0813 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 10.7311 - mae: 27.5379 - mape: 10.7311\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7583 - mae: 27.3483 - mape: 10.7583 - val_loss: 9.7084 - val_mae: 24.4047 - val_mape: 9.7084 - lr: 3.0000e-04\n",
      "Epoch 70: early stopping\n",
      "Score for fold 4: loss of 9.070025444030762; mae of 25.237478256225586; mape of 9.070025444030762%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n",
      "77/87 [=========================>....] - ETA: 0s - loss: 13.5631 - mae: 39.3884 - mape: 13.5631INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 18ms/step - loss: 13.5807 - mae: 39.8489 - mape: 13.5807 - val_loss: 12.6354 - val_mae: 26.5764 - val_mape: 12.6354 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.1546 - mae: 33.3775 - mape: 13.1546 - val_loss: 17.6874 - val_mae: 31.6580 - val_mape: 17.6874 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 14.2208 - mae: 34.8204 - mape: 14.2208 - val_loss: 12.7512 - val_mae: 21.9346 - val_mape: 12.7512 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 14.5202 - mae: 34.6179 - mape: 14.5202INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 24ms/step - loss: 14.5245 - mae: 34.0384 - mape: 14.5245 - val_loss: 10.7412 - val_mae: 24.8769 - val_mape: 10.7412 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 12.9324 - mae: 38.7332 - mape: 12.9324INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 18ms/step - loss: 12.9103 - mae: 39.1640 - mape: 12.9103 - val_loss: 10.6821 - val_mae: 29.6964 - val_mape: 10.6821 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 12.9131 - mae: 36.6993 - mape: 12.9131 - val_loss: 11.5270 - val_mae: 57.0068 - val_mape: 11.5270 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 13.4582 - mae: 38.6144 - mape: 13.4582 - val_loss: 11.3094 - val_mae: 23.8550 - val_mape: 11.3094 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.4271 - mae: 30.8414 - mape: 12.4271 - val_loss: 11.8099 - val_mae: 27.9986 - val_mape: 11.8099 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 15.4769 - mae: 36.4922 - mape: 15.4769 - val_loss: 19.2291 - val_mae: 43.4812 - val_mape: 19.2291 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.3711 - mae: 42.0147 - mape: 15.3711 - val_loss: 14.1276 - val_mae: 45.7013 - val_mape: 14.1276 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.4460 - mae: 32.7936 - mape: 13.4460 - val_loss: 11.5316 - val_mae: 28.9599 - val_mape: 11.5316 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.9438 - mae: 34.0759 - mape: 12.9438 - val_loss: 11.5262 - val_mae: 26.6928 - val_mape: 11.5262 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 13.6337 - mae: 35.2371 - mape: 13.6337 - val_loss: 11.7521 - val_mae: 27.0691 - val_mape: 11.7521 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 14.1016 - mae: 35.9105 - mape: 14.1016 - val_loss: 11.9175 - val_mae: 30.8133 - val_mape: 11.9175 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 13.1534 - mae: 32.7043 - mape: 13.1534 - val_loss: 14.0719 - val_mae: 35.5611 - val_mape: 14.0719 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 13.1293 - mae: 35.0008 - mape: 13.1293INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 28ms/step - loss: 13.0969 - mae: 34.6494 - mape: 13.0969 - val_loss: 10.6013 - val_mae: 23.1082 - val_mape: 10.6013 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.0769 - mae: 33.9768 - mape: 13.0769 - val_loss: 11.2456 - val_mae: 25.2694 - val_mape: 11.2456 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.3699 - mae: 36.1842 - mape: 13.3699 - val_loss: 11.8382 - val_mae: 41.2848 - val_mape: 11.8382 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.6120 - mae: 37.3446 - mape: 12.6120 - val_loss: 14.3047 - val_mae: 31.6429 - val_mape: 14.3047 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.9787 - mae: 31.4678 - mape: 12.9787 - val_loss: 11.4783 - val_mae: 29.9914 - val_mape: 11.4783 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.2269 - mae: 38.9535 - mape: 13.2269 - val_loss: 14.2681 - val_mae: 32.6670 - val_mape: 14.2681 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.2841 - mae: 32.3810 - mape: 13.2841 - val_loss: 15.8307 - val_mae: 22.5622 - val_mape: 15.8307 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 15.5361 - mae: 37.2473 - mape: 15.5361 - val_loss: 11.7959 - val_mae: 28.5890 - val_mape: 11.7959 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.0213 - mae: 35.2281 - mape: 13.0213 - val_loss: 10.9576 - val_mae: 44.2444 - val_mape: 10.9576 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 13.0645 - mae: 35.7108 - mape: 13.0645 - val_loss: 10.7093 - val_mae: 24.4300 - val_mape: 10.7093 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 15.3256 - mae: 41.1134 - mape: 15.3256 - val_loss: 12.8005 - val_mae: 49.6663 - val_mape: 12.8005 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 13.3495 - mae: 36.3486 - mape: 13.3495 - val_loss: 12.0617 - val_mae: 48.2612 - val_mape: 12.0617 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6032 - mae: 32.5443 - mape: 12.6032 - val_loss: 12.2739 - val_mae: 32.4000 - val_mape: 12.2739 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 14.0802 - mae: 38.2285 - mape: 14.0802 - val_loss: 14.8521 - val_mae: 26.0495 - val_mape: 14.8521 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.2914 - mae: 38.6902 - mape: 13.2914 - val_loss: 12.7643 - val_mae: 44.6372 - val_mape: 12.7643 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.5343 - mae: 33.4032 - mape: 12.5343 - val_loss: 12.6948 - val_mae: 30.9063 - val_mape: 12.6948 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.3070 - mae: 36.9023 - mape: 13.3070 - val_loss: 12.3952 - val_mae: 32.3221 - val_mape: 12.3952 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.3154 - mae: 32.9061 - mape: 13.3154 - val_loss: 12.3156 - val_mae: 29.8419 - val_mape: 12.3156 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.3406 - mae: 34.3674 - mape: 13.3406 - val_loss: 10.9046 - val_mae: 27.5046 - val_mape: 10.9046 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.5461 - mae: 32.2978 - mape: 12.5461 - val_loss: 12.1562 - val_mae: 23.9675 - val_mape: 12.1562 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 12.7624 - mae: 38.1918 - mape: 12.7624 - val_loss: 12.0542 - val_mae: 28.7431 - val_mape: 12.0542 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.1938 - mae: 32.9089 - mape: 13.1938 - val_loss: 13.4218 - val_mae: 27.2146 - val_mape: 13.4218 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.3759 - mae: 33.8350 - mape: 13.3759 - val_loss: 12.4639 - val_mae: 25.8831 - val_mape: 12.4639 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.5017 - mae: 34.5175 - mape: 13.5017 - val_loss: 15.9676 - val_mae: 34.3969 - val_mape: 15.9676 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.8548 - mae: 37.0625 - mape: 13.8548 - val_loss: 13.6374 - val_mae: 56.2268 - val_mape: 13.6374 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.5201 - mae: 37.7567 - mape: 13.5201 - val_loss: 11.9799 - val_mae: 28.7272 - val_mape: 11.9799 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.6851 - mae: 33.9337 - mape: 12.6851 - val_loss: 11.2853 - val_mae: 23.7773 - val_mape: 11.2853 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.0257 - mae: 38.8430 - mape: 13.0257 - val_loss: 15.6208 - val_mae: 23.9295 - val_mape: 15.6208 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 13.8488 - mae: 37.5139 - mape: 13.8488 - val_loss: 11.6551 - val_mae: 48.2292 - val_mape: 11.6551 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 12.2225 - mae: 33.8001 - mape: 12.2225 - val_loss: 11.7769 - val_mae: 26.0595 - val_mape: 11.7769 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 13.2607 - mae: 33.5347 - mape: 13.2607\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 13.0969 - mae: 35.0062 - mape: 13.0969 - val_loss: 12.1472 - val_mae: 22.9531 - val_mape: 12.1472 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1049 - mae: 29.1910 - mape: 11.1049 - val_loss: 11.9842 - val_mae: 23.9279 - val_mape: 11.9842 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 11.1027 - mae: 29.3470 - mape: 11.1027INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 18ms/step - loss: 11.0134 - mae: 29.7557 - mape: 11.0134 - val_loss: 10.3337 - val_mae: 20.7172 - val_mape: 10.3337 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 11.0913 - mae: 30.5269 - mape: 11.0913INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 17ms/step - loss: 11.0296 - mae: 30.6580 - mape: 11.0296 - val_loss: 10.2292 - val_mae: 20.3859 - val_mape: 10.2292 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.0845 - mae: 29.0834 - mape: 11.0845 - val_loss: 10.5812 - val_mae: 20.3171 - val_mape: 10.5812 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4669 - mae: 26.7225 - mape: 10.4669 - val_loss: 10.3745 - val_mae: 20.0108 - val_mape: 10.3745 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.5778 - mae: 28.1128 - mape: 10.5778 - val_loss: 11.6739 - val_mae: 23.0324 - val_mape: 11.6739 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.9574 - mae: 28.3613 - mape: 10.9574 - val_loss: 10.6790 - val_mae: 21.2738 - val_mape: 10.6790 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.7077 - mae: 29.1198 - mape: 10.7077 - val_loss: 13.0310 - val_mae: 24.5470 - val_mape: 13.0310 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 11.0800 - mae: 27.1405 - mape: 11.0800 - val_loss: 12.3200 - val_mae: 19.4176 - val_mape: 12.3200 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.1749 - mae: 29.9729 - mape: 11.1749 - val_loss: 10.4048 - val_mae: 21.0637 - val_mape: 10.4048 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.7129 - mae: 28.6552 - mape: 10.7129 - val_loss: 11.1723 - val_mae: 18.5263 - val_mape: 11.1723 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8179 - mae: 26.2908 - mape: 10.8179 - val_loss: 12.3450 - val_mae: 22.9714 - val_mape: 12.3450 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6229 - mae: 28.6456 - mape: 10.6229 - val_loss: 10.6937 - val_mae: 19.2431 - val_mape: 10.6937 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.8078 - mae: 30.3667 - mape: 10.8078 - val_loss: 11.7083 - val_mae: 25.8182 - val_mape: 11.7083 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.8001 - mae: 29.0122 - mape: 10.8001 - val_loss: 10.3967 - val_mae: 23.3561 - val_mape: 10.3967 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.9158 - mae: 29.2864 - mape: 10.9158 - val_loss: 10.9955 - val_mae: 24.2446 - val_mape: 10.9955 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6655 - mae: 29.8904 - mape: 10.6655 - val_loss: 10.8531 - val_mae: 20.7835 - val_mape: 10.8531 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.5871 - mae: 27.8913 - mape: 10.5871 - val_loss: 12.6820 - val_mae: 21.9442 - val_mape: 12.6820 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6378 - mae: 28.9585 - mape: 10.6378 - val_loss: 10.4592 - val_mae: 19.2420 - val_mape: 10.4592 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 11.2195 - mae: 29.8564 - mape: 11.2195 - val_loss: 11.1140 - val_mae: 22.2877 - val_mape: 11.1140 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.9559 - mae: 28.7155 - mape: 10.9559 - val_loss: 11.2224 - val_mae: 19.3725 - val_mape: 11.2224 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.5531 - mae: 27.3450 - mape: 10.5531 - val_loss: 10.6264 - val_mae: 24.4216 - val_mape: 10.6264 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.5643 - mae: 28.5314 - mape: 10.5643 - val_loss: 11.3366 - val_mae: 23.1292 - val_mape: 11.3366 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4755 - mae: 25.9610 - mape: 10.4755 - val_loss: 10.4861 - val_mae: 21.2483 - val_mape: 10.4861 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4934 - mae: 27.3501 - mape: 10.4934 - val_loss: 11.9423 - val_mae: 25.5996 - val_mape: 11.9423 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.9428 - mae: 29.6865 - mape: 10.9428 - val_loss: 10.6408 - val_mae: 20.8025 - val_mape: 10.6408 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 10.7742 - mae: 28.3362 - mape: 10.7742INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 17ms/step - loss: 10.8293 - mae: 28.6384 - mape: 10.8293 - val_loss: 10.2266 - val_mae: 19.5142 - val_mape: 10.2266 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7976 - mae: 29.1506 - mape: 10.7976 - val_loss: 12.3832 - val_mae: 39.0370 - val_mape: 12.3832 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.8082 - mae: 26.0935 - mape: 10.8082 - val_loss: 10.7675 - val_mae: 20.5084 - val_mape: 10.7675 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.5551 - mae: 29.0286 - mape: 10.5551 - val_loss: 12.9105 - val_mae: 25.2509 - val_mape: 12.9105 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 10.6099 - mae: 25.7906 - mape: 10.6099 - val_loss: 11.2270 - val_mae: 18.9905 - val_mape: 11.2270 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.3084 - mae: 26.4639 - mape: 10.3084 - val_loss: 10.3758 - val_mae: 22.2682 - val_mape: 10.3758 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.0168 - mae: 25.9114 - mape: 11.0168 - val_loss: 12.4179 - val_mae: 31.8870 - val_mape: 12.4179 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6657 - mae: 26.3356 - mape: 10.6657 - val_loss: 10.5079 - val_mae: 18.2598 - val_mape: 10.5079 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4218 - mae: 27.5454 - mape: 10.4218 - val_loss: 11.6328 - val_mae: 26.4551 - val_mape: 11.6328 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7973 - mae: 28.6106 - mape: 10.7973 - val_loss: 10.8472 - val_mae: 26.1073 - val_mape: 10.8472 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4613 - mae: 28.1046 - mape: 10.4613 - val_loss: 10.5357 - val_mae: 25.2163 - val_mape: 10.5357 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 11.0402 - mae: 30.3218 - mape: 11.0402 - val_loss: 10.9707 - val_mae: 18.4480 - val_mape: 10.9707 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7422 - mae: 29.4561 - mape: 10.7422 - val_loss: 10.6090 - val_mae: 20.8481 - val_mape: 10.6090 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.6835 - mae: 29.6129 - mape: 10.6835 - val_loss: 10.7379 - val_mae: 25.0847 - val_mape: 10.7379 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.5229 - mae: 26.6164 - mape: 10.5229 - val_loss: 10.4153 - val_mae: 19.7521 - val_mape: 10.4153 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4802 - mae: 28.7093 - mape: 10.4802 - val_loss: 10.5950 - val_mae: 20.2820 - val_mape: 10.5950 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3944 - mae: 28.2007 - mape: 10.3944 - val_loss: 10.5515 - val_mae: 23.9194 - val_mape: 10.5515 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.9319 - mae: 27.0144 - mape: 10.9319 - val_loss: 11.5317 - val_mae: 27.7066 - val_mape: 11.5317 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.8642 - mae: 30.2552 - mape: 10.8642 - val_loss: 10.6385 - val_mae: 23.9954 - val_mape: 10.6385 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 11.0049 - mae: 27.9074 - mape: 11.0049 - val_loss: 11.5261 - val_mae: 29.7720 - val_mape: 11.5261 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.4730 - mae: 27.2049 - mape: 10.4730 - val_loss: 11.2949 - val_mae: 24.6293 - val_mape: 11.2949 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 10.6829 - mae: 28.6242 - mape: 10.6829 - val_loss: 10.8482 - val_mae: 25.4753 - val_mape: 10.8482 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.4346 - mae: 28.3314 - mape: 10.4346 - val_loss: 10.5755 - val_mae: 19.6811 - val_mape: 10.5755 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.6766 - mae: 28.8590 - mape: 10.6766 - val_loss: 10.7052 - val_mae: 18.5838 - val_mape: 10.7052 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.5184 - mae: 26.4765 - mape: 10.5184 - val_loss: 10.6178 - val_mae: 19.6573 - val_mape: 10.6178 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.4994 - mae: 31.0101 - mape: 10.4994 - val_loss: 11.5594 - val_mae: 21.9582 - val_mape: 11.5594 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.7737 - mae: 28.9078 - mape: 10.7737 - val_loss: 11.6413 - val_mae: 23.7011 - val_mape: 11.6413 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.5575 - mae: 28.4352 - mape: 10.5575 - val_loss: 12.3092 - val_mae: 20.2988 - val_mape: 12.3092 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.3033 - mae: 26.0181 - mape: 10.3033 - val_loss: 11.1282 - val_mae: 20.5294 - val_mape: 11.1282 - lr: 3.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.2745 - mae: 28.1298 - mape: 10.2745 - val_loss: 11.0204 - val_mae: 20.9334 - val_mape: 11.0204 - lr: 3.0000e-04\n",
      "Epoch 103/1000\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 10.5226 - mae: 27.6051 - mape: 10.5226\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.5375 - mae: 27.7449 - mape: 10.5375 - val_loss: 11.1103 - val_mae: 21.1522 - val_mape: 11.1103 - lr: 3.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0982 - mae: 28.9084 - mape: 10.0982 - val_loss: 10.5352 - val_mae: 20.9546 - val_mape: 10.5352 - lr: 9.0000e-05\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.9160 - mae: 26.2667 - mape: 9.9160 - val_loss: 10.4057 - val_mae: 23.8602 - val_mape: 10.4057 - lr: 9.0000e-05\n",
      "Epoch 106/1000\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 9.9022 - mae: 25.2297 - mape: 9.9022INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 17ms/step - loss: 9.8637 - mae: 24.9715 - mape: 9.8637 - val_loss: 10.2027 - val_mae: 17.3260 - val_mape: 10.2027 - lr: 9.0000e-05\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6381 - mae: 24.8571 - mape: 9.6381 - val_loss: 10.2513 - val_mae: 21.0899 - val_mape: 10.2513 - lr: 9.0000e-05\n",
      "Epoch 108/1000\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 9.7242 - mae: 26.4415 - mape: 9.7242INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 16ms/step - loss: 9.7168 - mae: 26.9921 - mape: 9.7168 - val_loss: 10.0876 - val_mae: 17.7928 - val_mape: 10.0876 - lr: 9.0000e-05\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0582 - mae: 25.5454 - mape: 10.0582 - val_loss: 10.1630 - val_mae: 17.4482 - val_mape: 10.1630 - lr: 9.0000e-05\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.6460 - mae: 26.1582 - mape: 9.6460 - val_loss: 10.1997 - val_mae: 17.7959 - val_mape: 10.1997 - lr: 9.0000e-05\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.8785 - mae: 25.1627 - mape: 9.8785 - val_loss: 10.4744 - val_mae: 19.4666 - val_mape: 10.4744 - lr: 9.0000e-05\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.6212 - mae: 25.9188 - mape: 9.6212 - val_loss: 10.6800 - val_mae: 21.9245 - val_mape: 10.6800 - lr: 9.0000e-05\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8921 - mae: 26.7622 - mape: 9.8921 - val_loss: 10.3152 - val_mae: 18.3799 - val_mape: 10.3152 - lr: 9.0000e-05\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.8815 - mae: 24.3271 - mape: 9.8815 - val_loss: 10.2578 - val_mae: 17.9883 - val_mape: 10.2578 - lr: 9.0000e-05\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.0167 - mae: 28.2407 - mape: 10.0167 - val_loss: 10.6166 - val_mae: 22.2934 - val_mape: 10.6166 - lr: 9.0000e-05\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9.9773 - mae: 27.3856 - mape: 9.9773 - val_loss: 10.3226 - val_mae: 18.2682 - val_mape: 10.3226 - lr: 9.0000e-05\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9.9985 - mae: 26.1134 - mape: 9.9985 - val_loss: 10.4088 - val_mae: 21.5180 - val_mape: 10.4088 - lr: 9.0000e-05\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 9.7954 - mae: 25.6166 - mape: 9.7954 - val_loss: 10.5300 - val_mae: 19.0270 - val_mape: 10.5300 - lr: 9.0000e-05\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.4436 - mae: 24.2236 - mape: 9.4436 - val_loss: 11.5672 - val_mae: 24.9430 - val_mape: 11.5672 - lr: 9.0000e-05\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 10.0097 - mae: 25.9944 - mape: 10.0097 - val_loss: 10.3843 - val_mae: 19.4561 - val_mape: 10.3843 - lr: 9.0000e-05\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.6155 - mae: 25.1046 - mape: 9.6155 - val_loss: 10.1433 - val_mae: 17.5529 - val_mape: 10.1433 - lr: 9.0000e-05\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.7934 - mae: 25.8971 - mape: 9.7934 - val_loss: 10.2621 - val_mae: 19.1808 - val_mape: 10.2621 - lr: 9.0000e-05\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.9464 - mae: 25.7963 - mape: 9.9464 - val_loss: 10.1811 - val_mae: 19.2400 - val_mape: 10.1811 - lr: 9.0000e-05\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6825 - mae: 26.0057 - mape: 9.6825 - val_loss: 10.4723 - val_mae: 20.4556 - val_mape: 10.4723 - lr: 9.0000e-05\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8956 - mae: 24.5094 - mape: 9.8956 - val_loss: 10.1290 - val_mae: 17.7313 - val_mape: 10.1290 - lr: 9.0000e-05\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.9909 - mae: 26.9050 - mape: 9.9909 - val_loss: 10.4223 - val_mae: 18.5232 - val_mape: 10.4223 - lr: 9.0000e-05\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.7174 - mae: 25.7907 - mape: 9.7174 - val_loss: 10.9138 - val_mae: 19.3406 - val_mape: 10.9138 - lr: 9.0000e-05\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6845 - mae: 26.0019 - mape: 9.6845 - val_loss: 10.2395 - val_mae: 18.1315 - val_mape: 10.2395 - lr: 9.0000e-05\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5858 - mae: 25.4899 - mape: 9.5858 - val_loss: 10.2911 - val_mae: 21.2313 - val_mape: 10.2911 - lr: 9.0000e-05\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.7559 - mae: 25.2844 - mape: 9.7559 - val_loss: 10.2144 - val_mae: 17.3291 - val_mape: 10.2144 - lr: 9.0000e-05\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.7811 - mae: 26.6666 - mape: 9.7811 - val_loss: 10.1763 - val_mae: 19.2882 - val_mape: 10.1763 - lr: 9.0000e-05\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4647 - mae: 26.7229 - mape: 9.4647 - val_loss: 11.1937 - val_mae: 22.6774 - val_mape: 11.1937 - lr: 9.0000e-05\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6490 - mae: 26.3553 - mape: 9.6490 - val_loss: 10.2598 - val_mae: 18.0051 - val_mape: 10.2598 - lr: 9.0000e-05\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0570 - mae: 27.0063 - mape: 10.0570 - val_loss: 11.8776 - val_mae: 21.8524 - val_mape: 11.8776 - lr: 9.0000e-05\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 10.0214 - mae: 25.3794 - mape: 10.0214 - val_loss: 10.3193 - val_mae: 18.5003 - val_mape: 10.3193 - lr: 9.0000e-05\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6779 - mae: 24.3049 - mape: 9.6779 - val_loss: 10.1090 - val_mae: 17.2324 - val_mape: 10.1090 - lr: 9.0000e-05\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.7572 - mae: 26.4157 - mape: 9.7572 - val_loss: 10.6395 - val_mae: 17.0588 - val_mape: 10.6395 - lr: 9.0000e-05\n",
      "Epoch 138/1000\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 9.8054 - mae: 24.0669 - mape: 9.8054\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.8239 - mae: 24.0307 - mape: 9.8239 - val_loss: 10.1965 - val_mae: 17.6569 - val_mape: 10.1965 - lr: 9.0000e-05\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6198 - mae: 24.8425 - mape: 9.6198 - val_loss: 10.1404 - val_mae: 16.8690 - val_mape: 10.1404 - lr: 2.7000e-05\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5266 - mae: 26.4572 - mape: 9.5266 - val_loss: 10.1268 - val_mae: 17.6942 - val_mape: 10.1268 - lr: 2.7000e-05\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6625 - mae: 26.2660 - mape: 9.6625 - val_loss: 10.1264 - val_mae: 17.2931 - val_mape: 10.1264 - lr: 2.7000e-05\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6397 - mae: 27.3264 - mape: 9.6397 - val_loss: 10.1650 - val_mae: 16.8732 - val_mape: 10.1650 - lr: 2.7000e-05\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6394 - mae: 25.8405 - mape: 9.6394 - val_loss: 10.1003 - val_mae: 17.4672 - val_mape: 10.1003 - lr: 2.7000e-05\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4721 - mae: 24.6688 - mape: 9.4721 - val_loss: 10.1144 - val_mae: 17.3028 - val_mape: 10.1144 - lr: 2.7000e-05\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6121 - mae: 25.9333 - mape: 9.6121 - val_loss: 10.0988 - val_mae: 18.2042 - val_mape: 10.0988 - lr: 2.7000e-05\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5022 - mae: 24.9760 - mape: 9.5022 - val_loss: 10.5322 - val_mae: 17.8286 - val_mape: 10.5322 - lr: 2.7000e-05\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4988 - mae: 25.2186 - mape: 9.4988 - val_loss: 10.1829 - val_mae: 17.6442 - val_mape: 10.1829 - lr: 2.7000e-05\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4725 - mae: 25.4666 - mape: 9.4725 - val_loss: 10.1974 - val_mae: 17.6606 - val_mape: 10.1974 - lr: 2.7000e-05\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4295 - mae: 26.4672 - mape: 9.4295 - val_loss: 10.1149 - val_mae: 16.9559 - val_mape: 10.1149 - lr: 2.7000e-05\n",
      "Epoch 150/1000\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 9.5408 - mae: 24.7084 - mape: 9.5408INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 18ms/step - loss: 9.5181 - mae: 24.8254 - mape: 9.5181 - val_loss: 10.0650 - val_mae: 17.1636 - val_mape: 10.0650 - lr: 2.7000e-05\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4065 - mae: 25.0565 - mape: 9.4065 - val_loss: 10.1329 - val_mae: 19.1307 - val_mape: 10.1329 - lr: 2.7000e-05\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.3890 - mae: 23.6268 - mape: 9.3890 - val_loss: 10.0686 - val_mae: 17.0850 - val_mape: 10.0686 - lr: 2.7000e-05\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.6339 - mae: 25.0508 - mape: 9.6339 - val_loss: 10.0746 - val_mae: 17.5060 - val_mape: 10.0746 - lr: 2.7000e-05\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 9.6111 - mae: 26.1197 - mape: 9.6111 - val_loss: 10.3051 - val_mae: 18.0722 - val_mape: 10.3051 - lr: 2.7000e-05\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5297 - mae: 25.1585 - mape: 9.5297 - val_loss: 10.1447 - val_mae: 17.2764 - val_mape: 10.1447 - lr: 2.7000e-05\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.2893 - mae: 23.5976 - mape: 9.2893 - val_loss: 10.1664 - val_mae: 18.3765 - val_mape: 10.1664 - lr: 2.7000e-05\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3941 - mae: 23.6062 - mape: 9.3941 - val_loss: 10.2120 - val_mae: 16.9084 - val_mape: 10.2120 - lr: 2.7000e-05\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5193 - mae: 24.6974 - mape: 9.5193 - val_loss: 10.1407 - val_mae: 16.9889 - val_mape: 10.1407 - lr: 2.7000e-05\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4205 - mae: 26.3970 - mape: 9.4205 - val_loss: 10.2221 - val_mae: 18.0146 - val_mape: 10.2221 - lr: 2.7000e-05\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4365 - mae: 25.0542 - mape: 9.4365 - val_loss: 10.2732 - val_mae: 17.6896 - val_mape: 10.2732 - lr: 2.7000e-05\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3831 - mae: 23.3021 - mape: 9.3831 - val_loss: 10.1443 - val_mae: 19.2838 - val_mape: 10.1443 - lr: 2.7000e-05\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6794 - mae: 25.8565 - mape: 9.6794 - val_loss: 10.2579 - val_mae: 18.0118 - val_mape: 10.2579 - lr: 2.7000e-05\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6368 - mae: 24.1610 - mape: 9.6368 - val_loss: 10.2529 - val_mae: 18.4252 - val_mape: 10.2529 - lr: 2.7000e-05\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4007 - mae: 24.9307 - mape: 9.4007 - val_loss: 10.2466 - val_mae: 18.9410 - val_mape: 10.2466 - lr: 2.7000e-05\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3106 - mae: 25.6685 - mape: 9.3106 - val_loss: 10.1203 - val_mae: 17.7839 - val_mape: 10.1203 - lr: 2.7000e-05\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4776 - mae: 24.5876 - mape: 9.4776 - val_loss: 10.1920 - val_mae: 17.5163 - val_mape: 10.1920 - lr: 2.7000e-05\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5196 - mae: 24.4402 - mape: 9.5196 - val_loss: 10.1254 - val_mae: 17.3116 - val_mape: 10.1254 - lr: 2.7000e-05\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3488 - mae: 25.1975 - mape: 9.3488 - val_loss: 10.1007 - val_mae: 17.1330 - val_mape: 10.1007 - lr: 2.7000e-05\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5597 - mae: 26.7174 - mape: 9.5597 - val_loss: 10.2442 - val_mae: 18.5385 - val_mape: 10.2442 - lr: 2.7000e-05\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 9.4392 - mae: 25.0928 - mape: 9.4392 - val_loss: 10.3679 - val_mae: 17.2214 - val_mape: 10.3679 - lr: 2.7000e-05\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 9.5699 - mae: 26.2739 - mape: 9.5699 - val_loss: 10.1062 - val_mae: 17.7898 - val_mape: 10.1062 - lr: 2.7000e-05\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.6716 - mae: 25.4343 - mape: 9.6716 - val_loss: 10.2778 - val_mae: 17.9504 - val_mape: 10.2778 - lr: 2.7000e-05\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.4671 - mae: 23.9610 - mape: 9.4671 - val_loss: 10.1848 - val_mae: 17.4839 - val_mape: 10.1848 - lr: 2.7000e-05\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.5742 - mae: 25.2744 - mape: 9.5742 - val_loss: 10.2030 - val_mae: 18.3110 - val_mape: 10.2030 - lr: 2.7000e-05\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5697 - mae: 24.9771 - mape: 9.5697 - val_loss: 10.1639 - val_mae: 18.2255 - val_mape: 10.1639 - lr: 2.7000e-05\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6384 - mae: 26.1192 - mape: 9.6384 - val_loss: 10.1601 - val_mae: 18.8888 - val_mape: 10.1601 - lr: 2.7000e-05\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3415 - mae: 23.7236 - mape: 9.3415 - val_loss: 10.2722 - val_mae: 18.1182 - val_mape: 10.2722 - lr: 2.7000e-05\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4553 - mae: 24.3115 - mape: 9.4553 - val_loss: 10.1501 - val_mae: 17.1224 - val_mape: 10.1501 - lr: 2.7000e-05\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.6192 - mae: 28.2470 - mape: 9.6192 - val_loss: 10.2461 - val_mae: 18.0307 - val_mape: 10.2461 - lr: 2.7000e-05\n",
      "Epoch 180/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 9.4529 - mae: 23.6371 - mape: 9.4529\n",
      "Epoch 180: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5237 - mae: 23.6393 - mape: 9.5237 - val_loss: 10.2097 - val_mae: 17.0046 - val_mape: 10.2097 - lr: 2.7000e-05\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4892 - mae: 26.0876 - mape: 9.4892 - val_loss: 10.1601 - val_mae: 17.3753 - val_mape: 10.1601 - lr: 8.1000e-06\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5967 - mae: 26.8272 - mape: 9.5967 - val_loss: 10.1659 - val_mae: 17.2933 - val_mape: 10.1659 - lr: 8.1000e-06\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4754 - mae: 25.9552 - mape: 9.4754 - val_loss: 10.1604 - val_mae: 17.6435 - val_mape: 10.1604 - lr: 8.1000e-06\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5986 - mae: 27.6637 - mape: 9.5986 - val_loss: 10.1717 - val_mae: 17.9598 - val_mape: 10.1717 - lr: 8.1000e-06\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3052 - mae: 23.7428 - mape: 9.3052 - val_loss: 10.1619 - val_mae: 17.9601 - val_mape: 10.1619 - lr: 8.1000e-06\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4484 - mae: 23.8906 - mape: 9.4484 - val_loss: 10.1778 - val_mae: 18.3129 - val_mape: 10.1778 - lr: 8.1000e-06\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.2282 - mae: 23.6944 - mape: 9.2282 - val_loss: 10.1421 - val_mae: 17.5749 - val_mape: 10.1421 - lr: 8.1000e-06\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4139 - mae: 26.2287 - mape: 9.4139 - val_loss: 10.1382 - val_mae: 16.8847 - val_mape: 10.1382 - lr: 8.1000e-06\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3164 - mae: 25.1353 - mape: 9.3164 - val_loss: 10.2288 - val_mae: 17.0210 - val_mape: 10.2288 - lr: 8.1000e-06\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3331 - mae: 23.5760 - mape: 9.3331 - val_loss: 10.1747 - val_mae: 17.3169 - val_mape: 10.1747 - lr: 8.1000e-06\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3887 - mae: 25.2515 - mape: 9.3887 - val_loss: 10.1476 - val_mae: 17.1073 - val_mape: 10.1476 - lr: 8.1000e-06\n",
      "Epoch 192/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4520 - mae: 24.3599 - mape: 9.4520 - val_loss: 10.1933 - val_mae: 17.4626 - val_mape: 10.1933 - lr: 8.1000e-06\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4572 - mae: 25.6903 - mape: 9.4572 - val_loss: 10.1346 - val_mae: 17.0842 - val_mape: 10.1346 - lr: 8.1000e-06\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5173 - mae: 25.8768 - mape: 9.5173 - val_loss: 10.1415 - val_mae: 17.1456 - val_mape: 10.1415 - lr: 8.1000e-06\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5327 - mae: 26.7734 - mape: 9.5327 - val_loss: 10.1398 - val_mae: 17.3721 - val_mape: 10.1398 - lr: 8.1000e-06\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3797 - mae: 26.2474 - mape: 9.3797 - val_loss: 10.1496 - val_mae: 17.3113 - val_mape: 10.1496 - lr: 8.1000e-06\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4273 - mae: 24.3469 - mape: 9.4273 - val_loss: 10.1413 - val_mae: 17.0698 - val_mape: 10.1413 - lr: 8.1000e-06\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4998 - mae: 25.5231 - mape: 9.4998 - val_loss: 10.1709 - val_mae: 18.0967 - val_mape: 10.1709 - lr: 8.1000e-06\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3876 - mae: 24.7675 - mape: 9.3876 - val_loss: 10.1746 - val_mae: 17.5809 - val_mape: 10.1746 - lr: 8.1000e-06\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.3338 - mae: 25.6467 - mape: 9.3338 - val_loss: 10.1455 - val_mae: 17.7053 - val_mape: 10.1455 - lr: 8.1000e-06\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.5234 - mae: 24.9886 - mape: 9.5234 - val_loss: 10.1290 - val_mae: 17.5970 - val_mape: 10.1290 - lr: 8.1000e-06\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.3673 - mae: 26.1961 - mape: 9.3673 - val_loss: 10.1165 - val_mae: 17.9213 - val_mape: 10.1165 - lr: 8.1000e-06\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 9.1999 - mae: 24.4055 - mape: 9.1999 - val_loss: 10.1066 - val_mae: 17.3655 - val_mape: 10.1066 - lr: 8.1000e-06\n",
      "Epoch 204/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9.2608 - mae: 23.5997 - mape: 9.2608 - val_loss: 10.1164 - val_mae: 17.2382 - val_mape: 10.1164 - lr: 8.1000e-06\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 9.5462 - mae: 23.6147 - mape: 9.5462 - val_loss: 10.1381 - val_mae: 17.3852 - val_mape: 10.1381 - lr: 8.1000e-06\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.0797 - mae: 25.0392 - mape: 9.0797 - val_loss: 10.1176 - val_mae: 17.2633 - val_mape: 10.1176 - lr: 8.1000e-06\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.4535 - mae: 24.8595 - mape: 9.4535 - val_loss: 10.1939 - val_mae: 17.5660 - val_mape: 10.1939 - lr: 8.1000e-06\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 9.4529 - mae: 27.9283 - mape: 9.4529 - val_loss: 10.1125 - val_mae: 17.5264 - val_mape: 10.1125 - lr: 8.1000e-06\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 9.4253 - mae: 25.8452 - mape: 9.4253 - val_loss: 10.1228 - val_mae: 17.9027 - val_mape: 10.1228 - lr: 8.1000e-06\n",
      "Epoch 210/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 9.3527 - mae: 25.2286 - mape: 9.3527\n",
      "Epoch 210: ReduceLROnPlateau reducing learning rate to 2.429999949526973e-06.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 9.3405 - mae: 26.0066 - mape: 9.3405 - val_loss: 10.1154 - val_mae: 17.3674 - val_mape: 10.1154 - lr: 8.1000e-06\n",
      "Epoch 210: early stopping\n",
      "Score for fold 5: loss of 10.065009117126465; mae of 17.163557052612305; mape of 10.065009117126465%;\n"
     ]
    }
   ],
   "source": [
    "#Baseline\n",
    "model = keras.models.load_model('savedmodels/Baseline_nosupp_final')\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, \"crossvalidationmodels/Baseline_nosupp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 11.691810607910156 - Mean average error: 27.594125747680664% - Mean percentage error: 11.691810607910156%\n",
      "    Score on unseen data: Loss: 13.640799522399902 - Mean average error: 34.69724655151367% - Mean percentage error: 13.640799522399902%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 10.917817115783691 - Mean average error: 21.2031307220459% - Mean percentage error: 10.917817115783691%\n",
      "    Score on unseen data: Loss: 13.767284393310547 - Mean average error: 36.589019775390625% - Mean percentage error: 13.767284393310547%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 9.890689849853516 - Mean average error: 16.45372200012207% - Mean percentage error: 9.890689849853516%\n",
      "    Score on unseen data: Loss: 14.14288330078125 - Mean average error: 31.841482162475586% - Mean percentage error: 14.14288330078125%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 9.070025444030762 - Mean average error: 25.237478256225586% - Mean percentage error: 9.070025444030762%\n",
      "    Score on unseen data: Loss: 14.944561004638672 - Mean average error: 36.57535171508789% - Mean percentage error: 14.944561004638672%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 10.065009117126465 - Mean average error: 17.163557052612305% - Mean percentage error: 10.065009117126465%\n",
      "    Score on unseen data: Loss: 14.137367248535156 - Mean average error: 30.633352279663086% - Mean percentage error: 14.137367248535156%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 10.327070426940917\n",
      "> Mean average error: 21.530402755737306\n",
      "> Mean percentage error: 10.327070426940917\n",
      "> Unseen Loss: 14.126579093933106\n",
      "> Unseen Mean average error: 34.067290496826175\n",
      "> Unseen Mean percentage error: 14.126579093933106\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 39.1486 - mae: 96.0272 - mape: 35.2760"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 13s 140ms/step - loss: 39.1486 - mae: 96.0272 - mape: 35.2760 - val_loss: 21.3166 - val_mae: 40.8928 - val_mape: 17.5940 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 119ms/step - loss: 26.3029 - mae: 55.8468 - mape: 22.7037 - val_loss: 24.5790 - val_mae: 43.4094 - val_mape: 21.1045 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 23.7739 - mae: 45.9051 - mape: 20.4087"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 114ms/step - loss: 23.7739 - mae: 45.9051 - mape: 20.4087 - val_loss: 19.4143 - val_mae: 72.2982 - val_mape: 16.1564 - lr: 0.0010\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 23.8476 - mae: 45.9039 - mape: 20.6889"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 139ms/step - loss: 23.8476 - mae: 45.9039 - mape: 20.6889 - val_loss: 16.2270 - val_mae: 42.7802 - val_mape: 13.1625 - lr: 0.0010\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 110ms/step - loss: 23.9108 - mae: 50.3782 - mape: 20.9367 - val_loss: 18.2191 - val_mae: 70.1888 - val_mape: 15.3339 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 23.6964 - mae: 50.7833 - mape: 20.8854 - val_loss: 18.8788 - val_mae: 51.2455 - val_mape: 16.1450 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 22.0035 - mae: 48.9537 - mape: 19.3393 - val_loss: 18.5029 - val_mae: 44.2078 - val_mape: 15.9059 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 20.8920 - mae: 48.4706 - mape: 18.3549 - val_loss: 16.0046 - val_mae: 26.8902 - val_mape: 13.5325 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 20.7425 - mae: 42.6484 - mape: 18.3288 - val_loss: 16.9276 - val_mae: 47.6615 - val_mape: 14.5726 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 21.3585 - mae: 49.3132 - mape: 19.0570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 134ms/step - loss: 21.3585 - mae: 49.3132 - mape: 19.0570 - val_loss: 15.0138 - val_mae: 57.3869 - val_mape: 12.7668 - lr: 0.0010\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 110ms/step - loss: 20.8316 - mae: 45.1767 - mape: 18.6365 - val_loss: 17.1555 - val_mae: 30.0330 - val_mape: 15.0115 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 20.8893 - mae: 47.5207 - mape: 18.7883 - val_loss: 15.5582 - val_mae: 43.0034 - val_mape: 13.5099 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 21.1641 - mae: 46.6911 - mape: 19.1559 - val_loss: 16.4153 - val_mae: 32.7439 - val_mape: 14.4492 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 20.5873 - mae: 45.5879 - mape: 18.6610 - val_loss: 14.7282 - val_mae: 39.0312 - val_mape: 12.8407 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 20.2688 - mae: 43.7067 - mape: 18.4199 - val_loss: 18.6465 - val_mae: 65.9590 - val_mape: 16.8269 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 20.5251 - mae: 48.9522 - mape: 18.7482 - val_loss: 17.1156 - val_mae: 43.6762 - val_mape: 15.3759 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 10s 120ms/step - loss: 21.5118 - mae: 47.9701 - mape: 19.8066 - val_loss: 16.3230 - val_mae: 56.1845 - val_mape: 14.6508 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 19.7454 - mae: 45.9416 - mape: 18.1049 - val_loss: 14.8106 - val_mae: 41.3454 - val_mape: 13.2035 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 19.7822 - mae: 50.9938 - mape: 18.2095 - val_loss: 16.6569 - val_mae: 45.1538 - val_mape: 15.1133 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 20.2558 - mae: 44.4222 - mape: 18.7448 - val_loss: 19.1671 - val_mae: 49.3196 - val_mape: 17.6908 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 10s 120ms/step - loss: 19.5171 - mae: 43.7818 - mape: 18.0660 - val_loss: 18.6477 - val_mae: 38.0488 - val_mape: 17.2252 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 19.7467 - mae: 47.1737 - mape: 18.3507 - val_loss: 19.4232 - val_mae: 35.6325 - val_mape: 18.0539 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 19.7142 - mae: 46.6260 - mape: 18.3693 - val_loss: 20.3214 - val_mae: 58.7187 - val_mape: 19.0031 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 20.1358 - mae: 47.6754 - mape: 18.8388 - val_loss: 22.4084 - val_mae: 68.6992 - val_mape: 21.1336 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 19.2907 - mae: 44.3556 - mape: 18.0374 - val_loss: 15.9164 - val_mae: 59.6831 - val_mape: 14.6862 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 19.3162 - mae: 44.9717 - mape: 18.1089 - val_loss: 16.2770 - val_mae: 60.3469 - val_mape: 15.0904 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 19.8525 - mae: 46.5289 - mape: 18.6897 - val_loss: 15.4287 - val_mae: 44.3509 - val_mape: 14.2859 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 20.2574 - mae: 47.0327 - mape: 19.1370 - val_loss: 19.9658 - val_mae: 58.1605 - val_mape: 18.8666 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 19.7681 - mae: 49.0716 - mape: 18.6884 - val_loss: 24.9614 - val_mae: 65.6304 - val_mape: 23.9048 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 19.6991 - mae: 47.0203 - mape: 18.6608 - val_loss: 14.1391 - val_mae: 35.9983 - val_mape: 13.1157 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 19.2174 - mae: 43.5009 - mape: 18.2156 - val_loss: 17.7824 - val_mae: 42.8285 - val_mape: 16.8035 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 19.0971 - mae: 46.2323 - mape: 18.1355 - val_loss: 16.9283 - val_mae: 51.8239 - val_mape: 15.9844 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 20.1232 - mae: 52.5065 - mape: 19.1965 - val_loss: 16.3081 - val_mae: 64.6738 - val_mape: 15.3966 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 10s 121ms/step - loss: 20.7768 - mae: 51.1305 - mape: 19.8780 - val_loss: 15.9952 - val_mae: 85.1659 - val_mape: 15.1085 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 19.4655 - mae: 51.3629 - mape: 18.5929 - val_loss: 18.8383 - val_mae: 53.2037 - val_mape: 17.9825 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 19.3428 - mae: 47.2676 - mape: 18.5018 - val_loss: 14.8745 - val_mae: 36.0450 - val_mape: 14.0510 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 19.3274 - mae: 45.6451 - mape: 18.5176 - val_loss: 15.7829 - val_mae: 31.3514 - val_mape: 14.9856 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 18.6689 - mae: 45.2544 - mape: 17.8891 - val_loss: 18.4094 - val_mae: 85.3643 - val_mape: 17.6440 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 19.2002 - mae: 43.0954 - mape: 18.4471 - val_loss: 16.5245 - val_mae: 52.2811 - val_mape: 15.7847 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 18.4720 - mae: 45.6834 - mape: 17.7461 - val_loss: 19.1576 - val_mae: 55.8448 - val_mape: 18.4459 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 17.7275 - mae: 40.5313 - mape: 17.0295 - val_loss: 16.0529 - val_mae: 39.6498 - val_mape: 15.3682 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 20.8647 - mae: 46.8230 - mape: 20.1884 - val_loss: 18.2959 - val_mae: 67.4157 - val_mape: 17.6277 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 17.8242 - mae: 41.6349 - mape: 17.1691 - val_loss: 20.8850 - val_mae: 55.5007 - val_mape: 20.2410 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 18.9143 - mae: 41.9919 - mape: 18.2832 - val_loss: 27.2631 - val_mae: 43.6523 - val_mape: 26.6403 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 18.0912 - mae: 45.6119 - mape: 17.4800 - val_loss: 17.1967 - val_mae: 71.7262 - val_mape: 16.5990 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 18.8409 - mae: 45.8362 - mape: 18.2556 - val_loss: 28.0600 - val_mae: 84.1103 - val_mape: 27.4858 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 19.0586 - mae: 44.3481 - mape: 18.4932 - val_loss: 17.2945 - val_mae: 43.3838 - val_mape: 16.7386 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 18.5226 - mae: 46.7781 - mape: 17.9749 - val_loss: 27.0339 - val_mae: 47.4241 - val_mape: 26.4944 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 18.0341 - mae: 42.1360 - mape: 17.5023 - val_loss: 19.4071 - val_mae: 82.8681 - val_mape: 18.8834 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 19.2924 - mae: 46.6634 - mape: 18.7800 - val_loss: 21.1177 - val_mae: 71.0662 - val_mape: 20.6139 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 20.2751 - mae: 41.9225 - mape: 19.7787 - val_loss: 17.9788 - val_mae: 55.9326 - val_mape: 17.4927 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 17.6805 - mae: 41.1342 - mape: 17.2021 - val_loss: 23.5358 - val_mae: 81.3428 - val_mape: 23.0652 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 18.2494 - mae: 40.8223 - mape: 17.7844 - val_loss: 15.8471 - val_mae: 36.9870 - val_mape: 15.3883 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 20.2041 - mae: 46.1446 - mape: 19.7522 - val_loss: 17.2565 - val_mae: 42.5738 - val_mape: 16.8108 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 18.1794 - mae: 46.6619 - mape: 17.7406 - val_loss: 21.0376 - val_mae: 61.4243 - val_mape: 20.6034 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 17.4197 - mae: 43.3784 - mape: 16.9966 - val_loss: 17.9587 - val_mae: 65.7665 - val_mape: 17.5441 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 17.2295 - mae: 39.6912 - mape: 16.8192 - val_loss: 17.6558 - val_mae: 54.5344 - val_mape: 17.2518 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 17.6941 - mae: 43.8975 - mape: 17.2964 - val_loss: 16.3241 - val_mae: 43.2189 - val_mape: 15.9344 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 19.4755 - mae: 50.0757 - mape: 19.0922 - val_loss: 14.2302 - val_mae: 53.7492 - val_mape: 13.8554 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.9526 - mae: 41.3778 - mape: 17.5822\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 17.9526 - mae: 41.3778 - mape: 17.5822 - val_loss: 15.8491 - val_mae: 44.2699 - val_mape: 15.4847 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 16.0051 - mae: 37.4509 - mape: 15.6432 - val_loss: 16.5271 - val_mae: 60.2916 - val_mape: 16.1672 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 16.5675 - mae: 40.6896 - mape: 16.2096 - val_loss: 17.1827 - val_mae: 51.6558 - val_mape: 16.8264 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 16.3099 - mae: 37.8066 - mape: 15.9558 - val_loss: 17.4845 - val_mae: 70.4081 - val_mape: 17.1323 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 11s 129ms/step - loss: 15.8371 - mae: 40.3721 - mape: 15.4874 - val_loss: 16.8620 - val_mae: 52.6865 - val_mape: 16.5144 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 16.0248 - mae: 36.9989 - mape: 15.6789 - val_loss: 21.9681 - val_mae: 54.9130 - val_mape: 21.6239 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 15.6518 - mae: 40.2906 - mape: 15.3099 - val_loss: 21.2081 - val_mae: 56.4709 - val_mape: 20.8680 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 15.5099 - mae: 35.9941 - mape: 15.1720 - val_loss: 18.0676 - val_mae: 50.8547 - val_mape: 17.7319 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 15.5724 - mae: 36.3741 - mape: 15.2399 - val_loss: 18.2373 - val_mae: 55.1271 - val_mape: 17.9069 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 15.4775 - mae: 37.0699 - mape: 15.1497 - val_loss: 21.1098 - val_mae: 57.3564 - val_mape: 20.7842 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 15.6687 - mae: 40.6637 - mape: 15.3447 - val_loss: 18.5504 - val_mae: 63.6884 - val_mape: 18.2286 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 15.2011 - mae: 36.6981 - mape: 14.8803 - val_loss: 20.1364 - val_mae: 69.5577 - val_mape: 19.8174 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 15.7550 - mae: 35.2080 - mape: 15.4379 - val_loss: 21.8310 - val_mae: 66.9529 - val_mape: 21.5163 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 15.5557 - mae: 38.2073 - mape: 15.2435 - val_loss: 19.7763 - val_mae: 50.4173 - val_mape: 19.4651 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 15.1876 - mae: 33.8331 - mape: 14.8782 - val_loss: 22.9953 - val_mae: 79.5788 - val_mape: 22.6875 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 15.7259 - mae: 41.3854 - mape: 15.4194 - val_loss: 20.9949 - val_mae: 76.6389 - val_mape: 20.6901 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 10s 120ms/step - loss: 15.2382 - mae: 36.7678 - mape: 14.9349 - val_loss: 23.6533 - val_mae: 81.8069 - val_mape: 23.3521 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 15.0521 - mae: 36.3651 - mape: 14.7531 - val_loss: 26.1383 - val_mae: 77.6140 - val_mape: 25.8408 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 15.5734 - mae: 36.1821 - mape: 15.2782 - val_loss: 20.5802 - val_mae: 82.5360 - val_mape: 20.2875 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 15.1701 - mae: 38.5106 - mape: 14.8791 - val_loss: 24.9050 - val_mae: 82.7245 - val_mape: 24.6163 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 15.4346 - mae: 42.3215 - mape: 15.1476 - val_loss: 24.3864 - val_mae: 86.9683 - val_mape: 24.1014 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 15.1739 - mae: 35.6438 - mape: 14.8898 - val_loss: 24.6297 - val_mae: 63.9402 - val_mape: 24.3478 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 15.2796 - mae: 38.1786 - mape: 15.0005 - val_loss: 25.5772 - val_mae: 84.6175 - val_mape: 25.3002 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 11s 129ms/step - loss: 15.1033 - mae: 37.6290 - mape: 14.8275 - val_loss: 23.0695 - val_mae: 74.0637 - val_mape: 22.7957 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 15.1407 - mae: 38.1649 - mape: 14.8681 - val_loss: 21.6609 - val_mae: 68.2877 - val_mape: 21.3899 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 15.5926 - mae: 36.9395 - mape: 15.3233 - val_loss: 22.9402 - val_mae: 75.0947 - val_mape: 22.6724 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 14.9050 - mae: 37.2961 - mape: 14.6387 - val_loss: 20.9081 - val_mae: 57.0130 - val_mape: 20.6431 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 14.9028 - mae: 34.5878 - mape: 14.6390 - val_loss: 22.6081 - val_mae: 66.6564 - val_mape: 22.3446 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 14.9192 - mae: 35.7153 - mape: 14.6578 - val_loss: 21.1599 - val_mae: 76.3310 - val_mape: 20.8996 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 15.3862 - mae: 35.0583 - mape: 15.1276 - val_loss: 27.3227 - val_mae: 77.2958 - val_mape: 27.0652 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.8570 - mae: 34.4763 - mape: 14.6010\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 14.8570 - mae: 34.4763 - mape: 14.6010 - val_loss: 30.1419 - val_mae: 92.2110 - val_mape: 29.8877 - lr: 3.0000e-04\n",
      "Epoch 90: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 15.013823509216309; mae of 57.38688659667969; mape of 12.766820907592773%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 23.5107 - mae: 50.5310 - mape: 21.3950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 13s 139ms/step - loss: 23.5107 - mae: 50.5310 - mape: 21.3950 - val_loss: 15.2238 - val_mae: 37.4900 - val_mape: 13.2206 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 103ms/step - loss: 21.8708 - mae: 45.7775 - mape: 19.9566 - val_loss: 17.3193 - val_mae: 43.0064 - val_mape: 15.4900 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.7402 - mae: 43.6727 - mape: 17.9782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 131ms/step - loss: 19.7402 - mae: 43.6727 - mape: 17.9782 - val_loss: 14.4289 - val_mae: 35.6833 - val_mape: 12.7373 - lr: 0.0010\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 116ms/step - loss: 19.9441 - mae: 47.0133 - mape: 18.3135 - val_loss: 20.5109 - val_mae: 42.9488 - val_mape: 18.9439 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 20.2681 - mae: 43.7980 - mape: 18.7550 - val_loss: 21.2116 - val_mae: 78.4260 - val_mape: 19.7499 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 20.3205 - mae: 45.5062 - mape: 18.9043 - val_loss: 19.7409 - val_mae: 48.3983 - val_mape: 18.3673 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 20.6485 - mae: 47.9102 - mape: 19.3178 - val_loss: 14.6479 - val_mae: 38.4680 - val_mape: 13.3655 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 19.7574 - mae: 44.1705 - mape: 18.5175 - val_loss: 15.9984 - val_mae: 78.1082 - val_mape: 14.7986 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 21.1000 - mae: 47.5550 - mape: 19.9313 - val_loss: 17.3664 - val_mae: 65.7251 - val_mape: 16.2295 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 20.4113 - mae: 48.1276 - mape: 19.3056 - val_loss: 28.2919 - val_mae: 82.0143 - val_mape: 27.2169 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 20.6160 - mae: 52.6599 - mape: 19.5694 - val_loss: 23.9519 - val_mae: 64.7811 - val_mape: 22.9355 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 20.0505 - mae: 45.3447 - mape: 19.0584 - val_loss: 17.0118 - val_mae: 46.9029 - val_mape: 16.0472 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 19.6586 - mae: 50.1538 - mape: 18.7235 - val_loss: 15.8322 - val_mae: 72.1862 - val_mape: 14.9243 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 20.5403 - mae: 50.2686 - mape: 19.6523 - val_loss: 16.2874 - val_mae: 45.2745 - val_mape: 15.4222 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 19.6641 - mae: 49.5596 - mape: 18.8204 - val_loss: 25.0488 - val_mae: 74.3199 - val_mape: 24.2280 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 19.2510 - mae: 49.9387 - mape: 18.4494 - val_loss: 14.3987 - val_mae: 46.8838 - val_mape: 13.6148 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 18.9087 - mae: 40.2494 - mape: 18.1513 - val_loss: 15.8361 - val_mae: 58.1481 - val_mape: 15.0992 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 19.7267 - mae: 50.6006 - mape: 19.0039 - val_loss: 15.0934 - val_mae: 32.4443 - val_mape: 14.3909 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 18.7905 - mae: 44.2049 - mape: 18.1093 - val_loss: 15.7728 - val_mae: 37.1959 - val_mape: 15.1081 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 19.4515 - mae: 43.2944 - mape: 18.7995 - val_loss: 17.4839 - val_mae: 39.5186 - val_mape: 16.8459 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 18.8014 - mae: 44.0913 - mape: 18.1786 - val_loss: 14.5184 - val_mae: 59.1560 - val_mape: 13.9100 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 20.5444 - mae: 47.7729 - mape: 19.9503 - val_loss: 19.0963 - val_mae: 47.9950 - val_mape: 18.5154 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 20.1727 - mae: 49.2615 - mape: 19.6040 - val_loss: 16.0596 - val_mae: 73.7824 - val_mape: 15.5003 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 18.6564 - mae: 47.2709 - mape: 18.1125 - val_loss: 15.0327 - val_mae: 39.0002 - val_mape: 14.5044 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 18.7132 - mae: 48.0771 - mape: 18.1952 - val_loss: 17.8648 - val_mae: 39.0184 - val_mape: 17.3605 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 18.9124 - mae: 44.2643 - mape: 18.4167 - val_loss: 15.1387 - val_mae: 43.4835 - val_mape: 14.6523 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 18.9912 - mae: 50.0798 - mape: 18.5160 - val_loss: 23.3089 - val_mae: 100.4591 - val_mape: 22.8435 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 18.1129 - mae: 42.0298 - mape: 17.6529 - val_loss: 19.4849 - val_mae: 46.0031 - val_mape: 19.0307 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 18.0804 - mae: 45.8959 - mape: 17.6341 - val_loss: 14.8048 - val_mae: 34.0368 - val_mape: 14.3662 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 23s 261ms/step - loss: 17.7647 - mae: 41.8856 - mape: 17.3343 - val_loss: 19.9110 - val_mae: 53.8897 - val_mape: 19.4900 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 18.6393 - mae: 43.8216 - mape: 18.2257 - val_loss: 15.8287 - val_mae: 40.1617 - val_mape: 15.4237 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 18.6526 - mae: 52.1599 - mape: 18.2565 - val_loss: 18.8342 - val_mae: 49.7781 - val_mape: 18.4497 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 18.3411 - mae: 46.0616 - mape: 17.9645 - val_loss: 15.0820 - val_mae: 36.0235 - val_mape: 14.7109 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 17.7631 - mae: 41.0092 - mape: 17.4010 - val_loss: 16.0424 - val_mae: 50.7931 - val_mape: 15.6865 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 18.8019 - mae: 44.0290 - mape: 18.4514 - val_loss: 16.2960 - val_mae: 38.1863 - val_mape: 15.9493 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 18.0046 - mae: 45.7167 - mape: 17.6637 - val_loss: 15.7857 - val_mae: 43.3994 - val_mape: 15.4530 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 17.7107 - mae: 45.6039 - mape: 17.3823 - val_loss: 18.6174 - val_mae: 46.7180 - val_mape: 18.2922 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 18.1786 - mae: 41.9375 - mape: 17.8617 - val_loss: 16.0999 - val_mae: 52.9207 - val_mape: 15.7885 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 12s 139ms/step - loss: 18.6231 - mae: 44.1203 - mape: 18.3173 - val_loss: 14.7194 - val_mae: 46.2622 - val_mape: 14.4190 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 18.8020 - mae: 42.5207 - mape: 18.5060 - val_loss: 16.4118 - val_mae: 64.7309 - val_mape: 16.1203 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 19.0052 - mae: 45.0287 - mape: 18.7205 - val_loss: 17.3467 - val_mae: 53.8872 - val_mape: 17.0659 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 18.7649 - mae: 46.6650 - mape: 18.4896 - val_loss: 14.1810 - val_mae: 40.0447 - val_mape: 13.9099 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 18.9844 - mae: 45.8446 - mape: 18.7182 - val_loss: 13.9451 - val_mae: 38.4073 - val_mape: 13.6827 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.7856 - mae: 50.7845 - mape: 18.5273 - val_loss: 19.7732 - val_mae: 53.4582 - val_mape: 19.5178 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 17.7667 - mae: 45.2989 - mape: 17.5136 - val_loss: 22.8567 - val_mae: 54.6116 - val_mape: 22.6065 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5297 - mae: 48.6526 - mape: 19.2838 - val_loss: 24.4075 - val_mae: 47.8442 - val_mape: 24.1647 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.7066 - mae: 49.6765 - mape: 17.4676 - val_loss: 16.1162 - val_mae: 52.5631 - val_mape: 15.8812 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 17.4233 - mae: 39.8217 - mape: 17.1950 - val_loss: 19.3685 - val_mae: 60.8349 - val_mape: 19.1456 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.7796 - mae: 44.8528 - mape: 17.5610 - val_loss: 22.1148 - val_mae: 64.1217 - val_mape: 21.9007 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.8338 - mae: 45.5954 - mape: 17.6252 - val_loss: 19.5329 - val_mae: 42.1315 - val_mape: 19.3284 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 17.0992 - mae: 39.7612 - mape: 16.8983 - val_loss: 23.2321 - val_mae: 52.1818 - val_mape: 23.0341 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 18.3151 - mae: 45.7090 - mape: 18.1219 - val_loss: 20.1694 - val_mae: 82.5857 - val_mape: 19.9803 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.5115 - mae: 44.8345 - mape: 18.3261 - val_loss: 19.7195 - val_mae: 61.1620 - val_mape: 19.5376 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 17.6629 - mae: 43.9755 - mape: 17.4816 - val_loss: 18.5248 - val_mae: 59.4562 - val_mape: 18.3459 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 18.1263 - mae: 49.4813 - mape: 17.9508 - val_loss: 21.4839 - val_mae: 81.5072 - val_mape: 21.3111 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 18.1192 - mae: 44.1850 - mape: 17.9483 - val_loss: 16.1005 - val_mae: 55.5859 - val_mape: 15.9314 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.8927 - mae: 42.4394 - mape: 17.7275 - val_loss: 23.7291 - val_mae: 80.0469 - val_mape: 23.5674 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 19.0329 - mae: 45.1359 - mape: 18.8731 - val_loss: 25.7178 - val_mae: 81.7663 - val_mape: 25.5625 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 18.0527 - mae: 41.9851 - mape: 17.9008 - val_loss: 14.2273 - val_mae: 33.7929 - val_mape: 14.0785 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.7930 - mae: 42.1545 - mape: 17.6466 - val_loss: 19.1770 - val_mae: 90.8874 - val_mape: 19.0324 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.4513 - mae: 44.1172 - mape: 18.3072 - val_loss: 16.7108 - val_mae: 73.4628 - val_mape: 16.5670 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.7221 - mae: 43.5206 - mape: 17.5809 - val_loss: 17.6820 - val_mae: 78.4514 - val_mape: 17.5432 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 17.7865 - mae: 42.3301 - mape: 17.6497 - val_loss: 15.5957 - val_mae: 66.5668 - val_mape: 15.4605 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 18.3598 - mae: 43.2059 - mape: 18.2266 - val_loss: 22.3338 - val_mae: 56.1226 - val_mape: 22.2025 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.9721 - mae: 40.7312 - mape: 16.8429 - val_loss: 19.4030 - val_mae: 64.5523 - val_mape: 19.2737 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 17.6637 - mae: 48.8769 - mape: 17.5353 - val_loss: 16.4629 - val_mae: 79.3268 - val_mape: 16.3365 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5713 - mae: 40.7609 - mape: 16.4484 - val_loss: 26.1359 - val_mae: 62.7010 - val_mape: 26.0142 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 18.9692 - mae: 47.2286 - mape: 18.8490 - val_loss: 14.9555 - val_mae: 47.4206 - val_mape: 14.8350 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.4292 - mae: 40.5927 - mape: 17.3077 - val_loss: 18.6467 - val_mae: 46.0428 - val_mape: 18.5273 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 18.0279 - mae: 48.9007 - mape: 17.9103 - val_loss: 23.6614 - val_mae: 100.7092 - val_mape: 23.5451 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.0614 - mae: 50.6032 - mape: 16.9482 - val_loss: 22.2188 - val_mae: 88.0063 - val_mape: 22.1078 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.8601 - mae: 46.8955 - mape: 17.7508 - val_loss: 19.2394 - val_mae: 107.7980 - val_mape: 19.1314 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.5997 - mae: 44.5178 - mape: 18.4925\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 18.5997 - mae: 44.5178 - mape: 18.4925 - val_loss: 15.6757 - val_mae: 45.4170 - val_mape: 15.5702 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 15.7267 - mae: 39.1768 - mape: 15.6220 - val_loss: 16.6833 - val_mae: 54.3513 - val_mape: 16.5791 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.5151 - mae: 37.0234 - mape: 15.4111 - val_loss: 15.7325 - val_mae: 48.7498 - val_mape: 15.6286 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 15.2130 - mae: 36.4180 - mape: 15.1099 - val_loss: 22.4757 - val_mae: 75.7149 - val_mape: 22.3732 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.1421 - mae: 36.4966 - mape: 15.0405 - val_loss: 20.2970 - val_mae: 65.2379 - val_mape: 20.1965 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.2368 - mae: 36.3193 - mape: 15.1368 - val_loss: 19.4087 - val_mae: 66.1720 - val_mape: 19.3094 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.1730 - mae: 37.6359 - mape: 15.0743 - val_loss: 18.5115 - val_mae: 48.5534 - val_mape: 18.4134 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 15.2221 - mae: 37.7266 - mape: 15.1242 - val_loss: 23.4237 - val_mae: 73.2634 - val_mape: 23.3270 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.0492 - mae: 36.6657 - mape: 14.9530 - val_loss: 19.2350 - val_mae: 59.9944 - val_mape: 19.1391 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 15.2407 - mae: 39.7176 - mape: 15.1454 - val_loss: 20.4591 - val_mae: 54.1639 - val_mape: 20.3643 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.9899 - mae: 37.5703 - mape: 14.8956 - val_loss: 23.2829 - val_mae: 67.0623 - val_mape: 23.1889 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 15.2284 - mae: 38.2146 - mape: 15.1349 - val_loss: 19.4546 - val_mae: 57.0242 - val_mape: 19.3618 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.1533 - mae: 37.6424 - mape: 15.0612 - val_loss: 19.7946 - val_mae: 66.7315 - val_mape: 19.7033 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.7338 - mae: 33.5686 - mape: 14.6434 - val_loss: 20.9795 - val_mae: 65.4562 - val_mape: 20.8902 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.7409 - mae: 32.8563 - mape: 14.6516 - val_loss: 22.6575 - val_mae: 54.8444 - val_mape: 22.5691 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.1209 - mae: 32.9905 - mape: 15.0332 - val_loss: 24.0773 - val_mae: 87.8249 - val_mape: 23.9901 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.0787 - mae: 38.8018 - mape: 14.9926 - val_loss: 22.7768 - val_mae: 79.5109 - val_mape: 22.6912 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.7183 - mae: 33.8653 - mape: 14.6339 - val_loss: 19.5561 - val_mae: 62.5981 - val_mape: 19.4728 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.0579 - mae: 37.9267 - mape: 14.9746 - val_loss: 27.1853 - val_mae: 67.6858 - val_mape: 27.1023 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 14.5130 - mae: 35.0157 - mape: 14.4300 - val_loss: 19.4429 - val_mae: 73.8911 - val_mape: 19.3601 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 14.7084 - mae: 34.8738 - mape: 14.6258 - val_loss: 25.7749 - val_mae: 69.0192 - val_mape: 25.6927 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 15.1741 - mae: 37.6549 - mape: 15.0917 - val_loss: 26.8432 - val_mae: 78.2009 - val_mape: 26.7614 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 14.7473 - mae: 35.4643 - mape: 14.6661 - val_loss: 22.2505 - val_mae: 56.0405 - val_mape: 22.1695 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.6651 - mae: 35.8999 - mape: 14.5842 - val_loss: 22.5753 - val_mae: 74.7878 - val_mape: 22.4950 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.5118 - mae: 33.0623 - mape: 14.4321 - val_loss: 27.3484 - val_mae: 84.9468 - val_mape: 27.2690 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.2749 - mae: 34.4305 - mape: 14.1960 - val_loss: 23.0402 - val_mae: 59.7638 - val_mape: 22.9621 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.5139 - mae: 35.4030 - mape: 14.4362 - val_loss: 27.6098 - val_mae: 82.7968 - val_mape: 27.5324 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.9080 - mae: 34.0881 - mape: 14.8303 - val_loss: 19.5358 - val_mae: 76.1687 - val_mape: 19.4584 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.6653 - mae: 36.5140 - mape: 14.5882 - val_loss: 25.4949 - val_mae: 81.8371 - val_mape: 25.4179 - lr: 3.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.6737 - mae: 35.1062 - mape: 14.5965 - val_loss: 25.5475 - val_mae: 93.9755 - val_mape: 25.4698 - lr: 3.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.4666 - mae: 38.8182 - mape: 14.3898\n",
      "Epoch 103: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.4666 - mae: 38.8182 - mape: 14.3898 - val_loss: 22.6529 - val_mae: 78.3717 - val_mape: 22.5768 - lr: 3.0000e-04\n",
      "Epoch 103: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 14.428936958312988; mae of 35.683292388916016; mape of 12.737340927124023%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 21.7975 - mae: 54.9559 - mape: 20.2225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 13s 141ms/step - loss: 21.7975 - mae: 54.9559 - mape: 20.2225 - val_loss: 15.0789 - val_mae: 26.4071 - val_mape: 13.6047 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 121ms/step - loss: 20.7209 - mae: 50.6030 - mape: 19.3267 - val_loss: 18.0756 - val_mae: 41.6928 - val_mape: 16.7578 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 20.8724 - mae: 55.9245 - mape: 19.6098 - val_loss: 16.7098 - val_mae: 41.5624 - val_mape: 15.5005 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 19.9925 - mae: 51.5580 - mape: 18.8366 - val_loss: 16.1049 - val_mae: 30.7864 - val_mape: 15.0017 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 20.2549 - mae: 51.1258 - mape: 19.1917 - val_loss: 16.6216 - val_mae: 30.5796 - val_mape: 15.5975 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 19.9094 - mae: 47.8062 - mape: 18.9240 - val_loss: 15.6152 - val_mae: 50.9308 - val_mape: 14.6642 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.6292 - mae: 44.5085 - mape: 18.7102 - val_loss: 20.2189 - val_mae: 49.5894 - val_mape: 19.3371 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 20.3692 - mae: 47.9242 - mape: 19.5187 - val_loss: 22.4276 - val_mae: 50.2567 - val_mape: 21.6100 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 19.6684 - mae: 51.6022 - mape: 18.8772 - val_loss: 22.5501 - val_mae: 55.1054 - val_mape: 21.7859 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 9s 93ms/step - loss: 18.7813 - mae: 43.7057 - mape: 18.0426 - val_loss: 14.7781 - val_mae: 33.2709 - val_mape: 14.0652 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 18.0594 - mae: 44.7843 - mape: 17.3642 - val_loss: 18.7646 - val_mae: 37.7734 - val_mape: 18.0930 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 18.5321 - mae: 47.2112 - mape: 17.8861 - val_loss: 16.4866 - val_mae: 50.9198 - val_mape: 15.8672 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 18.5839 - mae: 48.8049 - mape: 17.9846 - val_loss: 16.9348 - val_mae: 55.6582 - val_mape: 16.3561 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 8s 85ms/step - loss: 20.7231 - mae: 49.5157 - mape: 20.1628 - val_loss: 18.1336 - val_mae: 38.1043 - val_mape: 17.5937 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 20.2372 - mae: 51.2340 - mape: 19.7147 - val_loss: 20.8361 - val_mae: 39.5975 - val_mape: 20.3291 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 19.5499 - mae: 48.9673 - mape: 19.0598 - val_loss: 18.9099 - val_mae: 64.4853 - val_mape: 18.4353 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 18.4896 - mae: 50.7446 - mape: 18.0273 - val_loss: 20.3464 - val_mae: 49.6855 - val_mape: 19.8996 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 19.1374 - mae: 51.6149 - mape: 18.7021 - val_loss: 17.4080 - val_mae: 54.5562 - val_mape: 16.9844 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 18.7202 - mae: 48.6552 - mape: 18.3084 - val_loss: 15.7001 - val_mae: 61.4246 - val_mape: 15.3024 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 18.4561 - mae: 51.5456 - mape: 18.0705 - val_loss: 20.1609 - val_mae: 39.7521 - val_mape: 19.7870 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 18.2996 - mae: 45.6324 - mape: 17.9366 - val_loss: 22.3063 - val_mae: 59.0575 - val_mape: 21.9534 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 19.1345 - mae: 52.3049 - mape: 18.7910 - val_loss: 15.7303 - val_mae: 31.6378 - val_mape: 15.3948 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 19.1564 - mae: 47.4546 - mape: 18.8332 - val_loss: 14.3410 - val_mae: 29.4371 - val_mape: 14.0274 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 18.2780 - mae: 48.9707 - mape: 17.9737 - val_loss: 14.9512 - val_mae: 39.2272 - val_mape: 14.6569 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.0931 - mae: 47.5309 - mape: 17.8075 - val_loss: 21.3854 - val_mae: 55.5560 - val_mape: 21.1080 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 17.8844 - mae: 48.5149 - mape: 17.6133 - val_loss: 16.0245 - val_mae: 30.9190 - val_mape: 15.7613 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 19.2597 - mae: 49.4334 - mape: 19.0030 - val_loss: 19.4346 - val_mae: 38.8051 - val_mape: 19.1848 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.7354 - mae: 48.5811 - mape: 17.4911 - val_loss: 22.9045 - val_mae: 54.0231 - val_mape: 22.6662 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 18.8417 - mae: 46.8327 - mape: 18.6098 - val_loss: 19.1891 - val_mae: 38.3844 - val_mape: 18.9622 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.2455 - mae: 46.3429 - mape: 18.0217 - val_loss: 20.9490 - val_mae: 55.9987 - val_mape: 20.7315 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 18.8462 - mae: 47.9407 - mape: 18.6354 - val_loss: 23.6299 - val_mae: 61.2642 - val_mape: 23.4267 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 18.1412 - mae: 55.5789 - mape: 17.9432 - val_loss: 14.9056 - val_mae: 39.7185 - val_mape: 14.7107 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.8773 - mae: 49.9665 - mape: 17.6885 - val_loss: 19.4943 - val_mae: 48.2253 - val_mape: 19.3115 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 12s 136ms/step - loss: 18.1217 - mae: 42.2352 - mape: 17.9416 - val_loss: 20.4448 - val_mae: 56.9573 - val_mape: 20.2684 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 18.5320 - mae: 54.6645 - mape: 18.3611 - val_loss: 24.1218 - val_mae: 52.5257 - val_mape: 23.9572 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 17.4015 - mae: 46.9999 - mape: 17.2396 - val_loss: 24.2651 - val_mae: 45.4060 - val_mape: 24.1065 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.3089 - mae: 51.9104 - mape: 18.1525"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 142ms/step - loss: 18.3089 - mae: 51.9104 - mape: 18.1525 - val_loss: 13.0025 - val_mae: 28.8313 - val_mape: 12.8501 - lr: 0.0010\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 139ms/step - loss: 19.1428 - mae: 53.2290 - mape: 18.9939 - val_loss: 14.6063 - val_mae: 35.0235 - val_mape: 14.4594 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 17.8750 - mae: 47.9917 - mape: 17.7330 - val_loss: 23.0745 - val_mae: 58.0821 - val_mape: 22.9365 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 19.0184 - mae: 50.7264 - mape: 18.8824 - val_loss: 13.5835 - val_mae: 35.3467 - val_mape: 13.4504 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.6232 - mae: 48.4831 - mape: 17.4938 - val_loss: 16.6961 - val_mae: 45.0004 - val_mape: 16.5687 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 18.6345 - mae: 49.4712 - mape: 18.5105 - val_loss: 16.7473 - val_mae: 59.4151 - val_mape: 16.6258 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 18.2582 - mae: 53.4639 - mape: 18.1389 - val_loss: 14.8946 - val_mae: 30.5776 - val_mape: 14.7777 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 17.6819 - mae: 52.5843 - mape: 17.5694 - val_loss: 17.4438 - val_mae: 39.3900 - val_mape: 17.3358 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 17.4711 - mae: 47.2636 - mape: 17.3658 - val_loss: 19.3795 - val_mae: 47.2511 - val_mape: 19.2770 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 17.5730 - mae: 43.9466 - mape: 17.4696 - val_loss: 23.3707 - val_mae: 48.9025 - val_mape: 23.2680 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 18.3816 - mae: 46.2433 - mape: 18.2806 - val_loss: 14.7994 - val_mae: 37.8870 - val_mape: 14.7026 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 17.8495 - mae: 46.6121 - mape: 17.7559 - val_loss: 20.4057 - val_mae: 66.2178 - val_mape: 20.3151 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 18.3865 - mae: 48.9050 - mape: 18.2988 - val_loss: 15.2140 - val_mae: 37.0064 - val_mape: 15.1296 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 17.4118 - mae: 44.5391 - mape: 17.3295 - val_loss: 15.7501 - val_mae: 41.3262 - val_mape: 15.6688 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 17.3157 - mae: 42.0991 - mape: 17.2393 - val_loss: 16.5481 - val_mae: 52.4837 - val_mape: 16.4741 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 16.5344 - mae: 44.5213 - mape: 16.4622 - val_loss: 17.2951 - val_mae: 52.2728 - val_mape: 17.2237 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 16.7845 - mae: 41.6281 - mape: 16.7148 - val_loss: 15.9851 - val_mae: 44.7344 - val_mape: 15.9173 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 17.0705 - mae: 44.4201 - mape: 17.0043 - val_loss: 18.1181 - val_mae: 57.8988 - val_mape: 18.0537 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.8604 - mae: 45.0801 - mape: 16.7973 - val_loss: 22.5559 - val_mae: 41.4240 - val_mape: 22.4942 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.2441 - mae: 42.9066 - mape: 17.1832 - val_loss: 19.3691 - val_mae: 49.9824 - val_mape: 19.3099 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 18.3319 - mae: 49.1963 - mape: 18.2737 - val_loss: 21.3045 - val_mae: 50.8182 - val_mape: 21.2471 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.4856 - mae: 39.7136 - mape: 16.4301 - val_loss: 23.0240 - val_mae: 49.4243 - val_mape: 22.9689 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 16.5687 - mae: 44.2382 - mape: 16.5152 - val_loss: 19.4619 - val_mae: 54.5161 - val_mape: 19.4100 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.5707 - mae: 49.5244 - mape: 19.5208 - val_loss: 14.7735 - val_mae: 51.6088 - val_mape: 14.7251 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 18.0016 - mae: 46.3596 - mape: 17.9534 - val_loss: 13.6451 - val_mae: 32.6975 - val_mape: 13.5970 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.4652 - mae: 44.7760 - mape: 17.4184 - val_loss: 17.2726 - val_mae: 58.6970 - val_mape: 17.2249 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 17.5327 - mae: 45.8714 - mape: 17.4864 - val_loss: 23.4279 - val_mae: 54.9400 - val_mape: 23.3824 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 17.2521 - mae: 42.1346 - mape: 17.2078 - val_loss: 18.6471 - val_mae: 51.4904 - val_mape: 18.6039 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 16.9541 - mae: 41.8988 - mape: 16.9120 - val_loss: 20.1346 - val_mae: 40.7482 - val_mape: 20.0946 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 17.1319 - mae: 47.8486 - mape: 17.0905 - val_loss: 17.2803 - val_mae: 42.1134 - val_mape: 17.2392 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.5135 - mae: 44.7251 - mape: 17.4742\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.5135 - mae: 44.7251 - mape: 17.4742 - val_loss: 17.2695 - val_mae: 44.7070 - val_mape: 17.2317 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.4665 - mae: 37.5626 - mape: 15.4288 - val_loss: 23.7895 - val_mae: 55.2323 - val_mape: 23.7518 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 15.2005 - mae: 38.5094 - mape: 15.1630 - val_loss: 17.4679 - val_mae: 43.3152 - val_mape: 17.4303 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.1488 - mae: 39.3643 - mape: 15.1113 - val_loss: 19.0204 - val_mae: 48.4847 - val_mape: 18.9833 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 14.7941 - mae: 37.3270 - mape: 14.7574 - val_loss: 20.1029 - val_mae: 52.3726 - val_mape: 20.0668 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 15.1474 - mae: 38.1219 - mape: 15.1114 - val_loss: 20.6451 - val_mae: 57.4809 - val_mape: 20.6094 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.8309 - mae: 39.1040 - mape: 14.7958 - val_loss: 18.2655 - val_mae: 52.8224 - val_mape: 18.2310 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 15.6879 - mae: 38.0535 - mape: 15.6537 - val_loss: 23.7345 - val_mae: 58.2719 - val_mape: 23.7006 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.4938 - mae: 40.4833 - mape: 15.4600 - val_loss: 19.8217 - val_mae: 50.9130 - val_mape: 19.7882 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.7536 - mae: 36.3375 - mape: 14.7201 - val_loss: 19.0999 - val_mae: 46.3471 - val_mape: 19.0664 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 15.2616 - mae: 39.0524 - mape: 15.2281 - val_loss: 18.7867 - val_mae: 52.8948 - val_mape: 18.7535 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 14.9924 - mae: 36.6829 - mape: 14.9593 - val_loss: 25.5826 - val_mae: 57.3867 - val_mape: 25.5494 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.9144 - mae: 40.0281 - mape: 14.8814 - val_loss: 23.9566 - val_mae: 62.2649 - val_mape: 23.9238 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 15.0583 - mae: 41.0163 - mape: 15.0257 - val_loss: 21.4346 - val_mae: 54.4613 - val_mape: 21.4018 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 14.6435 - mae: 35.5315 - mape: 14.6107 - val_loss: 21.4298 - val_mae: 64.3943 - val_mape: 21.3968 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.6823 - mae: 37.4162 - mape: 14.6490 - val_loss: 24.7383 - val_mae: 67.3967 - val_mape: 24.7048 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.7165 - mae: 38.5006 - mape: 14.6834 - val_loss: 23.7476 - val_mae: 49.9096 - val_mape: 23.7153 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 15.1242 - mae: 38.6212 - mape: 15.0920 - val_loss: 16.4306 - val_mae: 45.8305 - val_mape: 16.3988 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.6852 - mae: 38.6753 - mape: 15.6535 - val_loss: 21.4251 - val_mae: 61.3786 - val_mape: 21.3935 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 15.0802 - mae: 34.9188 - mape: 15.0487 - val_loss: 18.1529 - val_mae: 45.3274 - val_mape: 18.1216 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 14.8667 - mae: 36.9540 - mape: 14.8358 - val_loss: 24.1316 - val_mae: 65.8664 - val_mape: 24.1014 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 14.7363 - mae: 39.5271 - mape: 14.7061 - val_loss: 20.6341 - val_mae: 62.6885 - val_mape: 20.6042 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.4372 - mae: 36.5319 - mape: 14.4073 - val_loss: 21.8446 - val_mae: 65.7124 - val_mape: 21.8147 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.8066 - mae: 38.6489 - mape: 14.7769 - val_loss: 21.9276 - val_mae: 60.8258 - val_mape: 21.8979 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.0353 - mae: 35.2540 - mape: 14.0055 - val_loss: 22.5003 - val_mae: 60.7051 - val_mape: 22.4705 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.7408 - mae: 42.0826 - mape: 14.7113 - val_loss: 26.4388 - val_mae: 71.0870 - val_mape: 26.4097 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.4527 - mae: 36.6879 - mape: 14.4234 - val_loss: 25.4158 - val_mae: 64.5479 - val_mape: 25.3865 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.5872 - mae: 38.6681 - mape: 14.5579 - val_loss: 22.8960 - val_mae: 64.3699 - val_mape: 22.8666 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 14.5245 - mae: 37.2021 - mape: 14.4954 - val_loss: 23.2673 - val_mae: 71.7260 - val_mape: 23.2384 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.4460 - mae: 34.9480 - mape: 14.4174 - val_loss: 26.3582 - val_mae: 77.3976 - val_mape: 26.3298 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.4659 - mae: 36.2956 - mape: 14.4376\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.4659 - mae: 36.2956 - mape: 14.4376 - val_loss: 24.8853 - val_mae: 63.8959 - val_mape: 24.8571 - lr: 3.0000e-04\n",
      "Epoch 97: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 13.002521514892578; mae of 28.83129119873047; mape of 12.850089073181152%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.7915 - mae: 49.7480 - mape: 19.6543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 14s 146ms/step - loss: 19.7915 - mae: 49.7480 - mape: 19.6543 - val_loss: 16.8404 - val_mae: 31.2174 - val_mape: 16.7124 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 18.5551 - mae: 49.5772 - mape: 18.4322"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 140ms/step - loss: 18.5551 - mae: 49.5772 - mape: 18.4322 - val_loss: 16.6262 - val_mae: 33.2294 - val_mape: 16.5092 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 18.6546 - mae: 56.4983 - mape: 18.5429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 13s 145ms/step - loss: 18.6546 - mae: 56.4983 - mape: 18.5429 - val_loss: 13.4858 - val_mae: 41.9085 - val_mape: 13.3789 - lr: 0.0010\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 130ms/step - loss: 18.7486 - mae: 47.7305 - mape: 18.6475 - val_loss: 24.4755 - val_mae: 33.8521 - val_mape: 24.3802 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.6932 - mae: 46.9171 - mape: 17.6013 - val_loss: 17.8846 - val_mae: 39.5281 - val_mape: 17.7953 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 18.0672 - mae: 48.5891 - mape: 17.9810 - val_loss: 20.6128 - val_mae: 53.3725 - val_mape: 20.5299 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 18.2145 - mae: 52.9494 - mape: 18.1349 - val_loss: 16.8246 - val_mae: 42.1063 - val_mape: 16.7490 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.5334 - mae: 43.1250 - mape: 17.4586 - val_loss: 17.6427 - val_mae: 40.7126 - val_mape: 17.5681 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 17.8995 - mae: 47.0480 - mape: 17.8278 - val_loss: 30.0438 - val_mae: 75.9227 - val_mape: 29.9759 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 17.1249 - mae: 44.2491 - mape: 17.0590 - val_loss: 18.3288 - val_mae: 66.6416 - val_mape: 18.2642 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.7249 - mae: 46.6738 - mape: 17.6629 - val_loss: 20.1364 - val_mae: 44.6235 - val_mape: 20.0765 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.1283 - mae: 45.3062 - mape: 17.0712 - val_loss: 29.6693 - val_mae: 41.2101 - val_mape: 29.6148 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 18.3229 - mae: 46.0293 - mape: 18.2698 - val_loss: 21.2877 - val_mae: 44.6527 - val_mape: 21.2367 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 19.1059 - mae: 48.9874 - mape: 19.0552 - val_loss: 16.6129 - val_mae: 31.6105 - val_mape: 16.5617 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 16.9630 - mae: 46.5507 - mape: 16.9124 - val_loss: 16.1252 - val_mae: 39.0191 - val_mape: 16.0762 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 17.4426 - mae: 48.1092 - mape: 17.3943 - val_loss: 15.3892 - val_mae: 49.1218 - val_mape: 15.3402 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 17.6250 - mae: 48.7713 - mape: 17.5767 - val_loss: 16.7501 - val_mae: 38.9067 - val_mape: 16.7025 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 18.6708 - mae: 50.4609 - mape: 18.6255 - val_loss: 18.1858 - val_mae: 60.3875 - val_mape: 18.1418 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 18.2819 - mae: 47.3808 - mape: 18.2393 - val_loss: 17.4076 - val_mae: 57.6318 - val_mape: 17.3652 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 17.2815 - mae: 45.9959 - mape: 17.2404 - val_loss: 17.5106 - val_mae: 43.4361 - val_mape: 17.4692 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 16.9917 - mae: 48.1742 - mape: 16.9498 - val_loss: 20.8973 - val_mae: 65.3609 - val_mape: 20.8564 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.8760 - mae: 45.2807 - mape: 16.8369 - val_loss: 17.1837 - val_mae: 45.9903 - val_mape: 17.1460 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.8128 - mae: 47.1444 - mape: 17.7756 - val_loss: 17.1637 - val_mae: 37.1280 - val_mape: 17.1272 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 16.6091 - mae: 48.9176 - mape: 16.5728 - val_loss: 18.1990 - val_mae: 45.5870 - val_mape: 18.1627 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 18.7748 - mae: 57.6951 - mape: 18.7387 - val_loss: 15.1614 - val_mae: 37.2243 - val_mape: 15.1260 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.1440 - mae: 49.6489 - mape: 17.1105 - val_loss: 25.7674 - val_mae: 46.1700 - val_mape: 25.7350 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.7597 - mae: 57.9686 - mape: 17.7286 - val_loss: 23.1947 - val_mae: 43.5840 - val_mape: 23.1645 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.3376 - mae: 46.8991 - mape: 17.3078 - val_loss: 19.2601 - val_mae: 47.1431 - val_mape: 19.2306 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 18.9558 - mae: 55.4324 - mape: 18.9271 - val_loss: 17.0697 - val_mae: 48.0893 - val_mape: 17.0414 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 16.5508 - mae: 44.5719 - mape: 16.5228 - val_loss: 19.3218 - val_mae: 46.0244 - val_mape: 19.2944 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 18.8998 - mae: 48.4512 - mape: 18.8734 - val_loss: 16.2613 - val_mae: 31.0477 - val_mape: 16.2358 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.6175 - mae: 47.2735 - mape: 17.5917 - val_loss: 17.9781 - val_mae: 49.0673 - val_mape: 17.9520 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.0599 - mae: 43.1221 - mape: 16.0348\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 16.0599 - mae: 43.1221 - mape: 16.0348 - val_loss: 17.8428 - val_mae: 47.0728 - val_mape: 17.8186 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 15.4398 - mae: 37.4112 - mape: 15.4159 - val_loss: 22.2927 - val_mae: 51.5322 - val_mape: 22.2692 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.9736 - mae: 40.0473 - mape: 14.9500 - val_loss: 18.5053 - val_mae: 44.1485 - val_mape: 18.4818 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 14.5560 - mae: 36.3822 - mape: 14.5326 - val_loss: 18.3573 - val_mae: 51.1326 - val_mape: 18.3338 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.2291 - mae: 42.6709 - mape: 15.2055 - val_loss: 18.4149 - val_mae: 52.6393 - val_mape: 18.3917 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.9392 - mae: 41.6105 - mape: 14.9164 - val_loss: 21.5359 - val_mae: 51.5248 - val_mape: 21.5132 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.8458 - mae: 38.2360 - mape: 14.8231 - val_loss: 21.9675 - val_mae: 53.9788 - val_mape: 21.9450 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.9288 - mae: 39.5907 - mape: 14.9066 - val_loss: 27.3725 - val_mae: 53.0035 - val_mape: 27.3505 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.8469 - mae: 38.6945 - mape: 14.8253 - val_loss: 19.1153 - val_mae: 41.4095 - val_mape: 19.0940 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.7492 - mae: 39.8044 - mape: 14.7280 - val_loss: 21.9146 - val_mae: 55.6279 - val_mape: 21.8936 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.4644 - mae: 36.9131 - mape: 14.4435 - val_loss: 21.4498 - val_mae: 40.5435 - val_mape: 21.4290 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.5610 - mae: 41.4596 - mape: 14.5403 - val_loss: 24.0821 - val_mae: 62.6475 - val_mape: 24.0614 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 15.0132 - mae: 41.0546 - mape: 14.9927 - val_loss: 23.6468 - val_mae: 51.3491 - val_mape: 23.6264 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.8738 - mae: 37.4533 - mape: 14.8536 - val_loss: 25.0278 - val_mae: 55.2943 - val_mape: 25.0077 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 14.9499 - mae: 41.7759 - mape: 14.9298 - val_loss: 23.5809 - val_mae: 47.6045 - val_mape: 23.5609 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 14.6095 - mae: 39.5050 - mape: 14.5893 - val_loss: 20.5298 - val_mae: 56.2967 - val_mape: 20.5097 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.9212 - mae: 38.0177 - mape: 14.9010 - val_loss: 23.6709 - val_mae: 53.7843 - val_mape: 23.6504 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.1949 - mae: 35.0844 - mape: 14.1741 - val_loss: 20.5527 - val_mae: 48.0699 - val_mape: 20.5315 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 15.0889 - mae: 42.3130 - mape: 15.0678 - val_loss: 27.0169 - val_mae: 53.5629 - val_mape: 26.9961 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.4699 - mae: 37.4985 - mape: 15.4495 - val_loss: 24.3778 - val_mae: 50.9294 - val_mape: 24.3577 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.7678 - mae: 42.0577 - mape: 14.7478 - val_loss: 28.6117 - val_mae: 59.7734 - val_mape: 28.5920 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.7076 - mae: 40.2728 - mape: 14.6879 - val_loss: 26.6553 - val_mae: 62.9776 - val_mape: 26.6360 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 14.8403 - mae: 37.9986 - mape: 14.8211 - val_loss: 24.1003 - val_mae: 54.1033 - val_mape: 24.0811 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.3934 - mae: 36.5662 - mape: 14.3745 - val_loss: 24.7820 - val_mae: 50.1426 - val_mape: 24.7632 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.2978 - mae: 37.5935 - mape: 14.2789 - val_loss: 25.1783 - val_mae: 58.3707 - val_mape: 25.1596 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 14.2857 - mae: 38.6113 - mape: 14.2670 - val_loss: 23.7133 - val_mae: 45.6886 - val_mape: 23.6945 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.2130 - mae: 38.0673 - mape: 14.1943 - val_loss: 25.7684 - val_mae: 55.1076 - val_mape: 25.7498 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 15.3731 - mae: 38.7062 - mape: 15.3544 - val_loss: 27.6243 - val_mae: 66.3395 - val_mape: 27.6054 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.9470 - mae: 38.1902 - mape: 14.9278 - val_loss: 30.0890 - val_mae: 63.8694 - val_mape: 30.0695 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.2432 - mae: 35.8878 - mape: 14.2240 - val_loss: 27.7920 - val_mae: 55.6170 - val_mape: 27.7732 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.4979 - mae: 37.9207 - mape: 14.4791\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.4979 - mae: 37.9207 - mape: 14.4791 - val_loss: 27.9625 - val_mae: 59.1210 - val_mape: 27.9438 - lr: 3.0000e-04\n",
      "Epoch 63: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 13.48575210571289; mae of 41.90851593017578; mape of 13.378936767578125%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n",
      " 1/87 [..............................] - ETA: 1:22 - loss: 15.3113 - mae: 26.5728 - mape: 15.2045"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.3870 - mae: 49.8503 - mape: 19.2936"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 14s 147ms/step - loss: 19.3870 - mae: 49.8503 - mape: 19.2936 - val_loss: 19.5244 - val_mae: 49.4972 - val_mape: 19.4394 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 18.9753 - mae: 43.1426 - mape: 18.8946"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 141ms/step - loss: 18.9494 - mae: 43.6494 - mape: 18.8689 - val_loss: 15.9763 - val_mae: 63.6447 - val_mape: 15.9002 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 121ms/step - loss: 18.9848 - mae: 47.5442 - mape: 18.9125 - val_loss: 16.3691 - val_mae: 54.4950 - val_mape: 16.2995 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.9717 - mae: 40.5069 - mape: 18.9070 - val_loss: 16.9199 - val_mae: 56.6808 - val_mape: 16.8583 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.1375 - mae: 42.3474 - mape: 18.0779"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 106ms/step - loss: 18.1375 - mae: 42.3474 - mape: 18.0779 - val_loss: 13.9122 - val_mae: 58.6181 - val_mape: 13.8529 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      " 1/87 [..............................] - ETA: 8s - loss: 20.8319 - mae: 37.9800 - mape: 20.7726"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 121ms/step - loss: 17.6041 - mae: 45.3673 - mape: 17.5463 - val_loss: 15.4821 - val_mae: 41.8835 - val_mape: 15.4250 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.2522 - mae: 43.6093 - mape: 17.1974 - val_loss: 16.2011 - val_mae: 39.4002 - val_mape: 16.1496 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.5795 - mae: 45.7995 - mape: 17.5294 - val_loss: 25.1474 - val_mae: 86.1199 - val_mape: 25.0981 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.5669 - mae: 46.1283 - mape: 19.5181 - val_loss: 24.2811 - val_mae: 92.6474 - val_mape: 24.2338 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 19.3083 - mae: 53.0253 - mape: 19.2619 - val_loss: 15.9284 - val_mae: 32.4221 - val_mape: 15.8823 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 17.8239 - mae: 46.1071 - mape: 17.7766 - val_loss: 16.1244 - val_mae: 64.1292 - val_mape: 16.0780 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 17.5734 - mae: 43.5158 - mape: 17.5306 - val_loss: 22.0514 - val_mae: 83.5864 - val_mape: 22.0099 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 18.1966 - mae: 43.2862 - mape: 18.1560 - val_loss: 21.7257 - val_mae: 54.4687 - val_mape: 21.6874 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 18.0607 - mae: 46.8270 - mape: 18.0227 - val_loss: 17.8715 - val_mae: 61.1601 - val_mape: 17.8323 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.8122 - mae: 43.2973 - mape: 16.7730 - val_loss: 22.1567 - val_mae: 55.3761 - val_mape: 22.1200 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 17.8394 - mae: 41.6077 - mape: 17.8034 - val_loss: 16.0425 - val_mae: 72.7906 - val_mape: 16.0075 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 17.7178 - mae: 42.2707 - mape: 17.6841 - val_loss: 17.2890 - val_mae: 46.2619 - val_mape: 17.2557 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 18.8774 - mae: 47.3418 - mape: 18.8423 - val_loss: 19.6735 - val_mae: 48.2892 - val_mape: 19.6387 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 18.5706 - mae: 45.0121 - mape: 18.5365 - val_loss: 18.5940 - val_mae: 48.8783 - val_mape: 18.5591 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 18.0781 - mae: 40.5008 - mape: 18.0424 - val_loss: 19.7707 - val_mae: 78.4584 - val_mape: 19.7351 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 18.0314 - mae: 45.0861 - mape: 17.9974 - val_loss: 15.0258 - val_mae: 37.2153 - val_mape: 14.9923 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 18.5880 - mae: 48.1464 - mape: 18.5562 - val_loss: 16.1198 - val_mae: 49.5322 - val_mape: 16.0895 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 18.1640 - mae: 47.8440 - mape: 18.1349 - val_loss: 21.9385 - val_mae: 82.6231 - val_mape: 21.9100 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.4825 - mae: 38.9385 - mape: 16.4544 - val_loss: 19.1516 - val_mae: 70.5373 - val_mape: 19.1230 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.4082 - mae: 42.4529 - mape: 17.3777 - val_loss: 23.3973 - val_mae: 79.6373 - val_mape: 23.3655 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 17.8900 - mae: 44.8274 - mape: 17.8574 - val_loss: 20.6525 - val_mae: 92.6378 - val_mape: 20.6211 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 20.8930 - mae: 47.8608 - mape: 20.8630 - val_loss: 19.0402 - val_mae: 92.4946 - val_mape: 19.0113 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.6512 - mae: 43.0924 - mape: 16.6218 - val_loss: 24.9305 - val_mae: 69.8342 - val_mape: 24.9005 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.4337 - mae: 45.4892 - mape: 17.4039 - val_loss: 23.4823 - val_mae: 73.3669 - val_mape: 23.4526 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 16.7943 - mae: 41.8628 - mape: 16.7642 - val_loss: 19.6218 - val_mae: 59.6485 - val_mape: 19.5921 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.1485 - mae: 39.5627 - mape: 17.1191 - val_loss: 25.5970 - val_mae: 104.8834 - val_mape: 25.5672 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 17.7402 - mae: 52.7439 - mape: 17.7108 - val_loss: 19.1988 - val_mae: 62.0642 - val_mape: 19.1693 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 17.0659 - mae: 45.0054 - mape: 17.0380 - val_loss: 19.1887 - val_mae: 97.9315 - val_mape: 19.1626 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.6139 - mae: 41.0736 - mape: 17.5889 - val_loss: 21.0479 - val_mae: 86.0490 - val_mape: 21.0248 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.8769 - mae: 42.3500 - mape: 16.8545\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 16.8769 - mae: 42.3500 - mape: 16.8545 - val_loss: 24.6026 - val_mae: 87.1657 - val_mape: 24.5806 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.5934 - mae: 36.1748 - mape: 15.5717 - val_loss: 20.1165 - val_mae: 78.6851 - val_mape: 20.0948 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.4500 - mae: 37.5051 - mape: 15.4286 - val_loss: 20.4795 - val_mae: 72.9224 - val_mape: 20.4581 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.5058 - mae: 32.8768 - mape: 14.4848 - val_loss: 19.1918 - val_mae: 66.4496 - val_mape: 19.1707 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.7442 - mae: 35.1089 - mape: 14.7231 - val_loss: 24.2794 - val_mae: 101.9587 - val_mape: 24.2582 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 14.9355 - mae: 36.1126 - mape: 14.9142 - val_loss: 21.7480 - val_mae: 83.2065 - val_mape: 21.7267 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 14.6704 - mae: 36.9685 - mape: 14.6490 - val_loss: 20.4912 - val_mae: 83.5534 - val_mape: 20.4695 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 14.8038 - mae: 32.8522 - mape: 14.7822 - val_loss: 19.3437 - val_mae: 65.5800 - val_mape: 19.3222 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.4288 - mae: 36.2837 - mape: 14.4075 - val_loss: 23.2819 - val_mae: 77.4445 - val_mape: 23.2609 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.6268 - mae: 36.6366 - mape: 14.6060 - val_loss: 20.6339 - val_mae: 82.0104 - val_mape: 20.6131 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 15.5077 - mae: 36.5206 - mape: 15.4875 - val_loss: 21.4890 - val_mae: 77.3872 - val_mape: 21.4690 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.6138 - mae: 32.9408 - mape: 14.5938 - val_loss: 20.9488 - val_mae: 80.3213 - val_mape: 20.9291 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.8581 - mae: 35.1659 - mape: 14.8382 - val_loss: 24.3678 - val_mae: 83.9927 - val_mape: 24.3478 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.5158 - mae: 33.2174 - mape: 14.4956 - val_loss: 22.0489 - val_mae: 96.2348 - val_mape: 22.0285 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.4553 - mae: 31.7713 - mape: 14.4351 - val_loss: 22.0740 - val_mae: 88.4066 - val_mape: 22.0538 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.5886 - mae: 34.8863 - mape: 14.5685 - val_loss: 25.1328 - val_mae: 94.8196 - val_mape: 25.1128 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.2384 - mae: 35.8861 - mape: 14.2186 - val_loss: 24.3514 - val_mae: 77.0422 - val_mape: 24.3313 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.6387 - mae: 34.7296 - mape: 14.6186 - val_loss: 24.5518 - val_mae: 100.2115 - val_mape: 24.5313 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.8970 - mae: 38.6215 - mape: 14.8760 - val_loss: 23.1756 - val_mae: 78.5566 - val_mape: 23.1541 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.2925 - mae: 36.8124 - mape: 15.2709 - val_loss: 28.6824 - val_mae: 101.9615 - val_mape: 28.6611 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.2757 - mae: 33.6569 - mape: 14.2545 - val_loss: 23.4585 - val_mae: 72.2225 - val_mape: 23.4376 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.6697 - mae: 30.6953 - mape: 14.6488 - val_loss: 22.5959 - val_mae: 91.5749 - val_mape: 22.5754 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.2204 - mae: 32.9858 - mape: 14.2003 - val_loss: 23.8177 - val_mae: 92.8626 - val_mape: 23.7976 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 14.2639 - mae: 32.0765 - mape: 14.2438 - val_loss: 22.5774 - val_mae: 92.7322 - val_mape: 22.5570 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.6244 - mae: 33.8203 - mape: 14.6039 - val_loss: 23.8769 - val_mae: 90.5747 - val_mape: 23.8567 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.7399 - mae: 36.5288 - mape: 14.7201 - val_loss: 23.7711 - val_mae: 108.1918 - val_mape: 23.7513 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 14.4302 - mae: 37.4332 - mape: 14.4103 - val_loss: 25.4656 - val_mae: 89.9618 - val_mape: 25.4453 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.9332 - mae: 36.6510 - mape: 14.9130 - val_loss: 21.5298 - val_mae: 86.2115 - val_mape: 21.5099 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 14.7004 - mae: 34.6102 - mape: 14.6804 - val_loss: 21.8842 - val_mae: 86.1874 - val_mape: 21.8645 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.9029 - mae: 35.6005 - mape: 14.8834 - val_loss: 22.1901 - val_mae: 91.3578 - val_mape: 22.1706 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.8008 - mae: 35.5869 - mape: 14.7817\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.8008 - mae: 35.5869 - mape: 14.7817 - val_loss: 24.6642 - val_mae: 89.5971 - val_mape: 24.6455 - lr: 3.0000e-04\n",
      "Epoch 65: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 13.912227630615234; mae of 58.61808776855469; mape of 13.852940559387207%;\n"
     ]
    }
   ],
   "source": [
    "#Hybrid reset\n",
    "nnmodel = keras.models.load_model('savedmodels/Baseline_nosupp_final')\n",
    "gcnmodel = keras.models.load_model('savedmodels/GCN_simplified_normalized')\n",
    "\n",
    "combined = concatenate([nnmodel.get_layer('dropbaseline').output, gcnmodel.get_layer('dropgcn').output], name='join')\n",
    "z = Dense(128,'relu', name='dense1')(combined)\n",
    "z = Dense(64,'relu', name='dense4')(z)\n",
    "z = Dropout(0.3, name='finaldrop')(z)\n",
    "z = Dense(1, 'linear', name='regress')(z)\n",
    "model = Model(inputs = [gcnmodel.input, nnmodel.input], outputs = z)\n",
    "\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, 'crossvalidationmodels/Hybrid_nosupp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 15.013823509216309 - Mean average error: 57.38688659667969% - Mean percentage error: 12.766820907592773%\n",
      "    Score on unseen data: Loss: 17.34811782836914 - Mean average error: 98.9913558959961% - Mean percentage error: 15.101117134094238%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 14.428936958312988 - Mean average error: 35.683292388916016% - Mean percentage error: 12.737340927124023%\n",
      "    Score on unseen data: Loss: 17.058748245239258 - Mean average error: 69.0162582397461% - Mean percentage error: 15.367151260375977%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 13.002521514892578 - Mean average error: 28.83129119873047% - Mean percentage error: 12.850089073181152%\n",
      "    Score on unseen data: Loss: 14.792323112487793 - Mean average error: 40.151004791259766% - Mean percentage error: 14.639891624450684%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 13.48575210571289 - Mean average error: 41.90851593017578% - Mean percentage error: 13.378936767578125%\n",
      "    Score on unseen data: Loss: 15.386791229248047 - Mean average error: 102.66401672363281% - Mean percentage error: 15.279975891113281%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 13.912227630615234 - Mean average error: 58.61808776855469% - Mean percentage error: 13.852940559387207%\n",
      "    Score on unseen data: Loss: 15.761534690856934 - Mean average error: 88.29154205322266% - Mean percentage error: 15.702247619628906%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 13.96865234375\n",
      "> Mean average error: 44.48561477661133\n",
      "> Mean percentage error: 13.117225646972656\n",
      "> Unseen Loss: 16.069503021240234\n",
      "> Unseen Mean average error: 79.82283554077148\n",
      "> Unseen Mean percentage error: 15.218076705932617\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 39.5757 - mae: 65.3432 - mape: 29.1302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 102ms/step - loss: 39.5757 - mae: 65.3432 - mape: 29.1302 - val_loss: 22.8461 - val_mae: 30.7437 - val_mape: 13.3833 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 25.2062 - mae: 40.3084 - mape: 16.5039"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 111ms/step - loss: 25.2062 - mae: 40.3084 - mape: 16.5039 - val_loss: 18.5341 - val_mae: 20.3611 - val_mape: 10.4483 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 86ms/step - loss: 22.9696 - mae: 37.3887 - mape: 15.2508 - val_loss: 18.3788 - val_mae: 23.1135 - val_mape: 10.9675 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 21.7935 - mae: 33.6280 - mape: 14.5973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 106ms/step - loss: 21.7935 - mae: 33.6280 - mape: 14.5973 - val_loss: 17.0988 - val_mae: 24.5002 - val_mape: 10.0998 - lr: 0.0010\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 82ms/step - loss: 21.2285 - mae: 37.0288 - mape: 14.4057 - val_loss: 17.0359 - val_mae: 22.9750 - val_mape: 10.3821 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 20.6505 - mae: 36.2822 - mape: 14.1258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 96ms/step - loss: 20.6505 - mae: 36.2822 - mape: 14.1258 - val_loss: 16.2358 - val_mae: 24.1255 - val_mape: 9.8296 - lr: 0.0010\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 20.4880 - mae: 34.9404 - mape: 14.1782"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 90ms/step - loss: 20.4408 - mae: 35.1230 - mape: 14.1320 - val_loss: 15.7966 - val_mae: 21.7914 - val_mape: 9.5835 - lr: 0.0010\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 69ms/step - loss: 20.1799 - mae: 36.8007 - mape: 14.0542 - val_loss: 18.1467 - val_mae: 26.2287 - val_mape: 12.1101 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 20.0997 - mae: 34.4716 - mape: 14.1272 - val_loss: 16.1621 - val_mae: 24.2169 - val_mape: 10.2509 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 19.6816 - mae: 33.1470 - mape: 13.8301 - val_loss: 15.8515 - val_mae: 22.3854 - val_mape: 10.0617 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.7031 - mae: 38.1682 - mape: 13.9619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 98ms/step - loss: 19.7031 - mae: 38.1682 - mape: 13.9619 - val_loss: 15.1678 - val_mae: 19.3557 - val_mape: 9.4626 - lr: 0.0010\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 72ms/step - loss: 19.8789 - mae: 37.3926 - mape: 14.2294 - val_loss: 15.2108 - val_mae: 21.9877 - val_mape: 9.6200 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 19.6686 - mae: 34.6001 - mape: 14.1200 - val_loss: 16.0021 - val_mae: 23.6489 - val_mape: 10.4922 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 19.5748 - mae: 35.0877 - mape: 14.0763 - val_loss: 18.1513 - val_mae: 31.6730 - val_mape: 12.7015 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.5464 - mae: 35.3845 - mape: 14.1159"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 95ms/step - loss: 19.5464 - mae: 35.3845 - mape: 14.1159 - val_loss: 14.6724 - val_mae: 19.0852 - val_mape: 9.2656 - lr: 0.0010\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 80ms/step - loss: 19.1629 - mae: 35.1824 - mape: 13.7864 - val_loss: 14.8510 - val_mae: 22.7199 - val_mape: 9.4949 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 19.1868 - mae: 34.7758 - mape: 13.8582 - val_loss: 18.1111 - val_mae: 33.6733 - val_mape: 12.8127 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 19.0867 - mae: 35.4377 - mape: 13.8237 - val_loss: 15.9792 - val_mae: 26.9629 - val_mape: 10.7534 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 19.0019 - mae: 36.7394 - mape: 13.7965 - val_loss: 14.5726 - val_mae: 21.1208 - val_mape: 9.3957 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 19.3081 - mae: 36.6106 - mape: 14.1359 - val_loss: 14.5474 - val_mae: 20.2887 - val_mape: 9.3903 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 18.9980 - mae: 33.0320 - mape: 13.8618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 96ms/step - loss: 18.9957 - mae: 32.9481 - mape: 13.8597 - val_loss: 14.3783 - val_mae: 19.0210 - val_mape: 9.2625 - lr: 0.0010\n",
      "Epoch 22/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 79ms/step - loss: 19.0134 - mae: 35.4059 - mape: 13.9225 - val_loss: 14.7039 - val_mae: 21.7926 - val_mape: 9.6184 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 19.2132 - mae: 36.1690 - mape: 14.1528 - val_loss: 15.0949 - val_mae: 22.9869 - val_mape: 10.0529 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.7697 - mae: 36.2261 - mape: 13.7477 - val_loss: 14.4236 - val_mae: 20.2642 - val_mape: 9.4243 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.9988 - mae: 35.9846 - mape: 14.0168 - val_loss: 14.9318 - val_mae: 25.0238 - val_mape: 9.9602 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.6393 - mae: 37.0482 - mape: 13.6848 - val_loss: 14.3417 - val_mae: 19.7858 - val_mape: 9.4023 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 18.4998 - mae: 38.1774 - mape: 13.5827 - val_loss: 14.6125 - val_mae: 23.8390 - val_mape: 9.7113 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.7864 - mae: 35.8514 - mape: 13.8897 - val_loss: 14.9946 - val_mae: 24.4261 - val_mape: 10.0932 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.8774 - mae: 38.3825 - mape: 13.9998 - val_loss: 14.1891 - val_mae: 19.1437 - val_mape: 9.3160 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.7865 - mae: 37.1572 - mape: 13.9446 - val_loss: 15.9007 - val_mae: 25.3967 - val_mape: 11.0754 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 18.5973 - mae: 33.3192 - mape: 13.7801 - val_loss: 14.4216 - val_mae: 19.7735 - val_mape: 9.6003 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 18.9766 - mae: 37.7067 - mape: 14.1745 - val_loss: 14.9548 - val_mae: 25.9285 - val_mape: 10.1686 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.7997 - mae: 36.5623 - mape: 14.0248 - val_loss: 14.0677 - val_mae: 19.1878 - val_mape: 9.3069 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.8935 - mae: 35.5566 - mape: 14.1380 - val_loss: 14.1582 - val_mae: 21.0637 - val_mape: 9.4057 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 18.5830 - mae: 36.6265 - mape: 13.8466 - val_loss: 14.2112 - val_mae: 20.4389 - val_mape: 9.4749 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 18.4574 - mae: 34.4529 - mape: 13.7405 - val_loss: 14.4199 - val_mae: 22.5993 - val_mape: 9.7139 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 18.3544 - mae: 36.4552 - mape: 13.6584 - val_loss: 14.0806 - val_mae: 19.0659 - val_mape: 9.3857 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.1746 - mae: 34.6504 - mape: 13.4910 - val_loss: 15.3235 - val_mae: 26.7097 - val_mape: 10.6432 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.6740 - mae: 32.3068 - mape: 13.9887 - val_loss: 14.1772 - val_mae: 22.0759 - val_mape: 9.4933 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.4683 - mae: 38.1884 - mape: 13.7991 - val_loss: 14.1447 - val_mae: 20.8039 - val_mape: 9.4866 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 18.4862 - mae: 34.6933 - mape: 13.8329 - val_loss: 14.2016 - val_mae: 22.7392 - val_mape: 9.5591 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 18.7011 - mae: 34.5701 - mape: 14.0637 - val_loss: 14.8095 - val_mae: 19.5412 - val_mape: 10.1703 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 18.4664 - mae: 36.9396 - mape: 13.8347 - val_loss: 14.9308 - val_mae: 26.3148 - val_mape: 10.3155 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.6873 - mae: 37.3631 - mape: 14.0667 - val_loss: 14.1415 - val_mae: 22.1229 - val_mape: 9.5380 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 18.3555 - mae: 35.4103 - mape: 13.7617 - val_loss: 13.9875 - val_mae: 19.0459 - val_mape: 9.3986 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 18.4897 - mae: 36.1562 - mape: 13.9113 - val_loss: 14.4385 - val_mae: 23.5834 - val_mape: 9.8651 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.4399 - mae: 35.0347 - mape: 13.8509 - val_loss: 14.8040 - val_mae: 19.9040 - val_mape: 10.2155 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.3560 - mae: 35.5632 - mape: 13.7918 - val_loss: 13.9470 - val_mae: 21.6024 - val_mape: 9.3942 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.2738 - mae: 34.7734 - mape: 13.7235 - val_loss: 14.6772 - val_mae: 24.0578 - val_mape: 10.1233 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.4271 - mae: 37.1320 - mape: 13.8730"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 103ms/step - loss: 18.4271 - mae: 37.1320 - mape: 13.8730 - val_loss: 13.7821 - val_mae: 19.1027 - val_mape: 9.2388 - lr: 0.0010\n",
      "Epoch 51/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 78ms/step - loss: 18.6472 - mae: 36.6988 - mape: 14.1178 - val_loss: 13.8403 - val_mae: 20.6355 - val_mape: 9.3194 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 18.1688 - mae: 36.8766 - mape: 13.6488 - val_loss: 14.0018 - val_mae: 21.8980 - val_mape: 9.4817 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 18.3303 - mae: 38.0154 - mape: 13.8065 - val_loss: 14.2392 - val_mae: 23.5076 - val_mape: 9.7260 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.5091 - mae: 35.1994 - mape: 13.9998 - val_loss: 16.5442 - val_mae: 29.3767 - val_mape: 12.0453 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.2623 - mae: 35.6762 - mape: 13.7601 - val_loss: 13.7594 - val_mae: 19.0169 - val_mape: 9.2447 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.9611 - mae: 33.3474 - mape: 13.4508 - val_loss: 13.9973 - val_mae: 21.6692 - val_mape: 9.5002 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.0251 - mae: 36.8711 - mape: 13.5351 - val_loss: 13.9157 - val_mae: 19.3095 - val_mape: 9.4183 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.2450 - mae: 34.2562 - mape: 13.7477 - val_loss: 13.8558 - val_mae: 20.3407 - val_mape: 9.3768 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.0783 - mae: 35.8891 - mape: 13.6117 - val_loss: 13.9916 - val_mae: 20.8977 - val_mape: 9.5295 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.1405 - mae: 35.6390 - mape: 13.6652 - val_loss: 14.1754 - val_mae: 22.3579 - val_mape: 9.6873 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.1933 - mae: 37.2077 - mape: 13.7047 - val_loss: 15.0161 - val_mae: 26.4832 - val_mape: 10.5405 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.8486 - mae: 34.0815 - mape: 13.3675 - val_loss: 13.8234 - val_mae: 20.9219 - val_mape: 9.3458 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 18.3802 - mae: 35.5613 - mape: 13.8934 - val_loss: 13.9887 - val_mae: 19.0758 - val_mape: 9.5154 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.9036 - mae: 34.0592 - mape: 13.4512 - val_loss: 14.5119 - val_mae: 26.0021 - val_mape: 10.0707 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.2531 - mae: 36.0117 - mape: 13.7993 - val_loss: 13.7695 - val_mae: 19.8114 - val_mape: 9.3201 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.0185 - mae: 35.4766 - mape: 13.5791 - val_loss: 13.9921 - val_mae: 20.5827 - val_mape: 9.5576 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.8168 - mae: 32.9821 - mape: 13.3885 - val_loss: 13.7048 - val_mae: 19.1436 - val_mape: 9.2722 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.3318 - mae: 35.5110 - mape: 13.9006 - val_loss: 13.9160 - val_mae: 19.0809 - val_mape: 9.4786 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.8981 - mae: 35.0123 - mape: 13.4686 - val_loss: 14.1670 - val_mae: 22.9316 - val_mape: 9.7502 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.9497 - mae: 33.7297 - mape: 13.5130 - val_loss: 14.9085 - val_mae: 25.0476 - val_mape: 10.4761 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.0013 - mae: 38.7610 - mape: 13.5701 - val_loss: 13.9618 - val_mae: 21.2692 - val_mape: 9.5417 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.8826 - mae: 34.6682 - mape: 13.4658"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 17.8826 - mae: 34.6682 - mape: 13.4658 - val_loss: 13.6438 - val_mae: 19.0545 - val_mape: 9.2226 - lr: 0.0010\n",
      "Epoch 73/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 79ms/step - loss: 17.8073 - mae: 34.6931 - mape: 13.3924 - val_loss: 13.9226 - val_mae: 20.6365 - val_mape: 9.5026 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.6666 - mae: 31.9881 - mape: 13.2570 - val_loss: 13.6799 - val_mae: 19.3421 - val_mape: 9.2681 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.7121 - mae: 35.1528 - mape: 13.3105 - val_loss: 13.6522 - val_mae: 19.1644 - val_mape: 9.2480 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.8245 - mae: 34.3300 - mape: 13.4174 - val_loss: 13.6527 - val_mae: 19.0111 - val_mape: 9.2391 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.7826 - mae: 36.4683 - mape: 13.3796 - val_loss: 15.2903 - val_mae: 27.7730 - val_mape: 10.9040 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.6980 - mae: 34.2202 - mape: 13.3082 - val_loss: 13.6265 - val_mae: 19.0707 - val_mape: 9.2299 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.8388 - mae: 34.1210 - mape: 13.4600 - val_loss: 14.7332 - val_mae: 25.5999 - val_mape: 10.3584 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.8895 - mae: 35.3109 - mape: 13.5110 - val_loss: 13.7083 - val_mae: 19.0669 - val_mape: 9.3218 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.6246 - mae: 35.2298 - mape: 13.2459 - val_loss: 13.7035 - val_mae: 19.9336 - val_mape: 9.3207 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.7972 - mae: 36.4048 - mape: 13.4187 - val_loss: 13.6580 - val_mae: 19.9486 - val_mape: 9.2809 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.6675 - mae: 34.8902 - mape: 13.2891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 17.6675 - mae: 34.8902 - mape: 13.2891 - val_loss: 13.6075 - val_mae: 19.0043 - val_mape: 9.2199 - lr: 0.0010\n",
      "Epoch 84/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 85ms/step - loss: 18.1340 - mae: 36.7623 - mape: 13.7497 - val_loss: 13.9647 - val_mae: 21.3140 - val_mape: 9.5851 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.5365 - mae: 34.7979 - mape: 13.1619 - val_loss: 13.8977 - val_mae: 22.7293 - val_mape: 9.5400 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.8434 - mae: 34.3512 - mape: 13.4811 - val_loss: 14.0883 - val_mae: 21.7864 - val_mape: 9.7310 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.1888 - mae: 36.3059 - mape: 13.8265 - val_loss: 15.0637 - val_mae: 26.6441 - val_mape: 10.7078 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.9815 - mae: 34.0668 - mape: 13.6270 - val_loss: 13.7077 - val_mae: 19.1162 - val_mape: 9.3489 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.4053 - mae: 32.3374 - mape: 13.0578 - val_loss: 14.3373 - val_mae: 24.5666 - val_mape: 10.0041 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.7373 - mae: 34.4812 - mape: 13.4006 - val_loss: 13.8054 - val_mae: 21.5133 - val_mape: 9.4678 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.9665 - mae: 36.1638 - mape: 13.6245 - val_loss: 15.8210 - val_mae: 27.9119 - val_mape: 11.4803 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.6319 - mae: 35.7020 - mape: 13.2876 - val_loss: 13.7023 - val_mae: 20.4594 - val_mape: 9.3660 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.9827 - mae: 35.3192 - mape: 13.6475 - val_loss: 13.6769 - val_mae: 19.5465 - val_mape: 9.3274 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.5214 - mae: 32.8594 - mape: 13.1777 - val_loss: 13.6692 - val_mae: 19.0848 - val_mape: 9.3235 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.9729 - mae: 36.0966 - mape: 13.6303"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 102ms/step - loss: 17.9729 - mae: 36.0966 - mape: 13.6303 - val_loss: 13.5762 - val_mae: 19.1867 - val_mape: 9.2197 - lr: 0.0010\n",
      "Epoch 96/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 73ms/step - loss: 17.5934 - mae: 32.4659 - mape: 13.2441 - val_loss: 14.0105 - val_mae: 22.4668 - val_mape: 9.6765 - lr: 0.0010\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.6175 - mae: 35.7843 - mape: 13.2829 - val_loss: 13.7839 - val_mae: 19.9129 - val_mape: 9.4526 - lr: 0.0010\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.7888 - mae: 34.1621 - mape: 13.4516 - val_loss: 14.0587 - val_mae: 22.2555 - val_mape: 9.7230 - lr: 0.0010\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.3077 - mae: 36.3546 - mape: 12.9670 - val_loss: 13.7066 - val_mae: 19.0339 - val_mape: 9.3653 - lr: 0.0010\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.7855 - mae: 34.4798 - mape: 13.4482"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 17.7855 - mae: 34.4798 - mape: 13.4482 - val_loss: 13.5451 - val_mae: 19.1276 - val_mape: 9.2157 - lr: 0.0010\n",
      "Epoch 101/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 80ms/step - loss: 17.8069 - mae: 34.3833 - mape: 13.4870 - val_loss: 13.5753 - val_mae: 19.0189 - val_mape: 9.2627 - lr: 0.0010\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 7s 75ms/step - loss: 17.6125 - mae: 31.6401 - mape: 13.2987 - val_loss: 13.8942 - val_mae: 21.2591 - val_mape: 9.5774 - lr: 0.0010\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.7029 - mae: 39.0065 - mape: 13.3865 - val_loss: 13.5543 - val_mae: 19.0386 - val_mape: 9.2312 - lr: 0.0010\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.8056 - mae: 33.5254 - mape: 13.4901 - val_loss: 13.8605 - val_mae: 19.4805 - val_mape: 9.5411 - lr: 0.0010\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.7370 - mae: 33.8495 - mape: 13.4245 - val_loss: 13.7294 - val_mae: 19.9454 - val_mape: 9.4079 - lr: 0.0010\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.6265 - mae: 34.2283 - mape: 13.3120 - val_loss: 13.6909 - val_mae: 19.1180 - val_mape: 9.3777 - lr: 0.0010\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.2679 - mae: 33.9381 - mape: 12.9554 - val_loss: 13.5588 - val_mae: 19.2222 - val_mape: 9.2459 - lr: 0.0010\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.7948 - mae: 34.0299 - mape: 13.4908 - val_loss: 13.6844 - val_mae: 20.6375 - val_mape: 9.3794 - lr: 0.0010\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.7748 - mae: 35.0397 - mape: 13.4650"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 96ms/step - loss: 17.7748 - mae: 35.0397 - mape: 13.4650 - val_loss: 13.5254 - val_mae: 19.0823 - val_mape: 9.2081 - lr: 0.0010\n",
      "Epoch 110/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 80ms/step - loss: 17.4461 - mae: 36.2540 - mape: 13.1300 - val_loss: 13.8224 - val_mae: 21.2734 - val_mape: 9.5110 - lr: 0.0010\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.4706 - mae: 33.2470 - mape: 13.1505 - val_loss: 14.0772 - val_mae: 21.9859 - val_mape: 9.7660 - lr: 0.0010\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.5002 - mae: 32.4281 - mape: 13.1891 - val_loss: 14.2445 - val_mae: 20.2766 - val_mape: 9.9214 - lr: 0.0010\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.5445 - mae: 35.2565 - mape: 13.2214 - val_loss: 14.6499 - val_mae: 25.4686 - val_mape: 10.3264 - lr: 0.0010\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.5926 - mae: 34.3964 - mape: 13.2702 - val_loss: 13.5704 - val_mae: 19.0423 - val_mape: 9.2506 - lr: 0.0010\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 17.4578 - mae: 35.6643 - mape: 13.1473 - val_loss: 13.7226 - val_mae: 20.8186 - val_mape: 9.4213 - lr: 0.0010\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.2630 - mae: 32.8560 - mape: 12.9643 - val_loss: 13.6047 - val_mae: 19.9687 - val_mape: 9.3017 - lr: 0.0010\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 17.5803 - mae: 35.2775 - mape: 13.2690 - val_loss: 13.5551 - val_mae: 19.3195 - val_mape: 9.2532 - lr: 0.0010\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 6s 74ms/step - loss: 17.6042 - mae: 36.1740 - mape: 13.3056 - val_loss: 13.5828 - val_mae: 19.0739 - val_mape: 9.2833 - lr: 0.0010\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 6s 73ms/step - loss: 17.6180 - mae: 33.6824 - mape: 13.3203 - val_loss: 13.5387 - val_mae: 19.2051 - val_mape: 9.2425 - lr: 0.0010\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.2627 - mae: 33.5173 - mape: 12.9719 - val_loss: 13.5169 - val_mae: 19.1043 - val_mape: 9.2260 - lr: 0.0010\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.3365 - mae: 32.7667 - mape: 13.0485 - val_loss: 14.0978 - val_mae: 19.4261 - val_mape: 9.8121 - lr: 0.0010\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.4367 - mae: 33.9069 - mape: 13.1487 - val_loss: 13.9499 - val_mae: 21.8923 - val_mape: 9.6653 - lr: 0.0010\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.4693 - mae: 34.0526 - mape: 13.1813 - val_loss: 13.6184 - val_mae: 20.4213 - val_mape: 9.3287 - lr: 0.0010\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.4120 - mae: 34.9971 - mape: 13.1179 - val_loss: 13.5793 - val_mae: 19.6169 - val_mape: 9.2643 - lr: 0.0010\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.4207 - mae: 33.8374 - mape: 13.1301 - val_loss: 13.5936 - val_mae: 20.2679 - val_mape: 9.3107 - lr: 0.0010\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.3354 - mae: 32.5404 - mape: 13.0554 - val_loss: 14.2507 - val_mae: 23.9693 - val_mape: 9.9763 - lr: 0.0010\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.3801 - mae: 33.6648 - mape: 13.0951 - val_loss: 13.5218 - val_mae: 19.1814 - val_mape: 9.2407 - lr: 0.0010\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.4395 - mae: 34.4353 - mape: 13.1508 - val_loss: 13.5916 - val_mae: 19.0523 - val_mape: 9.3001 - lr: 0.0010\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.0663 - mae: 36.0274 - mape: 12.7848 - val_loss: 14.0872 - val_mae: 22.4670 - val_mape: 9.8039 - lr: 0.0010\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.2996 - mae: 34.3624 - mape: 13.0168 - val_loss: 13.7143 - val_mae: 20.3771 - val_mape: 9.4427 - lr: 0.0010\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.5286 - mae: 34.3852 - mape: 13.2492 - val_loss: 14.3391 - val_mae: 23.8568 - val_mape: 10.0655 - lr: 0.0010\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 6s 74ms/step - loss: 17.4853 - mae: 31.4311 - mape: 13.1977 - val_loss: 13.9551 - val_mae: 22.3857 - val_mape: 9.6656 - lr: 0.0010\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 6s 74ms/step - loss: 17.2977 - mae: 32.2868 - mape: 13.0177 - val_loss: 13.5115 - val_mae: 19.2888 - val_mape: 9.2451 - lr: 0.0010\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.3651 - mae: 33.6932 - mape: 13.1017 - val_loss: 13.8042 - val_mae: 21.9026 - val_mape: 9.5368 - lr: 0.0010\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.2513 - mae: 34.9549 - mape: 12.9812 - val_loss: 13.6078 - val_mae: 19.7949 - val_mape: 9.3316 - lr: 0.0010\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.0389 - mae: 32.4692 - mape: 12.7532 - val_loss: 13.9750 - val_mae: 22.4536 - val_mape: 9.6933 - lr: 0.0010\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.5672 - mae: 35.1973 - mape: 13.2907 - val_loss: 13.5843 - val_mae: 19.2817 - val_mape: 9.3028 - lr: 0.0010\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.1932 - mae: 35.5233 - mape: 12.9147 - val_loss: 14.0298 - val_mae: 22.9622 - val_mape: 9.7502 - lr: 0.0010\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.3207 - mae: 34.5023 - mape: 13.0379 - val_loss: 13.8066 - val_mae: 21.4528 - val_mape: 9.5288 - lr: 0.0010\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.2912 - mae: 35.9182 - mape: 13.0173 - val_loss: 13.5878 - val_mae: 19.4086 - val_mape: 9.3143 - lr: 0.0010\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.4904 - mae: 34.4590 - mape: 13.2093 - val_loss: 13.8052 - val_mae: 19.2863 - val_mape: 9.5081 - lr: 0.0010\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.1521 - mae: 33.3539 - mape: 12.8692 - val_loss: 13.5735 - val_mae: 19.5640 - val_mape: 9.2913 - lr: 0.0010\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0484 - mae: 32.4516 - mape: 12.7718 - val_loss: 13.6066 - val_mae: 19.0257 - val_mape: 9.3280 - lr: 0.0010\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.3454 - mae: 35.5277 - mape: 13.0631 - val_loss: 14.3830 - val_mae: 22.9184 - val_mape: 10.1019 - lr: 0.0010\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9245 - mae: 33.0065 - mape: 12.6328 - val_loss: 14.5494 - val_mae: 24.3641 - val_mape: 10.2662 - lr: 0.0010\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.2127 - mae: 33.3771 - mape: 12.9146 - val_loss: 13.6385 - val_mae: 19.3987 - val_mape: 9.3245 - lr: 0.0010\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.0061 - mae: 32.0891 - mape: 12.6929 - val_loss: 13.5770 - val_mae: 19.0093 - val_mape: 9.2794 - lr: 0.0010\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9631 - mae: 32.6878 - mape: 12.6737 - val_loss: 13.8692 - val_mae: 19.3643 - val_mape: 9.5774 - lr: 0.0010\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.2344 - mae: 32.1374 - mape: 12.9396"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 17.2344 - mae: 32.1374 - mape: 12.9396 - val_loss: 13.5061 - val_mae: 19.3034 - val_mape: 9.2075 - lr: 0.0010\n",
      "Epoch 150/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 77ms/step - loss: 17.3990 - mae: 36.0172 - mape: 13.1088 - val_loss: 13.5782 - val_mae: 19.0426 - val_mape: 9.2867 - lr: 0.0010\n",
      "Epoch 151/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 17.1956 - mae: 33.2933 - mape: 12.9033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 94ms/step - loss: 17.1858 - mae: 33.5682 - mape: 12.8935 - val_loss: 13.4907 - val_mae: 19.1145 - val_mape: 9.1991 - lr: 0.0010\n",
      "Epoch 152/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 76ms/step - loss: 17.1108 - mae: 34.2382 - mape: 12.8266 - val_loss: 13.9262 - val_mae: 23.2256 - val_mape: 9.6529 - lr: 0.0010\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.3055 - mae: 35.1851 - mape: 13.0212 - val_loss: 13.7364 - val_mae: 21.4962 - val_mape: 9.4535 - lr: 0.0010\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8509 - mae: 34.1498 - mape: 12.5603 - val_loss: 14.0512 - val_mae: 22.3568 - val_mape: 9.7692 - lr: 0.0010\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.0563 - mae: 34.8965 - mape: 12.7738 - val_loss: 13.5171 - val_mae: 19.3577 - val_mape: 9.2328 - lr: 0.0010\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0071 - mae: 33.9799 - mape: 12.7308 - val_loss: 13.5834 - val_mae: 19.6874 - val_mape: 9.3105 - lr: 0.0010\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1560 - mae: 34.6949 - mape: 12.8836 - val_loss: 13.5803 - val_mae: 19.5614 - val_mape: 9.3028 - lr: 0.0010\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.9954 - mae: 34.0904 - mape: 12.7159 - val_loss: 14.2588 - val_mae: 21.5894 - val_mape: 9.9807 - lr: 0.0010\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9406 - mae: 32.7781 - mape: 12.6632 - val_loss: 13.5672 - val_mae: 19.7282 - val_mape: 9.2849 - lr: 0.0010\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9374 - mae: 33.0256 - mape: 12.6651 - val_loss: 14.1743 - val_mae: 23.4336 - val_mape: 9.9115 - lr: 0.0010\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1311 - mae: 35.3822 - mape: 12.8610 - val_loss: 13.5280 - val_mae: 19.0741 - val_mape: 9.2516 - lr: 0.0010\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8527 - mae: 32.6173 - mape: 12.5814 - val_loss: 14.3362 - val_mae: 23.1024 - val_mape: 10.0664 - lr: 0.0010\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0171 - mae: 32.8860 - mape: 12.7410 - val_loss: 13.5009 - val_mae: 19.4800 - val_mape: 9.2249 - lr: 0.0010\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7776 - mae: 33.1343 - mape: 12.5025 - val_loss: 13.7356 - val_mae: 20.1893 - val_mape: 9.4551 - lr: 0.0010\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8490 - mae: 33.2782 - mape: 12.5662 - val_loss: 13.5779 - val_mae: 19.9971 - val_mape: 9.3019 - lr: 0.0010\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.4710 - mae: 31.7684 - mape: 13.1951 - val_loss: 13.9304 - val_mae: 22.5016 - val_mape: 9.6607 - lr: 0.0010\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9305 - mae: 34.7019 - mape: 12.6519 - val_loss: 13.5582 - val_mae: 19.1148 - val_mape: 9.2776 - lr: 0.0010\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0612 - mae: 34.2028 - mape: 12.7861 - val_loss: 13.8062 - val_mae: 19.5416 - val_mape: 9.5273 - lr: 0.0010\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1242 - mae: 30.5584 - mape: 12.8448 - val_loss: 13.8209 - val_mae: 21.0275 - val_mape: 9.5458 - lr: 0.0010\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.3204 - mae: 34.0048 - mape: 13.0431 - val_loss: 13.6785 - val_mae: 20.5520 - val_mape: 9.3954 - lr: 0.0010\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8283 - mae: 31.4979 - mape: 12.5390 - val_loss: 14.3561 - val_mae: 24.3277 - val_mape: 10.0660 - lr: 0.0010\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.1465 - mae: 34.4360 - mape: 12.8618 - val_loss: 13.5253 - val_mae: 19.5137 - val_mape: 9.2477 - lr: 0.0010\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8888 - mae: 33.5350 - mape: 12.6075 - val_loss: 13.4904 - val_mae: 19.0813 - val_mape: 9.2099 - lr: 0.0010\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.2238 - mae: 35.0213 - mape: 12.9446 - val_loss: 14.5264 - val_mae: 24.4771 - val_mape: 10.2521 - lr: 0.0010\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8963 - mae: 33.4846 - mape: 12.6083 - val_loss: 13.5684 - val_mae: 19.4465 - val_mape: 9.2721 - lr: 0.0010\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.0582 - mae: 32.9471 - mape: 12.7695 - val_loss: 13.8360 - val_mae: 22.0235 - val_mape: 9.5492 - lr: 0.0010\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6718 - mae: 32.1154 - mape: 12.3721 - val_loss: 13.8229 - val_mae: 22.1325 - val_mape: 9.5408 - lr: 0.0010\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8220 - mae: 33.1335 - mape: 12.5455 - val_loss: 13.6677 - val_mae: 21.0258 - val_mape: 9.3971 - lr: 0.0010\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9040 - mae: 33.5704 - mape: 12.6271 - val_loss: 13.7301 - val_mae: 20.8296 - val_mape: 9.4597 - lr: 0.0010\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8299 - mae: 33.4981 - mape: 12.5557 - val_loss: 13.5617 - val_mae: 19.5639 - val_mape: 9.2836 - lr: 0.0010\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.7211 - mae: 31.7453 - mape: 12.4453 - val_loss: 13.5219 - val_mae: 19.2239 - val_mape: 9.2394 - lr: 0.0010\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.7188 - mae: 32.8594 - mape: 12.4319 - val_loss: 13.6090 - val_mae: 20.2635 - val_mape: 9.3265 - lr: 0.0010\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8047 - mae: 33.9021 - mape: 12.5247 - val_loss: 13.5401 - val_mae: 19.6729 - val_mape: 9.2609 - lr: 0.0010\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9674 - mae: 33.8573 - mape: 12.6886 - val_loss: 13.7543 - val_mae: 21.3364 - val_mape: 9.4847 - lr: 0.0010\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9616 - mae: 31.4758 - mape: 12.6720 - val_loss: 13.5360 - val_mae: 19.1647 - val_mape: 9.2430 - lr: 0.0010\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.5078 - mae: 30.4044 - mape: 12.2293 - val_loss: 14.7893 - val_mae: 26.1632 - val_mape: 10.5214 - lr: 0.0010\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.1477 - mae: 33.5842 - mape: 12.8712 - val_loss: 14.6873 - val_mae: 25.2333 - val_mape: 10.4089 - lr: 0.0010\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8073 - mae: 32.7934 - mape: 12.5211 - val_loss: 14.0151 - val_mae: 22.5383 - val_mape: 9.7282 - lr: 0.0010\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9449 - mae: 32.4825 - mape: 12.6502 - val_loss: 13.9934 - val_mae: 20.6422 - val_mape: 9.7008 - lr: 0.0010\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.5867 - mae: 30.6401 - mape: 12.3024"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 16.5867 - mae: 30.6401 - mape: 12.3024 - val_loss: 13.4845 - val_mae: 19.3131 - val_mape: 9.1991 - lr: 0.0010\n",
      "Epoch 191/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.8642 - mae: 36.1837 - mape: 12.5837"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 97ms/step - loss: 16.8642 - mae: 36.1837 - mape: 12.5837 - val_loss: 13.4842 - val_mae: 19.3755 - val_mape: 9.1957 - lr: 0.0010\n",
      "Epoch 192/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 75ms/step - loss: 16.7991 - mae: 33.5316 - mape: 12.5172 - val_loss: 13.5496 - val_mae: 19.9192 - val_mape: 9.2793 - lr: 0.0010\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.7911 - mae: 31.3130 - mape: 12.5142 - val_loss: 13.7019 - val_mae: 20.0945 - val_mape: 9.4349 - lr: 0.0010\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8018 - mae: 33.0962 - mape: 12.5305 - val_loss: 13.9048 - val_mae: 21.4759 - val_mape: 9.6292 - lr: 0.0010\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9821 - mae: 33.4828 - mape: 12.7071 - val_loss: 13.5399 - val_mae: 19.0475 - val_mape: 9.2665 - lr: 0.0010\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0122 - mae: 34.1838 - mape: 12.7359 - val_loss: 13.7627 - val_mae: 20.1596 - val_mape: 9.4854 - lr: 0.0010\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8725 - mae: 30.7858 - mape: 12.5949 - val_loss: 13.9788 - val_mae: 21.8335 - val_mape: 9.7080 - lr: 0.0010\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9234 - mae: 30.8652 - mape: 12.6470 - val_loss: 13.5645 - val_mae: 19.1039 - val_mape: 9.2885 - lr: 0.0010\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0109 - mae: 33.5113 - mape: 12.7329 - val_loss: 13.5699 - val_mae: 19.5184 - val_mape: 9.2896 - lr: 0.0010\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0519 - mae: 32.9210 - mape: 12.7625 - val_loss: 13.6117 - val_mae: 20.4200 - val_mape: 9.3253 - lr: 0.0010\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8211 - mae: 33.1311 - mape: 12.5276 - val_loss: 13.7173 - val_mae: 19.9767 - val_mape: 9.4127 - lr: 0.0010\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8325 - mae: 31.7165 - mape: 12.5427 - val_loss: 14.1263 - val_mae: 21.7552 - val_mape: 9.8380 - lr: 0.0010\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6570 - mae: 30.9540 - mape: 12.3698 - val_loss: 13.5460 - val_mae: 19.2371 - val_mape: 9.2607 - lr: 0.0010\n",
      "Epoch 204/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7480 - mae: 32.9601 - mape: 12.4650 - val_loss: 13.5750 - val_mae: 20.2077 - val_mape: 9.2971 - lr: 0.0010\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9187 - mae: 34.2533 - mape: 12.6388 - val_loss: 13.5783 - val_mae: 20.0486 - val_mape: 9.2857 - lr: 0.0010\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9276 - mae: 35.1572 - mape: 12.6371 - val_loss: 13.7998 - val_mae: 20.8785 - val_mape: 9.5189 - lr: 0.0010\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8850 - mae: 30.2996 - mape: 12.5964 - val_loss: 13.5354 - val_mae: 19.2409 - val_mape: 9.2384 - lr: 0.0010\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6700 - mae: 31.8714 - mape: 12.3772 - val_loss: 13.7542 - val_mae: 20.8584 - val_mape: 9.4702 - lr: 0.0010\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8778 - mae: 35.7004 - mape: 12.6000 - val_loss: 13.5487 - val_mae: 19.4963 - val_mape: 9.2589 - lr: 0.0010\n",
      "Epoch 210/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0690 - mae: 32.6181 - mape: 12.7865 - val_loss: 13.8768 - val_mae: 21.2976 - val_mape: 9.5944 - lr: 0.0010\n",
      "Epoch 211/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6945 - mae: 31.4329 - mape: 12.4000 - val_loss: 13.6452 - val_mae: 19.9701 - val_mape: 9.3482 - lr: 0.0010\n",
      "Epoch 212/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.6176 - mae: 30.9772 - mape: 12.3266 - val_loss: 13.5123 - val_mae: 19.3816 - val_mape: 9.1966 - lr: 0.0010\n",
      "Epoch 213/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6050 - mae: 32.5639 - mape: 12.2972 - val_loss: 13.9200 - val_mae: 21.6636 - val_mape: 9.6169 - lr: 0.0010\n",
      "Epoch 214/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.4264 - mae: 30.4993 - mape: 12.1310 - val_loss: 13.9980 - val_mae: 23.4795 - val_mape: 9.7204 - lr: 0.0010\n",
      "Epoch 215/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7004 - mae: 31.3913 - mape: 12.4129 - val_loss: 13.5187 - val_mae: 19.2751 - val_mape: 9.2324 - lr: 0.0010\n",
      "Epoch 216/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.1830 - mae: 31.6530 - mape: 11.8929 - val_loss: 13.5257 - val_mae: 19.3397 - val_mape: 9.2178 - lr: 0.0010\n",
      "Epoch 217/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6561 - mae: 30.6482 - mape: 12.3727 - val_loss: 13.5293 - val_mae: 19.0498 - val_mape: 9.2552 - lr: 0.0010\n",
      "Epoch 218/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7381 - mae: 34.3252 - mape: 12.4624 - val_loss: 13.5513 - val_mae: 19.6098 - val_mape: 9.2635 - lr: 0.0010\n",
      "Epoch 219/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5580 - mae: 30.9276 - mape: 12.2728 - val_loss: 13.4976 - val_mae: 19.3217 - val_mape: 9.2033 - lr: 0.0010\n",
      "Epoch 220/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9874 - mae: 32.8522 - mape: 12.7061 - val_loss: 13.9250 - val_mae: 19.6648 - val_mape: 9.6186 - lr: 0.0010\n",
      "Epoch 221/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.6194 - mae: 31.6485 - mape: 12.3204\n",
      "Epoch 221: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6194 - mae: 31.6485 - mape: 12.3204 - val_loss: 13.6307 - val_mae: 20.3413 - val_mape: 9.3245 - lr: 0.0010\n",
      "Epoch 222/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.7886 - mae: 33.4632 - mape: 12.5002 - val_loss: 13.6101 - val_mae: 20.7580 - val_mape: 9.3338 - lr: 3.0000e-04\n",
      "Epoch 223/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5981 - mae: 33.7030 - mape: 12.3235 - val_loss: 14.4040 - val_mae: 25.1225 - val_mape: 10.1338 - lr: 3.0000e-04\n",
      "Epoch 224/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7682 - mae: 33.1696 - mape: 12.5006 - val_loss: 13.9716 - val_mae: 22.8643 - val_mape: 9.7049 - lr: 3.0000e-04\n",
      "Epoch 225/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5936 - mae: 35.1324 - mape: 12.3240 - val_loss: 13.8283 - val_mae: 22.2076 - val_mape: 9.5594 - lr: 3.0000e-04\n",
      "Epoch 226/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5712 - mae: 32.3661 - mape: 12.2997 - val_loss: 13.8530 - val_mae: 22.2006 - val_mape: 9.5786 - lr: 3.0000e-04\n",
      "Epoch 227/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4983 - mae: 31.0139 - mape: 12.2229 - val_loss: 13.5251 - val_mae: 19.5423 - val_mape: 9.2487 - lr: 3.0000e-04\n",
      "Epoch 228/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4935 - mae: 30.2678 - mape: 12.2204 - val_loss: 13.6019 - val_mae: 19.8983 - val_mape: 9.3233 - lr: 3.0000e-04\n",
      "Epoch 229/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5765 - mae: 31.0346 - mape: 12.3005 - val_loss: 13.8819 - val_mae: 21.8665 - val_mape: 9.6088 - lr: 3.0000e-04\n",
      "Epoch 230/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7081 - mae: 33.3799 - mape: 12.4297 - val_loss: 14.0506 - val_mae: 23.2425 - val_mape: 9.7752 - lr: 3.0000e-04\n",
      "Epoch 231/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.3690 - mae: 31.3782 - mape: 12.0891 - val_loss: 13.6779 - val_mae: 20.8818 - val_mape: 9.3963 - lr: 3.0000e-04\n",
      "Epoch 232/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6002 - mae: 31.3104 - mape: 12.3198 - val_loss: 13.7583 - val_mae: 21.1935 - val_mape: 9.4798 - lr: 3.0000e-04\n",
      "Epoch 233/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6656 - mae: 32.9501 - mape: 12.3913 - val_loss: 13.8156 - val_mae: 21.8440 - val_mape: 9.5440 - lr: 3.0000e-04\n",
      "Epoch 234/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7292 - mae: 31.5609 - mape: 12.4514 - val_loss: 13.7622 - val_mae: 21.1495 - val_mape: 9.4833 - lr: 3.0000e-04\n",
      "Epoch 235/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.4909 - mae: 31.1001 - mape: 12.2119 - val_loss: 13.9611 - val_mae: 21.9204 - val_mape: 9.6842 - lr: 3.0000e-04\n",
      "Epoch 236/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4245 - mae: 32.7600 - mape: 12.1476 - val_loss: 13.8552 - val_mae: 21.7350 - val_mape: 9.5778 - lr: 3.0000e-04\n",
      "Epoch 237/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4941 - mae: 32.4350 - mape: 12.2111 - val_loss: 13.9908 - val_mae: 21.2272 - val_mape: 9.6989 - lr: 3.0000e-04\n",
      "Epoch 238/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.3798 - mae: 33.1920 - mape: 12.0884 - val_loss: 13.8013 - val_mae: 21.1462 - val_mape: 9.5178 - lr: 3.0000e-04\n",
      "Epoch 239/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4596 - mae: 31.4194 - mape: 12.1752 - val_loss: 13.7265 - val_mae: 20.7596 - val_mape: 9.4428 - lr: 3.0000e-04\n",
      "Epoch 240/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7975 - mae: 32.9901 - mape: 12.5157 - val_loss: 14.0195 - val_mae: 23.1266 - val_mape: 9.7395 - lr: 3.0000e-04\n",
      "Epoch 241/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6451 - mae: 32.6982 - mape: 12.3626 - val_loss: 14.0538 - val_mae: 23.1871 - val_mape: 9.7756 - lr: 3.0000e-04\n",
      "Epoch 242/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4834 - mae: 34.6098 - mape: 12.2032 - val_loss: 13.7133 - val_mae: 20.3844 - val_mape: 9.4324 - lr: 3.0000e-04\n",
      "Epoch 243/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6843 - mae: 33.3368 - mape: 12.4082 - val_loss: 13.7215 - val_mae: 21.4775 - val_mape: 9.4483 - lr: 3.0000e-04\n",
      "Epoch 244/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5100 - mae: 31.8705 - mape: 12.2307 - val_loss: 14.0654 - val_mae: 22.5369 - val_mape: 9.7879 - lr: 3.0000e-04\n",
      "Epoch 245/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5435 - mae: 31.9124 - mape: 12.2584 - val_loss: 13.6232 - val_mae: 20.0801 - val_mape: 9.3376 - lr: 3.0000e-04\n",
      "Epoch 246/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7973 - mae: 32.1136 - mape: 12.5203 - val_loss: 13.5085 - val_mae: 19.1278 - val_mape: 9.2228 - lr: 3.0000e-04\n",
      "Epoch 247/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8350 - mae: 33.7514 - mape: 12.5574 - val_loss: 13.8866 - val_mae: 21.2711 - val_mape: 9.6048 - lr: 3.0000e-04\n",
      "Epoch 248/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7089 - mae: 34.1686 - mape: 12.4266 - val_loss: 13.5139 - val_mae: 19.3395 - val_mape: 9.2307 - lr: 3.0000e-04\n",
      "Epoch 249/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.1459 - mae: 29.0532 - mape: 11.8617 - val_loss: 13.7998 - val_mae: 20.9851 - val_mape: 9.5162 - lr: 3.0000e-04\n",
      "Epoch 250/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.8005 - mae: 32.9331 - mape: 12.5205 - val_loss: 13.5407 - val_mae: 19.4962 - val_mape: 9.2553 - lr: 3.0000e-04\n",
      "Epoch 251/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.7328 - mae: 32.2765 - mape: 12.4549\n",
      "Epoch 251: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7328 - mae: 32.2765 - mape: 12.4549 - val_loss: 13.5998 - val_mae: 20.0994 - val_mape: 9.3239 - lr: 3.0000e-04\n",
      "Epoch 251: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 13.484243392944336; mae of 19.375486373901367; mape of 9.195748329162598%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.9965 - mae: 33.8677 - mape: 12.7135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 89ms/step - loss: 16.9965 - mae: 33.8677 - mape: 12.7135 - val_loss: 13.0037 - val_mae: 19.5913 - val_mape: 8.7312 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.9332 - mae: 30.7046 - mape: 12.6578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 16.9332 - mae: 30.7046 - mape: 12.6578 - val_loss: 12.6917 - val_mae: 16.4863 - val_mape: 8.4082 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 76ms/step - loss: 17.0522 - mae: 32.2272 - mape: 12.7713 - val_loss: 12.8045 - val_mae: 16.9180 - val_mape: 8.5087 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.8819 - mae: 34.2326 - mape: 12.5931 - val_loss: 13.8232 - val_mae: 22.0023 - val_mape: 9.5415 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.0219 - mae: 31.3153 - mape: 12.7377 - val_loss: 15.0335 - val_mae: 27.8013 - val_mape: 10.7616 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9596 - mae: 33.8488 - mape: 12.6803 - val_loss: 12.7575 - val_mae: 16.7245 - val_mape: 8.4831 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1656 - mae: 33.7643 - mape: 12.8902 - val_loss: 12.9584 - val_mae: 18.6591 - val_mape: 8.6757 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0415 - mae: 32.8564 - mape: 12.7652 - val_loss: 13.2817 - val_mae: 21.7160 - val_mape: 9.0063 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5812 - mae: 32.5868 - mape: 12.3037 - val_loss: 13.1579 - val_mae: 21.9879 - val_mape: 8.8804 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8651 - mae: 31.4019 - mape: 12.5827 - val_loss: 13.1527 - val_mae: 20.7512 - val_mape: 8.8620 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8483 - mae: 32.3946 - mape: 12.5531 - val_loss: 12.7657 - val_mae: 15.9468 - val_mape: 8.4702 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8425 - mae: 32.7696 - mape: 12.5571 - val_loss: 13.5465 - val_mae: 20.5465 - val_mape: 9.2667 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.0478 - mae: 34.9854 - mape: 12.7655 - val_loss: 12.8242 - val_mae: 17.1002 - val_mape: 8.5480 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1376 - mae: 32.9333 - mape: 12.8578 - val_loss: 12.7387 - val_mae: 16.3931 - val_mape: 8.4454 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0441 - mae: 32.9851 - mape: 12.7574 - val_loss: 13.1639 - val_mae: 20.1692 - val_mape: 8.8811 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9422 - mae: 33.3032 - mape: 12.6639 - val_loss: 13.0441 - val_mae: 16.3144 - val_mape: 8.7619 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9176 - mae: 31.8715 - mape: 12.6402 - val_loss: 13.0619 - val_mae: 19.8921 - val_mape: 8.7733 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.7862 - mae: 31.6911 - mape: 12.4998 - val_loss: 12.8551 - val_mae: 17.8359 - val_mape: 8.5702 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7558 - mae: 31.0387 - mape: 12.4775 - val_loss: 12.7949 - val_mae: 17.9179 - val_mape: 8.5167 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8800 - mae: 30.8820 - mape: 12.6051 - val_loss: 13.6791 - val_mae: 24.3496 - val_mape: 9.4072 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8183 - mae: 30.7859 - mape: 12.5290 - val_loss: 12.9425 - val_mae: 18.4813 - val_mape: 8.6514 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0177 - mae: 34.9242 - mape: 12.7309 - val_loss: 13.4035 - val_mae: 20.8224 - val_mape: 9.1218 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8825 - mae: 31.6860 - mape: 12.6069 - val_loss: 12.9064 - val_mae: 18.1890 - val_mape: 8.6293 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7199 - mae: 30.7815 - mape: 12.4408 - val_loss: 14.0094 - val_mae: 23.8564 - val_mape: 9.7339 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7290 - mae: 33.0335 - mape: 12.4472 - val_loss: 12.9913 - val_mae: 19.0186 - val_mape: 8.7126 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7694 - mae: 33.1168 - mape: 12.4879 - val_loss: 12.8363 - val_mae: 18.7253 - val_mape: 8.5511 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.8226 - mae: 31.9295 - mape: 12.5329"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 16.8226 - mae: 31.9295 - mape: 12.5329 - val_loss: 12.6766 - val_mae: 15.9762 - val_mape: 8.3870 - lr: 0.0010\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 76ms/step - loss: 16.7749 - mae: 31.8298 - mape: 12.4855 - val_loss: 14.1806 - val_mae: 24.8595 - val_mape: 9.8989 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.7635 - mae: 32.1533 - mape: 12.4795 - val_loss: 13.2844 - val_mae: 21.1776 - val_mape: 8.9979 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9615 - mae: 31.2824 - mape: 12.6728 - val_loss: 13.8084 - val_mae: 25.3425 - val_mape: 9.5224 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5322 - mae: 33.0029 - mape: 12.2410 - val_loss: 13.0212 - val_mae: 19.5399 - val_mape: 8.7429 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9131 - mae: 33.2397 - mape: 12.6345 - val_loss: 12.7437 - val_mae: 17.4119 - val_mape: 8.4566 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8340 - mae: 33.5139 - mape: 12.5469 - val_loss: 12.8318 - val_mae: 17.6512 - val_mape: 8.5432 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9474 - mae: 33.4706 - mape: 12.6623 - val_loss: 13.2270 - val_mae: 21.7344 - val_mape: 8.9531 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9499 - mae: 33.4308 - mape: 12.6679 - val_loss: 13.1402 - val_mae: 19.7767 - val_mape: 8.8546 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9692 - mae: 34.2230 - mape: 12.6817 - val_loss: 12.7989 - val_mae: 17.2203 - val_mape: 8.5102 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.9016 - mae: 29.9186 - mape: 12.6195 - val_loss: 14.1048 - val_mae: 23.9875 - val_mape: 9.8294 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5278 - mae: 31.2762 - mape: 12.2500 - val_loss: 12.7557 - val_mae: 16.8632 - val_mape: 8.4817 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8619 - mae: 32.1168 - mape: 12.5815 - val_loss: 12.8433 - val_mae: 17.1377 - val_mape: 8.5646 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7169 - mae: 31.4532 - mape: 12.4365 - val_loss: 12.7867 - val_mae: 16.7210 - val_mape: 8.4924 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.9863 - mae: 32.7598 - mape: 12.6897 - val_loss: 13.6934 - val_mae: 20.9735 - val_mape: 9.4025 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7685 - mae: 31.3708 - mape: 12.4782 - val_loss: 12.7412 - val_mae: 16.3131 - val_mape: 8.4474 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.7327 - mae: 34.3704 - mape: 12.4456 - val_loss: 12.8853 - val_mae: 17.2719 - val_mape: 8.5958 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6074 - mae: 30.9129 - mape: 12.3217 - val_loss: 12.7772 - val_mae: 16.8624 - val_mape: 8.4886 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.6650 - mae: 29.6975 - mape: 12.3804 - val_loss: 13.4499 - val_mae: 21.9708 - val_mape: 9.1668 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9580 - mae: 32.8265 - mape: 12.6636 - val_loss: 13.3131 - val_mae: 22.2442 - val_mape: 9.0350 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6523 - mae: 31.8206 - mape: 12.3621 - val_loss: 12.8293 - val_mae: 17.8095 - val_mape: 8.5398 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8665 - mae: 31.8281 - mape: 12.5828 - val_loss: 13.2630 - val_mae: 18.8549 - val_mape: 8.9775 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7898 - mae: 34.6337 - mape: 12.5084 - val_loss: 12.8650 - val_mae: 18.0207 - val_mape: 8.5934 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8542 - mae: 33.5996 - mape: 12.5745 - val_loss: 12.7669 - val_mae: 17.4039 - val_mape: 8.4882 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6978 - mae: 32.2894 - mape: 12.4253 - val_loss: 13.2831 - val_mae: 21.4984 - val_mape: 9.0065 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6297 - mae: 32.6311 - mape: 12.3533 - val_loss: 14.6307 - val_mae: 28.0198 - val_mape: 10.3679 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9946 - mae: 34.7322 - mape: 12.7216 - val_loss: 13.0342 - val_mae: 19.5589 - val_mape: 8.7550 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9808 - mae: 34.2771 - mape: 12.7014 - val_loss: 13.6273 - val_mae: 23.6386 - val_mape: 9.3472 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.5976 - mae: 33.0315 - mape: 12.3125 - val_loss: 12.8057 - val_mae: 16.6788 - val_mape: 8.5189 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9454 - mae: 31.4245 - mape: 12.6623 - val_loss: 13.3139 - val_mae: 22.8902 - val_mape: 9.0365 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.0538 - mae: 36.0451 - mape: 12.7756\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0538 - mae: 36.0451 - mape: 12.7756 - val_loss: 12.7417 - val_mae: 18.2214 - val_mape: 8.4657 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5564 - mae: 31.7090 - mape: 12.2853 - val_loss: 12.8474 - val_mae: 19.3208 - val_mape: 8.5758 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8495 - mae: 29.1356 - mape: 12.5803 - val_loss: 13.0431 - val_mae: 20.5137 - val_mape: 8.7753 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5241 - mae: 32.2418 - mape: 12.2535 - val_loss: 13.1244 - val_mae: 21.4454 - val_mape: 8.8605 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6299 - mae: 32.5006 - mape: 12.3661 - val_loss: 13.0727 - val_mae: 20.9968 - val_mape: 8.8062 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.4418 - mae: 32.1444 - mape: 12.1762 - val_loss: 12.9633 - val_mae: 19.9323 - val_mape: 8.6923 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.4167 - mae: 31.4990 - mape: 12.1416 - val_loss: 12.9994 - val_mae: 19.3318 - val_mape: 8.7282 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6767 - mae: 29.4282 - mape: 12.4028 - val_loss: 12.8995 - val_mae: 18.0643 - val_mape: 8.6267 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6760 - mae: 29.8883 - mape: 12.4075 - val_loss: 12.8504 - val_mae: 18.2279 - val_mape: 8.5830 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6982 - mae: 31.6057 - mape: 12.4298 - val_loss: 12.9285 - val_mae: 18.9133 - val_mape: 8.6574 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5720 - mae: 32.5227 - mape: 12.3017 - val_loss: 13.0745 - val_mae: 19.5670 - val_mape: 8.8004 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5295 - mae: 31.0991 - mape: 12.2532 - val_loss: 13.0352 - val_mae: 19.4479 - val_mape: 8.7566 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5516 - mae: 29.3686 - mape: 12.2756 - val_loss: 13.1616 - val_mae: 19.8131 - val_mape: 8.8878 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.0371 - mae: 33.4268 - mape: 12.7619 - val_loss: 13.2089 - val_mae: 20.1297 - val_mape: 8.9342 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6829 - mae: 33.8909 - mape: 12.4120 - val_loss: 13.0677 - val_mae: 20.3356 - val_mape: 8.7992 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6587 - mae: 33.2030 - mape: 12.3883 - val_loss: 12.8725 - val_mae: 18.8709 - val_mape: 8.6005 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7242 - mae: 31.8670 - mape: 12.4557 - val_loss: 12.9379 - val_mae: 19.2986 - val_mape: 8.6660 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5585 - mae: 31.2907 - mape: 12.2914 - val_loss: 12.8099 - val_mae: 18.3121 - val_mape: 8.5406 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.3685 - mae: 32.1117 - mape: 12.1002 - val_loss: 12.7305 - val_mae: 17.0268 - val_mape: 8.4582 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4475 - mae: 32.0486 - mape: 12.1802 - val_loss: 13.0687 - val_mae: 19.7852 - val_mape: 8.7994 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5604 - mae: 30.9763 - mape: 12.2910 - val_loss: 13.1650 - val_mae: 20.1858 - val_mape: 8.8948 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8085 - mae: 31.9426 - mape: 12.5452 - val_loss: 13.0668 - val_mae: 19.7389 - val_mape: 8.8084 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8824 - mae: 33.0496 - mape: 12.6252 - val_loss: 13.5283 - val_mae: 22.5909 - val_mape: 9.2745 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4948 - mae: 31.9842 - mape: 12.2399 - val_loss: 13.0741 - val_mae: 20.7150 - val_mape: 8.8176 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8204 - mae: 31.1718 - mape: 12.5619 - val_loss: 13.8067 - val_mae: 24.3486 - val_mape: 9.5466 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7292 - mae: 32.4049 - mape: 12.4647 - val_loss: 13.4966 - val_mae: 22.1298 - val_mape: 9.2327 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7402 - mae: 34.4407 - mape: 12.4734 - val_loss: 12.8571 - val_mae: 17.9297 - val_mape: 8.5861 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8937 - mae: 31.7977 - mape: 12.6266 - val_loss: 14.1723 - val_mae: 25.8952 - val_mape: 9.9152 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6066 - mae: 33.2803 - mape: 12.3469 - val_loss: 13.0657 - val_mae: 20.1488 - val_mape: 8.8013 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6523 - mae: 32.1345 - mape: 12.3877 - val_loss: 13.5633 - val_mae: 21.9084 - val_mape: 9.2962 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.6830 - mae: 31.3208 - mape: 12.4131\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6830 - mae: 31.3208 - mape: 12.4131 - val_loss: 12.9298 - val_mae: 18.5855 - val_mape: 8.6574 - lr: 3.0000e-04\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 12.676579475402832; mae of 15.976175308227539; mape of 8.387003898620605%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 17.0524 - mae: 34.5353 - mape: 12.7593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 90ms/step - loss: 17.0524 - mae: 34.5353 - mape: 12.7593 - val_loss: 11.8713 - val_mae: 14.2596 - val_mape: 7.5737 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 74ms/step - loss: 17.1304 - mae: 33.9437 - mape: 12.8455 - val_loss: 11.8921 - val_mae: 14.9212 - val_mape: 7.6076 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 17.2544 - mae: 34.7230 - mape: 12.9658 - val_loss: 12.3457 - val_mae: 17.6817 - val_mape: 8.0492 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.3397 - mae: 34.6859 - mape: 13.0498 - val_loss: 12.9135 - val_mae: 20.5158 - val_mape: 8.6308 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.8907 - mae: 33.1233 - mape: 12.5976 - val_loss: 12.1061 - val_mae: 17.2337 - val_mape: 7.8067 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.3080 - mae: 32.8979 - mape: 13.0162 - val_loss: 15.2875 - val_mae: 31.0825 - val_mape: 10.9995 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 17.0086 - mae: 32.1937 - mape: 12.7120"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 97ms/step - loss: 17.0086 - mae: 32.1937 - mape: 12.7120 - val_loss: 11.8519 - val_mae: 14.3748 - val_mape: 7.5545 - lr: 0.0010\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 75ms/step - loss: 16.9912 - mae: 31.9438 - mape: 12.7117 - val_loss: 12.6444 - val_mae: 17.7493 - val_mape: 8.3716 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.9277 - mae: 34.9520 - mape: 12.6517 - val_loss: 12.8552 - val_mae: 17.7914 - val_mape: 8.5751 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8660 - mae: 33.8132 - mape: 12.5795 - val_loss: 11.9425 - val_mae: 15.0607 - val_mape: 7.6519 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8898 - mae: 31.6273 - mape: 12.6026 - val_loss: 12.2007 - val_mae: 19.1397 - val_mape: 7.9161 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1172 - mae: 35.1510 - mape: 12.8332 - val_loss: 12.0669 - val_mae: 16.3940 - val_mape: 7.7674 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6927 - mae: 32.5276 - mape: 12.4015 - val_loss: 12.0118 - val_mae: 16.2707 - val_mape: 7.7239 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.9423 - mae: 34.2623 - mape: 12.6651 - val_loss: 11.8865 - val_mae: 14.6553 - val_mape: 7.6140 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7879 - mae: 31.7449 - mape: 12.5008 - val_loss: 11.8948 - val_mae: 14.4706 - val_mape: 7.5906 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5058 - mae: 31.9153 - mape: 12.2140 - val_loss: 13.4984 - val_mae: 21.9927 - val_mape: 9.2176 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.7804 - mae: 32.8928 - mape: 12.4937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 97ms/step - loss: 16.7804 - mae: 32.8928 - mape: 12.4937 - val_loss: 11.8438 - val_mae: 14.2165 - val_mape: 7.5468 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      " 1/87 [..............................] - ETA: 7s - loss: 15.1416 - mae: 15.4353 - mape: 10.8447"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 76ms/step - loss: 16.9641 - mae: 33.8545 - mape: 12.6725 - val_loss: 12.7955 - val_mae: 20.6755 - val_mape: 8.4940 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.7734 - mae: 31.1863 - mape: 12.4655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 95ms/step - loss: 16.7734 - mae: 31.1863 - mape: 12.4655 - val_loss: 11.8305 - val_mae: 14.1397 - val_mape: 7.5203 - lr: 0.0010\n",
      "Epoch 20/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 76ms/step - loss: 16.8794 - mae: 32.7284 - mape: 12.5847 - val_loss: 12.6867 - val_mae: 18.8385 - val_mape: 8.3926 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7393 - mae: 31.9964 - mape: 12.4359 - val_loss: 12.7843 - val_mae: 19.2967 - val_mape: 8.4978 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9927 - mae: 34.0356 - mape: 12.6971 - val_loss: 11.9358 - val_mae: 14.7445 - val_mape: 7.6372 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9122 - mae: 34.3293 - mape: 12.6153 - val_loss: 12.1602 - val_mae: 15.4451 - val_mape: 7.8546 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.1958 - mae: 32.9356 - mape: 12.9029 - val_loss: 12.4566 - val_mae: 16.8463 - val_mape: 8.1666 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8834 - mae: 33.0162 - mape: 12.5960 - val_loss: 12.4130 - val_mae: 19.6728 - val_mape: 8.1310 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7611 - mae: 32.7093 - mape: 12.4655 - val_loss: 12.3565 - val_mae: 16.3163 - val_mape: 8.0629 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9633 - mae: 30.2853 - mape: 12.6729 - val_loss: 11.9336 - val_mae: 15.9214 - val_mape: 7.6369 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.9489 - mae: 32.5299 - mape: 12.6595 - val_loss: 12.1701 - val_mae: 17.0471 - val_mape: 7.8754 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8190 - mae: 33.7723 - mape: 12.5276 - val_loss: 12.3678 - val_mae: 18.0741 - val_mape: 8.0725 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7450 - mae: 32.7272 - mape: 12.4535 - val_loss: 11.9572 - val_mae: 15.8011 - val_mape: 7.6736 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8204 - mae: 33.3623 - mape: 12.5324 - val_loss: 12.1094 - val_mae: 17.3250 - val_mape: 7.8249 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.5479 - mae: 33.6723 - mape: 12.2634 - val_loss: 11.9541 - val_mae: 15.7998 - val_mape: 7.6671 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.0494 - mae: 34.9972 - mape: 12.7636 - val_loss: 12.3722 - val_mae: 19.3230 - val_mape: 8.0903 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8725 - mae: 31.8590 - mape: 12.5886 - val_loss: 12.2648 - val_mae: 18.3659 - val_mape: 7.9646 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8333 - mae: 32.1344 - mape: 12.5328 - val_loss: 11.9768 - val_mae: 16.0021 - val_mape: 7.6729 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.0215 - mae: 35.0661 - mape: 12.7242 - val_loss: 12.5655 - val_mae: 19.8694 - val_mape: 8.2775 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.9443 - mae: 33.9054 - mape: 12.6492 - val_loss: 12.1354 - val_mae: 18.1509 - val_mape: 7.8386 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1129 - mae: 34.3909 - mape: 12.8204 - val_loss: 12.3458 - val_mae: 18.5779 - val_mape: 8.0481 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 17.3337 - mae: 33.1648 - mape: 13.0318 - val_loss: 14.1456 - val_mae: 26.7275 - val_mape: 9.8422 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0885 - mae: 34.1141 - mape: 12.7817 - val_loss: 11.9953 - val_mae: 14.1896 - val_mape: 7.6963 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1024 - mae: 36.3835 - mape: 12.8077 - val_loss: 12.0681 - val_mae: 17.0602 - val_mape: 7.7675 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8893 - mae: 32.3497 - mape: 12.5856 - val_loss: 12.0934 - val_mae: 17.1646 - val_mape: 7.7988 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7572 - mae: 34.5866 - mape: 12.4535 - val_loss: 13.7893 - val_mae: 25.5730 - val_mape: 9.4764 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 6s 72ms/step - loss: 17.0585 - mae: 31.8099 - mape: 12.7536 - val_loss: 12.4842 - val_mae: 21.5620 - val_mape: 8.1966 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 6s 73ms/step - loss: 16.6445 - mae: 31.5776 - mape: 12.3554 - val_loss: 12.5747 - val_mae: 21.1869 - val_mape: 8.2839 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 16.7359 - mae: 32.6402 - mape: 12.4434 - val_loss: 11.9192 - val_mae: 14.2404 - val_mape: 7.6115 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 6s 74ms/step - loss: 17.1202 - mae: 34.4041 - mape: 12.8173 - val_loss: 12.3732 - val_mae: 17.1179 - val_mape: 8.0720 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 75ms/step - loss: 16.8876 - mae: 31.6178 - mape: 12.5927 - val_loss: 12.6848 - val_mae: 19.3198 - val_mape: 8.3933 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.6412 - mae: 30.6353 - mape: 12.3409\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.6412 - mae: 30.6353 - mape: 12.3409 - val_loss: 11.9668 - val_mae: 14.6437 - val_mape: 7.6688 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 16.7595 - mae: 31.8824 - mape: 12.4761 - val_loss: 12.4918 - val_mae: 18.9523 - val_mape: 8.2165 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.5619 - mae: 33.8564 - mape: 12.2801 - val_loss: 12.3698 - val_mae: 17.6078 - val_mape: 8.0840 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.5859 - mae: 32.6567 - mape: 12.3019 - val_loss: 12.7440 - val_mae: 19.6051 - val_mape: 8.4660 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 17.1551 - mae: 34.3980 - mape: 12.8712 - val_loss: 12.6659 - val_mae: 20.2315 - val_mape: 8.3863 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 6s 74ms/step - loss: 16.6832 - mae: 34.3621 - mape: 12.4028 - val_loss: 12.2000 - val_mae: 17.9332 - val_mape: 7.9194 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.6233 - mae: 31.6518 - mape: 12.3472 - val_loss: 12.6183 - val_mae: 19.9900 - val_mape: 8.3449 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7779 - mae: 33.2719 - mape: 12.5043 - val_loss: 12.3813 - val_mae: 18.4550 - val_mape: 8.1100 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5850 - mae: 33.5824 - mape: 12.3107 - val_loss: 12.1442 - val_mae: 16.8620 - val_mape: 7.8660 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6916 - mae: 33.4304 - mape: 12.4177 - val_loss: 12.6908 - val_mae: 19.4314 - val_mape: 8.4191 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.5226 - mae: 33.4962 - mape: 12.2508 - val_loss: 12.0695 - val_mae: 16.2035 - val_mape: 7.7975 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6326 - mae: 31.6551 - mape: 12.3624 - val_loss: 12.6470 - val_mae: 21.2691 - val_mape: 8.3777 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.5668 - mae: 33.4374 - mape: 12.2964 - val_loss: 12.0451 - val_mae: 17.0102 - val_mape: 7.7706 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5940 - mae: 31.6600 - mape: 12.3202 - val_loss: 12.2474 - val_mae: 18.3982 - val_mape: 7.9759 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7777 - mae: 33.9399 - mape: 12.5066 - val_loss: 12.3185 - val_mae: 18.6177 - val_mape: 8.0419 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.7772 - mae: 34.6748 - mape: 12.5037 - val_loss: 12.4749 - val_mae: 20.1410 - val_mape: 8.1988 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.3372 - mae: 31.3087 - mape: 12.0599 - val_loss: 12.0747 - val_mae: 16.5120 - val_mape: 7.7958 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.6389 - mae: 31.1862 - mape: 12.3609 - val_loss: 13.2530 - val_mae: 22.0098 - val_mape: 8.9783 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7435 - mae: 32.0569 - mape: 12.4692 - val_loss: 11.9813 - val_mae: 15.2870 - val_mape: 7.6943 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5848 - mae: 33.3364 - mape: 12.3072 - val_loss: 12.7165 - val_mae: 20.9464 - val_mape: 8.4377 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.7611 - mae: 32.7839 - mape: 12.4822 - val_loss: 13.0248 - val_mae: 21.9527 - val_mape: 8.7523 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.4574 - mae: 31.8482 - mape: 12.1828 - val_loss: 12.9490 - val_mae: 22.5614 - val_mape: 8.6799 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6713 - mae: 33.4589 - mape: 12.4002 - val_loss: 12.0690 - val_mae: 17.0936 - val_mape: 7.7938 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6498 - mae: 32.1307 - mape: 12.3785 - val_loss: 12.7516 - val_mae: 20.8302 - val_mape: 8.4760 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.4859 - mae: 33.0655 - mape: 12.2091 - val_loss: 12.5098 - val_mae: 19.7713 - val_mape: 8.2343 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 6s 74ms/step - loss: 16.8162 - mae: 34.1332 - mape: 12.5396 - val_loss: 12.1770 - val_mae: 18.0053 - val_mape: 7.8977 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.9435 - mae: 32.8816 - mape: 12.6641 - val_loss: 12.7166 - val_mae: 20.8885 - val_mape: 8.4382 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5223 - mae: 32.2007 - mape: 12.2428 - val_loss: 12.2470 - val_mae: 18.0094 - val_mape: 7.9658 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7910 - mae: 31.5482 - mape: 12.5148 - val_loss: 12.6853 - val_mae: 21.0844 - val_mape: 8.4134 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6568 - mae: 34.3009 - mape: 12.3837 - val_loss: 13.2363 - val_mae: 23.3721 - val_mape: 8.9622 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.5326 - mae: 30.6574 - mape: 12.2554\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.5326 - mae: 30.6574 - mape: 12.2554 - val_loss: 12.4372 - val_mae: 18.9455 - val_mape: 8.1575 - lr: 3.0000e-04\n",
      "Epoch 79: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 11.830459594726562; mae of 14.139742851257324; mape of 7.520269393920898%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.8539 - mae: 35.1320 - mape: 12.5585"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 93ms/step - loss: 16.8539 - mae: 35.1320 - mape: 12.5585 - val_loss: 13.6097 - val_mae: 22.0824 - val_mape: 9.3212 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 17.1033 - mae: 33.4036 - mape: 12.8097"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 103ms/step - loss: 17.1033 - mae: 33.4036 - mape: 12.8097 - val_loss: 13.0191 - val_mae: 21.7423 - val_mape: 8.7359 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 76ms/step - loss: 16.9630 - mae: 32.7912 - mape: 12.6705 - val_loss: 13.9630 - val_mae: 24.3254 - val_mape: 9.6796 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.6596 - mae: 30.7209 - mape: 12.3768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 98ms/step - loss: 16.6596 - mae: 30.7209 - mape: 12.3768 - val_loss: 12.5949 - val_mae: 19.0279 - val_mape: 8.3123 - lr: 0.0010\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 73ms/step - loss: 17.0261 - mae: 31.0364 - mape: 12.7356 - val_loss: 12.9718 - val_mae: 20.8821 - val_mape: 8.6759 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7487 - mae: 34.3895 - mape: 12.4629 - val_loss: 13.1785 - val_mae: 20.2524 - val_mape: 8.8832 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8879 - mae: 31.6325 - mape: 12.5906 - val_loss: 12.8535 - val_mae: 20.1017 - val_mape: 8.5593 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6987 - mae: 33.0846 - mape: 12.4041 - val_loss: 13.2847 - val_mae: 23.1227 - val_mape: 8.9940 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7145 - mae: 32.6928 - mape: 12.4192 - val_loss: 12.8394 - val_mae: 18.2459 - val_mape: 8.5390 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.7244 - mae: 31.5074 - mape: 12.4284 - val_loss: 12.6501 - val_mae: 19.2500 - val_mape: 8.3543 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6200 - mae: 30.0668 - mape: 12.3231 - val_loss: 13.3229 - val_mae: 21.0648 - val_mape: 9.0426 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.7141 - mae: 30.4045 - mape: 12.4234"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 16.7141 - mae: 30.4045 - mape: 12.4234 - val_loss: 12.3783 - val_mae: 17.1289 - val_mape: 8.0865 - lr: 0.0010\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 16.2926 - mae: 31.3903 - mape: 12.0088 - val_loss: 12.9787 - val_mae: 20.1162 - val_mape: 8.7021 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8496 - mae: 31.6026 - mape: 12.5656 - val_loss: 12.3724 - val_mae: 17.1105 - val_mape: 8.0890 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7835 - mae: 32.9314 - mape: 12.4945 - val_loss: 12.4922 - val_mae: 17.9238 - val_mape: 8.2072 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9804 - mae: 31.4624 - mape: 12.6876 - val_loss: 12.6088 - val_mae: 18.1021 - val_mape: 8.3020 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.8686 - mae: 33.3723 - mape: 12.5854 - val_loss: 12.3963 - val_mae: 17.6421 - val_mape: 8.1220 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6507 - mae: 32.4404 - mape: 12.3784 - val_loss: 12.9591 - val_mae: 20.1208 - val_mape: 8.6804 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5967 - mae: 31.0276 - mape: 12.3131 - val_loss: 12.4025 - val_mae: 17.4006 - val_mape: 8.1202 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.8375 - mae: 34.0602 - mape: 12.5593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 16.8375 - mae: 34.0602 - mape: 12.5593 - val_loss: 12.3637 - val_mae: 17.3496 - val_mape: 8.0805 - lr: 0.0010\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 75ms/step - loss: 16.8487 - mae: 34.3794 - mape: 12.5752 - val_loss: 12.3759 - val_mae: 17.5115 - val_mape: 8.1049 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.4612 - mae: 29.0930 - mape: 12.1786 - val_loss: 12.6533 - val_mae: 18.3247 - val_mape: 8.3586 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.8761 - mae: 36.8800 - mape: 12.5747 - val_loss: 13.5359 - val_mae: 21.7559 - val_mape: 9.2508 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.8468 - mae: 33.1911 - mape: 12.5624 - val_loss: 12.7626 - val_mae: 19.2448 - val_mape: 8.4595 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.9014 - mae: 34.3094 - mape: 12.6132 - val_loss: 13.4182 - val_mae: 20.0925 - val_mape: 9.1261 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7700 - mae: 33.0023 - mape: 12.4830 - val_loss: 12.5697 - val_mae: 18.5745 - val_mape: 8.2929 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.8535 - mae: 32.6530 - mape: 12.5718 - val_loss: 12.8341 - val_mae: 19.5582 - val_mape: 8.5460 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.8553 - mae: 32.0657 - mape: 12.5600 - val_loss: 12.7319 - val_mae: 19.3693 - val_mape: 8.4463 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6850 - mae: 32.1396 - mape: 12.3945 - val_loss: 13.8436 - val_mae: 23.0325 - val_mape: 9.5544 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.2770 - mae: 34.8018 - mape: 12.9814 - val_loss: 12.8805 - val_mae: 19.1098 - val_mape: 8.5873 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8089 - mae: 32.3680 - mape: 12.5200 - val_loss: 13.0665 - val_mae: 21.3394 - val_mape: 8.7701 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7421 - mae: 31.8112 - mape: 12.4526 - val_loss: 13.1841 - val_mae: 20.6317 - val_mape: 8.8865 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8139 - mae: 34.4850 - mape: 12.5186 - val_loss: 13.7032 - val_mae: 23.7848 - val_mape: 9.4116 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8833 - mae: 31.3507 - mape: 12.5951 - val_loss: 13.4680 - val_mae: 22.3733 - val_mape: 9.1773 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8966 - mae: 31.5711 - mape: 12.6052 - val_loss: 13.0342 - val_mae: 21.6334 - val_mape: 8.7533 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.0741 - mae: 33.4661 - mape: 12.7886 - val_loss: 12.6079 - val_mae: 18.4139 - val_mape: 8.3026 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.9731 - mae: 35.9749 - mape: 12.6672 - val_loss: 12.5230 - val_mae: 17.7566 - val_mape: 8.2066 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 75ms/step - loss: 16.8481 - mae: 33.9497 - mape: 12.5477 - val_loss: 13.2357 - val_mae: 22.0254 - val_mape: 8.9438 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.6018 - mae: 31.7072 - mape: 12.3067 - val_loss: 13.0880 - val_mae: 19.4805 - val_mape: 8.7814 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7458 - mae: 32.5121 - mape: 12.4358 - val_loss: 12.4935 - val_mae: 18.9035 - val_mape: 8.1816 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.1078 - mae: 35.0074 - mape: 12.8046 - val_loss: 13.6838 - val_mae: 22.9596 - val_mape: 9.3815 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.0610 - mae: 31.2029 - mape: 12.7531 - val_loss: 12.5632 - val_mae: 17.9851 - val_mape: 8.2513 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8449 - mae: 32.3492 - mape: 12.5457 - val_loss: 14.4778 - val_mae: 26.7223 - val_mape: 10.2011 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7568 - mae: 32.1968 - mape: 12.4634 - val_loss: 13.1220 - val_mae: 21.4512 - val_mape: 8.8360 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.9770 - mae: 32.5263 - mape: 12.6825 - val_loss: 12.5609 - val_mae: 18.5480 - val_mape: 8.2801 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7989 - mae: 33.5153 - mape: 12.4982 - val_loss: 14.6056 - val_mae: 27.2607 - val_mape: 10.3041 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.7683 - mae: 33.0697 - mape: 12.4577 - val_loss: 14.2150 - val_mae: 24.0146 - val_mape: 9.9166 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.9927 - mae: 34.1830 - mape: 12.6833 - val_loss: 13.8733 - val_mae: 25.5031 - val_mape: 9.5744 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.0153 - mae: 35.0284 - mape: 12.7119 - val_loss: 13.9086 - val_mae: 26.0441 - val_mape: 9.6116 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.6782 - mae: 32.4928 - mape: 12.3615\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6782 - mae: 32.4928 - mape: 12.3615 - val_loss: 13.9265 - val_mae: 23.5976 - val_mape: 9.6203 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5547 - mae: 32.9294 - mape: 12.2503 - val_loss: 13.0925 - val_mae: 20.9005 - val_mape: 8.7967 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7651 - mae: 31.4412 - mape: 12.4693 - val_loss: 13.9504 - val_mae: 23.6995 - val_mape: 9.6587 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6148 - mae: 29.8703 - mape: 12.3267 - val_loss: 13.7330 - val_mae: 23.3035 - val_mape: 9.4509 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6962 - mae: 32.8836 - mape: 12.4028 - val_loss: 13.8134 - val_mae: 24.1424 - val_mape: 9.5271 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.6543 - mae: 31.9192 - mape: 12.3658 - val_loss: 12.9518 - val_mae: 20.8250 - val_mape: 8.6665 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8828 - mae: 34.2260 - mape: 12.6031 - val_loss: 13.0762 - val_mae: 22.2994 - val_mape: 8.7980 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5943 - mae: 32.4254 - mape: 12.3160 - val_loss: 12.9241 - val_mae: 20.7903 - val_mape: 8.6432 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5760 - mae: 31.8059 - mape: 12.2943 - val_loss: 12.6591 - val_mae: 19.3123 - val_mape: 8.3759 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8748 - mae: 31.1591 - mape: 12.5959 - val_loss: 12.8594 - val_mae: 20.2776 - val_mape: 8.5814 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.5679 - mae: 33.7367 - mape: 12.2861 - val_loss: 13.6596 - val_mae: 23.4413 - val_mape: 9.3768 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6624 - mae: 30.5988 - mape: 12.3817 - val_loss: 12.6505 - val_mae: 18.8898 - val_mape: 8.3712 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5819 - mae: 32.4682 - mape: 12.3095 - val_loss: 12.6299 - val_mae: 19.0240 - val_mape: 8.3562 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.0259 - mae: 32.2702 - mape: 12.7558 - val_loss: 13.2453 - val_mae: 21.4366 - val_mape: 8.9730 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5744 - mae: 33.0810 - mape: 12.3040 - val_loss: 12.7028 - val_mae: 19.0096 - val_mape: 8.4310 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.4144 - mae: 31.4616 - mape: 12.1409 - val_loss: 12.8382 - val_mae: 19.2475 - val_mape: 8.5688 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.3729 - mae: 31.1260 - mape: 12.1056 - val_loss: 13.4981 - val_mae: 22.7959 - val_mape: 9.2362 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7169 - mae: 30.9799 - mape: 12.4507 - val_loss: 12.8633 - val_mae: 20.4302 - val_mape: 8.5950 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7686 - mae: 31.5265 - mape: 12.4967 - val_loss: 13.1443 - val_mae: 21.8424 - val_mape: 8.8625 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.6123 - mae: 33.4694 - mape: 12.3293 - val_loss: 12.8145 - val_mae: 20.0926 - val_mape: 8.5280 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.7949 - mae: 34.4250 - mape: 12.5129 - val_loss: 13.6866 - val_mae: 23.1201 - val_mape: 9.4088 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.7115 - mae: 33.5948 - mape: 12.4298 - val_loss: 13.2117 - val_mae: 21.3595 - val_mape: 8.9325 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.5492 - mae: 31.0643 - mape: 12.2663 - val_loss: 13.1153 - val_mae: 21.1152 - val_mape: 8.8313 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.5245 - mae: 34.9323 - mape: 12.2403 - val_loss: 13.4937 - val_mae: 22.7059 - val_mape: 9.2090 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.5607 - mae: 32.8238 - mape: 12.2792 - val_loss: 13.3304 - val_mae: 22.2152 - val_mape: 9.0541 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6168 - mae: 35.0112 - mape: 12.3383 - val_loss: 13.2501 - val_mae: 22.1103 - val_mape: 8.9724 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6801 - mae: 30.3740 - mape: 12.4014 - val_loss: 13.0068 - val_mae: 21.1108 - val_mape: 8.7316 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4526 - mae: 30.1899 - mape: 12.1810 - val_loss: 12.8273 - val_mae: 20.4901 - val_mape: 8.5556 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5909 - mae: 33.1323 - mape: 12.3189 - val_loss: 13.5680 - val_mae: 22.5797 - val_mape: 9.2975 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.7734 - mae: 34.9761 - mape: 12.5022 - val_loss: 13.2503 - val_mae: 20.9400 - val_mape: 8.9770 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.6268 - mae: 32.3396 - mape: 12.3513\n",
      "Epoch 80: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.6268 - mae: 32.3396 - mape: 12.3513 - val_loss: 12.8342 - val_mae: 19.6502 - val_mape: 8.5562 - lr: 3.0000e-04\n",
      "Epoch 80: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 12.36368179321289; mae of 17.349576950073242; mape of 8.080484390258789%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n",
      " 3/87 [>.............................] - ETA: 5s - loss: 14.3915 - mae: 33.2937 - mape: 10.0756"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.7461 - mae: 33.8232 - mape: 12.4680"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 95ms/step - loss: 16.7461 - mae: 33.8232 - mape: 12.4680 - val_loss: 12.6311 - val_mae: 23.6446 - val_mape: 8.3566 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.4582 - mae: 28.5031 - mape: 12.1812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 16.4582 - mae: 28.5031 - mape: 12.1812 - val_loss: 12.2231 - val_mae: 21.7684 - val_mape: 7.9450 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 78ms/step - loss: 16.7345 - mae: 31.8232 - mape: 12.4634 - val_loss: 12.2754 - val_mae: 21.5669 - val_mape: 8.0114 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.8087 - mae: 28.6856 - mape: 12.5372 - val_loss: 12.4362 - val_mae: 24.5556 - val_mape: 8.1599 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.8299 - mae: 31.1339 - mape: 12.5564 - val_loss: 12.5447 - val_mae: 24.2543 - val_mape: 8.2671 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 16.7491 - mae: 31.0765 - mape: 12.4677 - val_loss: 12.8782 - val_mae: 28.1310 - val_mape: 8.5909 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 16.7841 - mae: 31.2947 - mape: 12.5011 - val_loss: 13.0499 - val_mae: 24.1082 - val_mape: 8.7534 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.8653 - mae: 30.6382 - mape: 12.5751 - val_loss: 12.8105 - val_mae: 26.1217 - val_mape: 8.5314 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.6735 - mae: 31.1168 - mape: 12.3922 - val_loss: 12.4687 - val_mae: 22.7407 - val_mape: 8.1920 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.9622 - mae: 30.1921 - mape: 12.6775 - val_loss: 12.4128 - val_mae: 21.3327 - val_mape: 8.1283 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.8772 - mae: 31.0024 - mape: 12.5963"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 94ms/step - loss: 16.8772 - mae: 31.0024 - mape: 12.5963 - val_loss: 12.2268 - val_mae: 20.4768 - val_mape: 7.9444 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      " 1/87 [..............................] - ETA: 6s - loss: 15.3860 - mae: 25.6336 - mape: 11.1036"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 79ms/step - loss: 16.6231 - mae: 28.3706 - mape: 12.3462 - val_loss: 13.2365 - val_mae: 26.4276 - val_mape: 8.9696 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 17.0063 - mae: 30.1466 - mape: 12.7298 - val_loss: 12.4800 - val_mae: 21.6716 - val_mape: 8.2038 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.6153 - mae: 27.3923 - mape: 12.3284 - val_loss: 12.9751 - val_mae: 25.5839 - val_mape: 8.6844 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1757 - mae: 29.8849 - mape: 12.8820 - val_loss: 12.3619 - val_mae: 21.5838 - val_mape: 8.0657 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.8674 - mae: 29.7533 - mape: 12.5820 - val_loss: 12.8610 - val_mae: 25.6074 - val_mape: 8.5719 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.0784 - mae: 31.8459 - mape: 12.7769 - val_loss: 12.4568 - val_mae: 23.9194 - val_mape: 8.1479 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.8623 - mae: 30.0903 - mape: 12.5585 - val_loss: 13.4926 - val_mae: 29.4790 - val_mape: 9.1921 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.0847 - mae: 34.6402 - mape: 12.7928 - val_loss: 12.6832 - val_mae: 22.0889 - val_mape: 8.3799 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7116 - mae: 30.3040 - mape: 12.4152 - val_loss: 12.4551 - val_mae: 22.8045 - val_mape: 8.1530 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5564 - mae: 29.8161 - mape: 12.2664 - val_loss: 12.4463 - val_mae: 22.5522 - val_mape: 8.1675 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 17.0176 - mae: 31.9029 - mape: 12.7346 - val_loss: 14.3712 - val_mae: 34.0612 - val_mape: 10.0878 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 17.0712 - mae: 31.4165 - mape: 12.7771 - val_loss: 12.5559 - val_mae: 24.9792 - val_mape: 8.2669 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.6546 - mae: 30.2482 - mape: 12.3659 - val_loss: 12.9943 - val_mae: 27.5156 - val_mape: 8.6912 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 16.8434 - mae: 30.9298 - mape: 12.5394 - val_loss: 12.3291 - val_mae: 23.0237 - val_mape: 8.0311 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 16.6630 - mae: 28.4144 - mape: 12.3768 - val_loss: 12.9014 - val_mae: 26.3587 - val_mape: 8.6154 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.8779 - mae: 29.0976 - mape: 12.5950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 102ms/step - loss: 16.8779 - mae: 29.0976 - mape: 12.5950 - val_loss: 12.2122 - val_mae: 20.9680 - val_mape: 7.9322 - lr: 0.0010\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 86ms/step - loss: 16.6959 - mae: 29.3941 - mape: 12.4190 - val_loss: 12.6620 - val_mae: 25.7320 - val_mape: 8.3989 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6656 - mae: 29.4241 - mape: 12.3874 - val_loss: 12.5025 - val_mae: 23.8324 - val_mape: 8.2010 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.7632 - mae: 30.7719 - mape: 12.4770 - val_loss: 12.4966 - val_mae: 24.6044 - val_mape: 8.2015 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.4979 - mae: 27.9894 - mape: 12.2030 - val_loss: 12.4440 - val_mae: 23.9990 - val_mape: 8.1416 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8068 - mae: 30.3428 - mape: 12.5105 - val_loss: 12.5359 - val_mae: 22.4348 - val_mape: 8.2457 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8734 - mae: 32.5687 - mape: 12.5911 - val_loss: 12.3100 - val_mae: 21.2182 - val_mape: 8.0261 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 17.2121 - mae: 31.1493 - mape: 12.9119 - val_loss: 12.4845 - val_mae: 23.7888 - val_mape: 8.1952 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8808 - mae: 30.2622 - mape: 12.6019 - val_loss: 12.3326 - val_mae: 21.3189 - val_mape: 8.0599 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 16.9945 - mae: 30.1234 - mape: 12.7199 - val_loss: 12.3715 - val_mae: 22.9387 - val_mape: 8.0989 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8336 - mae: 32.0888 - mape: 12.5517 - val_loss: 12.6030 - val_mae: 24.7324 - val_mape: 8.3326 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.8891 - mae: 31.1929 - mape: 12.6094 - val_loss: 12.3279 - val_mae: 19.6542 - val_mape: 8.0555 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.8133 - mae: 31.4124 - mape: 12.5415 - val_loss: 12.3918 - val_mae: 20.9977 - val_mape: 8.1135 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8070 - mae: 30.0121 - mape: 12.5318 - val_loss: 12.6565 - val_mae: 23.2921 - val_mape: 8.3626 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6863 - mae: 29.2247 - mape: 12.4016 - val_loss: 12.8406 - val_mae: 27.7604 - val_mape: 8.5371 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8583 - mae: 30.0930 - mape: 12.5597 - val_loss: 12.2756 - val_mae: 20.6621 - val_mape: 7.9754 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9175 - mae: 31.0700 - mape: 12.6261 - val_loss: 12.9137 - val_mae: 27.9126 - val_mape: 8.6282 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5431 - mae: 29.4818 - mape: 12.2512 - val_loss: 12.4772 - val_mae: 21.6850 - val_mape: 8.1826 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7419 - mae: 29.5280 - mape: 12.4509 - val_loss: 12.5876 - val_mae: 25.6157 - val_mape: 8.3092 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.8672 - mae: 30.1292 - mape: 12.5938 - val_loss: 12.3807 - val_mae: 24.1784 - val_mape: 8.1114 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.7791 - mae: 32.0263 - mape: 12.5027 - val_loss: 12.2750 - val_mae: 22.0682 - val_mape: 7.9892 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.0810 - mae: 31.4800 - mape: 12.8008 - val_loss: 12.3000 - val_mae: 23.7288 - val_mape: 8.0092 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7655 - mae: 29.1041 - mape: 12.4795 - val_loss: 12.3973 - val_mae: 22.4934 - val_mape: 8.1158 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 17.1052 - mae: 30.3521 - mape: 12.8231 - val_loss: 12.3987 - val_mae: 24.4551 - val_mape: 8.1215 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5835 - mae: 28.0989 - mape: 12.3050 - val_loss: 12.6554 - val_mae: 24.6967 - val_mape: 8.3643 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.5707 - mae: 31.4595 - mape: 12.2811 - val_loss: 12.6798 - val_mae: 27.7562 - val_mape: 8.3851 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 17.0702 - mae: 31.2005 - mape: 12.7871 - val_loss: 12.3452 - val_mae: 22.2183 - val_mape: 8.0666 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.8197 - mae: 29.7210 - mape: 12.5333 - val_loss: 12.2820 - val_mae: 20.5022 - val_mape: 7.9828 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9924 - mae: 30.5468 - mape: 12.6998 - val_loss: 12.9204 - val_mae: 25.5045 - val_mape: 8.6365 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9224 - mae: 31.6402 - mape: 12.6412 - val_loss: 12.8081 - val_mae: 24.4718 - val_mape: 8.5339 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.9897 - mae: 30.4821 - mape: 12.7031\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.9897 - mae: 30.4821 - mape: 12.7031 - val_loss: 12.2698 - val_mae: 20.6915 - val_mape: 7.9666 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7643 - mae: 29.8623 - mape: 12.4769 - val_loss: 12.5528 - val_mae: 24.1051 - val_mape: 8.2700 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7183 - mae: 29.7591 - mape: 12.4367 - val_loss: 12.4250 - val_mae: 23.4615 - val_mape: 8.1453 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.6772 - mae: 29.9717 - mape: 12.4049 - val_loss: 12.7533 - val_mae: 26.0852 - val_mape: 8.4833 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.9212 - mae: 32.4381 - mape: 12.6433 - val_loss: 12.7278 - val_mae: 25.0029 - val_mape: 8.4426 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5658 - mae: 32.1264 - mape: 12.2847 - val_loss: 12.3372 - val_mae: 22.1144 - val_mape: 8.0531 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7926 - mae: 30.2018 - mape: 12.5119 - val_loss: 12.5676 - val_mae: 24.1120 - val_mape: 8.2848 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6678 - mae: 28.2675 - mape: 12.3908 - val_loss: 12.8304 - val_mae: 26.5969 - val_mape: 8.5596 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7167 - mae: 28.8025 - mape: 12.4431 - val_loss: 12.6653 - val_mae: 25.5996 - val_mape: 8.3915 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.5678 - mae: 31.6949 - mape: 12.2955 - val_loss: 12.7116 - val_mae: 26.5399 - val_mape: 8.4384 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5138 - mae: 27.5687 - mape: 12.2439 - val_loss: 12.9750 - val_mae: 27.9232 - val_mape: 8.7055 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.6494 - mae: 30.1406 - mape: 12.3785 - val_loss: 12.6743 - val_mae: 24.4502 - val_mape: 8.3994 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5785 - mae: 32.0518 - mape: 12.3041 - val_loss: 12.7892 - val_mae: 24.4109 - val_mape: 8.5098 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6104 - mae: 29.1138 - mape: 12.3271 - val_loss: 13.0792 - val_mae: 25.3658 - val_mape: 8.7963 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7532 - mae: 30.6059 - mape: 12.4729 - val_loss: 12.9711 - val_mae: 23.9429 - val_mape: 8.6938 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.5071 - mae: 31.6753 - mape: 12.2310 - val_loss: 12.8578 - val_mae: 25.7488 - val_mape: 8.5820 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6447 - mae: 29.6771 - mape: 12.3708 - val_loss: 12.9312 - val_mae: 26.2380 - val_mape: 8.6616 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 16.4070 - mae: 28.5643 - mape: 12.1369 - val_loss: 13.2813 - val_mae: 29.5395 - val_mape: 9.0142 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6769 - mae: 30.5276 - mape: 12.4053 - val_loss: 12.7302 - val_mae: 26.4484 - val_mape: 8.4632 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6056 - mae: 30.9279 - mape: 12.3431 - val_loss: 12.9293 - val_mae: 28.1266 - val_mape: 8.6742 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 16.6836 - mae: 29.3056 - mape: 12.4271 - val_loss: 12.7431 - val_mae: 26.5860 - val_mape: 8.4828 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.8793 - mae: 34.4118 - mape: 12.6132 - val_loss: 13.2654 - val_mae: 27.5784 - val_mape: 8.9916 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6896 - mae: 30.0289 - mape: 12.4161 - val_loss: 13.0970 - val_mae: 27.1042 - val_mape: 8.8183 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4706 - mae: 29.6041 - mape: 12.1955 - val_loss: 13.1731 - val_mae: 26.9822 - val_mape: 8.8955 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7923 - mae: 29.2104 - mape: 12.5204 - val_loss: 12.5975 - val_mae: 23.6390 - val_mape: 8.3264 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.4062 - mae: 30.8774 - mape: 12.1420 - val_loss: 13.1814 - val_mae: 28.2777 - val_mape: 8.9172 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 16.6190 - mae: 31.7219 - mape: 12.3534 - val_loss: 13.1750 - val_mae: 27.5374 - val_mape: 8.9086 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 16.7337 - mae: 30.4579 - mape: 12.4603 - val_loss: 13.5711 - val_mae: 28.7557 - val_mape: 9.2974 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.6970 - mae: 30.4081 - mape: 12.4237 - val_loss: 12.9450 - val_mae: 25.9044 - val_mape: 8.6727 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.4653 - mae: 30.9255 - mape: 12.1938 - val_loss: 13.2314 - val_mae: 28.5463 - val_mape: 8.9621 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.7631 - mae: 31.4860 - mape: 12.4929\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 16.7631 - mae: 31.4860 - mape: 12.4929 - val_loss: 15.0347 - val_mae: 37.0043 - val_mape: 10.7729 - lr: 3.0000e-04\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 12.21220874786377; mae of 20.968006134033203; mape of 7.932228088378906%;\n"
     ]
    }
   ],
   "source": [
    "#Hybrid freeze\n",
    "nnmodel = keras.models.load_model('crossvalidationmodels/Baseline_nosupp_5/')\n",
    "for layer in nnmodel.layers:\n",
    "    layer.trainable = False\n",
    "gcnmodel = keras.models.load_model('savedmodels/GCN_simplified_normalized')\n",
    "for layer in gcnmodel.layers:\n",
    "    layer.trainable = False \n",
    "\n",
    "combined = concatenate([nnmodel.get_layer('dropbaseline').output, gcnmodel.get_layer('dropgcn').output], name='join')\n",
    "z = Dense(128,'relu', name='dense1')(combined)\n",
    "z = Dense(64,'relu', kernel_regularizer=keras.regularizers.L1(0.01), name='dense4')(z)\n",
    "z = Dropout(0.3, name='finaldrop')(z)\n",
    "z = Dense(1, 'linear', name='regress')(z)\n",
    "model = Model(inputs = [gcnmodel.input, nnmodel.input], outputs = z)\n",
    "\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, 'crossvalidationmodels/Hybrid_nosupp_freeze')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n",
      " 1/87 [..............................] - ETA: 1:09 - loss: 107.5901 - mae: 443.9589 - mape: 103.5191"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 58.2286 - mae: 139.6452 - mape: 54.1577"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 97ms/step - loss: 58.2286 - mae: 139.6452 - mape: 54.1577 - val_loss: 21.2746 - val_mae: 30.4642 - val_mape: 17.2036 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 25.3043 - mae: 47.8842 - mape: 21.2334"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 96ms/step - loss: 25.3043 - mae: 47.8842 - mape: 21.2334 - val_loss: 19.0683 - val_mae: 25.6194 - val_mape: 14.9973 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 24.1100 - mae: 46.6492 - mape: 20.0390"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 24.1100 - mae: 46.6492 - mape: 20.0390 - val_loss: 17.9964 - val_mae: 24.1376 - val_mape: 13.9254 - lr: 0.0010\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 22.9127 - mae: 45.2749 - mape: 18.8417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 22.9127 - mae: 45.2749 - mape: 18.8417 - val_loss: 17.1131 - val_mae: 22.3611 - val_mape: 13.0421 - lr: 0.0010\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 22.1222 - mae: 43.2407 - mape: 18.0512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 22.1222 - mae: 43.2407 - mape: 18.0512 - val_loss: 16.3715 - val_mae: 21.7041 - val_mape: 12.3005 - lr: 0.0010\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 21.4292 - mae: 43.0395 - mape: 17.3582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 21.4371 - mae: 43.0046 - mape: 17.3661 - val_loss: 16.1639 - val_mae: 23.4408 - val_mape: 12.0930 - lr: 0.0010\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 21.6866 - mae: 41.7265 - mape: 17.6156"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 104ms/step - loss: 21.6866 - mae: 41.7265 - mape: 17.6156 - val_loss: 15.5061 - val_mae: 20.6485 - val_mape: 11.4351 - lr: 0.0010\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 21.2625 - mae: 41.1138 - mape: 17.1915"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 96ms/step - loss: 21.2625 - mae: 41.1138 - mape: 17.1915 - val_loss: 14.8703 - val_mae: 20.4232 - val_mape: 10.7993 - lr: 0.0010\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 21.1800 - mae: 42.8260 - mape: 17.1090"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 92ms/step - loss: 21.1800 - mae: 42.8260 - mape: 17.1090 - val_loss: 14.4598 - val_mae: 19.6889 - val_mape: 10.3889 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      " 2/87 [..............................] - ETA: 6s - loss: 19.3724 - mae: 32.6838 - mape: 15.3015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 20.9563 - mae: 44.9424 - mape: 16.8854"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 20.9563 - mae: 44.9424 - mape: 16.8854 - val_loss: 14.0641 - val_mae: 18.0626 - val_mape: 9.9931 - lr: 0.0010\n",
      "Epoch 11/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 20.8861 - mae: 43.1069 - mape: 16.8151"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 20.8861 - mae: 43.1069 - mape: 16.8151 - val_loss: 13.8752 - val_mae: 19.1211 - val_mape: 9.8042 - lr: 0.0010\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 20.4641 - mae: 40.9373 - mape: 16.3931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 20.4641 - mae: 40.9373 - mape: 16.3931 - val_loss: 13.7164 - val_mae: 18.9348 - val_mape: 9.6455 - lr: 0.0010\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 20.7081 - mae: 41.8019 - mape: 16.6371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 89ms/step - loss: 20.7081 - mae: 41.8019 - mape: 16.6371 - val_loss: 13.4833 - val_mae: 17.8361 - val_mape: 9.4124 - lr: 0.0010\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 20.5246 - mae: 44.8443 - mape: 16.4536 - val_loss: 13.5735 - val_mae: 19.0003 - val_mape: 9.5026 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 20.4519 - mae: 40.2571 - mape: 16.3809 - val_loss: 14.0546 - val_mae: 20.0314 - val_mape: 9.9836 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 20.8176 - mae: 43.1649 - mape: 16.7466"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 104ms/step - loss: 20.8176 - mae: 43.1649 - mape: 16.7466 - val_loss: 13.3986 - val_mae: 19.7439 - val_mape: 9.3276 - lr: 0.0010\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 73ms/step - loss: 20.3854 - mae: 46.0800 - mape: 16.3144 - val_loss: 14.1215 - val_mae: 22.6075 - val_mape: 10.0505 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 20.3898 - mae: 40.3116 - mape: 16.3188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 20.3898 - mae: 40.3116 - mape: 16.3188 - val_loss: 13.0417 - val_mae: 17.7380 - val_mape: 8.9707 - lr: 0.0010\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 85ms/step - loss: 20.1559 - mae: 42.4277 - mape: 16.0849 - val_loss: 13.3796 - val_mae: 18.8123 - val_mape: 9.3087 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 20.5340 - mae: 42.6930 - mape: 16.4630 - val_loss: 13.1551 - val_mae: 19.6697 - val_mape: 9.0842 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 20.4389 - mae: 43.7096 - mape: 16.3680 - val_loss: 13.1229 - val_mae: 19.6687 - val_mape: 9.0519 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 20.1320 - mae: 40.8043 - mape: 16.0610"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 20.1320 - mae: 40.8043 - mape: 16.0610 - val_loss: 12.9733 - val_mae: 18.9750 - val_mape: 8.9023 - lr: 0.0010\n",
      "Epoch 23/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 19.9676 - mae: 41.7114 - mape: 15.8967 - val_loss: 13.8166 - val_mae: 21.8003 - val_mape: 9.7456 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.8630 - mae: 39.6679 - mape: 15.7921"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 19.8630 - mae: 39.6679 - mape: 15.7921 - val_loss: 12.9726 - val_mae: 19.5208 - val_mape: 8.9017 - lr: 0.0010\n",
      "Epoch 25/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 20.2975 - mae: 42.1242 - mape: 16.2266 - val_loss: 12.9991 - val_mae: 19.4733 - val_mape: 8.9281 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 20.0270 - mae: 40.5786 - mape: 15.9561 - val_loss: 13.4439 - val_mae: 20.4777 - val_mape: 9.3729 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 20.2760 - mae: 42.5470 - mape: 16.2050 - val_loss: 12.9903 - val_mae: 18.9333 - val_mape: 8.9194 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 20.6230 - mae: 41.5233 - mape: 16.5520"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 20.6230 - mae: 41.5233 - mape: 16.5520 - val_loss: 12.7668 - val_mae: 17.9591 - val_mape: 8.6958 - lr: 0.0010\n",
      "Epoch 29/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 20.0159 - mae: 47.1601 - mape: 15.9449 - val_loss: 12.8342 - val_mae: 19.0858 - val_mape: 8.7632 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 20.0642 - mae: 40.9323 - mape: 15.9932 - val_loss: 13.0463 - val_mae: 19.5925 - val_mape: 8.9754 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 20.3829 - mae: 44.9379 - mape: 16.3119 - val_loss: 13.6022 - val_mae: 22.5329 - val_mape: 9.5313 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 20.4053 - mae: 43.6287 - mape: 16.3343 - val_loss: 12.8007 - val_mae: 18.6033 - val_mape: 8.7297 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.7109 - mae: 39.0010 - mape: 15.6400 - val_loss: 12.9291 - val_mae: 19.5627 - val_mape: 8.8582 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 20.1935 - mae: 41.8616 - mape: 16.1225 - val_loss: 13.0279 - val_mae: 19.1057 - val_mape: 8.9570 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 20.0754 - mae: 43.0675 - mape: 16.0045 - val_loss: 12.7745 - val_mae: 17.8985 - val_mape: 8.7035 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.6396 - mae: 41.8084 - mape: 15.5686 - val_loss: 12.7778 - val_mae: 18.5728 - val_mape: 8.7068 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.8794 - mae: 40.7792 - mape: 15.8084 - val_loss: 13.8240 - val_mae: 22.0696 - val_mape: 9.7531 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.9110 - mae: 42.1076 - mape: 15.8401 - val_loss: 12.8661 - val_mae: 17.9945 - val_mape: 8.7951 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 19.9003 - mae: 39.9524 - mape: 15.8293 - val_loss: 14.4953 - val_mae: 24.3880 - val_mape: 10.4243 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.8481 - mae: 41.7521 - mape: 15.7772 - val_loss: 12.7869 - val_mae: 18.7775 - val_mape: 8.7159 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4678 - mae: 43.3252 - mape: 15.3968 - val_loss: 14.1166 - val_mae: 23.6560 - val_mape: 10.0457 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.5350 - mae: 41.8036 - mape: 15.4640 - val_loss: 13.5353 - val_mae: 22.5844 - val_mape: 9.4643 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.6928 - mae: 39.3957 - mape: 15.6219"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 102ms/step - loss: 19.6928 - mae: 39.3957 - mape: 15.6219 - val_loss: 12.7307 - val_mae: 18.2350 - val_mape: 8.6597 - lr: 0.0010\n",
      "Epoch 44/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 86ms/step - loss: 19.2079 - mae: 39.4829 - mape: 15.1370 - val_loss: 13.3048 - val_mae: 21.4709 - val_mape: 9.2338 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.5784 - mae: 39.6822 - mape: 15.5075 - val_loss: 13.8905 - val_mae: 22.4630 - val_mape: 9.8196 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.7018 - mae: 43.2631 - mape: 15.6308 - val_loss: 13.1906 - val_mae: 20.5303 - val_mape: 9.1196 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.5746 - mae: 42.8929 - mape: 15.5036 - val_loss: 13.3805 - val_mae: 22.1280 - val_mape: 9.3095 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.6927 - mae: 40.6162 - mape: 15.6218 - val_loss: 12.8869 - val_mae: 19.7356 - val_mape: 8.8160 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4777 - mae: 43.4367 - mape: 15.4068 - val_loss: 13.4777 - val_mae: 21.6573 - val_mape: 9.4068 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 20.0184 - mae: 42.5838 - mape: 15.9474 - val_loss: 13.1757 - val_mae: 20.5272 - val_mape: 9.1047 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5475 - mae: 43.3997 - mape: 15.4765 - val_loss: 12.7677 - val_mae: 18.5974 - val_mape: 8.6967 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.7278 - mae: 39.3822 - mape: 15.6568 - val_loss: 12.9342 - val_mae: 19.7917 - val_mape: 8.8632 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3847 - mae: 41.2394 - mape: 15.3137 - val_loss: 13.1166 - val_mae: 20.0503 - val_mape: 9.0456 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3718 - mae: 41.1395 - mape: 15.3009 - val_loss: 13.0754 - val_mae: 20.6885 - val_mape: 9.0045 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.6435 - mae: 42.9183 - mape: 15.5725 - val_loss: 12.7560 - val_mae: 18.4222 - val_mape: 8.6850 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.7895 - mae: 40.4210 - mape: 15.7186 - val_loss: 12.7326 - val_mae: 18.3579 - val_mape: 8.6616 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.6626 - mae: 44.0864 - mape: 15.5916 - val_loss: 12.9450 - val_mae: 19.3700 - val_mape: 8.8741 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.5035 - mae: 37.0389 - mape: 15.4325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 101ms/step - loss: 19.5035 - mae: 37.0389 - mape: 15.4325 - val_loss: 12.6920 - val_mae: 17.3391 - val_mape: 8.6210 - lr: 0.0010\n",
      "Epoch 59/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 86ms/step - loss: 19.5593 - mae: 37.8872 - mape: 15.4883 - val_loss: 13.0031 - val_mae: 20.2896 - val_mape: 8.9321 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.9690 - mae: 38.6066 - mape: 15.8981 - val_loss: 13.1093 - val_mae: 20.6313 - val_mape: 9.0383 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3752 - mae: 41.2821 - mape: 15.3043 - val_loss: 12.9567 - val_mae: 17.3763 - val_mape: 8.8858 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.4643 - mae: 40.4397 - mape: 15.3934 - val_loss: 12.9200 - val_mae: 19.1534 - val_mape: 8.8491 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.8064 - mae: 38.0873 - mape: 15.7355 - val_loss: 12.8266 - val_mae: 17.6671 - val_mape: 8.7556 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.8244 - mae: 40.8174 - mape: 15.7535 - val_loss: 12.8202 - val_mae: 18.9801 - val_mape: 8.7493 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.7289 - mae: 43.5825 - mape: 15.6579 - val_loss: 12.7027 - val_mae: 17.4894 - val_mape: 8.6317 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.6769 - mae: 38.9585 - mape: 15.6059 - val_loss: 13.4848 - val_mae: 22.8245 - val_mape: 9.4138 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4584 - mae: 41.9896 - mape: 15.3874 - val_loss: 13.1483 - val_mae: 21.1079 - val_mape: 9.0774 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.7223 - mae: 39.5851 - mape: 15.6513 - val_loss: 13.2228 - val_mae: 20.7155 - val_mape: 9.1519 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3642 - mae: 41.3133 - mape: 15.2932 - val_loss: 13.1417 - val_mae: 20.6793 - val_mape: 9.0707 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2147 - mae: 38.7638 - mape: 15.1438 - val_loss: 12.7504 - val_mae: 18.7794 - val_mape: 8.6795 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.3140 - mae: 36.5214 - mape: 15.2430 - val_loss: 13.8249 - val_mae: 22.8464 - val_mape: 9.7540 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.6557 - mae: 45.1442 - mape: 15.5847 - val_loss: 13.4386 - val_mae: 22.0470 - val_mape: 9.3676 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.8051 - mae: 42.3718 - mape: 15.7341 - val_loss: 12.7187 - val_mae: 18.0815 - val_mape: 8.6477 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.2483 - mae: 43.1467 - mape: 15.1774 - val_loss: 13.4357 - val_mae: 21.8379 - val_mape: 9.3648 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.5324 - mae: 43.8232 - mape: 15.4614 - val_loss: 13.4231 - val_mae: 21.6690 - val_mape: 9.3522 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3731 - mae: 38.2567 - mape: 15.3021 - val_loss: 12.8000 - val_mae: 19.3349 - val_mape: 8.7290 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4208 - mae: 39.7521 - mape: 15.3499 - val_loss: 12.7456 - val_mae: 18.5104 - val_mape: 8.6746 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3599 - mae: 38.2139 - mape: 15.2889 - val_loss: 12.7351 - val_mae: 17.3908 - val_mape: 8.6641 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 19.3897 - mae: 38.3446 - mape: 15.3187 - val_loss: 13.0977 - val_mae: 20.6473 - val_mape: 9.0267 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.1694 - mae: 41.2746 - mape: 15.0984 - val_loss: 13.1392 - val_mae: 21.5768 - val_mape: 9.0683 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 19.4624 - mae: 43.9368 - mape: 15.3914 - val_loss: 14.2306 - val_mae: 23.9329 - val_mape: 10.1597 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.6142 - mae: 40.9693 - mape: 15.5432 - val_loss: 13.5990 - val_mae: 23.5230 - val_mape: 9.5281 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 20.0079 - mae: 45.0927 - mape: 15.9369 - val_loss: 13.0321 - val_mae: 21.2250 - val_mape: 8.9611 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4452 - mae: 41.7277 - mape: 15.3743 - val_loss: 14.4674 - val_mae: 25.4547 - val_mape: 10.3965 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.6990 - mae: 42.8449 - mape: 15.6280 - val_loss: 12.8117 - val_mae: 17.7231 - val_mape: 8.7407 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 19.6559 - mae: 41.6909 - mape: 15.5849 - val_loss: 12.7900 - val_mae: 17.8559 - val_mape: 8.7190 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.5185 - mae: 41.0370 - mape: 15.4476 - val_loss: 12.9630 - val_mae: 20.2920 - val_mape: 8.8920 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.4099 - mae: 43.0974 - mape: 15.3389\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4099 - mae: 43.0974 - mape: 15.3389 - val_loss: 13.0955 - val_mae: 20.3709 - val_mape: 9.0245 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.4337 - mae: 45.8368 - mape: 15.3627 - val_loss: 12.7170 - val_mae: 18.7085 - val_mape: 8.6461 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3146 - mae: 38.8920 - mape: 15.2436 - val_loss: 12.7878 - val_mae: 19.1606 - val_mape: 8.7168 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.6984 - mae: 41.1232 - mape: 15.6275 - val_loss: 13.0302 - val_mae: 20.3615 - val_mape: 8.9593 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.6690 - mae: 41.8971 - mape: 14.5980 - val_loss: 12.8742 - val_mae: 19.7135 - val_mape: 8.8032 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3995 - mae: 41.4179 - mape: 15.3286 - val_loss: 13.1990 - val_mae: 20.9505 - val_mape: 9.1281 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3179 - mae: 42.2551 - mape: 15.2469 - val_loss: 13.2516 - val_mae: 21.1288 - val_mape: 9.1806 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.0106 - mae: 37.9954 - mape: 14.9397 - val_loss: 12.8246 - val_mae: 19.4333 - val_mape: 8.7536 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.2503 - mae: 39.2439 - mape: 15.1793 - val_loss: 12.8123 - val_mae: 18.9427 - val_mape: 8.7413 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3853 - mae: 40.5947 - mape: 15.3143 - val_loss: 12.9467 - val_mae: 19.7678 - val_mape: 8.8757 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.4075 - mae: 44.9938 - mape: 15.3365 - val_loss: 13.0302 - val_mae: 20.2481 - val_mape: 8.9593 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4404 - mae: 41.4882 - mape: 15.3694 - val_loss: 12.8135 - val_mae: 19.4491 - val_mape: 8.7425 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4019 - mae: 41.3306 - mape: 15.3309 - val_loss: 12.8438 - val_mae: 19.6111 - val_mape: 8.7729 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 19.1718 - mae: 38.9067 - mape: 15.1008 - val_loss: 12.7361 - val_mae: 18.6905 - val_mape: 8.6652 - lr: 3.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2774 - mae: 39.0991 - mape: 15.2064 - val_loss: 13.1188 - val_mae: 20.6517 - val_mape: 9.0478 - lr: 3.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.5933 - mae: 40.4792 - mape: 15.5224 - val_loss: 12.7809 - val_mae: 19.1222 - val_mape: 8.7099 - lr: 3.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3526 - mae: 37.0920 - mape: 15.2816 - val_loss: 13.2433 - val_mae: 21.5273 - val_mape: 9.1724 - lr: 3.0000e-04\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.1285 - mae: 37.9991 - mape: 15.0575 - val_loss: 13.0226 - val_mae: 20.6786 - val_mape: 8.9516 - lr: 3.0000e-04\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.9919 - mae: 42.5873 - mape: 15.9210 - val_loss: 13.0581 - val_mae: 20.7663 - val_mape: 8.9871 - lr: 3.0000e-04\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2139 - mae: 40.9215 - mape: 15.1430 - val_loss: 12.7523 - val_mae: 18.6304 - val_mape: 8.6813 - lr: 3.0000e-04\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3852 - mae: 42.0714 - mape: 15.3143 - val_loss: 13.0082 - val_mae: 20.4097 - val_mape: 8.9372 - lr: 3.0000e-04\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.4346 - mae: 39.4643 - mape: 15.3636 - val_loss: 12.8527 - val_mae: 19.4518 - val_mape: 8.7817 - lr: 3.0000e-04\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 19.3446 - mae: 41.5201 - mape: 15.2736 - val_loss: 12.8272 - val_mae: 19.1945 - val_mape: 8.7562 - lr: 3.0000e-04\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.2278 - mae: 40.4484 - mape: 15.1569 - val_loss: 13.0281 - val_mae: 19.9707 - val_mape: 8.9571 - lr: 3.0000e-04\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1416 - mae: 40.8075 - mape: 15.0706 - val_loss: 13.1582 - val_mae: 20.6187 - val_mape: 9.0872 - lr: 3.0000e-04\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3132 - mae: 40.5232 - mape: 15.2423 - val_loss: 13.0311 - val_mae: 20.3676 - val_mape: 8.9602 - lr: 3.0000e-04\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.2514 - mae: 41.9104 - mape: 15.1804 - val_loss: 12.9963 - val_mae: 20.1327 - val_mape: 8.9254 - lr: 3.0000e-04\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.3761 - mae: 42.1907 - mape: 15.3051 - val_loss: 12.7928 - val_mae: 19.3266 - val_mape: 8.7218 - lr: 3.0000e-04\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.2415 - mae: 41.5368 - mape: 15.1705 - val_loss: 12.7847 - val_mae: 19.2650 - val_mape: 8.7137 - lr: 3.0000e-04\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.2812 - mae: 39.3960 - mape: 15.2102 - val_loss: 12.7164 - val_mae: 17.7919 - val_mape: 8.6454 - lr: 3.0000e-04\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.8427 - mae: 39.3299 - mape: 14.7717\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.8427 - mae: 39.3299 - mape: 14.7717 - val_loss: 13.0432 - val_mae: 20.6581 - val_mape: 8.9722 - lr: 3.0000e-04\n",
      "Epoch 118: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 12.691978454589844; mae of 17.339069366455078; mape of 8.621012687683105%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.9406 - mae: 40.2359 - mape: 15.8696"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 93ms/step - loss: 19.9406 - mae: 40.2359 - mape: 15.8696 - val_loss: 12.8251 - val_mae: 26.5348 - val_mape: 8.7541 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.5458 - mae: 39.9493 - mape: 15.4749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 19.5458 - mae: 39.9493 - mape: 15.4749 - val_loss: 12.2053 - val_mae: 22.9199 - val_mape: 8.1343 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.2959 - mae: 37.6185 - mape: 15.2249"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 19.2959 - mae: 37.6185 - mape: 15.2249 - val_loss: 12.1653 - val_mae: 22.7705 - val_mape: 8.0943 - lr: 0.0010\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 74ms/step - loss: 19.8020 - mae: 42.2120 - mape: 15.7310 - val_loss: 12.5891 - val_mae: 27.2471 - val_mape: 8.5181 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.6729 - mae: 38.0386 - mape: 15.6019 - val_loss: 12.8096 - val_mae: 28.2373 - val_mape: 8.7386 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.9727 - mae: 44.2941 - mape: 15.9018 - val_loss: 13.0001 - val_mae: 30.3114 - val_mape: 8.9291 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.3590 - mae: 39.2689 - mape: 15.2880 - val_loss: 12.2701 - val_mae: 24.7750 - val_mape: 8.1992 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2679 - mae: 37.7087 - mape: 15.1969 - val_loss: 12.4150 - val_mae: 24.9491 - val_mape: 8.3440 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.6742 - mae: 38.9892 - mape: 15.6032 - val_loss: 12.5152 - val_mae: 26.1365 - val_mape: 8.4443 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.8873 - mae: 40.3776 - mape: 15.8164 - val_loss: 12.3254 - val_mae: 22.1389 - val_mape: 8.2544 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.7596 - mae: 37.4140 - mape: 15.6886 - val_loss: 13.0413 - val_mae: 29.1448 - val_mape: 8.9704 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.4868 - mae: 40.8334 - mape: 15.4158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 98ms/step - loss: 19.4868 - mae: 40.8334 - mape: 15.4158 - val_loss: 12.1248 - val_mae: 22.2133 - val_mape: 8.0538 - lr: 0.0010\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.3735 - mae: 39.0330 - mape: 15.3025"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 101ms/step - loss: 19.3735 - mae: 39.0330 - mape: 15.3025 - val_loss: 12.1094 - val_mae: 22.7606 - val_mape: 8.0385 - lr: 0.0010\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 73ms/step - loss: 19.5882 - mae: 37.3338 - mape: 15.5172 - val_loss: 12.1225 - val_mae: 21.4184 - val_mape: 8.0515 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.4952 - mae: 37.3610 - mape: 15.4242 - val_loss: 12.4980 - val_mae: 25.7009 - val_mape: 8.4271 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.5313 - mae: 34.9931 - mape: 15.4603 - val_loss: 12.5193 - val_mae: 26.2133 - val_mape: 8.4484 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.4309 - mae: 37.4265 - mape: 15.3599 - val_loss: 12.3432 - val_mae: 26.0891 - val_mape: 8.2723 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.2878 - mae: 38.0148 - mape: 15.2168 - val_loss: 12.1535 - val_mae: 21.6571 - val_mape: 8.0825 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.7402 - mae: 40.9233 - mape: 15.6693 - val_loss: 12.5144 - val_mae: 26.7260 - val_mape: 8.4434 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4024 - mae: 38.1808 - mape: 15.3314 - val_loss: 12.3820 - val_mae: 25.6733 - val_mape: 8.3110 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.5632 - mae: 39.4129 - mape: 15.4923 - val_loss: 12.5024 - val_mae: 26.2320 - val_mape: 8.4314 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.7345 - mae: 37.9055 - mape: 15.6635 - val_loss: 12.2286 - val_mae: 23.4592 - val_mape: 8.1576 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.9054 - mae: 37.0335 - mape: 14.8344"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 105ms/step - loss: 18.9054 - mae: 37.0335 - mape: 14.8344 - val_loss: 12.0552 - val_mae: 21.4458 - val_mape: 7.9843 - lr: 0.0010\n",
      "Epoch 24/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 6s 73ms/step - loss: 19.7524 - mae: 41.7809 - mape: 15.6814 - val_loss: 12.7330 - val_mae: 26.8506 - val_mape: 8.6621 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.6319 - mae: 36.7742 - mape: 15.5609 - val_loss: 12.6581 - val_mae: 29.1251 - val_mape: 8.5871 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.5815 - mae: 38.4975 - mape: 15.5106 - val_loss: 12.2770 - val_mae: 25.0491 - val_mape: 8.2061 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5245 - mae: 37.7116 - mape: 15.4536 - val_loss: 12.7305 - val_mae: 27.8576 - val_mape: 8.6596 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0126 - mae: 38.3728 - mape: 14.9416 - val_loss: 12.3904 - val_mae: 26.3068 - val_mape: 8.3195 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 6s 74ms/step - loss: 19.1736 - mae: 36.9865 - mape: 15.1026 - val_loss: 12.7169 - val_mae: 27.5034 - val_mape: 8.6459 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.3348 - mae: 38.4370 - mape: 15.2638 - val_loss: 13.0495 - val_mae: 30.2181 - val_mape: 8.9785 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5225 - mae: 38.7406 - mape: 15.4515 - val_loss: 12.6196 - val_mae: 27.6792 - val_mape: 8.5486 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.2755 - mae: 37.0723 - mape: 15.2045 - val_loss: 12.3741 - val_mae: 25.4924 - val_mape: 8.3031 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2918 - mae: 39.5161 - mape: 15.2208 - val_loss: 12.5995 - val_mae: 28.2162 - val_mape: 8.5285 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0820 - mae: 38.3321 - mape: 15.0111 - val_loss: 12.6898 - val_mae: 27.7615 - val_mape: 8.6188 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2030 - mae: 40.8783 - mape: 15.1320 - val_loss: 12.9040 - val_mae: 28.3280 - val_mape: 8.8331 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.3293 - mae: 41.5919 - mape: 15.2583 - val_loss: 12.5961 - val_mae: 28.4431 - val_mape: 8.5251 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4763 - mae: 37.4803 - mape: 15.4054 - val_loss: 12.2160 - val_mae: 24.8049 - val_mape: 8.1450 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3598 - mae: 41.2399 - mape: 15.2889 - val_loss: 13.2903 - val_mae: 30.8701 - val_mape: 9.2193 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.8375 - mae: 37.5972 - mape: 15.7665 - val_loss: 13.1995 - val_mae: 32.8918 - val_mape: 9.1285 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2903 - mae: 39.3657 - mape: 15.2193 - val_loss: 14.0726 - val_mae: 36.2562 - val_mape: 10.0016 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1896 - mae: 36.0832 - mape: 15.1187 - val_loss: 12.4035 - val_mae: 24.9772 - val_mape: 8.3325 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.3844 - mae: 39.8417 - mape: 15.3135 - val_loss: 12.6950 - val_mae: 29.0849 - val_mape: 8.6241 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5793 - mae: 38.0746 - mape: 15.5083 - val_loss: 12.3203 - val_mae: 25.3357 - val_mape: 8.2493 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.7296 - mae: 39.1530 - mape: 15.6587 - val_loss: 13.0771 - val_mae: 30.7920 - val_mape: 9.0061 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.5307 - mae: 41.6746 - mape: 15.4597 - val_loss: 12.3135 - val_mae: 25.1033 - val_mape: 8.2425 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5889 - mae: 39.0913 - mape: 15.5179 - val_loss: 12.5644 - val_mae: 25.4500 - val_mape: 8.4934 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1687 - mae: 39.3665 - mape: 15.0977 - val_loss: 12.0735 - val_mae: 21.4992 - val_mape: 8.0025 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0984 - mae: 35.8351 - mape: 15.0274 - val_loss: 12.7122 - val_mae: 27.4585 - val_mape: 8.6412 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.3660 - mae: 37.5620 - mape: 15.2950 - val_loss: 12.6128 - val_mae: 27.4248 - val_mape: 8.5418 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4297 - mae: 37.6082 - mape: 15.3587 - val_loss: 12.0925 - val_mae: 22.4770 - val_mape: 8.0216 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1613 - mae: 40.6740 - mape: 15.0903 - val_loss: 12.2118 - val_mae: 24.1525 - val_mape: 8.1408 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.7625 - mae: 38.9241 - mape: 15.6915 - val_loss: 12.0871 - val_mae: 21.3439 - val_mape: 8.0161 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.5277 - mae: 42.1704 - mape: 15.4568\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.5277 - mae: 42.1704 - mape: 15.4568 - val_loss: 12.5445 - val_mae: 26.9356 - val_mape: 8.4735 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4977 - mae: 39.7354 - mape: 15.4267 - val_loss: 12.3701 - val_mae: 26.1856 - val_mape: 8.2991 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3438 - mae: 37.4058 - mape: 15.2729 - val_loss: 12.5278 - val_mae: 27.5505 - val_mape: 8.4569 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2345 - mae: 39.1161 - mape: 15.1636 - val_loss: 12.5630 - val_mae: 27.7313 - val_mape: 8.4920 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0793 - mae: 40.7503 - mape: 15.0083 - val_loss: 12.4065 - val_mae: 26.4396 - val_mape: 8.3356 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.1490 - mae: 38.8454 - mape: 15.0780 - val_loss: 12.4678 - val_mae: 26.5679 - val_mape: 8.3968 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.0154 - mae: 37.1355 - mape: 14.9444 - val_loss: 12.4620 - val_mae: 26.7621 - val_mape: 8.3910 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.1266 - mae: 34.0462 - mape: 15.0556 - val_loss: 12.8570 - val_mae: 29.2507 - val_mape: 8.7860 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.6057 - mae: 39.9288 - mape: 15.5348 - val_loss: 12.5724 - val_mae: 27.4048 - val_mape: 8.5014 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3229 - mae: 39.5566 - mape: 15.2519 - val_loss: 12.3073 - val_mae: 25.6528 - val_mape: 8.2363 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 19.1962 - mae: 40.3136 - mape: 15.1252 - val_loss: 12.4596 - val_mae: 26.8880 - val_mape: 8.3886 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0185 - mae: 38.8675 - mape: 14.9476 - val_loss: 12.2466 - val_mae: 24.9837 - val_mape: 8.1756 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1694 - mae: 39.4110 - mape: 15.0985 - val_loss: 12.2415 - val_mae: 24.8669 - val_mape: 8.1705 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1704 - mae: 38.2480 - mape: 15.0994 - val_loss: 12.5539 - val_mae: 27.8520 - val_mape: 8.4830 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.3156 - mae: 39.8416 - mape: 15.2447 - val_loss: 12.4368 - val_mae: 27.0637 - val_mape: 8.3659 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1831 - mae: 38.4692 - mape: 15.1121 - val_loss: 12.7397 - val_mae: 28.8634 - val_mape: 8.6688 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.9520 - mae: 39.6002 - mape: 14.8811 - val_loss: 12.3152 - val_mae: 25.8350 - val_mape: 8.2442 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.3467 - mae: 37.7407 - mape: 15.2758 - val_loss: 12.4210 - val_mae: 26.7578 - val_mape: 8.3500 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2389 - mae: 39.4611 - mape: 15.1679 - val_loss: 12.8674 - val_mae: 30.1329 - val_mape: 8.7964 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2775 - mae: 42.5103 - mape: 15.2065 - val_loss: 12.4241 - val_mae: 27.1849 - val_mape: 8.3531 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.1421 - mae: 35.3692 - mape: 15.0711 - val_loss: 13.0749 - val_mae: 30.4440 - val_mape: 9.0039 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9608 - mae: 35.7500 - mape: 14.8898 - val_loss: 12.5469 - val_mae: 27.3325 - val_mape: 8.4760 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2584 - mae: 38.5277 - mape: 15.1874 - val_loss: 12.4526 - val_mae: 26.6599 - val_mape: 8.3817 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1714 - mae: 38.7418 - mape: 15.1005 - val_loss: 13.1227 - val_mae: 30.3223 - val_mape: 9.0517 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1414 - mae: 36.6126 - mape: 15.0704 - val_loss: 12.2992 - val_mae: 25.7286 - val_mape: 8.2282 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0249 - mae: 37.7986 - mape: 14.9539 - val_loss: 12.3068 - val_mae: 25.5551 - val_mape: 8.2358 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1306 - mae: 40.5888 - mape: 15.0596 - val_loss: 12.9062 - val_mae: 29.3296 - val_mape: 8.8353 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1772 - mae: 39.8890 - mape: 15.1062 - val_loss: 12.4494 - val_mae: 26.3413 - val_mape: 8.3784 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3626 - mae: 40.5950 - mape: 15.2916 - val_loss: 12.3552 - val_mae: 26.0313 - val_mape: 8.2842 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3890 - mae: 39.5645 - mape: 15.3180 - val_loss: 12.1108 - val_mae: 22.9893 - val_mape: 8.0399 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.5085 - mae: 40.3047 - mape: 15.4376\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5085 - mae: 40.3047 - mape: 15.4376 - val_loss: 12.3842 - val_mae: 25.4189 - val_mape: 8.3132 - lr: 3.0000e-04\n",
      "Epoch 83: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 12.055237770080566; mae of 21.445785522460938; mape of 7.9842705726623535%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.3135 - mae: 40.6195 - mape: 15.2426"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 94ms/step - loss: 19.3135 - mae: 40.6195 - mape: 15.2426 - val_loss: 12.7941 - val_mae: 22.6785 - val_mape: 8.7231 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.6736 - mae: 46.4142 - mape: 15.6027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 108ms/step - loss: 19.6736 - mae: 46.4142 - mape: 15.6027 - val_loss: 12.0410 - val_mae: 17.0690 - val_mape: 7.9700 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 75ms/step - loss: 19.5502 - mae: 43.6541 - mape: 15.4792 - val_loss: 12.0750 - val_mae: 17.3890 - val_mape: 8.0040 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.6966 - mae: 44.2710 - mape: 15.6256 - val_loss: 12.6245 - val_mae: 21.1859 - val_mape: 8.5535 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 75ms/step - loss: 19.6751 - mae: 45.4513 - mape: 15.6042 - val_loss: 12.5657 - val_mae: 20.5860 - val_mape: 8.4948 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 19.6780 - mae: 38.8283 - mape: 15.6070 - val_loss: 13.1178 - val_mae: 23.6042 - val_mape: 9.0469 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.3255 - mae: 41.6172 - mape: 15.2545"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 19.3255 - mae: 41.6172 - mape: 15.2545 - val_loss: 11.9846 - val_mae: 16.0722 - val_mape: 7.9136 - lr: 0.0010\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2823 - mae: 39.8915 - mape: 15.2113 - val_loss: 12.4031 - val_mae: 20.1161 - val_mape: 8.3321 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2317 - mae: 39.1450 - mape: 15.1607 - val_loss: 12.6892 - val_mae: 21.7651 - val_mape: 8.6183 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.6048 - mae: 42.7970 - mape: 15.5339 - val_loss: 12.0775 - val_mae: 15.3486 - val_mape: 8.0065 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.7508 - mae: 42.6342 - mape: 15.6798 - val_loss: 12.0387 - val_mae: 16.5050 - val_mape: 7.9677 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4444 - mae: 43.3340 - mape: 15.3734 - val_loss: 12.1942 - val_mae: 18.6445 - val_mape: 8.1233 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.8374 - mae: 43.8596 - mape: 15.7664 - val_loss: 12.4054 - val_mae: 19.8090 - val_mape: 8.3344 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4697 - mae: 43.4143 - mape: 15.3988 - val_loss: 12.8820 - val_mae: 22.0623 - val_mape: 8.8110 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4087 - mae: 41.3938 - mape: 15.3377 - val_loss: 12.4612 - val_mae: 20.1374 - val_mape: 8.3903 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5337 - mae: 42.7279 - mape: 15.4627 - val_loss: 12.9211 - val_mae: 23.1604 - val_mape: 8.8501 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2405 - mae: 40.3128 - mape: 15.1695 - val_loss: 12.2741 - val_mae: 19.3474 - val_mape: 8.2031 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5230 - mae: 41.9774 - mape: 15.4520 - val_loss: 12.2393 - val_mae: 19.3753 - val_mape: 8.1683 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9297 - mae: 39.7718 - mape: 14.8587 - val_loss: 12.2844 - val_mae: 19.9183 - val_mape: 8.2134 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3466 - mae: 42.7847 - mape: 15.2757 - val_loss: 12.3887 - val_mae: 20.7447 - val_mape: 8.3177 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.9826 - mae: 39.1826 - mape: 14.9116 - val_loss: 12.2901 - val_mae: 20.0700 - val_mape: 8.2192 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5928 - mae: 44.4182 - mape: 15.5219 - val_loss: 12.4713 - val_mae: 21.0754 - val_mape: 8.4003 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4402 - mae: 42.6069 - mape: 15.3693 - val_loss: 12.6728 - val_mae: 22.2565 - val_mape: 8.6018 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5480 - mae: 42.6199 - mape: 15.4770 - val_loss: 13.0970 - val_mae: 24.1680 - val_mape: 9.0260 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9787 - mae: 38.8242 - mape: 14.9078 - val_loss: 12.1753 - val_mae: 18.8526 - val_mape: 8.1043 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3421 - mae: 41.8259 - mape: 15.2711 - val_loss: 12.7482 - val_mae: 22.6092 - val_mape: 8.6773 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.6728 - mae: 42.3704 - mape: 15.6019 - val_loss: 12.2494 - val_mae: 19.5277 - val_mape: 8.1784 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9824 - mae: 41.4658 - mape: 14.9114 - val_loss: 12.5011 - val_mae: 21.7275 - val_mape: 8.4301 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4187 - mae: 42.5553 - mape: 15.3478 - val_loss: 12.2148 - val_mae: 19.1912 - val_mape: 8.1439 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.9351 - mae: 40.2398 - mape: 14.8641 - val_loss: 12.3266 - val_mae: 19.8890 - val_mape: 8.2557 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4936 - mae: 38.2477 - mape: 15.4226 - val_loss: 12.7259 - val_mae: 22.2208 - val_mape: 8.6549 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2284 - mae: 39.4899 - mape: 15.1574 - val_loss: 12.3297 - val_mae: 20.2593 - val_mape: 8.2587 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3067 - mae: 37.4091 - mape: 15.2357 - val_loss: 12.0917 - val_mae: 18.0044 - val_mape: 8.0207 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1562 - mae: 39.1764 - mape: 15.0853 - val_loss: 12.3112 - val_mae: 19.7344 - val_mape: 8.2402 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3051 - mae: 42.4183 - mape: 15.2341 - val_loss: 12.3681 - val_mae: 20.1254 - val_mape: 8.2971 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1530 - mae: 43.5748 - mape: 15.0821 - val_loss: 12.2356 - val_mae: 19.6159 - val_mape: 8.1646 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.0787 - mae: 40.9786 - mape: 15.0077\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0787 - mae: 40.9786 - mape: 15.0077 - val_loss: 12.1202 - val_mae: 15.6850 - val_mape: 8.0492 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.8605 - mae: 41.9270 - mape: 14.7896 - val_loss: 12.4603 - val_mae: 20.7612 - val_mape: 8.3893 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2857 - mae: 40.1172 - mape: 15.2148 - val_loss: 12.1074 - val_mae: 18.1862 - val_mape: 8.0365 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1554 - mae: 41.1780 - mape: 15.0844 - val_loss: 12.1287 - val_mae: 18.3893 - val_mape: 8.0578 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1232 - mae: 41.5442 - mape: 15.0523 - val_loss: 12.3601 - val_mae: 20.3190 - val_mape: 8.2891 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1527 - mae: 41.0633 - mape: 15.0818 - val_loss: 12.2585 - val_mae: 19.6038 - val_mape: 8.1875 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9160 - mae: 41.3371 - mape: 14.8450 - val_loss: 12.3920 - val_mae: 20.4003 - val_mape: 8.3211 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2807 - mae: 40.0754 - mape: 15.2097 - val_loss: 12.3279 - val_mae: 19.8617 - val_mape: 8.2570 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1412 - mae: 39.2166 - mape: 15.0702 - val_loss: 12.0783 - val_mae: 17.8973 - val_mape: 8.0073 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.4233 - mae: 41.5489 - mape: 15.3523 - val_loss: 12.4339 - val_mae: 20.8030 - val_mape: 8.3629 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2999 - mae: 42.4548 - mape: 15.2290 - val_loss: 12.4040 - val_mae: 20.3090 - val_mape: 8.3331 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2104 - mae: 41.0752 - mape: 15.1394 - val_loss: 12.1312 - val_mae: 18.3125 - val_mape: 8.0602 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1388 - mae: 39.7297 - mape: 15.0679 - val_loss: 12.4260 - val_mae: 20.3064 - val_mape: 8.3550 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3855 - mae: 38.2408 - mape: 15.3145 - val_loss: 12.3180 - val_mae: 19.7531 - val_mape: 8.2471 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.9220 - mae: 40.8252 - mape: 14.8511 - val_loss: 12.2913 - val_mae: 19.7000 - val_mape: 8.2203 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.3817 - mae: 38.7877 - mape: 15.3107 - val_loss: 12.4641 - val_mae: 21.1455 - val_mape: 8.3931 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1666 - mae: 43.9809 - mape: 15.0956 - val_loss: 12.1242 - val_mae: 18.5061 - val_mape: 8.0532 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3103 - mae: 42.3881 - mape: 15.2393 - val_loss: 12.2285 - val_mae: 19.3565 - val_mape: 8.1575 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 19.1741 - mae: 39.8130 - mape: 15.1031 - val_loss: 12.1834 - val_mae: 19.1492 - val_mape: 8.1125 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2485 - mae: 39.1300 - mape: 15.1775 - val_loss: 12.0961 - val_mae: 18.1391 - val_mape: 8.0252 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0312 - mae: 38.8201 - mape: 14.9603 - val_loss: 12.2302 - val_mae: 19.3754 - val_mape: 8.1592 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3222 - mae: 38.7869 - mape: 15.2513 - val_loss: 12.3378 - val_mae: 20.1260 - val_mape: 8.2669 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1923 - mae: 37.8603 - mape: 15.1213 - val_loss: 12.2870 - val_mae: 19.6642 - val_mape: 8.2160 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 19.4686 - mae: 44.8036 - mape: 15.3977 - val_loss: 12.2585 - val_mae: 19.4191 - val_mape: 8.1875 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.0756 - mae: 40.3820 - mape: 15.0046 - val_loss: 12.4161 - val_mae: 20.4015 - val_mape: 8.3452 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1499 - mae: 44.4233 - mape: 15.0790 - val_loss: 12.2901 - val_mae: 19.8417 - val_mape: 8.2191 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.8162 - mae: 36.2873 - mape: 14.7453 - val_loss: 12.1319 - val_mae: 18.5656 - val_mape: 8.0609 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0908 - mae: 39.3191 - mape: 15.0198 - val_loss: 12.1336 - val_mae: 18.5593 - val_mape: 8.0626 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 19.3466 - mae: 42.4246 - mape: 15.2756 - val_loss: 12.3060 - val_mae: 19.7853 - val_mape: 8.2351 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2817 - mae: 43.6687 - mape: 15.2107 - val_loss: 12.3314 - val_mae: 20.2426 - val_mape: 8.2604 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.9443 - mae: 40.5291 - mape: 14.8733\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9443 - mae: 40.5291 - mape: 14.8733 - val_loss: 12.2270 - val_mae: 19.5460 - val_mape: 8.1561 - lr: 3.0000e-04\n",
      "Epoch 67: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 11.984583854675293; mae of 16.07221794128418; mape of 7.913617134094238%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.1801 - mae: 38.0114 - mape: 15.1091"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 90ms/step - loss: 19.1801 - mae: 38.0114 - mape: 15.1091 - val_loss: 12.2494 - val_mae: 21.9458 - val_mape: 8.1784 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 79ms/step - loss: 19.3917 - mae: 40.0595 - mape: 15.3208 - val_loss: 12.3502 - val_mae: 23.0341 - val_mape: 8.2792 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 19.5719 - mae: 39.9262 - mape: 15.5010 - val_loss: 12.2731 - val_mae: 21.5199 - val_mape: 8.2021 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 19.4361 - mae: 41.8351 - mape: 15.3652 - val_loss: 13.5726 - val_mae: 31.2684 - val_mape: 9.5017 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.5245 - mae: 39.4078 - mape: 15.4535 - val_loss: 12.6747 - val_mae: 25.9453 - val_mape: 8.6037 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.5436 - mae: 38.8804 - mape: 15.4726 - val_loss: 12.5905 - val_mae: 24.8675 - val_mape: 8.5196 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 20.0636 - mae: 42.9577 - mape: 15.9927 - val_loss: 12.8438 - val_mae: 25.6968 - val_mape: 8.7728 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0002 - mae: 41.2383 - mape: 14.9292 - val_loss: 12.3101 - val_mae: 22.3615 - val_mape: 8.2391 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.5627 - mae: 38.9188 - mape: 15.4918 - val_loss: 13.0460 - val_mae: 26.4865 - val_mape: 8.9751 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.4151 - mae: 40.1367 - mape: 15.3441 - val_loss: 12.4614 - val_mae: 23.4795 - val_mape: 8.3905 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1277 - mae: 40.0932 - mape: 15.0568 - val_loss: 12.5061 - val_mae: 24.7809 - val_mape: 8.4352 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3656 - mae: 40.0982 - mape: 15.2946 - val_loss: 13.2844 - val_mae: 28.5731 - val_mape: 9.2134 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5215 - mae: 37.0589 - mape: 15.4505 - val_loss: 12.7335 - val_mae: 26.8135 - val_mape: 8.6625 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.9530 - mae: 39.7036 - mape: 14.8820"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 18.9530 - mae: 39.7036 - mape: 14.8820 - val_loss: 12.1840 - val_mae: 19.8013 - val_mape: 8.1130 - lr: 0.0010\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 86ms/step - loss: 19.2880 - mae: 38.4838 - mape: 15.2170 - val_loss: 13.0973 - val_mae: 28.6738 - val_mape: 9.0263 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.4589 - mae: 37.5201 - mape: 15.3879 - val_loss: 12.7837 - val_mae: 27.4918 - val_mape: 8.7128 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.5387 - mae: 39.8994 - mape: 15.4677 - val_loss: 12.2848 - val_mae: 21.9245 - val_mape: 8.2138 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1841 - mae: 41.3027 - mape: 15.1132 - val_loss: 12.4199 - val_mae: 24.0894 - val_mape: 8.3489 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3116 - mae: 40.8385 - mape: 15.2406 - val_loss: 13.1142 - val_mae: 28.1294 - val_mape: 9.0433 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1652 - mae: 38.6932 - mape: 15.0943 - val_loss: 13.0700 - val_mae: 27.4820 - val_mape: 8.9991 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9146 - mae: 37.0478 - mape: 14.8436 - val_loss: 13.0712 - val_mae: 27.5580 - val_mape: 9.0002 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.3588 - mae: 37.5110 - mape: 15.2878 - val_loss: 12.8364 - val_mae: 26.7920 - val_mape: 8.7654 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1694 - mae: 38.5439 - mape: 15.0985 - val_loss: 12.7225 - val_mae: 25.9806 - val_mape: 8.6516 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1276 - mae: 38.2257 - mape: 15.0567 - val_loss: 12.7833 - val_mae: 25.3686 - val_mape: 8.7123 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.0079 - mae: 37.1542 - mape: 14.9369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 19.0079 - mae: 37.1542 - mape: 14.9369 - val_loss: 12.1555 - val_mae: 20.2979 - val_mape: 8.0845 - lr: 0.0010\n",
      "Epoch 26/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2612 - mae: 39.2242 - mape: 15.1902 - val_loss: 12.5988 - val_mae: 25.4104 - val_mape: 8.5278 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.1542 - mae: 39.2347 - mape: 15.0833 - val_loss: 12.4671 - val_mae: 23.7391 - val_mape: 8.3961 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.3584 - mae: 38.2639 - mape: 15.2874 - val_loss: 12.3051 - val_mae: 21.9111 - val_mape: 8.2341 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2377 - mae: 36.2636 - mape: 15.1667 - val_loss: 12.9609 - val_mae: 27.2557 - val_mape: 8.8900 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.4432 - mae: 41.4734 - mape: 15.3723 - val_loss: 13.7309 - val_mae: 32.6478 - val_mape: 9.6600 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9895 - mae: 39.9200 - mape: 14.9186 - val_loss: 12.6656 - val_mae: 25.3270 - val_mape: 8.5946 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 75ms/step - loss: 19.2965 - mae: 39.5152 - mape: 15.2255 - val_loss: 12.1978 - val_mae: 20.7459 - val_mape: 8.1268 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.2374 - mae: 38.5973 - mape: 15.1665 - val_loss: 12.9250 - val_mae: 24.9805 - val_mape: 8.8540 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3203 - mae: 38.6713 - mape: 15.2493 - val_loss: 12.5766 - val_mae: 24.7455 - val_mape: 8.5057 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0425 - mae: 42.3728 - mape: 14.9716 - val_loss: 12.2679 - val_mae: 22.2346 - val_mape: 8.1969 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0377 - mae: 40.6047 - mape: 14.9668 - val_loss: 12.2964 - val_mae: 22.0642 - val_mape: 8.2254 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.2611 - mae: 41.0160 - mape: 15.1901 - val_loss: 12.5577 - val_mae: 25.4318 - val_mape: 8.4867 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.4585 - mae: 39.4304 - mape: 15.3875 - val_loss: 13.4048 - val_mae: 29.1538 - val_mape: 9.3338 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1304 - mae: 40.3113 - mape: 15.0595 - val_loss: 12.4380 - val_mae: 24.0949 - val_mape: 8.3670 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7473 - mae: 39.6806 - mape: 14.6763 - val_loss: 12.3559 - val_mae: 23.4146 - val_mape: 8.2849 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1860 - mae: 40.5692 - mape: 15.1151 - val_loss: 12.2076 - val_mae: 19.4942 - val_mape: 8.1366 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0032 - mae: 38.3457 - mape: 14.9322 - val_loss: 13.4199 - val_mae: 30.2400 - val_mape: 9.3489 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1993 - mae: 40.5766 - mape: 15.1283 - val_loss: 13.0402 - val_mae: 28.6426 - val_mape: 8.9692 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0713 - mae: 38.8179 - mape: 15.0003 - val_loss: 13.2297 - val_mae: 27.7992 - val_mape: 9.1587 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0152 - mae: 39.9129 - mape: 14.9442 - val_loss: 13.9069 - val_mae: 33.6553 - val_mape: 9.8359 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0309 - mae: 38.9102 - mape: 14.9599 - val_loss: 12.7980 - val_mae: 27.0225 - val_mape: 8.7270 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.3444 - mae: 38.7331 - mape: 15.2735 - val_loss: 12.7965 - val_mae: 26.9864 - val_mape: 8.7255 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.8030 - mae: 39.5973 - mape: 14.7320 - val_loss: 12.3509 - val_mae: 23.0469 - val_mape: 8.2799 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0325 - mae: 38.8633 - mape: 14.9615 - val_loss: 12.9202 - val_mae: 27.1957 - val_mape: 8.8492 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1232 - mae: 40.1600 - mape: 15.0522 - val_loss: 12.8957 - val_mae: 27.8783 - val_mape: 8.8248 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9665 - mae: 39.5983 - mape: 14.8956 - val_loss: 12.2705 - val_mae: 22.2095 - val_mape: 8.1995 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1949 - mae: 39.3150 - mape: 15.1239 - val_loss: 12.2291 - val_mae: 21.0244 - val_mape: 8.1581 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.5029 - mae: 43.7171 - mape: 15.4319 - val_loss: 12.1894 - val_mae: 20.8098 - val_mape: 8.1184 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.3522 - mae: 41.1547 - mape: 15.2813 - val_loss: 13.0324 - val_mae: 27.6162 - val_mape: 8.9614 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.1501 - mae: 39.9166 - mape: 15.0791\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1501 - mae: 39.9166 - mape: 15.0791 - val_loss: 13.3778 - val_mae: 29.4838 - val_mape: 9.3068 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9819 - mae: 38.2729 - mape: 14.9110 - val_loss: 13.2049 - val_mae: 28.8950 - val_mape: 9.1340 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0305 - mae: 38.9399 - mape: 14.9596 - val_loss: 12.7379 - val_mae: 26.6401 - val_mape: 8.6670 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1844 - mae: 37.1834 - mape: 15.1135 - val_loss: 12.7410 - val_mae: 26.3970 - val_mape: 8.6700 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0684 - mae: 38.8792 - mape: 14.9974 - val_loss: 13.1423 - val_mae: 28.8179 - val_mape: 9.0713 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9850 - mae: 37.2836 - mape: 14.9140 - val_loss: 12.8030 - val_mae: 26.2866 - val_mape: 8.7320 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.7379 - mae: 37.4201 - mape: 14.6669 - val_loss: 12.7619 - val_mae: 26.4581 - val_mape: 8.6910 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1413 - mae: 39.1318 - mape: 15.0703 - val_loss: 12.3673 - val_mae: 23.3276 - val_mape: 8.2963 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9418 - mae: 36.7994 - mape: 14.8708 - val_loss: 12.5530 - val_mae: 24.7157 - val_mape: 8.4820 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2085 - mae: 43.9298 - mape: 15.1376 - val_loss: 12.8198 - val_mae: 26.7482 - val_mape: 8.7488 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.8606 - mae: 39.2742 - mape: 14.7896 - val_loss: 13.2099 - val_mae: 29.0732 - val_mape: 9.1389 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.8188 - mae: 38.1932 - mape: 14.7479 - val_loss: 13.0113 - val_mae: 27.9493 - val_mape: 8.9404 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.0287 - mae: 38.9789 - mape: 14.9577 - val_loss: 12.4878 - val_mae: 24.1539 - val_mape: 8.4168 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.8940 - mae: 37.1971 - mape: 14.8231 - val_loss: 12.3482 - val_mae: 23.1559 - val_mape: 8.2772 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.8677 - mae: 39.8228 - mape: 14.7967 - val_loss: 12.3871 - val_mae: 23.6043 - val_mape: 8.3162 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1636 - mae: 38.9465 - mape: 15.0926 - val_loss: 12.6574 - val_mae: 26.0050 - val_mape: 8.5865 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9924 - mae: 37.6865 - mape: 14.9215 - val_loss: 12.5897 - val_mae: 25.6208 - val_mape: 8.5188 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9206 - mae: 39.7099 - mape: 14.8496 - val_loss: 12.8647 - val_mae: 27.1020 - val_mape: 8.7938 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.8481 - mae: 38.9765 - mape: 14.7771 - val_loss: 12.5838 - val_mae: 24.9561 - val_mape: 8.5129 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7848 - mae: 35.6242 - mape: 14.7138 - val_loss: 12.5722 - val_mae: 25.1077 - val_mape: 8.5012 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.6957 - mae: 37.2697 - mape: 14.6248 - val_loss: 12.3469 - val_mae: 22.9026 - val_mape: 8.2760 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7639 - mae: 40.7359 - mape: 14.6930 - val_loss: 12.6089 - val_mae: 25.3534 - val_mape: 8.5379 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9486 - mae: 37.7684 - mape: 14.8776 - val_loss: 12.9309 - val_mae: 27.2368 - val_mape: 8.8599 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.5924 - mae: 39.2914 - mape: 14.5214 - val_loss: 12.8036 - val_mae: 26.3955 - val_mape: 8.7326 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7103 - mae: 38.7832 - mape: 14.6393 - val_loss: 13.1307 - val_mae: 28.8516 - val_mape: 9.0597 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9826 - mae: 37.0375 - mape: 14.9116 - val_loss: 12.7396 - val_mae: 26.5685 - val_mape: 8.6686 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.9512 - mae: 43.8755 - mape: 14.8803 - val_loss: 12.4754 - val_mae: 24.1870 - val_mape: 8.4045 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1765 - mae: 39.1146 - mape: 15.1055 - val_loss: 12.9214 - val_mae: 27.5842 - val_mape: 8.8505 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7705 - mae: 37.1436 - mape: 14.6995 - val_loss: 12.7463 - val_mae: 26.2901 - val_mape: 8.6754 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.8084 - mae: 40.9687 - mape: 14.7374 - val_loss: 12.8202 - val_mae: 26.4489 - val_mape: 8.7493 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 19.2241 - mae: 41.6059 - mape: 15.1532\n",
      "Epoch 85: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.2241 - mae: 41.6059 - mape: 15.1532 - val_loss: 12.4100 - val_mae: 23.5639 - val_mape: 8.3391 - lr: 3.0000e-04\n",
      "Epoch 85: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 12.155454635620117; mae of 20.29786491394043; mape of 8.084487915039062%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 18.9998 - mae: 39.8467 - mape: 14.9289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 91ms/step - loss: 18.9998 - mae: 39.8467 - mape: 14.9289 - val_loss: 12.9230 - val_mae: 20.1294 - val_mape: 8.8520 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.4056 - mae: 42.9758 - mape: 15.3346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 105ms/step - loss: 19.4056 - mae: 42.9758 - mape: 15.3346 - val_loss: 12.8401 - val_mae: 20.3418 - val_mape: 8.7692 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 19.0019 - mae: 36.0686 - mape: 14.9310"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 96ms/step - loss: 19.0019 - mae: 36.0686 - mape: 14.9310 - val_loss: 12.7132 - val_mae: 19.0955 - val_mape: 8.6422 - lr: 0.0010\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 77ms/step - loss: 19.1375 - mae: 39.6696 - mape: 15.0665 - val_loss: 12.7135 - val_mae: 18.1169 - val_mape: 8.6426 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.2619 - mae: 41.4171 - mape: 15.1909 - val_loss: 13.3992 - val_mae: 22.3552 - val_mape: 9.3283 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9131 - mae: 37.8510 - mape: 14.8421 - val_loss: 13.1342 - val_mae: 21.9718 - val_mape: 9.0632 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 19.1425 - mae: 39.9774 - mape: 15.0716 - val_loss: 13.0075 - val_mae: 20.5728 - val_mape: 8.9365 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.9605 - mae: 42.7931 - mape: 14.8895 - val_loss: 12.9558 - val_mae: 20.5068 - val_mape: 8.8848 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 19.0072 - mae: 41.3547 - mape: 14.9362"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 19.0065 - mae: 41.0862 - mape: 14.9355 - val_loss: 12.6942 - val_mae: 18.5498 - val_mape: 8.6232 - lr: 0.0010\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1075 - mae: 41.2183 - mape: 15.0366 - val_loss: 12.9854 - val_mae: 21.9554 - val_mape: 8.9145 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.8663 - mae: 38.3328 - mape: 14.7953 - val_loss: 12.7388 - val_mae: 18.8802 - val_mape: 8.6679 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0575 - mae: 41.2174 - mape: 14.9865 - val_loss: 13.2029 - val_mae: 21.8913 - val_mape: 9.1319 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.8685 - mae: 41.0026 - mape: 14.7976 - val_loss: 12.9686 - val_mae: 20.2974 - val_mape: 8.8976 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9784 - mae: 43.4534 - mape: 14.9074 - val_loss: 12.9036 - val_mae: 20.0193 - val_mape: 8.8326 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 19.0097 - mae: 41.6243 - mape: 14.9387 - val_loss: 13.1353 - val_mae: 21.8545 - val_mape: 9.0643 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9764 - mae: 38.5534 - mape: 14.9055 - val_loss: 12.7253 - val_mae: 18.8096 - val_mape: 8.6543 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9241 - mae: 41.2891 - mape: 14.8532 - val_loss: 12.7325 - val_mae: 18.8549 - val_mape: 8.6616 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.2815 - mae: 40.3276 - mape: 15.2105 - val_loss: 13.4243 - val_mae: 23.0381 - val_mape: 9.3533 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1400 - mae: 40.3016 - mape: 15.0690 - val_loss: 12.7514 - val_mae: 19.1740 - val_mape: 8.6805 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 19.2986 - mae: 41.5041 - mape: 15.2276"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 19.2899 - mae: 41.1766 - mape: 15.2190 - val_loss: 12.6897 - val_mae: 18.6845 - val_mape: 8.6187 - lr: 0.0010\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9559 - mae: 40.3736 - mape: 14.8850 - val_loss: 13.3143 - val_mae: 21.7079 - val_mape: 9.2433 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.8585 - mae: 39.2147 - mape: 14.7875 - val_loss: 13.5735 - val_mae: 23.9646 - val_mape: 9.5026 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.0005 - mae: 40.1284 - mape: 14.9295 - val_loss: 12.8826 - val_mae: 20.2427 - val_mape: 8.8116 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 18.9912 - mae: 39.8388 - mape: 14.9202 - val_loss: 12.9052 - val_mae: 17.1525 - val_mape: 8.8343 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.2328 - mae: 42.4502 - mape: 15.1618 - val_loss: 12.7376 - val_mae: 17.4129 - val_mape: 8.6666 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9431 - mae: 39.7288 - mape: 14.8721 - val_loss: 12.8597 - val_mae: 20.1775 - val_mape: 8.7887 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.2961 - mae: 42.0113 - mape: 15.2251 - val_loss: 12.9719 - val_mae: 20.8800 - val_mape: 8.9009 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.6468 - mae: 39.7458 - mape: 14.5758 - val_loss: 12.9296 - val_mae: 20.3719 - val_mape: 8.8586 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9097 - mae: 41.1679 - mape: 14.8388 - val_loss: 12.7185 - val_mae: 18.2111 - val_mape: 8.6476 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9231 - mae: 39.3700 - mape: 14.8521 - val_loss: 12.6987 - val_mae: 18.0441 - val_mape: 8.6277 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.0112 - mae: 45.4266 - mape: 14.9403 - val_loss: 12.7624 - val_mae: 18.8973 - val_mape: 8.6914 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 18.9158 - mae: 41.5433 - mape: 14.8449 - val_loss: 12.8481 - val_mae: 19.5770 - val_mape: 8.7771 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9754 - mae: 41.2026 - mape: 14.9044 - val_loss: 13.3369 - val_mae: 22.2624 - val_mape: 9.2659 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0674 - mae: 41.0285 - mape: 14.9965 - val_loss: 13.1596 - val_mae: 21.8551 - val_mape: 9.0886 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.7914 - mae: 39.9230 - mape: 14.7204 - val_loss: 13.4811 - val_mae: 22.3728 - val_mape: 9.4101 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9080 - mae: 38.6430 - mape: 14.8370 - val_loss: 12.7819 - val_mae: 19.0942 - val_mape: 8.7110 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 18.9359 - mae: 43.4590 - mape: 14.8649 - val_loss: 13.0405 - val_mae: 21.1634 - val_mape: 8.9695 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.3327 - mae: 42.5324 - mape: 15.2618 - val_loss: 12.7660 - val_mae: 17.4156 - val_mape: 8.6950 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.9996 - mae: 41.4936 - mape: 14.9286 - val_loss: 13.0267 - val_mae: 21.5325 - val_mape: 8.9557 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9157 - mae: 38.9867 - mape: 14.8447 - val_loss: 13.0123 - val_mae: 20.1590 - val_mape: 8.9413 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.8919 - mae: 40.6104 - mape: 14.8210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_freeze_complex_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 18.8919 - mae: 40.6104 - mape: 14.8210 - val_loss: 12.6719 - val_mae: 18.0203 - val_mape: 8.6010 - lr: 0.0010\n",
      "Epoch 42/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 75ms/step - loss: 19.0506 - mae: 39.8472 - mape: 14.9796 - val_loss: 12.7331 - val_mae: 19.2154 - val_mape: 8.6621 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.8682 - mae: 42.8362 - mape: 14.7972 - val_loss: 12.9388 - val_mae: 21.2671 - val_mape: 8.8678 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.5722 - mae: 42.3745 - mape: 14.5013 - val_loss: 13.1673 - val_mae: 21.2928 - val_mape: 9.0963 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.1072 - mae: 39.6218 - mape: 15.0362 - val_loss: 13.0680 - val_mae: 21.0509 - val_mape: 8.9970 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.7711 - mae: 44.0692 - mape: 14.7001 - val_loss: 13.6893 - val_mae: 24.0323 - val_mape: 9.6184 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.4858 - mae: 35.5414 - mape: 14.4148 - val_loss: 12.7509 - val_mae: 19.3533 - val_mape: 8.6800 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7345 - mae: 43.4760 - mape: 14.6635 - val_loss: 13.3127 - val_mae: 22.1070 - val_mape: 9.2418 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.5042 - mae: 39.1155 - mape: 14.4332 - val_loss: 12.9967 - val_mae: 20.5721 - val_mape: 8.9257 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.9489 - mae: 42.5184 - mape: 14.8780 - val_loss: 13.6147 - val_mae: 22.8244 - val_mape: 9.5438 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.7390 - mae: 41.8701 - mape: 14.6680 - val_loss: 12.8059 - val_mae: 19.7348 - val_mape: 8.7349 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.0570 - mae: 40.7640 - mape: 14.9861 - val_loss: 13.0764 - val_mae: 21.3282 - val_mape: 9.0054 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.6398 - mae: 38.9095 - mape: 14.5689 - val_loss: 12.7039 - val_mae: 18.7083 - val_mape: 8.6329 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.8134 - mae: 38.5742 - mape: 14.7424 - val_loss: 12.8584 - val_mae: 20.7075 - val_mape: 8.7875 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7908 - mae: 42.0586 - mape: 14.7198 - val_loss: 12.7036 - val_mae: 18.2095 - val_mape: 8.6327 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0789 - mae: 41.4794 - mape: 15.0079 - val_loss: 12.8280 - val_mae: 20.2242 - val_mape: 8.7570 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.0953 - mae: 43.3543 - mape: 15.0243 - val_loss: 12.8262 - val_mae: 20.1674 - val_mape: 8.7552 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9403 - mae: 39.4802 - mape: 14.8694 - val_loss: 12.7448 - val_mae: 19.1523 - val_mape: 8.6738 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.7702 - mae: 37.3766 - mape: 14.6993 - val_loss: 12.7045 - val_mae: 18.6027 - val_mape: 8.6336 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0511 - mae: 43.6713 - mape: 14.9801 - val_loss: 12.9421 - val_mae: 20.7784 - val_mape: 8.8712 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.7558 - mae: 37.1160 - mape: 14.6849 - val_loss: 12.8796 - val_mae: 19.8264 - val_mape: 8.8086 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.1938 - mae: 43.0876 - mape: 15.1228 - val_loss: 12.9330 - val_mae: 20.5687 - val_mape: 8.8620 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.5777 - mae: 41.9819 - mape: 14.5068 - val_loss: 13.1353 - val_mae: 21.9132 - val_mape: 9.0643 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.6933 - mae: 40.5242 - mape: 14.6223 - val_loss: 12.7073 - val_mae: 18.9984 - val_mape: 8.6363 - lr: 0.0010\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7246 - mae: 42.6074 - mape: 14.6536 - val_loss: 12.6906 - val_mae: 18.3039 - val_mape: 8.6196 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.8471 - mae: 42.1960 - mape: 14.7761 - val_loss: 12.7250 - val_mae: 18.6181 - val_mape: 8.6540 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.6280 - mae: 40.4485 - mape: 14.5570 - val_loss: 12.7288 - val_mae: 19.0566 - val_mape: 8.6578 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 18.6311 - mae: 41.4220 - mape: 14.5602 - val_loss: 12.8827 - val_mae: 19.9093 - val_mape: 8.8117 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9957 - mae: 43.8099 - mape: 14.9248 - val_loss: 13.2744 - val_mae: 22.3880 - val_mape: 9.2034 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.7186 - mae: 41.8292 - mape: 14.6476 - val_loss: 12.6977 - val_mae: 18.5305 - val_mape: 8.6268 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.9071 - mae: 40.3125 - mape: 14.8361\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.9071 - mae: 40.3125 - mape: 14.8361 - val_loss: 13.3095 - val_mae: 22.7756 - val_mape: 9.2385 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7556 - mae: 40.7843 - mape: 14.6847 - val_loss: 12.7163 - val_mae: 18.9669 - val_mape: 8.6453 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.2569 - mae: 45.2659 - mape: 15.1859 - val_loss: 12.9541 - val_mae: 20.8238 - val_mape: 8.8832 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9301 - mae: 41.1015 - mape: 14.8592 - val_loss: 12.8711 - val_mae: 20.2438 - val_mape: 8.8001 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.7494 - mae: 38.8413 - mape: 14.6785 - val_loss: 12.8154 - val_mae: 19.9121 - val_mape: 8.7444 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9645 - mae: 39.5731 - mape: 14.8935 - val_loss: 12.8794 - val_mae: 20.0575 - val_mape: 8.8084 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.4036 - mae: 39.3195 - mape: 14.3326 - val_loss: 12.6941 - val_mae: 18.3669 - val_mape: 8.6231 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 19.0421 - mae: 40.3582 - mape: 14.9712 - val_loss: 12.7360 - val_mae: 19.1892 - val_mape: 8.6651 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.9460 - mae: 43.7588 - mape: 14.8750 - val_loss: 12.7293 - val_mae: 18.9396 - val_mape: 8.6583 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7395 - mae: 41.6782 - mape: 14.6686 - val_loss: 12.6987 - val_mae: 18.3466 - val_mape: 8.6277 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 19.0514 - mae: 44.1845 - mape: 14.9804 - val_loss: 12.8031 - val_mae: 19.7319 - val_mape: 8.7321 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.7958 - mae: 42.8214 - mape: 14.7249 - val_loss: 12.7309 - val_mae: 18.8352 - val_mape: 8.6599 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.8580 - mae: 39.4125 - mape: 14.7870 - val_loss: 12.7516 - val_mae: 19.3277 - val_mape: 8.6807 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 18.2243 - mae: 41.1456 - mape: 14.1534 - val_loss: 12.7025 - val_mae: 18.6233 - val_mape: 8.6315 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 19.0550 - mae: 40.0985 - mape: 14.9840 - val_loss: 12.9974 - val_mae: 21.0386 - val_mape: 8.9264 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.5570 - mae: 39.4769 - mape: 14.4861 - val_loss: 13.0671 - val_mae: 21.3325 - val_mape: 8.9961 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.9793 - mae: 40.3017 - mape: 14.9083 - val_loss: 12.9469 - val_mae: 20.8214 - val_mape: 8.8759 - lr: 3.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.9114 - mae: 42.2054 - mape: 14.8405 - val_loss: 12.8650 - val_mae: 20.2133 - val_mape: 8.7940 - lr: 3.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 19.2837 - mae: 43.5238 - mape: 15.2127 - val_loss: 12.9987 - val_mae: 20.9479 - val_mape: 8.9278 - lr: 3.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.9086 - mae: 40.1012 - mape: 14.8377 - val_loss: 12.6991 - val_mae: 18.6315 - val_mape: 8.6281 - lr: 3.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.4949 - mae: 38.8785 - mape: 14.4240 - val_loss: 12.7514 - val_mae: 19.1690 - val_mape: 8.6804 - lr: 3.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.6098 - mae: 39.9742 - mape: 14.5388 - val_loss: 12.8920 - val_mae: 20.2239 - val_mape: 8.8211 - lr: 3.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.5144 - mae: 39.9473 - mape: 14.4434 - val_loss: 12.7619 - val_mae: 19.2054 - val_mape: 8.6910 - lr: 3.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.6778 - mae: 40.7409 - mape: 14.6069 - val_loss: 12.8467 - val_mae: 19.8569 - val_mape: 8.7758 - lr: 3.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.6104 - mae: 42.9572 - mape: 14.5394 - val_loss: 12.8304 - val_mae: 19.9260 - val_mape: 8.7595 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.8203 - mae: 40.6817 - mape: 14.7494 - val_loss: 12.7821 - val_mae: 19.3289 - val_mape: 8.7112 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.7633 - mae: 39.8424 - mape: 14.6923 - val_loss: 13.2352 - val_mae: 21.7824 - val_mape: 9.1642 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 18.4932 - mae: 41.2516 - mape: 14.4222 - val_loss: 12.7295 - val_mae: 19.1613 - val_mape: 8.6586 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.5515 - mae: 42.5702 - mape: 14.4805 - val_loss: 12.7821 - val_mae: 19.6245 - val_mape: 8.7111 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 18.6864 - mae: 37.9907 - mape: 14.6154 - val_loss: 12.7110 - val_mae: 18.7710 - val_mape: 8.6401 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 18.6054 - mae: 40.2087 - mape: 14.5344\n",
      "Epoch 101: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 18.6054 - mae: 40.2087 - mape: 14.5344 - val_loss: 12.7916 - val_mae: 19.5442 - val_mape: 8.7207 - lr: 3.0000e-04\n",
      "Epoch 101: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 12.671918869018555; mae of 18.020259857177734; mape of 8.600951194763184%;\n"
     ]
    }
   ],
   "source": [
    "#Hybrid freeze complex?\n",
    "nnmodel = keras.models.load_model('crossvalidationmodels/Baseline_nosupp_5/')\n",
    "for layer in nnmodel.layers:\n",
    "    layer.trainable = False\n",
    "gcnmodel = keras.models.load_model('savedmodels/GCN_simplified_normalized')\n",
    "for layer in gcnmodel.layers:\n",
    "    layer.trainable = False \n",
    "\n",
    "combined = concatenate([nnmodel.get_layer('dropbaseline').output, gcnmodel.get_layer('dropgcn').output], name='join')\n",
    "z = Dense(32,'relu', name='dense1')(combined)\n",
    "z = Dropout(0.2, name='drop')(z)\n",
    "z = Dense(1, 'linear', name='regress')(z)\n",
    "model = Model(inputs = [gcnmodel.input, nnmodel.input], outputs = z)\n",
    "\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, 'crossvalidationmodels/Hybrid_nosupp_freeze_complex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 13.484243392944336 - Mean average error: 19.375486373901367% - Mean percentage error: 9.195748329162598%\n",
      "    Score on unseen data: Loss: 18.194435119628906 - Mean average error: 33.4757080078125% - Mean percentage error: 13.905938148498535%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 12.676579475402832 - Mean average error: 15.976175308227539% - Mean percentage error: 8.387003898620605%\n",
      "    Score on unseen data: Loss: 18.164281845092773 - Mean average error: 33.48053741455078% - Mean percentage error: 13.874706268310547%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 11.830459594726562 - Mean average error: 14.139742851257324% - Mean percentage error: 7.520269393920898%\n",
      "    Score on unseen data: Loss: 18.142850875854492 - Mean average error: 33.41679382324219% - Mean percentage error: 13.832660675048828%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 12.36368179321289 - Mean average error: 17.349576950073242% - Mean percentage error: 8.080484390258789%\n",
      "    Score on unseen data: Loss: 18.067066192626953 - Mean average error: 33.908721923828125% - Mean percentage error: 13.783869743347168%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 12.21220874786377 - Mean average error: 20.968006134033203% - Mean percentage error: 7.932228088378906%\n",
      "    Score on unseen data: Loss: 18.180023193359375 - Mean average error: 35.05418395996094% - Mean percentage error: 13.900043487548828%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 12.513434600830077\n",
      "> Mean average error: 17.561797523498534\n",
      "> Mean percentage error: 8.22314682006836\n",
      "> Unseen Loss: 18.1497314453125\n",
      "> Unseen Mean average error: 33.86718902587891\n",
      "> Unseen Mean percentage error: 13.859443664550781\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.9515 - mae: 30.4134 - mape: 12.7527"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 104ms/step - loss: 16.9515 - mae: 30.4134 - mape: 12.7527 - val_loss: 13.0474 - val_mae: 21.4710 - val_mape: 8.9168 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n",
      " 2/87 [..............................] - ETA: 6s - loss: 15.2780 - mae: 26.8137 - mape: 11.1481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.8473 - mae: 28.6542 - mape: 12.7750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 122ms/step - loss: 16.8473 - mae: 28.6542 - mape: 12.7750 - val_loss: 12.6497 - val_mae: 23.5202 - val_mape: 8.6360 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.1892 - mae: 29.9517 - mape: 12.2267"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 109ms/step - loss: 16.1892 - mae: 29.9517 - mape: 12.2267 - val_loss: 12.5196 - val_mae: 23.2062 - val_mape: 8.6084 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 81ms/step - loss: 16.2478 - mae: 31.2691 - mape: 12.3850 - val_loss: 12.7094 - val_mae: 20.3597 - val_mape: 8.8971 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.1701 - mae: 32.7036 - mape: 12.4012"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 103ms/step - loss: 16.1701 - mae: 32.7036 - mape: 12.4012 - val_loss: 12.2730 - val_mae: 19.7565 - val_mape: 8.5483 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.3677 - mae: 34.0893 - mape: 12.6823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 102ms/step - loss: 16.3677 - mae: 34.0893 - mape: 12.6823 - val_loss: 12.1254 - val_mae: 19.6001 - val_mape: 8.4808 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 78ms/step - loss: 15.7622 - mae: 30.8450 - mape: 12.1568 - val_loss: 12.4164 - val_mae: 20.4596 - val_mape: 8.8488 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.0821 - mae: 33.0134 - mape: 12.5502 - val_loss: 12.6569 - val_mae: 23.3543 - val_mape: 9.1592 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.9066 - mae: 31.7966 - mape: 12.4417 - val_loss: 12.1530 - val_mae: 24.1406 - val_mape: 8.7219 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.8970 - mae: 33.3057 - mape: 12.4973 - val_loss: 12.1227 - val_mae: 29.2927 - val_mape: 8.7559 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.7528 - mae: 31.5674 - mape: 12.4159 - val_loss: 13.0776 - val_mae: 21.6392 - val_mape: 9.7724 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.5637 - mae: 32.1377 - mape: 12.2874 - val_loss: 11.9521 - val_mae: 21.4366 - val_mape: 8.7043 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.5460 - mae: 31.2331 - mape: 12.3249 - val_loss: 12.0306 - val_mae: 25.9482 - val_mape: 8.8367 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.4879 - mae: 30.9704 - mape: 12.3205 - val_loss: 12.4351 - val_mae: 26.4060 - val_mape: 9.2951 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.3050 - mae: 31.8149 - mape: 12.1887 - val_loss: 11.9093 - val_mae: 25.3076 - val_mape: 8.8162 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.9197 - mae: 31.3190 - mape: 11.8510 - val_loss: 12.0200 - val_mae: 21.1493 - val_mape: 8.9738 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.2689 - mae: 31.0751 - mape: 12.2480 - val_loss: 11.7994 - val_mae: 24.3840 - val_mape: 8.8036 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.8745 - mae: 31.3541 - mape: 11.9017 - val_loss: 12.8359 - val_mae: 21.9197 - val_mape: 9.8838 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.9780 - mae: 31.3605 - mape: 12.0473 - val_loss: 12.0792 - val_mae: 27.7651 - val_mape: 9.1710 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.2147 - mae: 33.4772 - mape: 12.3261 - val_loss: 11.8136 - val_mae: 23.3624 - val_mape: 8.9455 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.6505 - mae: 31.3229 - mape: 11.8007 - val_loss: 13.5424 - val_mae: 25.5569 - val_mape: 10.7144 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.9515 - mae: 30.7720 - mape: 12.1402 - val_loss: 12.0803 - val_mae: 23.6338 - val_mape: 9.2865 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.9195 - mae: 30.9077 - mape: 12.1443 - val_loss: 11.4509 - val_mae: 20.4913 - val_mape: 8.6934 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.9585 - mae: 32.4231 - mape: 12.2197 - val_loss: 11.4215 - val_mae: 19.7131 - val_mape: 8.7023 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.5718 - mae: 29.4003 - mape: 11.8696 - val_loss: 11.2349 - val_mae: 19.6011 - val_mape: 8.5478 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.0876 - mae: 30.4643 - mape: 12.4201 - val_loss: 11.8593 - val_mae: 31.4270 - val_mape: 9.2117 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.6503 - mae: 29.5417 - mape: 12.0161 - val_loss: 11.4584 - val_mae: 21.8024 - val_mape: 8.8417 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.6520 - mae: 31.8785 - mape: 12.0498 - val_loss: 11.8054 - val_mae: 21.8627 - val_mape: 9.2170 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.8005 - mae: 30.2034 - mape: 12.2282 - val_loss: 11.4408 - val_mae: 26.4788 - val_mape: 8.8828 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.7403 - mae: 31.6438 - mape: 12.1985 - val_loss: 11.8293 - val_mae: 24.5467 - val_mape: 9.3011 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.3585 - mae: 31.5709 - mape: 11.8436 - val_loss: 11.3773 - val_mae: 20.1573 - val_mape: 8.8767 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.5396 - mae: 30.1835 - mape: 12.0521 - val_loss: 11.9063 - val_mae: 28.2844 - val_mape: 9.4326 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.6747 - mae: 32.0973 - mape: 12.2128 - val_loss: 11.2350 - val_mae: 19.8942 - val_mape: 8.7861 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.7490 - mae: 31.2468 - mape: 12.3120 - val_loss: 11.4177 - val_mae: 24.4960 - val_mape: 8.9945 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.5487 - mae: 29.1981 - mape: 12.1383 - val_loss: 11.8871 - val_mae: 23.7058 - val_mape: 9.4896 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.4093 - mae: 29.2353 - mape: 12.0246 - val_loss: 11.9000 - val_mae: 27.3565 - val_mape: 9.5294 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.0243 - mae: 28.4356 - mape: 11.6627 - val_loss: 12.0969 - val_mae: 27.2597 - val_mape: 9.7492 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.3685 - mae: 30.4579 - mape: 12.0325 - val_loss: 11.8226 - val_mae: 21.9914 - val_mape: 9.4985 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.3481 - mae: 31.5094 - mape: 12.0318 - val_loss: 11.2976 - val_mae: 22.4865 - val_mape: 8.9936 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.1342 - mae: 30.5906 - mape: 11.8409 - val_loss: 11.6962 - val_mae: 22.6658 - val_mape: 9.4152 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.2356 - mae: 27.9762 - mape: 11.9658 - val_loss: 11.0590 - val_mae: 19.5635 - val_mape: 8.8011 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2018 - mae: 29.7613 - mape: 11.9549 - val_loss: 11.2088 - val_mae: 26.2875 - val_mape: 8.9721 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2546 - mae: 28.2826 - mape: 12.0298 - val_loss: 10.9237 - val_mae: 23.3399 - val_mape: 8.7088 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0916 - mae: 30.3498 - mape: 11.8874 - val_loss: 11.2614 - val_mae: 22.1358 - val_mape: 9.0671 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2845 - mae: 30.6130 - mape: 12.1009 - val_loss: 10.9664 - val_mae: 24.1161 - val_mape: 8.7899 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9597 - mae: 30.2518 - mape: 11.7946 - val_loss: 11.5423 - val_mae: 29.8794 - val_mape: 9.3890 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.0658 - mae: 31.2170 - mape: 11.9188 - val_loss: 11.5799 - val_mae: 22.0252 - val_mape: 9.4376 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 14.3634 - mae: 32.0559 - mape: 12.2312 - val_loss: 11.5932 - val_mae: 28.8999 - val_mape: 9.4684 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 14.0708 - mae: 29.7617 - mape: 11.9558 - val_loss: 13.6116 - val_mae: 26.1151 - val_mape: 11.5080 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.3441 - mae: 30.9773 - mape: 12.2462 - val_loss: 11.3459 - val_mae: 25.1126 - val_mape: 9.2560 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 14.0389 - mae: 27.5653 - mape: 11.9582 - val_loss: 10.8787 - val_mae: 19.7366 - val_mape: 8.8048 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 14.1146 - mae: 31.7348 - mape: 12.0514 - val_loss: 10.8831 - val_mae: 20.0821 - val_mape: 8.8274 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 14.0032 - mae: 32.5950 - mape: 11.9584 - val_loss: 12.0405 - val_mae: 29.6275 - val_mape: 10.0052 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.8856 - mae: 33.5920 - mape: 11.8581 - val_loss: 11.3569 - val_mae: 22.8111 - val_mape: 9.3379 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.8319 - mae: 29.2050 - mape: 11.8214 - val_loss: 11.4587 - val_mae: 32.0833 - val_mape: 9.4577 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7977 - mae: 32.0999 - mape: 11.8046 - val_loss: 10.7675 - val_mae: 20.8572 - val_mape: 8.7826 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.0326 - mae: 31.9990 - mape: 12.0558 - val_loss: 11.1213 - val_mae: 25.5695 - val_mape: 9.1529 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.8750 - mae: 31.1155 - mape: 11.9123 - val_loss: 11.4413 - val_mae: 27.3952 - val_mape: 9.4861 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9705 - mae: 31.6075 - mape: 12.0209 - val_loss: 10.8696 - val_mae: 19.9972 - val_mape: 8.9277 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9197 - mae: 33.0841 - mape: 11.9855 - val_loss: 10.8606 - val_mae: 24.9227 - val_mape: 8.9352 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7158 - mae: 29.1951 - mape: 11.7972 - val_loss: 11.5984 - val_mae: 23.4618 - val_mape: 9.6863 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0040 - mae: 31.4976 - mape: 12.0990 - val_loss: 11.0743 - val_mae: 19.6152 - val_mape: 9.1732 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9075 - mae: 29.6767 - mape: 12.0137 - val_loss: 10.9169 - val_mae: 28.5943 - val_mape: 9.0282 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.8639 - mae: 30.9296 - mape: 11.9832 - val_loss: 10.7993 - val_mae: 22.0358 - val_mape: 8.9268 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9969 - mae: 32.6313 - mape: 12.1307 - val_loss: 10.8609 - val_mae: 20.2239 - val_mape: 8.9993 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9908 - mae: 31.0223 - mape: 12.1365 - val_loss: 11.2635 - val_mae: 25.6946 - val_mape: 9.4155 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.6196 - mae: 30.1351 - mape: 11.7783 - val_loss: 10.9976 - val_mae: 21.9227 - val_mape: 9.1618 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.7695 - mae: 29.8022 - mape: 11.9393 - val_loss: 11.0775 - val_mae: 20.8986 - val_mape: 9.2544 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9049 - mae: 31.3334 - mape: 12.0897 - val_loss: 12.6167 - val_mae: 26.7139 - val_mape: 10.8099 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.8185 - mae: 29.4082 - mape: 12.0180 - val_loss: 10.8994 - val_mae: 20.0849 - val_mape: 9.1045 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.8210 - mae: 30.3355 - mape: 12.0332 - val_loss: 11.0579 - val_mae: 29.3055 - val_mape: 9.2763 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.7154 - mae: 30.1770 - mape: 11.9400 - val_loss: 12.4205 - val_mae: 25.0221 - val_mape: 10.6514 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.5570 - mae: 32.0829 - mape: 11.7940 - val_loss: 11.6989 - val_mae: 24.9296 - val_mape: 9.9416 - lr: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.5629 - mae: 31.1902 - mape: 11.8093 - val_loss: 11.4498 - val_mae: 23.2698 - val_mape: 9.7027 - lr: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.9563 - mae: 32.4198 - mape: 12.2171 - val_loss: 10.9515 - val_mae: 26.6554 - val_mape: 9.2177 - lr: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.6860 - mae: 32.5332 - mape: 11.9581 - val_loss: 10.8981 - val_mae: 27.1635 - val_mape: 9.1758 - lr: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3420 - mae: 31.3136 - mape: 11.6236 - val_loss: 11.1309 - val_mae: 27.3859 - val_mape: 9.4151 - lr: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.6540 - mae: 30.2211 - mape: 11.9458 - val_loss: 12.5419 - val_mae: 29.1989 - val_mape: 10.8401 - lr: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.5995 - mae: 29.2323 - mape: 11.9007 - val_loss: 11.0929 - val_mae: 24.0944 - val_mape: 9.3990 - lr: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.4851 - mae: 29.1777 - mape: 11.7956 - val_loss: 10.8100 - val_mae: 22.2958 - val_mape: 9.1231 - lr: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.5495 - mae: 29.6748 - mape: 11.8692 - val_loss: 10.6136 - val_mae: 21.3757 - val_mape: 8.9392 - lr: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4181 - mae: 29.0369 - mape: 11.7502 - val_loss: 10.8244 - val_mae: 20.3659 - val_mape: 9.1623 - lr: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.5033 - mae: 31.4979 - mape: 11.8457 - val_loss: 10.7161 - val_mae: 26.4230 - val_mape: 9.0619 - lr: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3705 - mae: 31.9435 - mape: 11.7222 - val_loss: 11.2049 - val_mae: 21.5792 - val_mape: 9.5655 - lr: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2195 - mae: 30.8741 - mape: 11.5825 - val_loss: 10.7446 - val_mae: 20.9681 - val_mape: 9.1093 - lr: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2997 - mae: 29.7107 - mape: 11.6713 - val_loss: 11.3228 - val_mae: 22.8392 - val_mape: 9.6996 - lr: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4158 - mae: 30.9733 - mape: 11.7959 - val_loss: 11.2238 - val_mae: 23.7650 - val_mape: 9.6078 - lr: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.6433 - mae: 29.7928 - mape: 12.0320 - val_loss: 10.9675 - val_mae: 21.9100 - val_mape: 9.3601 - lr: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.7956 - mae: 33.4316 - mape: 12.1912 - val_loss: 10.8534 - val_mae: 23.7941 - val_mape: 9.2541 - lr: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2833 - mae: 28.8638 - mape: 11.6896 - val_loss: 10.7356 - val_mae: 23.8810 - val_mape: 9.1454 - lr: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.4547 - mae: 32.2765 - mape: 11.8698 - val_loss: 11.0861 - val_mae: 24.3755 - val_mape: 9.5044 - lr: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.3325 - mae: 30.1057 - mape: 11.7549 - val_loss: 10.8285 - val_mae: 24.9504 - val_mape: 9.2543 - lr: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4592 - mae: 30.6403 - mape: 11.8915 - val_loss: 11.2885 - val_mae: 22.5571 - val_mape: 9.7246 - lr: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.7058 - mae: 32.3139 - mape: 12.1489 - val_loss: 10.6592 - val_mae: 21.7286 - val_mape: 9.1073 - lr: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2672 - mae: 31.3154 - mape: 11.7180 - val_loss: 11.4810 - val_mae: 29.0711 - val_mape: 9.9311 - lr: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9431 - mae: 26.4219 - mape: 11.3992 - val_loss: 11.0722 - val_mae: 21.3999 - val_mape: 9.5332 - lr: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2414 - mae: 32.5752 - mape: 11.7085 - val_loss: 10.8143 - val_mae: 25.6532 - val_mape: 9.2847 - lr: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1593 - mae: 29.3150 - mape: 11.6324 - val_loss: 11.0661 - val_mae: 21.9975 - val_mape: 9.5430 - lr: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0483 - mae: 30.1139 - mape: 11.5295 - val_loss: 10.9107 - val_mae: 21.3971 - val_mape: 9.3990 - lr: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3361 - mae: 31.7063 - mape: 11.8279 - val_loss: 10.6129 - val_mae: 25.5827 - val_mape: 9.1071 - lr: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1948 - mae: 28.4211 - mape: 11.6923 - val_loss: 11.8697 - val_mae: 23.7966 - val_mape: 10.3724 - lr: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3172 - mae: 31.2999 - mape: 11.8234 - val_loss: 10.7171 - val_mae: 20.8672 - val_mape: 9.2241 - lr: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.9408 - mae: 27.7102 - mape: 11.4506 - val_loss: 10.6230 - val_mae: 20.1698 - val_mape: 9.1387 - lr: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1236 - mae: 29.8121 - mape: 11.6419 - val_loss: 11.6062 - val_mae: 30.5741 - val_mape: 10.1294 - lr: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0082 - mae: 28.9442 - mape: 11.5323 - val_loss: 10.8706 - val_mae: 23.3384 - val_mape: 9.3968 - lr: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.5889 - mae: 32.1574 - mape: 12.1200 - val_loss: 10.7167 - val_mae: 23.2157 - val_mape: 9.2503 - lr: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3469 - mae: 31.3538 - mape: 11.8844 - val_loss: 11.1253 - val_mae: 26.2163 - val_mape: 9.6674 - lr: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3471 - mae: 29.3492 - mape: 11.8910 - val_loss: 10.4905 - val_mae: 19.8505 - val_mape: 9.0341 - lr: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9237 - mae: 30.7557 - mape: 11.4706 - val_loss: 10.8266 - val_mae: 20.0460 - val_mape: 9.3738 - lr: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2062 - mae: 28.6756 - mape: 11.7600 - val_loss: 10.9636 - val_mae: 25.8064 - val_mape: 9.5211 - lr: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.5295 - mae: 29.4712 - mape: 12.0882 - val_loss: 10.6351 - val_mae: 22.9975 - val_mape: 9.1955 - lr: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0333 - mae: 28.7551 - mape: 11.5970 - val_loss: 10.8071 - val_mae: 23.8311 - val_mape: 9.3751 - lr: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.9096 - mae: 29.4620 - mape: 11.4811 - val_loss: 11.1522 - val_mae: 26.5147 - val_mape: 9.7259 - lr: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2081 - mae: 32.0633 - mape: 11.7844 - val_loss: 11.9930 - val_mae: 21.7275 - val_mape: 10.5733 - lr: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.2411 - mae: 31.8593 - mape: 11.8269 - val_loss: 11.5026 - val_mae: 25.3406 - val_mape: 10.0936 - lr: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1911 - mae: 31.2282 - mape: 11.7847 - val_loss: 10.8478 - val_mae: 21.4152 - val_mape: 9.4440 - lr: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1153 - mae: 30.8657 - mape: 11.7140 - val_loss: 10.8858 - val_mae: 25.1697 - val_mape: 9.4841 - lr: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1767 - mae: 30.6315 - mape: 11.7828 - val_loss: 11.1462 - val_mae: 23.6848 - val_mape: 9.7544 - lr: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.8734 - mae: 30.0120 - mape: 11.4829 - val_loss: 10.9508 - val_mae: 20.9683 - val_mape: 9.5656 - lr: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1816 - mae: 30.7239 - mape: 11.7997 - val_loss: 10.6028 - val_mae: 25.6820 - val_mape: 9.2209 - lr: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.8559 - mae: 28.7765 - mape: 11.4759 - val_loss: 10.7029 - val_mae: 20.9282 - val_mape: 9.3245 - lr: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.8435 - mae: 27.5565 - mape: 11.4696 - val_loss: 10.6888 - val_mae: 26.1130 - val_mape: 9.3183 - lr: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9597 - mae: 27.6605 - mape: 11.5925 - val_loss: 10.8035 - val_mae: 24.6473 - val_mape: 9.4376 - lr: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0581 - mae: 32.0730 - mape: 11.6959 - val_loss: 11.1208 - val_mae: 32.7167 - val_mape: 9.7607 - lr: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6993 - mae: 29.9753 - mape: 11.3396 - val_loss: 10.7689 - val_mae: 21.1153 - val_mape: 9.4131 - lr: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.9951 - mae: 30.9493 - mape: 11.6434 - val_loss: 10.5951 - val_mae: 28.2550 - val_mape: 9.2448 - lr: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0178 - mae: 31.7952 - mape: 11.6704 - val_loss: 10.9106 - val_mae: 25.2859 - val_mape: 9.5649 - lr: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.0234 - mae: 30.8827 - mape: 11.6807 - val_loss: 10.7269 - val_mae: 22.7060 - val_mape: 9.3837 - lr: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.8421 - mae: 31.3126 - mape: 11.5044 - val_loss: 10.6214 - val_mae: 22.0840 - val_mape: 9.2879 - lr: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.0090 - mae: 30.2652 - mape: 11.6761 - val_loss: 10.5782 - val_mae: 23.7282 - val_mape: 9.2482 - lr: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9418 - mae: 29.2069 - mape: 11.6144 - val_loss: 11.4859 - val_mae: 24.2415 - val_mape: 10.1587 - lr: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5799 - mae: 28.9851 - mape: 11.2551 - val_loss: 10.9720 - val_mae: 30.0722 - val_mape: 9.6510 - lr: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0526 - mae: 34.0951 - mape: 11.7330 - val_loss: 11.4523 - val_mae: 28.5768 - val_mape: 10.1390 - lr: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.7912 - mae: 28.1819 - mape: 11.4810 - val_loss: 10.7891 - val_mae: 22.8354 - val_mape: 9.4833 - lr: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0252 - mae: 29.2844 - mape: 11.7200 - val_loss: 12.1681 - val_mae: 29.8811 - val_mape: 10.8639 - lr: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.7680 - mae: 29.0598 - mape: 11.4682 - val_loss: 10.9661 - val_mae: 30.6032 - val_mape: 9.6697 - lr: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5719 - mae: 30.5900 - mape: 11.2769 - val_loss: 11.1206 - val_mae: 27.0594 - val_mape: 9.8243 - lr: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.9457 - mae: 30.8174 - mape: 11.6527\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.9457 - mae: 30.8174 - mape: 11.6527 - val_loss: 10.6196 - val_mae: 23.3666 - val_mape: 9.3286 - lr: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6557 - mae: 30.1751 - mape: 11.3673 - val_loss: 10.9566 - val_mae: 26.1133 - val_mape: 9.6712 - lr: 3.0000e-05\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.6079 - mae: 29.9290 - mape: 11.3233 - val_loss: 10.6440 - val_mae: 23.7049 - val_mape: 9.3601 - lr: 3.0000e-05\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.7591 - mae: 30.2927 - mape: 11.4757 - val_loss: 10.4601 - val_mae: 22.2194 - val_mape: 9.1753 - lr: 3.0000e-05\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5822 - mae: 27.0598 - mape: 11.2977 - val_loss: 10.7373 - val_mae: 26.5112 - val_mape: 9.4540 - lr: 3.0000e-05\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.6501 - mae: 29.1528 - mape: 11.3691 - val_loss: 10.7573 - val_mae: 24.9712 - val_mape: 9.4782 - lr: 3.0000e-05\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9131 - mae: 30.3789 - mape: 11.6346 - val_loss: 10.7515 - val_mae: 24.0974 - val_mape: 9.4742 - lr: 3.0000e-05\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.7873 - mae: 30.5070 - mape: 11.5104 - val_loss: 11.5769 - val_mae: 33.2471 - val_mape: 10.3011 - lr: 3.0000e-05\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6527 - mae: 30.6791 - mape: 11.3768 - val_loss: 10.8985 - val_mae: 25.4242 - val_mape: 9.6233 - lr: 3.0000e-05\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5780 - mae: 29.8467 - mape: 11.3047 - val_loss: 10.6827 - val_mae: 24.8559 - val_mape: 9.4092 - lr: 3.0000e-05\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.6827 - mae: 30.6072 - mape: 11.4095 - val_loss: 11.3112 - val_mae: 24.9344 - val_mape: 10.0382 - lr: 3.0000e-05\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9050 - mae: 29.9816 - mape: 11.6330 - val_loss: 11.1066 - val_mae: 23.5428 - val_mape: 9.8357 - lr: 3.0000e-05\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.4474 - mae: 29.3122 - mape: 11.1766 - val_loss: 10.6819 - val_mae: 23.1760 - val_mape: 9.4124 - lr: 3.0000e-05\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.7260 - mae: 30.2554 - mape: 11.4560 - val_loss: 10.9152 - val_mae: 27.1487 - val_mape: 9.6463 - lr: 3.0000e-05\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.7759 - mae: 31.0066 - mape: 11.5078 - val_loss: 11.0344 - val_mae: 23.2252 - val_mape: 9.7675 - lr: 3.0000e-05\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6590 - mae: 32.4090 - mape: 11.3931 - val_loss: 10.8904 - val_mae: 22.5706 - val_mape: 9.6240 - lr: 3.0000e-05\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.6248 - mae: 26.5631 - mape: 11.3588 - val_loss: 10.6979 - val_mae: 21.3911 - val_mape: 9.4329 - lr: 3.0000e-05\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5428 - mae: 29.2260 - mape: 11.2789 - val_loss: 10.4932 - val_mae: 22.6206 - val_mape: 9.2287 - lr: 3.0000e-05\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.5658 - mae: 30.1189 - mape: 11.3034 - val_loss: 11.1171 - val_mae: 23.1751 - val_mape: 9.8560 - lr: 3.0000e-05\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3914 - mae: 27.8882 - mape: 11.1299 - val_loss: 10.5412 - val_mae: 22.7869 - val_mape: 9.2807 - lr: 3.0000e-05\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3829 - mae: 30.5389 - mape: 11.1231 - val_loss: 10.7347 - val_mae: 22.6801 - val_mape: 9.4755 - lr: 3.0000e-05\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.8400 - mae: 30.3242 - mape: 11.5813 - val_loss: 10.9987 - val_mae: 24.1358 - val_mape: 9.7402 - lr: 3.0000e-05\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.4823 - mae: 29.5251 - mape: 11.2242 - val_loss: 10.6354 - val_mae: 21.6971 - val_mape: 9.3783 - lr: 3.0000e-05\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5626 - mae: 29.2163 - mape: 11.3064 - val_loss: 10.7438 - val_mae: 24.2624 - val_mape: 9.4877 - lr: 3.0000e-05\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5950 - mae: 30.3872 - mape: 11.3397 - val_loss: 10.6781 - val_mae: 27.0420 - val_mape: 9.4237 - lr: 3.0000e-05\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6275 - mae: 30.7947 - mape: 11.3736 - val_loss: 11.1763 - val_mae: 24.7689 - val_mape: 9.9226 - lr: 3.0000e-05\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5849 - mae: 28.1842 - mape: 11.3317 - val_loss: 10.4897 - val_mae: 22.3933 - val_mape: 9.2364 - lr: 3.0000e-05\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5973 - mae: 27.9401 - mape: 11.3443 - val_loss: 10.7271 - val_mae: 26.3227 - val_mape: 9.4744 - lr: 3.0000e-05\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.4767 - mae: 29.0226 - mape: 11.2253 - val_loss: 11.4104 - val_mae: 27.1249 - val_mape: 10.1606 - lr: 3.0000e-05\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.4559 - mae: 28.5908 - mape: 11.2066 - val_loss: 10.7205 - val_mae: 25.7331 - val_mape: 9.4726 - lr: 3.0000e-05\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5302 - mae: 29.3662 - mape: 11.2830 - val_loss: 10.5520 - val_mae: 25.1979 - val_mape: 9.3051 - lr: 3.0000e-05\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6904 - mae: 30.0350 - mape: 11.4453 - val_loss: 10.9371 - val_mae: 26.6857 - val_mape: 9.6932 - lr: 3.0000e-05\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.4094 - mae: 31.1339 - mape: 11.1654 - val_loss: 10.5916 - val_mae: 25.5044 - val_mape: 9.3472 - lr: 3.0000e-05\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.3459 - mae: 29.8421 - mape: 11.1024\n",
      "Epoch 171: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3459 - mae: 29.8421 - mape: 11.1024 - val_loss: 10.7407 - val_mae: 22.9387 - val_mape: 9.4976 - lr: 3.0000e-05\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.2288 - mae: 28.2275 - mape: 10.9859 - val_loss: 10.6145 - val_mae: 22.9503 - val_mape: 9.3720 - lr: 9.0000e-06\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5251 - mae: 28.5707 - mape: 11.2832 - val_loss: 10.8121 - val_mae: 23.8830 - val_mape: 9.5709 - lr: 9.0000e-06\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.4257 - mae: 30.7924 - mape: 11.1847 - val_loss: 11.0153 - val_mae: 25.2442 - val_mape: 9.7745 - lr: 9.0000e-06\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.5053 - mae: 31.2599 - mape: 11.2649 - val_loss: 10.8488 - val_mae: 25.0471 - val_mape: 9.6088 - lr: 9.0000e-06\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.6001 - mae: 29.5947 - mape: 11.3604 - val_loss: 10.8116 - val_mae: 25.7863 - val_mape: 9.5723 - lr: 9.0000e-06\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.3503 - mae: 28.2299 - mape: 11.1108 - val_loss: 10.7725 - val_mae: 25.0461 - val_mape: 9.5334 - lr: 9.0000e-06\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3148 - mae: 28.4484 - mape: 11.0760 - val_loss: 10.5131 - val_mae: 23.0033 - val_mape: 9.2741 - lr: 9.0000e-06\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3074 - mae: 29.3123 - mape: 11.0689 - val_loss: 10.6527 - val_mae: 24.5973 - val_mape: 9.4147 - lr: 9.0000e-06\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5601 - mae: 29.4596 - mape: 11.3222 - val_loss: 10.7745 - val_mae: 23.2345 - val_mape: 9.5362 - lr: 9.0000e-06\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.4354 - mae: 30.3658 - mape: 11.1975 - val_loss: 10.6899 - val_mae: 24.1501 - val_mape: 9.4527 - lr: 9.0000e-06\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3668 - mae: 29.5443 - mape: 11.1294 - val_loss: 10.7728 - val_mae: 23.9062 - val_mape: 9.5354 - lr: 9.0000e-06\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.4284 - mae: 28.9562 - mape: 11.1910 - val_loss: 10.8068 - val_mae: 24.5243 - val_mape: 9.5695 - lr: 9.0000e-06\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.2605 - mae: 27.9561 - mape: 11.0233 - val_loss: 10.5316 - val_mae: 24.3665 - val_mape: 9.2938 - lr: 9.0000e-06\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.4656 - mae: 28.0157 - mape: 11.2283 - val_loss: 10.7580 - val_mae: 24.3018 - val_mape: 9.5210 - lr: 9.0000e-06\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 12.5039 - mae: 28.0852 - mape: 11.2675 - val_loss: 10.6400 - val_mae: 24.7712 - val_mape: 9.4036 - lr: 9.0000e-06\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 12.3793 - mae: 29.5085 - mape: 11.1430 - val_loss: 10.7846 - val_mae: 23.7780 - val_mape: 9.5480 - lr: 9.0000e-06\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5732 - mae: 27.9190 - mape: 11.3367 - val_loss: 10.9858 - val_mae: 25.1813 - val_mape: 9.7500 - lr: 9.0000e-06\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 12.4074 - mae: 28.2272 - mape: 11.1718 - val_loss: 10.8445 - val_mae: 24.3239 - val_mape: 9.6090 - lr: 9.0000e-06\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.3517 - mae: 30.1926 - mape: 11.1160 - val_loss: 10.9438 - val_mae: 24.4929 - val_mape: 9.7090 - lr: 9.0000e-06\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.2775 - mae: 29.5093 - mape: 11.0426 - val_loss: 10.9228 - val_mae: 24.1808 - val_mape: 9.6882 - lr: 9.0000e-06\n",
      "Epoch 192/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.3911 - mae: 29.9610 - mape: 11.1565 - val_loss: 10.7910 - val_mae: 25.2099 - val_mape: 9.5562 - lr: 9.0000e-06\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 12.5556 - mae: 29.5472 - mape: 11.3206 - val_loss: 10.8108 - val_mae: 24.2310 - val_mape: 9.5754 - lr: 9.0000e-06\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 12.4880 - mae: 30.7995 - mape: 11.2532 - val_loss: 10.6035 - val_mae: 24.7310 - val_mape: 9.3693 - lr: 9.0000e-06\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.4472 - mae: 29.8953 - mape: 11.2131 - val_loss: 10.8253 - val_mae: 24.0605 - val_mape: 9.5914 - lr: 9.0000e-06\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3748 - mae: 29.5484 - mape: 11.1407 - val_loss: 10.6153 - val_mae: 25.9629 - val_mape: 9.3813 - lr: 9.0000e-06\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5482 - mae: 31.2787 - mape: 11.3148 - val_loss: 10.7209 - val_mae: 24.9947 - val_mape: 9.4875 - lr: 9.0000e-06\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.5408 - mae: 29.8643 - mape: 11.3075 - val_loss: 10.6152 - val_mae: 23.7137 - val_mape: 9.3820 - lr: 9.0000e-06\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.4424 - mae: 28.7539 - mape: 11.2097 - val_loss: 11.0712 - val_mae: 25.8068 - val_mape: 9.8387 - lr: 9.0000e-06\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.2733 - mae: 29.5679 - mape: 11.0409 - val_loss: 10.7011 - val_mae: 25.2310 - val_mape: 9.4687 - lr: 9.0000e-06\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.4209 - mae: 28.0210 - mape: 11.1888\n",
      "Epoch 201: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.4209 - mae: 28.0210 - mape: 11.1888 - val_loss: 10.9314 - val_mae: 26.8370 - val_mape: 9.6999 - lr: 9.0000e-06\n",
      "Epoch 201: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 12.125433921813965; mae of 19.60015296936035; mape of 8.480804443359375%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n",
      " 3/87 [>.............................] - ETA: 4s - loss: 16.2643 - mae: 40.0035 - mape: 11.9861"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.7638 - mae: 32.6137 - mape: 12.5611"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 101ms/step - loss: 16.7638 - mae: 32.6137 - mape: 12.5611 - val_loss: 12.5855 - val_mae: 18.5483 - val_mape: 8.4491 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n",
      " 2/87 [..............................] - ETA: 4s - loss: 15.0564 - mae: 11.7341 - mape: 10.9206"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.4071 - mae: 33.2143 - mape: 12.3306"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 16.4071 - mae: 33.2143 - mape: 12.3306 - val_loss: 12.4527 - val_mae: 18.3239 - val_mape: 8.4331 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 78ms/step - loss: 16.2749 - mae: 31.7484 - mape: 12.3091 - val_loss: 12.3874 - val_mae: 20.2173 - val_mape: 8.4754 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.2551 - mae: 34.8922 - mape: 12.3904 - val_loss: 13.0339 - val_mae: 18.2048 - val_mape: 9.2198 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.9294 - mae: 30.4217 - mape: 12.1613 - val_loss: 13.2100 - val_mae: 20.2310 - val_mape: 9.4927 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.0070 - mae: 34.4206 - mape: 12.3320 - val_loss: 12.4877 - val_mae: 21.8160 - val_mape: 8.8563 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 15.7952 - mae: 31.8636 - mape: 12.2064 - val_loss: 12.0000 - val_mae: 18.1975 - val_mape: 8.4524 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.9880 - mae: 31.9144 - mape: 12.4810 - val_loss: 12.2613 - val_mae: 20.3811 - val_mape: 8.7961 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.6117 - mae: 34.8686 - mape: 12.1861 - val_loss: 12.6413 - val_mae: 23.0459 - val_mape: 9.2545 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.5801 - mae: 32.7740 - mape: 12.2278 - val_loss: 11.9287 - val_mae: 20.2101 - val_mape: 8.6130 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.4054 - mae: 32.4110 - mape: 12.1253 - val_loss: 12.2235 - val_mae: 20.9286 - val_mape: 8.9745 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.5453 - mae: 31.7226 - mape: 12.3291 - val_loss: 11.9195 - val_mae: 21.3687 - val_mape: 8.7359 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.3661 - mae: 31.9119 - mape: 12.2142 - val_loss: 11.6033 - val_mae: 18.3519 - val_mape: 8.4825 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.4577 - mae: 31.8785 - mape: 12.3636 - val_loss: 12.2230 - val_mae: 22.0504 - val_mape: 9.1569 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 15.1293 - mae: 30.4193 - mape: 12.0900"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 97ms/step - loss: 15.1293 - mae: 30.4193 - mape: 12.0900 - val_loss: 11.3563 - val_mae: 18.0926 - val_mape: 8.3443 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 79ms/step - loss: 15.3495 - mae: 33.4346 - mape: 12.3664 - val_loss: 11.8024 - val_mae: 19.5137 - val_mape: 8.8450 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.2145 - mae: 34.0357 - mape: 12.2831 - val_loss: 12.2823 - val_mae: 21.9523 - val_mape: 9.3777 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.2301 - mae: 32.4411 - mape: 12.3495 - val_loss: 11.6010 - val_mae: 19.4863 - val_mape: 8.7405 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.2450 - mae: 35.6068 - mape: 12.4100 - val_loss: 11.7194 - val_mae: 24.1615 - val_mape: 8.9080 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.0427 - mae: 32.8140 - mape: 12.2531 - val_loss: 11.6700 - val_mae: 20.8434 - val_mape: 8.9030 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.6351 - mae: 30.5472 - mape: 11.8910 - val_loss: 11.6749 - val_mae: 19.2937 - val_mape: 8.9538 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.0694 - mae: 35.0023 - mape: 12.3659 - val_loss: 11.6413 - val_mae: 19.5123 - val_mape: 8.9581 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.5631 - mae: 32.0377 - mape: 11.9013 - val_loss: 12.5581 - val_mae: 22.0585 - val_mape: 9.9156 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.5326 - mae: 32.6687 - mape: 11.9058 - val_loss: 11.5003 - val_mae: 23.9010 - val_mape: 8.8912 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 14.8878 - mae: 32.2215 - mape: 12.2989 - val_loss: 11.4431 - val_mae: 18.4612 - val_mape: 8.8736 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.5129 - mae: 31.9540 - mape: 11.9594 - val_loss: 11.2309 - val_mae: 17.9802 - val_mape: 8.6933 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.9466 - mae: 32.4946 - mape: 12.4262 - val_loss: 11.2644 - val_mae: 20.5781 - val_mape: 8.7605 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.5223 - mae: 33.3614 - mape: 12.0332 - val_loss: 11.7353 - val_mae: 24.6213 - val_mape: 9.2626 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.5715 - mae: 33.1024 - mape: 12.1130 - val_loss: 12.6923 - val_mae: 21.0721 - val_mape: 10.2525 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.5308 - mae: 32.1450 - mape: 12.1058 - val_loss: 11.3714 - val_mae: 20.5458 - val_mape: 8.9608 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.3479 - mae: 32.5235 - mape: 11.9514 - val_loss: 11.7761 - val_mae: 21.5223 - val_mape: 9.3973 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.4851 - mae: 33.6916 - mape: 12.1181 - val_loss: 11.5889 - val_mae: 21.3302 - val_mape: 9.2376 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2785 - mae: 31.5630 - mape: 11.9398 - val_loss: 12.8918 - val_mae: 22.9676 - val_mape: 10.5670 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.5381 - mae: 33.1631 - mape: 12.2237 - val_loss: 11.2373 - val_mae: 23.7361 - val_mape: 8.9352 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.0871 - mae: 31.0729 - mape: 11.7984 - val_loss: 11.1265 - val_mae: 20.0407 - val_mape: 8.8501 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.5394 - mae: 34.5255 - mape: 12.2780 - val_loss: 11.4259 - val_mae: 21.8791 - val_mape: 9.1749 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.1716 - mae: 28.8450 - mape: 11.9324 - val_loss: 10.9059 - val_mae: 17.5906 - val_mape: 8.6798 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.4537 - mae: 33.3903 - mape: 12.2395 - val_loss: 11.5184 - val_mae: 20.4811 - val_mape: 9.3185 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.9923 - mae: 30.3674 - mape: 11.8019 - val_loss: 10.9837 - val_mae: 19.5253 - val_mape: 8.8026 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.2479 - mae: 31.0425 - mape: 12.0787 - val_loss: 11.0107 - val_mae: 21.6313 - val_mape: 8.8536 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.7122 - mae: 32.9400 - mape: 12.5667 - val_loss: 12.5953 - val_mae: 23.8103 - val_mape: 10.4601 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.4385 - mae: 34.7993 - mape: 12.3130 - val_loss: 10.7602 - val_mae: 18.9803 - val_mape: 8.6434 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2090 - mae: 32.9139 - mape: 12.1043 - val_loss: 11.5352 - val_mae: 18.8531 - val_mape: 9.4413 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.3601 - mae: 31.8050 - mape: 12.2768 - val_loss: 13.6654 - val_mae: 24.3279 - val_mape: 11.5956 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.1314 - mae: 31.7044 - mape: 12.0696 - val_loss: 11.2049 - val_mae: 21.9715 - val_mape: 9.1543 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.3402 - mae: 31.4748 - mape: 12.2980 - val_loss: 11.3816 - val_mae: 20.2862 - val_mape: 9.3460 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0543 - mae: 31.1846 - mape: 12.0286 - val_loss: 10.8298 - val_mae: 20.5296 - val_mape: 8.8142 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0530 - mae: 32.8336 - mape: 12.0476 - val_loss: 12.5139 - val_mae: 25.0727 - val_mape: 10.5215 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.9605 - mae: 31.2990 - mape: 11.9740 - val_loss: 12.0975 - val_mae: 26.2591 - val_mape: 10.1219 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.0764 - mae: 33.7290 - mape: 12.1105 - val_loss: 11.3791 - val_mae: 19.5941 - val_mape: 9.4216 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 14.0069 - mae: 32.7538 - mape: 12.0568 - val_loss: 10.9908 - val_mae: 19.8333 - val_mape: 9.0442 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.8451 - mae: 33.2518 - mape: 11.9093 - val_loss: 11.0613 - val_mae: 20.6452 - val_mape: 9.1350 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.7556 - mae: 31.2428 - mape: 11.8362 - val_loss: 14.8063 - val_mae: 25.5078 - val_mape: 12.8966 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.0080 - mae: 31.0303 - mape: 12.1062 - val_loss: 10.9132 - val_mae: 18.3793 - val_mape: 9.0197 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.5259 - mae: 30.5975 - mape: 11.6396 - val_loss: 11.7384 - val_mae: 23.6854 - val_mape: 9.8608 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.7085 - mae: 31.5718 - mape: 11.8387 - val_loss: 11.3290 - val_mae: 19.4843 - val_mape: 9.4662 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.8566 - mae: 32.2978 - mape: 11.9998 - val_loss: 11.1754 - val_mae: 20.5637 - val_mape: 9.3268 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.8279 - mae: 32.3397 - mape: 11.9874 - val_loss: 11.3868 - val_mae: 21.4103 - val_mape: 9.5566 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.8071 - mae: 31.4531 - mape: 11.9810 - val_loss: 11.0265 - val_mae: 19.8632 - val_mape: 9.2092 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.8125 - mae: 31.7381 - mape: 12.0044 - val_loss: 10.8378 - val_mae: 20.6573 - val_mape: 9.0384 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.6996 - mae: 31.3973 - mape: 11.9066 - val_loss: 11.3196 - val_mae: 21.7317 - val_mape: 9.5341 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.7996 - mae: 29.8150 - mape: 12.0215 - val_loss: 11.4071 - val_mae: 20.9957 - val_mape: 9.6359 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.6969 - mae: 32.1436 - mape: 11.9321 - val_loss: 11.8773 - val_mae: 21.3191 - val_mape: 10.1186 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.4704 - mae: 31.6594 - mape: 11.7189 - val_loss: 12.4368 - val_mae: 21.1617 - val_mape: 10.6937 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0162 - mae: 33.3061 - mape: 12.2794 - val_loss: 10.8666 - val_mae: 20.7281 - val_mape: 9.1341 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.8396 - mae: 32.9537 - mape: 12.1141 - val_loss: 12.5552 - val_mae: 24.4321 - val_mape: 10.8377 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.4266 - mae: 31.9303 - mape: 11.7135 - val_loss: 10.7814 - val_mae: 20.6477 - val_mape: 9.0763 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.5854 - mae: 32.9403 - mape: 11.8860 - val_loss: 11.0963 - val_mae: 19.1349 - val_mape: 9.4015 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.5661 - mae: 35.5724 - mape: 11.8774 - val_loss: 11.6266 - val_mae: 22.3546 - val_mape: 9.9433 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.5634 - mae: 31.1552 - mape: 11.8847 - val_loss: 11.9421 - val_mae: 22.5113 - val_mape: 10.2697 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3131 - mae: 29.3428 - mape: 11.6477 - val_loss: 10.8645 - val_mae: 20.3626 - val_mape: 9.2052 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.4803 - mae: 29.9616 - mape: 11.8261\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.4803 - mae: 29.9616 - mape: 11.8261 - val_loss: 11.0334 - val_mae: 21.0902 - val_mape: 9.3858 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4152 - mae: 31.5379 - mape: 11.7705 - val_loss: 10.7299 - val_mae: 19.6759 - val_mape: 9.0861 - lr: 3.0000e-05\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.2475 - mae: 30.3339 - mape: 11.6069 - val_loss: 11.1407 - val_mae: 20.4609 - val_mape: 9.5031 - lr: 3.0000e-05\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2532 - mae: 29.4730 - mape: 11.6166 - val_loss: 10.9515 - val_mae: 19.2331 - val_mape: 9.3167 - lr: 3.0000e-05\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.0617 - mae: 30.8973 - mape: 11.4287 - val_loss: 10.7214 - val_mae: 19.8372 - val_mape: 9.0900 - lr: 3.0000e-05\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2582 - mae: 31.2645 - mape: 11.6291 - val_loss: 11.1288 - val_mae: 20.6599 - val_mape: 9.5013 - lr: 3.0000e-05\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2911 - mae: 30.5479 - mape: 11.6661 - val_loss: 11.4736 - val_mae: 20.8258 - val_mape: 9.8511 - lr: 3.0000e-05\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3488 - mae: 31.3054 - mape: 11.7285 - val_loss: 10.7918 - val_mae: 21.0151 - val_mape: 9.1714 - lr: 3.0000e-05\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3485 - mae: 32.4898 - mape: 11.7295 - val_loss: 11.4944 - val_mae: 20.8263 - val_mape: 9.8774 - lr: 3.0000e-05\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1192 - mae: 29.6068 - mape: 11.5030 - val_loss: 10.6438 - val_mae: 20.0281 - val_mape: 9.0287 - lr: 3.0000e-05\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2645 - mae: 33.5769 - mape: 11.6517 - val_loss: 10.8307 - val_mae: 20.1704 - val_mape: 9.2190 - lr: 3.0000e-05\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1436 - mae: 31.3963 - mape: 11.5339 - val_loss: 10.6193 - val_mae: 19.5665 - val_mape: 9.0105 - lr: 3.0000e-05\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1999 - mae: 32.5264 - mape: 11.5932 - val_loss: 10.9199 - val_mae: 19.4490 - val_mape: 9.3155 - lr: 3.0000e-05\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1607 - mae: 29.3053 - mape: 11.5576 - val_loss: 10.8065 - val_mae: 19.5883 - val_mape: 9.2049 - lr: 3.0000e-05\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.3388 - mae: 31.1982 - mape: 11.7395 - val_loss: 10.9104 - val_mae: 19.2212 - val_mape: 9.3123 - lr: 3.0000e-05\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1758 - mae: 31.5897 - mape: 11.5798 - val_loss: 10.7332 - val_mae: 19.2602 - val_mape: 9.1385 - lr: 3.0000e-05\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.8931 - mae: 30.4618 - mape: 11.2994 - val_loss: 10.6562 - val_mae: 19.8846 - val_mape: 9.0632 - lr: 3.0000e-05\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0589 - mae: 32.8779 - mape: 11.4674 - val_loss: 11.2362 - val_mae: 20.5437 - val_mape: 9.6475 - lr: 3.0000e-05\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.9458 - mae: 31.0391 - mape: 11.3591 - val_loss: 10.9718 - val_mae: 20.7251 - val_mape: 9.3866 - lr: 3.0000e-05\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1672 - mae: 33.6210 - mape: 11.5833 - val_loss: 10.7541 - val_mae: 19.8272 - val_mape: 9.1715 - lr: 3.0000e-05\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0981 - mae: 28.6711 - mape: 11.5160 - val_loss: 10.5909 - val_mae: 19.7124 - val_mape: 9.0102 - lr: 3.0000e-05\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.2424 - mae: 30.9378 - mape: 11.6637 - val_loss: 10.8019 - val_mae: 20.0453 - val_mape: 9.2250 - lr: 3.0000e-05\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1025 - mae: 31.1509 - mape: 11.5273 - val_loss: 10.4885 - val_mae: 18.7865 - val_mape: 8.9128 - lr: 3.0000e-05\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1386 - mae: 29.0045 - mape: 11.5652 - val_loss: 10.8146 - val_mae: 19.2500 - val_mape: 9.2412 - lr: 3.0000e-05\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1884 - mae: 30.0474 - mape: 11.6175 - val_loss: 11.0855 - val_mae: 22.4746 - val_mape: 9.5179 - lr: 3.0000e-05\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0381 - mae: 28.4621 - mape: 11.4723 - val_loss: 10.6527 - val_mae: 20.8939 - val_mape: 9.0879 - lr: 3.0000e-05\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2648 - mae: 34.4412 - mape: 11.7021 - val_loss: 10.9855 - val_mae: 20.8927 - val_mape: 9.4242 - lr: 3.0000e-05\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.7419 - mae: 30.5446 - mape: 11.1820 - val_loss: 10.6124 - val_mae: 18.8780 - val_mape: 9.0533 - lr: 3.0000e-05\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1183 - mae: 29.6126 - mape: 11.5612 - val_loss: 10.5283 - val_mae: 19.5508 - val_mape: 8.9715 - lr: 3.0000e-05\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1261 - mae: 29.6749 - mape: 11.5718 - val_loss: 10.6937 - val_mae: 19.3210 - val_mape: 9.1414 - lr: 3.0000e-05\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9725 - mae: 29.9783 - mape: 11.4220 - val_loss: 10.8820 - val_mae: 20.1025 - val_mape: 9.3334 - lr: 3.0000e-05\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0569 - mae: 31.4083 - mape: 11.5096 - val_loss: 10.7108 - val_mae: 19.8353 - val_mape: 9.1657 - lr: 3.0000e-05\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.0931 - mae: 31.1017 - mape: 11.5498 - val_loss: 11.1102 - val_mae: 19.9801 - val_mape: 9.5689 - lr: 3.0000e-05\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1250 - mae: 31.1059 - mape: 11.5852 - val_loss: 11.0053 - val_mae: 22.0409 - val_mape: 9.4670 - lr: 3.0000e-05\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.9918 - mae: 32.2753 - mape: 11.4536 - val_loss: 11.0546 - val_mae: 20.8752 - val_mape: 9.5175 - lr: 3.0000e-05\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0655 - mae: 31.3052 - mape: 11.5305 - val_loss: 10.8413 - val_mae: 20.4273 - val_mape: 9.3080 - lr: 3.0000e-05\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3302 - mae: 34.3592 - mape: 11.7990 - val_loss: 10.7032 - val_mae: 19.8499 - val_mape: 9.1735 - lr: 3.0000e-05\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0938 - mae: 31.3622 - mape: 11.5652 - val_loss: 10.7709 - val_mae: 20.0351 - val_mape: 9.2446 - lr: 3.0000e-05\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0894 - mae: 32.8504 - mape: 11.5645 - val_loss: 10.8988 - val_mae: 20.0377 - val_mape: 9.3745 - lr: 3.0000e-05\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.2151 - mae: 31.0651 - mape: 11.6909 - val_loss: 10.6097 - val_mae: 19.7438 - val_mape: 9.0867 - lr: 3.0000e-05\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0341 - mae: 28.2393 - mape: 11.5133 - val_loss: 10.8192 - val_mae: 19.8614 - val_mape: 9.2990 - lr: 3.0000e-05\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.7259 - mae: 27.8601 - mape: 11.2075 - val_loss: 10.8298 - val_mae: 20.3702 - val_mape: 9.3137 - lr: 3.0000e-05\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.9062 - mae: 30.1808 - mape: 11.3917 - val_loss: 10.7767 - val_mae: 20.1321 - val_mape: 9.2642 - lr: 3.0000e-05\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.9658 - mae: 31.7256 - mape: 11.4547 - val_loss: 10.8913 - val_mae: 20.1078 - val_mape: 9.3810 - lr: 3.0000e-05\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1192 - mae: 32.2823 - mape: 11.6103 - val_loss: 10.7306 - val_mae: 19.8643 - val_mape: 9.2242 - lr: 3.0000e-05\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.9010 - mae: 31.3917 - mape: 11.3954 - val_loss: 10.4957 - val_mae: 18.7326 - val_mape: 8.9894 - lr: 3.0000e-05\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.8392 - mae: 29.5685 - mape: 11.3348 - val_loss: 10.5593 - val_mae: 18.4970 - val_mape: 9.0561 - lr: 3.0000e-05\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.7381 - mae: 30.7412 - mape: 11.2375 - val_loss: 10.6891 - val_mae: 20.6164 - val_mape: 9.1898 - lr: 3.0000e-05\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0016 - mae: 31.0306 - mape: 11.5037 - val_loss: 10.6598 - val_mae: 19.7713 - val_mape: 9.1633 - lr: 3.0000e-05\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.7975 - mae: 28.5790 - mape: 11.3022 - val_loss: 10.7130 - val_mae: 19.4881 - val_mape: 9.2193 - lr: 3.0000e-05\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.9824 - mae: 31.1805 - mape: 11.4892 - val_loss: 10.6939 - val_mae: 21.5601 - val_mape: 9.2024 - lr: 3.0000e-05\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2044 - mae: 30.7596 - mape: 11.7142 - val_loss: 10.9227 - val_mae: 22.2074 - val_mape: 9.4334 - lr: 3.0000e-05\n",
      "Epoch 124/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 12.9553 - mae: 32.4589 - mape: 11.4680\n",
      "Epoch 124: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9185 - mae: 32.1924 - mape: 11.4312 - val_loss: 10.6758 - val_mae: 20.7498 - val_mape: 9.1895 - lr: 3.0000e-05\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.6869 - mae: 30.5593 - mape: 11.2017 - val_loss: 10.6080 - val_mae: 19.5949 - val_mape: 9.1227 - lr: 9.0000e-06\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.7836 - mae: 29.9456 - mape: 11.2991 - val_loss: 10.6392 - val_mae: 19.7535 - val_mape: 9.1548 - lr: 9.0000e-06\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.6618 - mae: 28.9141 - mape: 11.1778 - val_loss: 10.6638 - val_mae: 20.1335 - val_mape: 9.1803 - lr: 9.0000e-06\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9705 - mae: 32.8039 - mape: 11.4877 - val_loss: 10.8137 - val_mae: 20.8866 - val_mape: 9.3312 - lr: 9.0000e-06\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9501 - mae: 30.2809 - mape: 11.4676 - val_loss: 10.8061 - val_mae: 19.9880 - val_mape: 9.3240 - lr: 9.0000e-06\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0970 - mae: 30.8526 - mape: 11.6153 - val_loss: 10.7698 - val_mae: 19.8428 - val_mape: 9.2884 - lr: 9.0000e-06\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.8069 - mae: 31.2446 - mape: 11.3257 - val_loss: 10.8906 - val_mae: 19.9337 - val_mape: 9.4102 - lr: 9.0000e-06\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.8329 - mae: 31.3720 - mape: 11.3530 - val_loss: 10.7799 - val_mae: 19.9934 - val_mape: 9.3002 - lr: 9.0000e-06\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.8011 - mae: 31.2014 - mape: 11.3214 - val_loss: 10.7396 - val_mae: 20.0241 - val_mape: 9.2604 - lr: 9.0000e-06\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.9251 - mae: 30.2361 - mape: 11.4463 - val_loss: 10.7242 - val_mae: 20.8080 - val_mape: 9.2457 - lr: 9.0000e-06\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1065 - mae: 33.1309 - mape: 11.6286 - val_loss: 10.7523 - val_mae: 21.0105 - val_mape: 9.2750 - lr: 9.0000e-06\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.8200 - mae: 30.0894 - mape: 11.3431 - val_loss: 10.8332 - val_mae: 21.0222 - val_mape: 9.3567 - lr: 9.0000e-06\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.0005 - mae: 30.6347 - mape: 11.5242 - val_loss: 10.7535 - val_mae: 20.6291 - val_mape: 9.2776 - lr: 9.0000e-06\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.8523 - mae: 30.1298 - mape: 11.3769 - val_loss: 10.7372 - val_mae: 19.7251 - val_mape: 9.2621 - lr: 9.0000e-06\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.9618 - mae: 32.0879 - mape: 11.4871 - val_loss: 10.6823 - val_mae: 19.7921 - val_mape: 9.2077 - lr: 9.0000e-06\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.0424 - mae: 30.8338 - mape: 11.5680 - val_loss: 10.7240 - val_mae: 19.9780 - val_mape: 9.2498 - lr: 9.0000e-06\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.8906 - mae: 33.3845 - mape: 11.4171 - val_loss: 10.6355 - val_mae: 20.0196 - val_mape: 9.1620 - lr: 9.0000e-06\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9648 - mae: 29.6809 - mape: 11.4920 - val_loss: 10.7451 - val_mae: 20.4039 - val_mape: 9.2726 - lr: 9.0000e-06\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 12.8414 - mae: 31.0130 - mape: 11.3691 - val_loss: 10.5977 - val_mae: 20.0181 - val_mape: 9.1257 - lr: 9.0000e-06\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.0239 - mae: 30.5238 - mape: 11.5522 - val_loss: 10.6778 - val_mae: 20.8202 - val_mape: 9.2067 - lr: 9.0000e-06\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0093 - mae: 32.4522 - mape: 11.5390 - val_loss: 10.8244 - val_mae: 20.4484 - val_mape: 9.3543 - lr: 9.0000e-06\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5922 - mae: 30.9463 - mape: 11.1224 - val_loss: 10.9657 - val_mae: 21.4214 - val_mape: 9.4967 - lr: 9.0000e-06\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9091 - mae: 30.4257 - mape: 11.4402 - val_loss: 10.7220 - val_mae: 20.7305 - val_mape: 9.2534 - lr: 9.0000e-06\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.6767 - mae: 32.1119 - mape: 11.2087 - val_loss: 10.7383 - val_mae: 20.1524 - val_mape: 9.2702 - lr: 9.0000e-06\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.9327 - mae: 31.3594 - mape: 11.4650 - val_loss: 10.7761 - val_mae: 20.3337 - val_mape: 9.3086 - lr: 9.0000e-06\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.8240 - mae: 29.5074 - mape: 11.3570 - val_loss: 10.6313 - val_mae: 20.3945 - val_mape: 9.1647 - lr: 9.0000e-06\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.0242 - mae: 32.8599 - mape: 11.5581 - val_loss: 10.5937 - val_mae: 19.3953 - val_mape: 9.1275 - lr: 9.0000e-06\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0522 - mae: 32.6849 - mape: 11.5867 - val_loss: 10.7465 - val_mae: 19.9120 - val_mape: 9.2816 - lr: 9.0000e-06\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.6592 - mae: 29.1326 - mape: 11.1945 - val_loss: 10.7950 - val_mae: 20.2157 - val_mape: 9.3307 - lr: 9.0000e-06\n",
      "Epoch 154/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 12.6499 - mae: 27.1797 - mape: 11.1861\n",
      "Epoch 154: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6292 - mae: 27.3536 - mape: 11.1653 - val_loss: 10.7466 - val_mae: 20.4598 - val_mape: 9.2833 - lr: 9.0000e-06\n",
      "Epoch 154: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 11.35626220703125; mae of 18.092626571655273; mape of 8.3443021774292%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.7854 - mae: 34.8899 - mape: 12.5879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 99ms/step - loss: 16.7854 - mae: 34.8899 - mape: 12.5879 - val_loss: 12.7270 - val_mae: 22.4426 - val_mape: 8.5967 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.5353 - mae: 32.1229 - mape: 12.4578"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 101ms/step - loss: 16.5353 - mae: 32.1229 - mape: 12.4578 - val_loss: 11.8236 - val_mae: 17.1232 - val_mape: 7.8026 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 79ms/step - loss: 16.7454 - mae: 31.5290 - mape: 12.7764 - val_loss: 12.4628 - val_mae: 18.5532 - val_mape: 8.5445 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 16.4885 - mae: 33.8337 - mape: 12.6173 - val_loss: 12.3562 - val_mae: 18.6489 - val_mape: 8.5323 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 16.4299 - mae: 31.5464 - mape: 12.6485 - val_loss: 11.8175 - val_mae: 20.1202 - val_mape: 8.0818 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.7437 - mae: 31.4655 - mape: 12.0473 - val_loss: 11.6012 - val_mae: 17.8555 - val_mape: 7.9463 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.1791 - mae: 33.2658 - mape: 12.5617"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 97ms/step - loss: 16.1791 - mae: 33.2658 - mape: 12.5617 - val_loss: 11.3150 - val_mae: 16.8404 - val_mape: 7.7317 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 82ms/step - loss: 15.9203 - mae: 32.4399 - mape: 12.3753 - val_loss: 11.7772 - val_mae: 23.5318 - val_mape: 8.2675 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 15.9806 - mae: 32.2183 - mape: 12.5031 - val_loss: 11.4402 - val_mae: 17.3033 - val_mape: 7.9936 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.6878 - mae: 34.0239 - mape: 12.2763 - val_loss: 12.4534 - val_mae: 22.6635 - val_mape: 9.0755 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.8377 - mae: 31.6100 - mape: 12.4891 - val_loss: 11.7825 - val_mae: 20.6170 - val_mape: 8.4634 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.6252 - mae: 31.7987 - mape: 12.3355 - val_loss: 12.6625 - val_mae: 25.5654 - val_mape: 9.4035 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.6273 - mae: 32.1040 - mape: 12.3940 - val_loss: 11.5303 - val_mae: 18.7715 - val_mape: 8.3260 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.5558 - mae: 35.1026 - mape: 12.3757 - val_loss: 11.2768 - val_mae: 17.7311 - val_mape: 8.1214 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.3399 - mae: 31.2143 - mape: 12.2094 - val_loss: 11.1994 - val_mae: 17.7568 - val_mape: 8.0919 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.4429 - mae: 30.7133 - mape: 12.3592 - val_loss: 12.5302 - val_mae: 24.9513 - val_mape: 9.4708 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.1850 - mae: 30.8323 - mape: 12.1456 - val_loss: 11.2089 - val_mae: 19.1854 - val_mape: 8.1911 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.2758 - mae: 29.4433 - mape: 12.2806 - val_loss: 11.0611 - val_mae: 20.9255 - val_mape: 8.0871 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.3885 - mae: 31.2189 - mape: 12.4366 - val_loss: 13.1737 - val_mae: 24.0410 - val_mape: 10.2446 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.1011 - mae: 35.8057 - mape: 12.1917 - val_loss: 11.7870 - val_mae: 20.9631 - val_mape: 8.8988 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 15.0195 - mae: 33.3624 - mape: 12.1523 - val_loss: 11.4241 - val_mae: 25.8373 - val_mape: 8.5780 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.0587 - mae: 32.4857 - mape: 12.2296 - val_loss: 11.7516 - val_mae: 23.7995 - val_mape: 8.9415 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.2679 - mae: 33.1247 - mape: 12.4751 - val_loss: 11.0012 - val_mae: 19.4461 - val_mape: 8.2272 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.9605 - mae: 33.0885 - mape: 12.2037 - val_loss: 13.2393 - val_mae: 24.1384 - val_mape: 10.4998 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 15.3003 - mae: 34.8274 - mape: 12.5763 - val_loss: 10.8628 - val_mae: 18.8413 - val_mape: 8.1551 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.8484 - mae: 31.1316 - mape: 12.1579 - val_loss: 11.2345 - val_mae: 24.5724 - val_mape: 8.5630 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.7741 - mae: 30.5773 - mape: 12.1175 - val_loss: 11.0052 - val_mae: 17.7938 - val_mape: 8.3615 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.6237 - mae: 30.0580 - mape: 11.9946 - val_loss: 11.0281 - val_mae: 20.2287 - val_mape: 8.4159 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.8291 - mae: 31.8229 - mape: 12.2344 - val_loss: 10.8968 - val_mae: 19.7029 - val_mape: 8.3182 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.9503 - mae: 32.4274 - mape: 12.3857 - val_loss: 10.6683 - val_mae: 17.5644 - val_mape: 8.1159 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.9376 - mae: 35.7704 - mape: 12.4015 - val_loss: 10.9258 - val_mae: 20.7136 - val_mape: 8.4044 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.5717 - mae: 32.8166 - mape: 12.0634 - val_loss: 10.7667 - val_mae: 19.0328 - val_mape: 8.2688 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.6552 - mae: 32.8949 - mape: 12.1719 - val_loss: 12.0684 - val_mae: 30.1575 - val_mape: 9.6004 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.6509 - mae: 31.3203 - mape: 12.1937 - val_loss: 11.1493 - val_mae: 20.5940 - val_mape: 8.7067 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.7720 - mae: 31.5199 - mape: 12.3408 - val_loss: 12.3113 - val_mae: 20.7095 - val_mape: 9.8899 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.5005 - mae: 32.5092 - mape: 12.0904 - val_loss: 11.6150 - val_mae: 29.3509 - val_mape: 9.2189 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.5282 - mae: 33.2802 - mape: 12.1413 - val_loss: 11.1596 - val_mae: 25.5086 - val_mape: 8.7855 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.6028 - mae: 32.5125 - mape: 12.2396 - val_loss: 10.8435 - val_mae: 18.4757 - val_mape: 8.4891 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.5515 - mae: 33.3918 - mape: 12.2092 - val_loss: 11.2478 - val_mae: 20.7956 - val_mape: 8.9157 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.4366 - mae: 33.1088 - mape: 12.1144 - val_loss: 10.8972 - val_mae: 19.0386 - val_mape: 8.5851 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.6028 - mae: 32.4286 - mape: 12.3019 - val_loss: 11.4338 - val_mae: 20.5461 - val_mape: 9.1419 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2693 - mae: 33.5722 - mape: 11.9897 - val_loss: 11.5146 - val_mae: 25.8790 - val_mape: 9.2459 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.2845 - mae: 31.2333 - mape: 12.0244 - val_loss: 11.0084 - val_mae: 18.3602 - val_mape: 8.7599 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0776 - mae: 29.2401 - mape: 11.8372 - val_loss: 10.9620 - val_mae: 19.6544 - val_mape: 8.7302 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0410 - mae: 31.2240 - mape: 11.8198 - val_loss: 11.1037 - val_mae: 18.6870 - val_mape: 8.8894 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2268 - mae: 33.1608 - mape: 12.0236 - val_loss: 11.8042 - val_mae: 19.8989 - val_mape: 9.6076 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 14.4255 - mae: 32.0829 - mape: 12.2418 - val_loss: 10.7724 - val_mae: 18.8481 - val_mape: 8.5993 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.2019 - mae: 30.7751 - mape: 12.0389 - val_loss: 10.6063 - val_mae: 18.5731 - val_mape: 8.4518 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0990 - mae: 29.3611 - mape: 11.9538 - val_loss: 10.8647 - val_mae: 18.5512 - val_mape: 8.7286 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.4836 - mae: 34.3788 - mape: 12.3553 - val_loss: 10.7480 - val_mae: 19.8961 - val_mape: 8.6251 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.0653 - mae: 32.3142 - mape: 11.9498 - val_loss: 10.8239 - val_mae: 24.4284 - val_mape: 8.7184 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2769 - mae: 33.1549 - mape: 12.1784 - val_loss: 10.9573 - val_mae: 18.7902 - val_mape: 8.8681 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.5988 - mae: 33.1961 - mape: 12.5170 - val_loss: 10.7743 - val_mae: 18.8100 - val_mape: 8.6982 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.0016 - mae: 30.8759 - mape: 11.9362 - val_loss: 10.7940 - val_mae: 20.7804 - val_mape: 8.7370 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.0697 - mae: 33.3098 - mape: 12.0191 - val_loss: 11.3726 - val_mae: 20.9265 - val_mape: 9.3267 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.2053 - mae: 32.4012 - mape: 12.1669 - val_loss: 10.8271 - val_mae: 21.3493 - val_mape: 8.7979 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.1047 - mae: 31.6918 - mape: 12.0832 - val_loss: 11.6799 - val_mae: 19.3511 - val_mape: 9.6642 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.8322 - mae: 30.0919 - mape: 11.8247 - val_loss: 10.7166 - val_mae: 17.8733 - val_mape: 8.7159 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.1373 - mae: 32.7342 - mape: 12.1465 - val_loss: 12.3489 - val_mae: 19.9915 - val_mape: 10.3656 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.2710 - mae: 32.1722 - mape: 12.2931 - val_loss: 12.2898 - val_mae: 22.1109 - val_mape: 10.3195 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.9927 - mae: 32.4072 - mape: 12.0261 - val_loss: 10.7080 - val_mae: 19.0846 - val_mape: 8.7448 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.0477 - mae: 31.3127 - mape: 12.0920 - val_loss: 11.1662 - val_mae: 21.3686 - val_mape: 9.2173 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7071 - mae: 28.9240 - mape: 11.7658 - val_loss: 12.3579 - val_mae: 20.2551 - val_mape: 10.4250 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7300 - mae: 32.1987 - mape: 11.8026 - val_loss: 10.6773 - val_mae: 19.1146 - val_mape: 8.7545 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.6784 - mae: 29.0827 - mape: 11.7615 - val_loss: 11.0242 - val_mae: 18.6639 - val_mape: 9.1148 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.6247 - mae: 32.0340 - mape: 11.7186 - val_loss: 11.0388 - val_mae: 18.8775 - val_mape: 9.1387 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.0904 - mae: 34.1232 - mape: 12.1941 - val_loss: 11.0455 - val_mae: 19.9797 - val_mape: 9.1559 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7754 - mae: 32.1508 - mape: 11.8915 - val_loss: 11.6092 - val_mae: 21.2824 - val_mape: 9.7308 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 14.3203 - mae: 30.8765 - mape: 12.4488 - val_loss: 11.1669 - val_mae: 23.7857 - val_mape: 9.2982 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.9813 - mae: 34.8525 - mape: 12.1189 - val_loss: 10.7937 - val_mae: 18.1749 - val_mape: 8.9364 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7386 - mae: 29.8157 - mape: 11.8856 - val_loss: 11.2442 - val_mae: 21.5776 - val_mape: 9.3968 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.0214 - mae: 34.1011 - mape: 12.1790 - val_loss: 10.8980 - val_mae: 23.7362 - val_mape: 9.0621 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.5273 - mae: 30.7239 - mape: 11.6939 - val_loss: 10.8718 - val_mae: 19.2451 - val_mape: 9.0453 - lr: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7412 - mae: 33.3562 - mape: 11.9211 - val_loss: 12.8843 - val_mae: 22.4642 - val_mape: 11.0706 - lr: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.6484 - mae: 31.3497 - mape: 11.8395 - val_loss: 11.0236 - val_mae: 19.3170 - val_mape: 9.2220 - lr: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4732 - mae: 32.4224 - mape: 11.6752 - val_loss: 10.6142 - val_mae: 23.5201 - val_mape: 8.8192 - lr: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.7867 - mae: 35.4212 - mape: 11.9975 - val_loss: 10.6705 - val_mae: 23.2228 - val_mape: 8.8854 - lr: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.4937 - mae: 29.7320 - mape: 11.7150\n",
      "Epoch 78: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4937 - mae: 29.7320 - mape: 11.7150 - val_loss: 11.1532 - val_mae: 18.8732 - val_mape: 9.3828 - lr: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3491 - mae: 29.6302 - mape: 11.5809 - val_loss: 10.8631 - val_mae: 18.0286 - val_mape: 9.0960 - lr: 3.0000e-05\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3626 - mae: 29.2504 - mape: 11.5969 - val_loss: 10.7486 - val_mae: 20.0541 - val_mape: 8.9848 - lr: 3.0000e-05\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4336 - mae: 32.4453 - mape: 11.6723 - val_loss: 11.6571 - val_mae: 22.5310 - val_mape: 9.8986 - lr: 3.0000e-05\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.5134 - mae: 31.1115 - mape: 11.7549 - val_loss: 10.7375 - val_mae: 20.9948 - val_mape: 8.9793 - lr: 3.0000e-05\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3467 - mae: 29.7318 - mape: 11.5902 - val_loss: 10.7312 - val_mae: 18.8636 - val_mape: 8.9761 - lr: 3.0000e-05\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2175 - mae: 30.7710 - mape: 11.4639 - val_loss: 10.7472 - val_mae: 19.5527 - val_mape: 8.9946 - lr: 3.0000e-05\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3849 - mae: 29.5471 - mape: 11.6347 - val_loss: 10.5570 - val_mae: 19.1257 - val_mape: 8.8080 - lr: 3.0000e-05\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.5137 - mae: 30.9376 - mape: 11.7670 - val_loss: 10.7605 - val_mae: 18.8039 - val_mape: 9.0152 - lr: 3.0000e-05\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.5083 - mae: 30.2864 - mape: 11.7651 - val_loss: 10.6745 - val_mae: 18.8295 - val_mape: 8.9313 - lr: 3.0000e-05\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3867 - mae: 32.7512 - mape: 11.6451 - val_loss: 10.7605 - val_mae: 21.5123 - val_mape: 9.0210 - lr: 3.0000e-05\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.4669 - mae: 30.9219 - mape: 11.7287 - val_loss: 11.1176 - val_mae: 22.0237 - val_mape: 9.3820 - lr: 3.0000e-05\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3046 - mae: 30.6111 - mape: 11.5704 - val_loss: 10.7926 - val_mae: 18.7241 - val_mape: 9.0592 - lr: 3.0000e-05\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.0248 - mae: 32.3861 - mape: 11.2927 - val_loss: 10.7039 - val_mae: 20.7222 - val_mape: 8.9732 - lr: 3.0000e-05\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4706 - mae: 30.3580 - mape: 11.7421 - val_loss: 11.8796 - val_mae: 20.3247 - val_mape: 10.1526 - lr: 3.0000e-05\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4364 - mae: 34.0947 - mape: 11.7111 - val_loss: 10.9425 - val_mae: 20.8092 - val_mape: 9.2184 - lr: 3.0000e-05\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4251 - mae: 32.1962 - mape: 11.7019 - val_loss: 10.9429 - val_mae: 20.8136 - val_mape: 9.2208 - lr: 3.0000e-05\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4766 - mae: 31.0521 - mape: 11.7548 - val_loss: 11.3407 - val_mae: 21.6315 - val_mape: 9.6196 - lr: 3.0000e-05\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4516 - mae: 30.2670 - mape: 11.7325 - val_loss: 10.7291 - val_mae: 18.9043 - val_mape: 9.0109 - lr: 3.0000e-05\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.2721 - mae: 29.3267 - mape: 11.5553 - val_loss: 10.8440 - val_mae: 20.9076 - val_mape: 9.1296 - lr: 3.0000e-05\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.4003 - mae: 30.7488 - mape: 11.6876 - val_loss: 10.9652 - val_mae: 20.5773 - val_mape: 9.2545 - lr: 3.0000e-05\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3423 - mae: 33.1855 - mape: 11.6319 - val_loss: 11.5124 - val_mae: 20.2941 - val_mape: 9.8031 - lr: 3.0000e-05\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4216 - mae: 31.1556 - mape: 11.7140 - val_loss: 11.0412 - val_mae: 19.4957 - val_mape: 9.3356 - lr: 3.0000e-05\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1776 - mae: 29.8605 - mape: 11.4731 - val_loss: 10.9980 - val_mae: 20.3129 - val_mape: 9.2941 - lr: 3.0000e-05\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1029 - mae: 27.9856 - mape: 11.3999 - val_loss: 10.8679 - val_mae: 20.3592 - val_mape: 9.1658 - lr: 3.0000e-05\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.4755 - mae: 31.3937 - mape: 11.7746 - val_loss: 11.0182 - val_mae: 21.2778 - val_mape: 9.3185 - lr: 3.0000e-05\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 6s 72ms/step - loss: 13.3902 - mae: 28.4914 - mape: 11.6915 - val_loss: 10.6692 - val_mae: 18.0540 - val_mape: 8.9720 - lr: 3.0000e-05\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3096 - mae: 30.9771 - mape: 11.6142 - val_loss: 10.6041 - val_mae: 18.1577 - val_mape: 8.9092 - lr: 3.0000e-05\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4400 - mae: 31.0993 - mape: 11.7475 - val_loss: 10.7274 - val_mae: 19.1236 - val_mape: 9.0353 - lr: 3.0000e-05\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2443 - mae: 31.8301 - mape: 11.5538 - val_loss: 10.7940 - val_mae: 22.1079 - val_mape: 9.1055 - lr: 3.0000e-05\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3257 - mae: 30.4548 - mape: 11.6389 - val_loss: 10.9610 - val_mae: 19.5912 - val_mape: 9.2759 - lr: 3.0000e-05\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2252 - mae: 30.1993 - mape: 11.5408 - val_loss: 10.9444 - val_mae: 19.5763 - val_mape: 9.2610 - lr: 3.0000e-05\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1769 - mae: 30.2828 - mape: 11.4945 - val_loss: 10.5847 - val_mae: 18.8340 - val_mape: 8.9023 - lr: 3.0000e-05\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3336 - mae: 33.5183 - mape: 11.6531 - val_loss: 11.0547 - val_mae: 19.8189 - val_mape: 9.3765 - lr: 3.0000e-05\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3222 - mae: 32.6460 - mape: 11.6449 - val_loss: 10.6615 - val_mae: 19.4616 - val_mape: 8.9850 - lr: 3.0000e-05\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3008 - mae: 30.0028 - mape: 11.6272 - val_loss: 10.8102 - val_mae: 21.5360 - val_mape: 9.1370 - lr: 3.0000e-05\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2590 - mae: 30.1525 - mape: 11.5868 - val_loss: 10.7211 - val_mae: 19.8357 - val_mape: 9.0507 - lr: 3.0000e-05\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.2583 - mae: 31.1448 - mape: 11.5891\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2583 - mae: 31.1448 - mape: 11.5891 - val_loss: 10.8912 - val_mae: 19.8274 - val_mape: 9.2238 - lr: 3.0000e-05\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.4176 - mae: 30.9006 - mape: 11.7512 - val_loss: 10.7529 - val_mae: 19.9484 - val_mape: 9.0869 - lr: 9.0000e-06\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3422 - mae: 30.8493 - mape: 11.6767 - val_loss: 10.8175 - val_mae: 20.5245 - val_mape: 9.1521 - lr: 9.0000e-06\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.9647 - mae: 30.0288 - mape: 11.2996 - val_loss: 10.8756 - val_mae: 19.8713 - val_mape: 9.2107 - lr: 9.0000e-06\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2816 - mae: 29.6339 - mape: 11.6171 - val_loss: 10.9532 - val_mae: 20.8045 - val_mape: 9.2892 - lr: 9.0000e-06\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3856 - mae: 33.1625 - mape: 11.7218 - val_loss: 10.8013 - val_mae: 20.9496 - val_mape: 9.1382 - lr: 9.0000e-06\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1537 - mae: 29.2246 - mape: 11.4911 - val_loss: 10.7844 - val_mae: 20.5488 - val_mape: 9.1219 - lr: 9.0000e-06\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.1397 - mae: 31.2139 - mape: 11.4776 - val_loss: 10.8344 - val_mae: 20.6470 - val_mape: 9.1729 - lr: 9.0000e-06\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.9925 - mae: 28.3333 - mape: 11.3312 - val_loss: 10.8022 - val_mae: 20.0290 - val_mape: 9.1414 - lr: 9.0000e-06\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.8546 - mae: 29.1157 - mape: 11.1943 - val_loss: 10.8224 - val_mae: 19.1130 - val_mape: 9.1625 - lr: 9.0000e-06\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1137 - mae: 32.0517 - mape: 11.4543 - val_loss: 10.9775 - val_mae: 20.4384 - val_mape: 9.3190 - lr: 9.0000e-06\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1901 - mae: 30.2494 - mape: 11.5315 - val_loss: 10.8027 - val_mae: 19.1668 - val_mape: 9.1441 - lr: 9.0000e-06\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.3496 - mae: 29.9503 - mape: 11.6918 - val_loss: 11.0086 - val_mae: 20.1004 - val_mape: 9.3517 - lr: 9.0000e-06\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1305 - mae: 30.0082 - mape: 11.4735 - val_loss: 10.8055 - val_mae: 19.6770 - val_mape: 9.1487 - lr: 9.0000e-06\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1310 - mae: 30.3725 - mape: 11.4745 - val_loss: 10.9818 - val_mae: 20.1959 - val_mape: 9.3262 - lr: 9.0000e-06\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.3840 - mae: 30.9390 - mape: 11.7285 - val_loss: 10.8539 - val_mae: 20.3065 - val_mape: 9.1983 - lr: 9.0000e-06\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.2095 - mae: 29.7985 - mape: 11.5540 - val_loss: 10.6720 - val_mae: 20.1732 - val_mape: 9.0167 - lr: 9.0000e-06\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1066 - mae: 31.5610 - mape: 11.4517 - val_loss: 10.8156 - val_mae: 19.5764 - val_mape: 9.1612 - lr: 9.0000e-06\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0796 - mae: 29.2723 - mape: 11.4259 - val_loss: 10.7445 - val_mae: 20.4431 - val_mape: 9.0909 - lr: 9.0000e-06\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.9668 - mae: 30.4265 - mape: 11.3137 - val_loss: 10.7900 - val_mae: 21.0589 - val_mape: 9.1374 - lr: 9.0000e-06\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.9379 - mae: 31.3108 - mape: 11.2854 - val_loss: 10.7523 - val_mae: 19.9510 - val_mape: 9.0998 - lr: 9.0000e-06\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3796 - mae: 29.4895 - mape: 11.7274 - val_loss: 10.7285 - val_mae: 19.1192 - val_mape: 9.0759 - lr: 9.0000e-06\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9252 - mae: 31.0917 - mape: 11.2723 - val_loss: 10.8917 - val_mae: 18.7512 - val_mape: 9.2393 - lr: 9.0000e-06\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.1686 - mae: 28.8966 - mape: 11.5173 - val_loss: 10.8015 - val_mae: 19.8808 - val_mape: 9.1510 - lr: 9.0000e-06\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0098 - mae: 30.0415 - mape: 11.3599 - val_loss: 10.7455 - val_mae: 19.2258 - val_mape: 9.0959 - lr: 9.0000e-06\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.9726 - mae: 28.4696 - mape: 11.3232 - val_loss: 10.7825 - val_mae: 20.0073 - val_mape: 9.1331 - lr: 9.0000e-06\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.2412 - mae: 31.0434 - mape: 11.5926 - val_loss: 11.1351 - val_mae: 20.5638 - val_mape: 9.4875 - lr: 9.0000e-06\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.2094 - mae: 31.7611 - mape: 11.5615 - val_loss: 10.7109 - val_mae: 19.1282 - val_mape: 9.0629 - lr: 9.0000e-06\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1045 - mae: 30.1073 - mape: 11.4569 - val_loss: 11.0503 - val_mae: 19.6470 - val_mape: 9.4037 - lr: 9.0000e-06\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 13.2092 - mae: 30.5707 - mape: 11.5628 - val_loss: 10.7611 - val_mae: 19.9655 - val_mape: 9.1150 - lr: 9.0000e-06\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.3084 - mae: 31.1541 - mape: 11.6627\n",
      "Epoch 145: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.3084 - mae: 31.1541 - mape: 11.6627 - val_loss: 10.7914 - val_mae: 20.4212 - val_mape: 9.1462 - lr: 9.0000e-06\n",
      "Epoch 145: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 11.315043449401855; mae of 16.840408325195312; mape of 7.731719017028809%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n",
      " 1/87 [..............................] - ETA: 1:23 - loss: 19.2029 - mae: 15.8498 - mape: 14.9197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.6641 - mae: 29.5758 - mape: 12.4675"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 97ms/step - loss: 16.6641 - mae: 29.5758 - mape: 12.4675 - val_loss: 12.8377 - val_mae: 21.7694 - val_mape: 8.7109 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 80ms/step - loss: 16.5033 - mae: 32.6487 - mape: 12.4349 - val_loss: 12.9469 - val_mae: 20.1785 - val_mape: 8.9350 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 16.5711 - mae: 32.6733 - mape: 12.6098"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 16.5711 - mae: 32.6733 - mape: 12.6098 - val_loss: 12.1709 - val_mae: 19.1236 - val_mape: 8.2603 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.5563 - mae: 33.7897 - mape: 12.6943"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 107ms/step - loss: 16.5563 - mae: 33.7897 - mape: 12.6943 - val_loss: 11.7538 - val_mae: 20.9116 - val_mape: 7.9396 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      " 2/87 [..............................] - ETA: 7s - loss: 17.0288 - mae: 27.1123 - mape: 13.2150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 79ms/step - loss: 16.0528 - mae: 31.1819 - mape: 12.2838 - val_loss: 11.8061 - val_mae: 24.1761 - val_mape: 8.0816 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.4982 - mae: 31.4363 - mape: 12.8148 - val_loss: 11.5884 - val_mae: 19.4880 - val_mape: 7.9468 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 16.1615 - mae: 32.9993 - mape: 12.5574 - val_loss: 11.9079 - val_mae: 22.4268 - val_mape: 8.3422 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.9162 - mae: 33.1111 - mape: 12.3885 - val_loss: 12.6731 - val_mae: 24.1460 - val_mape: 9.1825 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.8559 - mae: 31.1705 - mape: 12.4018 - val_loss: 11.7133 - val_mae: 18.8599 - val_mape: 8.2970 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.7282 - mae: 32.6500 - mape: 12.3439 - val_loss: 11.5743 - val_mae: 20.1705 - val_mape: 8.2206 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.8246 - mae: 30.6700 - mape: 12.5035 - val_loss: 11.4392 - val_mae: 18.3614 - val_mape: 8.1486 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.8772 - mae: 34.1383 - mape: 12.6141 - val_loss: 11.6264 - val_mae: 17.8966 - val_mape: 8.3889 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.6214 - mae: 33.0880 - mape: 12.4112 - val_loss: 11.5432 - val_mae: 29.3193 - val_mape: 8.3623 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.6731 - mae: 34.0490 - mape: 12.5169 - val_loss: 12.9463 - val_mae: 26.0006 - val_mape: 9.8193 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.7854 - mae: 33.3052 - mape: 12.6808 - val_loss: 11.2397 - val_mae: 18.2170 - val_mape: 8.1592 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.4791 - mae: 33.3594 - mape: 12.4237 - val_loss: 11.3405 - val_mae: 22.5810 - val_mape: 8.3119 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.3017 - mae: 30.8644 - mape: 12.2933 - val_loss: 11.5015 - val_mae: 20.5032 - val_mape: 8.5159 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.1202 - mae: 31.2031 - mape: 12.1563 - val_loss: 11.0725 - val_mae: 17.1363 - val_mape: 8.1295 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.3219 - mae: 33.8042 - mape: 12.3987 - val_loss: 11.9487 - val_mae: 20.6616 - val_mape: 9.0459 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.9462 - mae: 32.5391 - mape: 12.0637 - val_loss: 12.0513 - val_mae: 21.2155 - val_mape: 9.1882 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.1478 - mae: 32.2103 - mape: 12.3015 - val_loss: 11.7038 - val_mae: 19.7168 - val_mape: 8.8773 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.0257 - mae: 32.8446 - mape: 12.2150 - val_loss: 11.7899 - val_mae: 22.1049 - val_mape: 8.9992 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.8285 - mae: 31.5876 - mape: 12.0545 - val_loss: 11.5224 - val_mae: 19.4782 - val_mape: 8.7672 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.0666 - mae: 33.9100 - mape: 12.3266 - val_loss: 11.8772 - val_mae: 27.8137 - val_mape: 9.1545 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.8686 - mae: 31.4958 - mape: 12.1604 - val_loss: 11.5468 - val_mae: 24.5896 - val_mape: 8.8574 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.8191 - mae: 31.7441 - mape: 12.1456 - val_loss: 11.2382 - val_mae: 20.2029 - val_mape: 8.5799 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.0100 - mae: 32.2961 - mape: 12.3684 - val_loss: 10.8869 - val_mae: 18.8405 - val_mape: 8.2590 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.7717 - mae: 33.4780 - mape: 12.1587 - val_loss: 12.3465 - val_mae: 26.2661 - val_mape: 9.7506 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 14.7836 - mae: 34.1657 - mape: 12.2008 - val_loss: 10.7958 - val_mae: 17.0983 - val_mape: 8.2254 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.1508 - mae: 31.9841 - mape: 12.5949 - val_loss: 11.0799 - val_mae: 22.6896 - val_mape: 8.5380 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.8612 - mae: 33.7573 - mape: 12.3318 - val_loss: 10.7167 - val_mae: 23.2346 - val_mape: 8.1989 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 14.7146 - mae: 33.2825 - mape: 12.2111 - val_loss: 10.9536 - val_mae: 19.7475 - val_mape: 8.4618 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.6063 - mae: 31.7207 - mape: 12.1288 - val_loss: 10.8252 - val_mae: 19.2567 - val_mape: 8.3602 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 14.6406 - mae: 30.0805 - mape: 12.1895 - val_loss: 10.8829 - val_mae: 20.7405 - val_mape: 8.4439 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.1747 - mae: 33.6213 - mape: 12.7480 - val_loss: 10.9332 - val_mae: 20.5302 - val_mape: 8.5173 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 14.6713 - mae: 32.0177 - mape: 12.2713 - val_loss: 10.7163 - val_mae: 21.3147 - val_mape: 8.3293 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 14.6507 - mae: 31.9200 - mape: 12.2748 - val_loss: 10.9951 - val_mae: 24.3713 - val_mape: 8.6323 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 14.6537 - mae: 32.6462 - mape: 12.3026 - val_loss: 11.1488 - val_mae: 19.8567 - val_mape: 8.8083 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.7291 - mae: 33.9666 - mape: 12.3978 - val_loss: 10.9563 - val_mae: 19.6792 - val_mape: 8.6358 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.4816 - mae: 33.0590 - mape: 12.1734 - val_loss: 10.6616 - val_mae: 21.2788 - val_mape: 8.3645 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.7046 - mae: 31.7471 - mape: 12.4206 - val_loss: 10.8839 - val_mae: 21.1740 - val_mape: 8.6089 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.8621 - mae: 36.1960 - mape: 12.5978 - val_loss: 10.8721 - val_mae: 23.0254 - val_mape: 8.6183 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.3727 - mae: 33.8213 - mape: 12.1284 - val_loss: 10.7811 - val_mae: 20.8617 - val_mape: 8.5453 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 14.3266 - mae: 32.0002 - mape: 12.1012 - val_loss: 11.2380 - val_mae: 19.8560 - val_mape: 9.0205 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 14.3096 - mae: 30.6472 - mape: 12.1044 - val_loss: 10.8736 - val_mae: 19.4152 - val_mape: 8.6784 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.3660 - mae: 29.6586 - mape: 12.1818 - val_loss: 10.6904 - val_mae: 20.5769 - val_mape: 8.5189 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.1716 - mae: 31.5631 - mape: 12.0068 - val_loss: 11.1260 - val_mae: 20.4102 - val_mape: 8.9682 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.6450 - mae: 33.6740 - mape: 12.4959 - val_loss: 11.0383 - val_mae: 20.9218 - val_mape: 8.8980 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.9753 - mae: 30.6366 - mape: 11.8433 - val_loss: 10.9684 - val_mae: 22.5838 - val_mape: 8.8430 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.2371 - mae: 32.6105 - mape: 12.1190 - val_loss: 11.2272 - val_mae: 23.6819 - val_mape: 9.1163 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.2552 - mae: 32.0495 - mape: 12.1533 - val_loss: 14.2992 - val_mae: 27.4710 - val_mape: 12.2090 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.2136 - mae: 31.4490 - mape: 12.1302 - val_loss: 10.8182 - val_mae: 23.7054 - val_mape: 8.7411 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.2130 - mae: 32.6087 - mape: 12.1452 - val_loss: 11.0549 - val_mae: 29.6139 - val_mape: 8.9997 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.1212 - mae: 34.0902 - mape: 12.0739 - val_loss: 10.8267 - val_mae: 23.1167 - val_mape: 8.7847 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.1900 - mae: 32.7282 - mape: 12.1579 - val_loss: 10.6244 - val_mae: 19.5002 - val_mape: 8.5989 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.0629 - mae: 31.8299 - mape: 12.0459 - val_loss: 10.3732 - val_mae: 18.5311 - val_mape: 8.3609 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.3342 - mae: 33.0514 - mape: 12.3285 - val_loss: 10.6054 - val_mae: 23.4415 - val_mape: 8.6061 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.2138 - mae: 33.2269 - mape: 12.2214 - val_loss: 10.6475 - val_mae: 18.3779 - val_mape: 8.6590 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.9617 - mae: 29.6803 - mape: 11.9815 - val_loss: 11.5304 - val_mae: 26.9677 - val_mape: 9.5575 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.8279 - mae: 32.7373 - mape: 11.8628 - val_loss: 10.5923 - val_mae: 21.0151 - val_mape: 8.6338 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.0242 - mae: 32.8235 - mape: 12.0736 - val_loss: 12.6587 - val_mae: 25.4692 - val_mape: 10.7178 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 14.1540 - mae: 32.3594 - mape: 12.2182 - val_loss: 11.3875 - val_mae: 21.1147 - val_mape: 9.4588 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 13.7667 - mae: 32.9609 - mape: 11.8424 - val_loss: 10.5107 - val_mae: 17.5643 - val_mape: 8.5890 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 13.8282 - mae: 32.9110 - mape: 11.9143 - val_loss: 10.8487 - val_mae: 20.2605 - val_mape: 8.9433 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.6385 - mae: 31.2351 - mape: 11.7397 - val_loss: 11.9769 - val_mae: 24.3337 - val_mape: 10.0806 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.9393 - mae: 32.6158 - mape: 12.0488 - val_loss: 10.5865 - val_mae: 20.8171 - val_mape: 8.7021 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.6915 - mae: 30.5514 - mape: 11.8139 - val_loss: 10.6437 - val_mae: 21.4519 - val_mape: 8.7711 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.6376 - mae: 33.0959 - mape: 11.7711 - val_loss: 10.5070 - val_mae: 19.3913 - val_mape: 8.6447 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.8291 - mae: 32.4484 - mape: 11.9745 - val_loss: 10.5342 - val_mae: 20.3720 - val_mape: 8.6869 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.8576 - mae: 31.3948 - mape: 12.0176 - val_loss: 12.2224 - val_mae: 24.5027 - val_mape: 10.3914 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.9498 - mae: 33.2583 - mape: 12.1215 - val_loss: 12.7392 - val_mae: 22.5309 - val_mape: 10.9146 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.7509 - mae: 30.9192 - mape: 11.9331 - val_loss: 10.4700 - val_mae: 19.3275 - val_mape: 8.6594 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.6007 - mae: 30.5783 - mape: 11.7965 - val_loss: 10.5694 - val_mae: 22.5391 - val_mape: 8.7696 - lr: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.7176 - mae: 32.2548 - mape: 11.9234 - val_loss: 10.9808 - val_mae: 27.0039 - val_mape: 9.1928 - lr: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.8465 - mae: 31.4564 - mape: 12.0651 - val_loss: 11.4964 - val_mae: 21.9535 - val_mape: 9.7237 - lr: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.7548 - mae: 31.2281 - mape: 11.9867 - val_loss: 10.8358 - val_mae: 24.3714 - val_mape: 9.0739 - lr: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.5293 - mae: 34.7080 - mape: 11.7706 - val_loss: 10.6735 - val_mae: 23.0593 - val_mape: 8.9144 - lr: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 13.5785 - mae: 33.7082 - mape: 11.8265 - val_loss: 11.2248 - val_mae: 27.2691 - val_mape: 9.4792 - lr: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.5557 - mae: 32.4038 - mape: 11.8125 - val_loss: 11.0883 - val_mae: 23.2921 - val_mape: 9.3514 - lr: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.6462 - mae: 32.6844 - mape: 11.9151 - val_loss: 10.4885 - val_mae: 23.1221 - val_mape: 8.7597 - lr: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.2545 - mae: 31.4237 - mape: 11.5287 - val_loss: 10.9117 - val_mae: 25.0498 - val_mape: 9.1850 - lr: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.2742 - mae: 31.6311 - mape: 11.5552 - val_loss: 10.7236 - val_mae: 22.0570 - val_mape: 9.0116 - lr: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.4877 - mae: 31.9870 - mape: 11.7815 - val_loss: 11.5176 - val_mae: 22.3946 - val_mape: 9.8144 - lr: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.4312 - mae: 29.8545 - mape: 11.7303 - val_loss: 10.3851 - val_mae: 18.7074 - val_mape: 8.6889 - lr: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.7231 - mae: 30.4638 - mape: 12.0329 - val_loss: 11.8803 - val_mae: 23.0470 - val_mape: 10.1958 - lr: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.9065 - mae: 32.9388 - mape: 12.2256\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.9065 - mae: 32.9388 - mape: 12.2256 - val_loss: 11.7495 - val_mae: 22.8030 - val_mape: 10.0738 - lr: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.1268 - mae: 31.5859 - mape: 11.4527 - val_loss: 10.8443 - val_mae: 21.8612 - val_mape: 9.1723 - lr: 3.0000e-05\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.3212 - mae: 29.8489 - mape: 11.6496 - val_loss: 11.0735 - val_mae: 23.3664 - val_mape: 9.4029 - lr: 3.0000e-05\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.5219 - mae: 31.8282 - mape: 11.8536 - val_loss: 10.2288 - val_mae: 19.4473 - val_mape: 8.5615 - lr: 3.0000e-05\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 13.3448 - mae: 32.2428 - mape: 11.6795 - val_loss: 10.8057 - val_mae: 20.2418 - val_mape: 9.1418 - lr: 3.0000e-05\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.2931 - mae: 31.8755 - mape: 11.6313 - val_loss: 10.8491 - val_mae: 21.1381 - val_mape: 9.1890 - lr: 3.0000e-05\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.1470 - mae: 30.1495 - mape: 11.4893 - val_loss: 10.2815 - val_mae: 20.1703 - val_mape: 8.6254 - lr: 3.0000e-05\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.1460 - mae: 29.8486 - mape: 11.4907 - val_loss: 10.7107 - val_mae: 24.4655 - val_mape: 9.0560 - lr: 3.0000e-05\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.3870 - mae: 33.5176 - mape: 11.7337 - val_loss: 10.5094 - val_mae: 22.1287 - val_mape: 8.8579 - lr: 3.0000e-05\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.4291 - mae: 32.0434 - mape: 11.7782 - val_loss: 11.1144 - val_mae: 23.5873 - val_mape: 9.4648 - lr: 3.0000e-05\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 13.4458 - mae: 32.5983 - mape: 11.7963 - val_loss: 10.8957 - val_mae: 22.2890 - val_mape: 9.2470 - lr: 3.0000e-05\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.2944 - mae: 29.8331 - mape: 11.6475 - val_loss: 10.6941 - val_mae: 23.1329 - val_mape: 9.0491 - lr: 3.0000e-05\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.1645 - mae: 30.8622 - mape: 11.5212 - val_loss: 11.1348 - val_mae: 21.6924 - val_mape: 9.4924 - lr: 3.0000e-05\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.4365 - mae: 32.2449 - mape: 11.7952 - val_loss: 10.6408 - val_mae: 23.4615 - val_mape: 9.0010 - lr: 3.0000e-05\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.1108 - mae: 29.9532 - mape: 11.4714 - val_loss: 10.5305 - val_mae: 20.9398 - val_mape: 8.8918 - lr: 3.0000e-05\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.1211 - mae: 30.2275 - mape: 11.4837 - val_loss: 10.6889 - val_mae: 20.8312 - val_mape: 9.0524 - lr: 3.0000e-05\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.3587 - mae: 32.3519 - mape: 11.7236 - val_loss: 10.4176 - val_mae: 20.6081 - val_mape: 8.7839 - lr: 3.0000e-05\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.3714 - mae: 31.6384 - mape: 11.7398 - val_loss: 10.3467 - val_mae: 21.4141 - val_mape: 8.7166 - lr: 3.0000e-05\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.2284 - mae: 32.1598 - mape: 11.6001 - val_loss: 11.1252 - val_mae: 23.0668 - val_mape: 9.4984 - lr: 3.0000e-05\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 12.9620 - mae: 30.6664 - mape: 11.3352 - val_loss: 10.6479 - val_mae: 20.0009 - val_mape: 9.0231 - lr: 3.0000e-05\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.2937 - mae: 31.7424 - mape: 11.6694 - val_loss: 10.8116 - val_mae: 20.8585 - val_mape: 9.1886 - lr: 3.0000e-05\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 12.9670 - mae: 31.2541 - mape: 11.3449 - val_loss: 11.2659 - val_mae: 21.0712 - val_mape: 9.6460 - lr: 3.0000e-05\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 12.9466 - mae: 30.7839 - mape: 11.3272 - val_loss: 11.0921 - val_mae: 21.7564 - val_mape: 9.4737 - lr: 3.0000e-05\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.1386 - mae: 30.8139 - mape: 11.5199 - val_loss: 11.3028 - val_mae: 23.2764 - val_mape: 9.6849 - lr: 3.0000e-05\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.0958 - mae: 29.9434 - mape: 11.4786 - val_loss: 10.3725 - val_mae: 21.3569 - val_mape: 8.7563 - lr: 3.0000e-05\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.4614 - mae: 31.8405 - mape: 11.8465 - val_loss: 10.7458 - val_mae: 23.3459 - val_mape: 9.1326 - lr: 3.0000e-05\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.2009 - mae: 32.8128 - mape: 11.5888 - val_loss: 10.9378 - val_mae: 22.7125 - val_mape: 9.3277 - lr: 3.0000e-05\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.2399 - mae: 33.3150 - mape: 11.6302 - val_loss: 10.9653 - val_mae: 22.0675 - val_mape: 9.3567 - lr: 3.0000e-05\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.0974 - mae: 31.3594 - mape: 11.4909 - val_loss: 10.2849 - val_mae: 21.2397 - val_mape: 8.6786 - lr: 3.0000e-05\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.3642 - mae: 31.7117 - mape: 11.7597 - val_loss: 10.5185 - val_mae: 21.3825 - val_mape: 8.9154 - lr: 3.0000e-05\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.3291 - mae: 32.7518 - mape: 11.7273 - val_loss: 11.1047 - val_mae: 21.5514 - val_mape: 9.5041 - lr: 3.0000e-05\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.4444 - mae: 30.1741 - mape: 11.8451 - val_loss: 10.6371 - val_mae: 22.6624 - val_mape: 9.0390 - lr: 3.0000e-05\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.2202 - mae: 32.7621 - mape: 11.6225 - val_loss: 10.8627 - val_mae: 22.8312 - val_mape: 9.2655 - lr: 3.0000e-05\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.9523 - mae: 29.2151 - mape: 11.3559\n",
      "Epoch 119: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.9523 - mae: 29.2151 - mape: 11.3559 - val_loss: 10.6022 - val_mae: 22.1394 - val_mape: 9.0073 - lr: 3.0000e-05\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.0785 - mae: 29.4449 - mape: 11.4845 - val_loss: 10.7359 - val_mae: 21.3234 - val_mape: 9.1426 - lr: 9.0000e-06\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 12.9880 - mae: 31.5642 - mape: 11.3950 - val_loss: 10.8737 - val_mae: 23.6798 - val_mape: 9.2811 - lr: 9.0000e-06\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.2872 - mae: 29.6968 - mape: 11.6948 - val_loss: 10.6738 - val_mae: 21.2100 - val_mape: 9.0816 - lr: 9.0000e-06\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.1102 - mae: 31.5556 - mape: 11.5181 - val_loss: 10.4172 - val_mae: 20.0255 - val_mape: 8.8252 - lr: 9.0000e-06\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 12.9505 - mae: 31.7641 - mape: 11.3589 - val_loss: 10.4709 - val_mae: 20.5045 - val_mape: 8.8792 - lr: 9.0000e-06\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.0198 - mae: 30.5205 - mape: 11.4288 - val_loss: 10.7666 - val_mae: 20.2685 - val_mape: 9.1760 - lr: 9.0000e-06\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.0978 - mae: 30.7163 - mape: 11.5074 - val_loss: 10.5997 - val_mae: 21.4488 - val_mape: 9.0100 - lr: 9.0000e-06\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.1039 - mae: 30.6604 - mape: 11.5148 - val_loss: 10.5215 - val_mae: 22.2182 - val_mape: 8.9329 - lr: 9.0000e-06\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.0415 - mae: 32.5184 - mape: 11.4532 - val_loss: 10.6341 - val_mae: 21.3014 - val_mape: 9.0463 - lr: 9.0000e-06\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1840 - mae: 32.1805 - mape: 11.5967 - val_loss: 10.5385 - val_mae: 20.8408 - val_mape: 8.9513 - lr: 9.0000e-06\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.1960 - mae: 32.4155 - mape: 11.6090 - val_loss: 10.7714 - val_mae: 21.0397 - val_mape: 9.1849 - lr: 9.0000e-06\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.3094 - mae: 32.2624 - mape: 11.7231 - val_loss: 10.3915 - val_mae: 21.0728 - val_mape: 8.8055 - lr: 9.0000e-06\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.3526 - mae: 31.9314 - mape: 11.7672 - val_loss: 10.3463 - val_mae: 19.7929 - val_mape: 8.7608 - lr: 9.0000e-06\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 13.1770 - mae: 30.9316 - mape: 11.5916 - val_loss: 10.6376 - val_mae: 20.9475 - val_mape: 9.0525 - lr: 9.0000e-06\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 13.2321 - mae: 32.4440 - mape: 11.6480 - val_loss: 11.0132 - val_mae: 21.9764 - val_mape: 9.4301 - lr: 9.0000e-06\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.1268 - mae: 30.7405 - mape: 11.5430 - val_loss: 10.6187 - val_mae: 20.2706 - val_mape: 9.0351 - lr: 9.0000e-06\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1807 - mae: 31.0153 - mape: 11.5972 - val_loss: 10.6308 - val_mae: 21.0245 - val_mape: 9.0476 - lr: 9.0000e-06\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.1224 - mae: 34.7621 - mape: 11.5394 - val_loss: 10.5145 - val_mae: 21.0025 - val_mape: 8.9316 - lr: 9.0000e-06\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.1458 - mae: 30.3416 - mape: 11.5632 - val_loss: 10.6024 - val_mae: 21.7112 - val_mape: 9.0201 - lr: 9.0000e-06\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.1876 - mae: 32.7156 - mape: 11.6059 - val_loss: 10.5346 - val_mae: 21.7782 - val_mape: 8.9533 - lr: 9.0000e-06\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.0532 - mae: 30.1808 - mape: 11.4723 - val_loss: 10.9636 - val_mae: 21.0371 - val_mape: 9.3830 - lr: 9.0000e-06\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.9280 - mae: 29.9503 - mape: 11.3474 - val_loss: 10.5873 - val_mae: 21.3214 - val_mape: 9.0072 - lr: 9.0000e-06\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.1044 - mae: 30.7790 - mape: 11.5249 - val_loss: 10.3901 - val_mae: 20.9677 - val_mape: 8.8105 - lr: 9.0000e-06\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.9889 - mae: 30.2339 - mape: 11.4103 - val_loss: 10.4250 - val_mae: 21.3619 - val_mape: 8.8463 - lr: 9.0000e-06\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.8945 - mae: 29.4939 - mape: 11.3161 - val_loss: 10.5002 - val_mae: 20.9205 - val_mape: 8.9220 - lr: 9.0000e-06\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.9407 - mae: 32.3415 - mape: 11.3632 - val_loss: 10.5616 - val_mae: 21.6427 - val_mape: 8.9846 - lr: 9.0000e-06\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.1840 - mae: 31.8624 - mape: 11.6072 - val_loss: 10.6331 - val_mae: 22.4642 - val_mape: 9.0564 - lr: 9.0000e-06\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 12.9262 - mae: 30.1882 - mape: 11.3496 - val_loss: 10.6954 - val_mae: 21.6869 - val_mape: 9.1191 - lr: 9.0000e-06\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.0846 - mae: 32.3449 - mape: 11.5088 - val_loss: 10.8370 - val_mae: 24.6067 - val_mape: 9.2621 - lr: 9.0000e-06\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 13.1603 - mae: 32.0243 - mape: 11.5854\n",
      "Epoch 149: ReduceLROnPlateau reducing learning rate to 2.6999998226528985e-06.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.1603 - mae: 32.0243 - mape: 11.5854 - val_loss: 10.7546 - val_mae: 23.0705 - val_mape: 9.1802 - lr: 9.0000e-06\n",
      "Epoch 149: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 11.753775596618652; mae of 20.91160774230957; mape of 7.9395670890808105%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 16.7581 - mae: 33.0194 - mape: 12.5512"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_nosupp_additional_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 103ms/step - loss: 16.7581 - mae: 33.0194 - mape: 12.5512 - val_loss: 13.3295 - val_mae: 22.2204 - val_mape: 9.1866 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 88ms/step - loss: 16.5897 - mae: 32.4035 - mape: 12.5112 - val_loss: 14.0111 - val_mae: 17.7208 - val_mape: 9.9959 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 16.4430 - mae: 32.7704 - mape: 12.4839 - val_loss: 14.4757 - val_mae: 25.3844 - val_mape: 10.5765 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 15.9952 - mae: 34.4307 - mape: 12.1501 - val_loss: 13.5539 - val_mae: 19.1273 - val_mape: 9.7657 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.8574 - mae: 32.3010 - mape: 12.1218 - val_loss: 12.9503 - val_mae: 16.7742 - val_mape: 9.2638 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.5302 - mae: 31.3086 - mape: 11.8953 - val_loss: 13.6070 - val_mae: 18.3751 - val_mape: 10.0217 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.6369 - mae: 32.1901 - mape: 12.0984 - val_loss: 13.0331 - val_mae: 21.4019 - val_mape: 9.5409 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 15.4995 - mae: 30.2635 - mape: 12.0499 - val_loss: 12.9073 - val_mae: 20.1792 - val_mape: 9.4997 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.4170 - mae: 33.8165 - mape: 12.0514 - val_loss: 14.8154 - val_mae: 27.8322 - val_mape: 11.4927 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 15.3292 - mae: 32.0206 - mape: 12.0439 - val_loss: 13.1343 - val_mae: 25.6650 - val_mape: 9.8885 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 15.3532 - mae: 30.0138 - mape: 12.1450 - val_loss: 12.7243 - val_mae: 18.7435 - val_mape: 9.5505 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 15.2385 - mae: 30.9982 - mape: 12.1000 - val_loss: 13.2441 - val_mae: 30.1387 - val_mape: 10.1413 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 15.0460 - mae: 30.9955 - mape: 11.9734 - val_loss: 12.7244 - val_mae: 21.0370 - val_mape: 9.6844 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 15.1009 - mae: 32.7052 - mape: 12.0923 - val_loss: 12.6748 - val_mae: 18.4417 - val_mape: 9.6976 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 15.0271 - mae: 31.2059 - mape: 12.0803 - val_loss: 12.3256 - val_mae: 17.3756 - val_mape: 9.4106 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.7232 - mae: 30.8361 - mape: 11.8372 - val_loss: 13.5940 - val_mae: 26.9511 - val_mape: 10.7390 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.9217 - mae: 30.9810 - mape: 12.0935 - val_loss: 13.1974 - val_mae: 26.3149 - val_mape: 10.3938 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.8103 - mae: 30.7177 - mape: 12.0322 - val_loss: 13.2170 - val_mae: 22.9881 - val_mape: 10.4659 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.8474 - mae: 32.2980 - mape: 12.1212 - val_loss: 12.3773 - val_mae: 18.6917 - val_mape: 9.6758 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.7906 - mae: 32.2250 - mape: 12.1157 - val_loss: 12.6949 - val_mae: 24.7861 - val_mape: 10.0450 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 14.6350 - mae: 29.7807 - mape: 12.0061 - val_loss: 12.6444 - val_mae: 21.0844 - val_mape: 10.0378 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.6809 - mae: 32.7373 - mape: 12.0978 - val_loss: 12.7332 - val_mae: 35.3162 - val_mape: 10.1713 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 14.3894 - mae: 30.7423 - mape: 11.8463 - val_loss: 12.4582 - val_mae: 23.3481 - val_mape: 9.9373 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 14.4562 - mae: 31.2456 - mape: 11.9551 - val_loss: 12.2265 - val_mae: 23.1002 - val_mape: 9.7445 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.0892 - mae: 30.0343 - mape: 11.6281 - val_loss: 12.1566 - val_mae: 17.6452 - val_mape: 9.7163 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.1076 - mae: 30.4716 - mape: 11.6862 - val_loss: 12.0402 - val_mae: 19.1229 - val_mape: 9.6352 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.4384 - mae: 30.9046 - mape: 12.0537 - val_loss: 13.3988 - val_mae: 22.3942 - val_mape: 11.0296 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.5835 - mae: 30.6612 - mape: 12.2314 - val_loss: 12.2673 - val_mae: 21.6303 - val_mape: 9.9312 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.1303 - mae: 33.2486 - mape: 11.8120 - val_loss: 12.4677 - val_mae: 25.6327 - val_mape: 10.1655 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 14.2219 - mae: 33.5108 - mape: 11.9346 - val_loss: 12.9895 - val_mae: 25.4688 - val_mape: 10.7178 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.1942 - mae: 32.6149 - mape: 11.9394 - val_loss: 12.3703 - val_mae: 19.7511 - val_mape: 10.1340 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.9955 - mae: 33.0764 - mape: 11.7736 - val_loss: 12.7624 - val_mae: 22.1696 - val_mape: 10.5566 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 14.2554 - mae: 32.3573 - mape: 12.0637 - val_loss: 13.8380 - val_mae: 28.5185 - val_mape: 11.6611 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 14.2844 - mae: 32.2668 - mape: 12.1216 - val_loss: 12.2083 - val_mae: 20.2838 - val_mape: 10.0593 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 14.2041 - mae: 33.2077 - mape: 12.0698 - val_loss: 12.8484 - val_mae: 23.7601 - val_mape: 10.7259 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 14.3505 - mae: 33.0701 - mape: 12.2407 - val_loss: 11.8936 - val_mae: 20.4840 - val_mape: 9.7969 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.1853 - mae: 32.5017 - mape: 12.1032 - val_loss: 12.2254 - val_mae: 25.4380 - val_mape: 10.1574 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 14.0811 - mae: 31.4409 - mape: 12.0259 - val_loss: 12.2312 - val_mae: 20.0178 - val_mape: 10.1924 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.8929 - mae: 31.3201 - mape: 11.8636 - val_loss: 12.5092 - val_mae: 28.0110 - val_mape: 10.4930 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.8895 - mae: 33.5600 - mape: 11.8814 - val_loss: 12.4418 - val_mae: 19.5835 - val_mape: 10.4446 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.6908 - mae: 32.4224 - mape: 11.7060 - val_loss: 12.4974 - val_mae: 27.6933 - val_mape: 10.5240 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.8215 - mae: 29.2416 - mape: 11.8593 - val_loss: 12.3529 - val_mae: 19.4897 - val_mape: 10.4022 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.7324 - mae: 32.1645 - mape: 11.7902 - val_loss: 12.7193 - val_mae: 22.3575 - val_mape: 10.7862 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.7902 - mae: 29.7098 - mape: 11.8649 - val_loss: 11.7943 - val_mae: 22.6602 - val_mape: 9.8769 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.5999 - mae: 29.4720 - mape: 11.6933 - val_loss: 11.7817 - val_mae: 20.2979 - val_mape: 9.8827 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.8093 - mae: 29.7644 - mape: 11.9214 - val_loss: 12.1426 - val_mae: 26.1207 - val_mape: 10.2649 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.5168 - mae: 29.9024 - mape: 11.6492 - val_loss: 13.6509 - val_mae: 31.8341 - val_mape: 11.7935 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.6916 - mae: 31.2772 - mape: 11.8435 - val_loss: 11.7021 - val_mae: 19.7304 - val_mape: 9.8622 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.4997 - mae: 31.9320 - mape: 11.6693 - val_loss: 11.8833 - val_mae: 20.9884 - val_mape: 10.0623 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.5293 - mae: 29.6106 - mape: 11.7187 - val_loss: 12.1780 - val_mae: 20.0987 - val_mape: 10.3771 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.5957 - mae: 29.5459 - mape: 11.8040 - val_loss: 11.8215 - val_mae: 20.8710 - val_mape: 10.0375 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.3792 - mae: 32.0806 - mape: 11.6039 - val_loss: 12.5932 - val_mae: 19.8918 - val_mape: 10.8282 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.6205 - mae: 32.5449 - mape: 11.8632 - val_loss: 14.0381 - val_mae: 22.1899 - val_mape: 12.2885 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 13.8547 - mae: 31.5382 - mape: 12.1116 - val_loss: 11.7379 - val_mae: 22.8928 - val_mape: 10.0038 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.4405 - mae: 32.5011 - mape: 11.7152 - val_loss: 12.0969 - val_mae: 19.4313 - val_mape: 10.3791 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.1650 - mae: 31.0178 - mape: 11.4554 - val_loss: 12.4015 - val_mae: 26.9711 - val_mape: 10.7001 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.6895 - mae: 34.5013 - mape: 11.9958 - val_loss: 11.7326 - val_mae: 21.0675 - val_mape: 10.0453 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 13.1944 - mae: 31.1855 - mape: 11.5139 - val_loss: 12.3403 - val_mae: 31.0902 - val_mape: 10.6679 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.3575 - mae: 30.2199 - mape: 11.6902 - val_loss: 11.7444 - val_mae: 21.8357 - val_mape: 10.0847 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.3332 - mae: 29.9896 - mape: 11.6832 - val_loss: 12.6672 - val_mae: 29.8815 - val_mape: 11.0238 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.4682 - mae: 30.4216 - mape: 11.8305 - val_loss: 13.5102 - val_mae: 30.9717 - val_mape: 11.8804 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 13.1740 - mae: 32.5203 - mape: 11.5505 - val_loss: 11.9670 - val_mae: 28.6205 - val_mape: 10.3511 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.2758 - mae: 29.8389 - mape: 11.6655 - val_loss: 12.1136 - val_mae: 26.7538 - val_mape: 10.5109 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.2067 - mae: 30.0378 - mape: 11.6108 - val_loss: 12.2945 - val_mae: 20.6303 - val_mape: 10.7078 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 13.1045 - mae: 28.1755 - mape: 11.5212 - val_loss: 12.1459 - val_mae: 22.9107 - val_mape: 10.5699 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.2248 - mae: 29.8144 - mape: 11.6548 - val_loss: 12.4244 - val_mae: 22.5113 - val_mape: 10.8591 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.2837 - mae: 32.7909 - mape: 11.7241 - val_loss: 12.6665 - val_mae: 23.9134 - val_mape: 11.1154 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.3886 - mae: 34.3809 - mape: 11.8424 - val_loss: 12.7492 - val_mae: 27.4083 - val_mape: 11.2073 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.9051 - mae: 29.0282 - mape: 11.3679 - val_loss: 12.4643 - val_mae: 28.1387 - val_mape: 10.9336 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.0895 - mae: 29.5283 - mape: 11.5636 - val_loss: 12.5665 - val_mae: 30.6870 - val_mape: 11.0475 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 13.2599 - mae: 31.1708 - mape: 11.7450 - val_loss: 11.8061 - val_mae: 25.4241 - val_mape: 10.2961 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.2247 - mae: 30.0002 - mape: 11.7196 - val_loss: 12.9467 - val_mae: 23.1907 - val_mape: 11.4456 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 13.3235 - mae: 33.1028 - mape: 11.8279 - val_loss: 11.6747 - val_mae: 24.1109 - val_mape: 10.1843 - lr: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 12.9634 - mae: 28.7007 - mape: 11.4787 - val_loss: 11.9098 - val_mae: 27.3007 - val_mape: 10.4325 - lr: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.0718 - mae: 29.5854 - mape: 11.6006 - val_loss: 14.7943 - val_mae: 28.5108 - val_mape: 13.3314 - lr: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 13.2019 - mae: 29.6655 - mape: 11.7417 - val_loss: 12.1494 - val_mae: 27.2023 - val_mape: 10.6951 - lr: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 8s 91ms/step - loss: 13.1741 - mae: 28.8675 - mape: 11.7232 - val_loss: 12.0583 - val_mae: 22.7499 - val_mape: 10.6115 - lr: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 12.9504 - mae: 31.7308 - mape: 11.5061 - val_loss: 11.9743 - val_mae: 25.4923 - val_mape: 10.5331 - lr: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.0433 - mae: 30.3718 - mape: 11.6069 - val_loss: 11.8355 - val_mae: 19.9949 - val_mape: 10.4003 - lr: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 13.1194 - mae: 31.2565 - mape: 11.6895 - val_loss: 12.0216 - val_mae: 23.5410 - val_mape: 10.5964 - lr: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 12.9524 - mae: 31.2985 - mape: 11.5322 - val_loss: 12.8817 - val_mae: 20.8361 - val_mape: 11.4684 - lr: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 12.9984 - mae: 32.9434 - mape: 11.5887 - val_loss: 11.8323 - val_mae: 21.2895 - val_mape: 10.4262 - lr: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 13.0989 - mae: 31.2819 - mape: 11.6986 - val_loss: 11.5694 - val_mae: 20.6388 - val_mape: 10.1704 - lr: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 13.1927 - mae: 30.4604 - mape: 11.8001 - val_loss: 14.2332 - val_mae: 24.8333 - val_mape: 12.8454 - lr: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.0724 - mae: 33.0200 - mape: 11.6882 - val_loss: 11.5881 - val_mae: 18.4805 - val_mape: 10.2071 - lr: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.8636 - mae: 30.1215 - mape: 11.4858 - val_loss: 11.6858 - val_mae: 24.4959 - val_mape: 10.3113 - lr: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 12.9124 - mae: 30.4018 - mape: 11.5423 - val_loss: 11.4787 - val_mae: 19.4950 - val_mape: 10.1096 - lr: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 13.1447 - mae: 30.7549 - mape: 11.7811 - val_loss: 11.6435 - val_mae: 18.3542 - val_mape: 10.2847 - lr: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 13.0788 - mae: 32.3103 - mape: 11.7218 - val_loss: 11.5545 - val_mae: 20.9395 - val_mape: 10.2010 - lr: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.7122 - mae: 32.1493 - mape: 11.3618 - val_loss: 12.1591 - val_mae: 28.1555 - val_mape: 10.8134 - lr: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.7998 - mae: 29.0630 - mape: 11.4564 - val_loss: 11.6752 - val_mae: 25.7325 - val_mape: 10.3357 - lr: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 13.3712 - mae: 31.3040 - mape: 12.0360 - val_loss: 12.4040 - val_mae: 24.3047 - val_mape: 11.0766 - lr: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.8924 - mae: 29.7588 - mape: 11.5684 - val_loss: 11.7139 - val_mae: 24.3419 - val_mape: 10.3926 - lr: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 12.6945 - mae: 28.6690 - mape: 11.3776 - val_loss: 12.1154 - val_mae: 26.0853 - val_mape: 10.7989 - lr: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 8s 94ms/step - loss: 12.9792 - mae: 32.6519 - mape: 11.6697 - val_loss: 11.7603 - val_mae: 20.3281 - val_mape: 10.4564 - lr: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 12.8776 - mae: 29.9086 - mape: 11.5760 - val_loss: 11.6777 - val_mae: 19.6976 - val_mape: 10.3784 - lr: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.0502 - mae: 32.3235 - mape: 11.7544 - val_loss: 11.6786 - val_mae: 19.7310 - val_mape: 10.3844 - lr: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.8714 - mae: 30.6559 - mape: 11.5807 - val_loss: 12.8163 - val_mae: 22.0574 - val_mape: 11.5246 - lr: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.9236 - mae: 29.7488 - mape: 11.6361 - val_loss: 11.7262 - val_mae: 20.6147 - val_mape: 10.4422 - lr: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.7379 - mae: 31.5644 - mape: 11.4589 - val_loss: 12.3285 - val_mae: 26.6063 - val_mape: 11.0537 - lr: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.9188 - mae: 30.1522 - mape: 11.6453 - val_loss: 12.1300 - val_mae: 22.6223 - val_mape: 10.8571 - lr: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.7901 - mae: 30.7983 - mape: 11.5208 - val_loss: 12.4146 - val_mae: 26.2722 - val_mape: 11.1501 - lr: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.8179 - mae: 31.8223 - mape: 11.5563 - val_loss: 12.3150 - val_mae: 35.4884 - val_mape: 11.0565 - lr: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.9036 - mae: 29.9463 - mape: 11.6463 - val_loss: 12.2646 - val_mae: 21.3931 - val_mape: 11.0083 - lr: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.5803 - mae: 29.4092 - mape: 11.3280 - val_loss: 12.4228 - val_mae: 23.3878 - val_mape: 11.1715 - lr: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 12.7950 - mae: 32.1886 - mape: 11.5508 - val_loss: 11.7604 - val_mae: 27.7696 - val_mape: 10.5196 - lr: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 12.7550 - mae: 29.4140 - mape: 11.5159 - val_loss: 11.9084 - val_mae: 22.8656 - val_mape: 10.6733 - lr: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.5104 - mae: 29.6176 - mape: 11.2787 - val_loss: 11.5662 - val_mae: 23.7429 - val_mape: 10.3374 - lr: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3882 - mae: 29.1730 - mape: 11.1644 - val_loss: 11.8256 - val_mae: 23.6201 - val_mape: 10.6058 - lr: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 13.0378 - mae: 29.9138 - mape: 11.8212 - val_loss: 12.5559 - val_mae: 25.4686 - val_mape: 11.3426 - lr: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6813 - mae: 31.7432 - mape: 11.4725 - val_loss: 11.5511 - val_mae: 19.9801 - val_mape: 10.3433 - lr: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 76ms/step - loss: 12.4629 - mae: 28.6243 - mape: 11.2580 - val_loss: 11.8266 - val_mae: 19.5690 - val_mape: 10.6225 - lr: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5531 - mae: 28.2734 - mape: 11.3517 - val_loss: 11.4985 - val_mae: 24.4051 - val_mape: 10.3007 - lr: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.4965 - mae: 28.3570 - mape: 11.3028 - val_loss: 11.8220 - val_mae: 21.1615 - val_mape: 10.6303 - lr: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.4668 - mae: 29.0741 - mape: 11.2776 - val_loss: 11.5917 - val_mae: 25.2933 - val_mape: 10.4039 - lr: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 12.7970 - mae: 29.7877 - mape: 11.6138 - val_loss: 11.2926 - val_mae: 19.3441 - val_mape: 10.1112 - lr: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.6840 - mae: 29.3547 - mape: 11.5068 - val_loss: 11.7910 - val_mae: 21.0733 - val_mape: 10.6152 - lr: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.6107 - mae: 31.1769 - mape: 11.4346 - val_loss: 12.1908 - val_mae: 20.7186 - val_mape: 11.0191 - lr: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 13.1887 - mae: 31.4759 - mape: 12.0182 - val_loss: 11.7027 - val_mae: 24.3179 - val_mape: 10.5320 - lr: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.6360 - mae: 31.9025 - mape: 11.4688 - val_loss: 12.1514 - val_mae: 28.1537 - val_mape: 10.9867 - lr: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 12.3881 - mae: 28.0117 - mape: 11.2281 - val_loss: 12.7101 - val_mae: 29.1377 - val_mape: 11.5543 - lr: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 12.7013 - mae: 30.8781 - mape: 11.5445 - val_loss: 11.6551 - val_mae: 21.2511 - val_mape: 10.4999 - lr: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.6281 - mae: 30.6993 - mape: 11.4771 - val_loss: 12.9234 - val_mae: 27.3334 - val_mape: 11.7755 - lr: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 6s 75ms/step - loss: 12.4568 - mae: 30.3342 - mape: 11.3105 - val_loss: 11.5524 - val_mae: 20.7077 - val_mape: 10.4080 - lr: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.6434 - mae: 31.6516 - mape: 11.5022 - val_loss: 11.4996 - val_mae: 20.9625 - val_mape: 10.3604 - lr: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 12.5789 - mae: 30.2289 - mape: 11.4427 - val_loss: 12.2112 - val_mae: 29.1199 - val_mape: 11.0761 - lr: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.6910 - mae: 32.4331 - mape: 11.5557 - val_loss: 12.6193 - val_mae: 28.9814 - val_mape: 11.4866 - lr: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.4626 - mae: 29.4894 - mape: 11.3301 - val_loss: 12.0264 - val_mae: 36.7723 - val_mape: 10.8971 - lr: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 12.3981 - mae: 32.0928 - mape: 11.2679 - val_loss: 11.5832 - val_mae: 21.4481 - val_mape: 10.4541 - lr: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.7348 - mae: 32.6165 - mape: 11.6116 - val_loss: 12.3223 - val_mae: 24.6796 - val_mape: 11.2045 - lr: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.3708 - mae: 30.0304 - mape: 11.2537 - val_loss: 12.3549 - val_mae: 20.4723 - val_mape: 11.2407 - lr: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.4899 - mae: 28.5262 - mape: 11.3766 - val_loss: 11.5837 - val_mae: 24.8041 - val_mape: 10.4691 - lr: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.4374 - mae: 32.4551 - mape: 11.3272 - val_loss: 11.5138 - val_mae: 20.4677 - val_mape: 10.4067 - lr: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 12.3130 - mae: 28.7361 - mape: 11.2099 - val_loss: 11.5294 - val_mae: 23.2536 - val_mape: 10.4267 - lr: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 12.7648 - mae: 30.6161 - mape: 11.6658 - val_loss: 13.1925 - val_mae: 34.7499 - val_mape: 12.0970 - lr: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.5274 - mae: 30.8214 - mape: 11.4324 - val_loss: 13.3996 - val_mae: 29.7042 - val_mape: 12.3073 - lr: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 12.5587 - mae: 31.0792 - mape: 11.4664 - val_loss: 11.8536 - val_mae: 23.2862 - val_mape: 10.7626 - lr: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 12.5147 - mae: 30.2059 - mape: 11.4268 - val_loss: 12.6772 - val_mae: 25.7649 - val_mape: 11.5919 - lr: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6804 - mae: 30.1089 - mape: 11.5957 - val_loss: 11.8735 - val_mae: 27.5131 - val_mape: 10.7889 - lr: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.6955 - mae: 31.5942 - mape: 11.6138 - val_loss: 12.7301 - val_mae: 25.7882 - val_mape: 11.6507 - lr: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 12.6795 - mae: 28.3494 - mape: 11.6006 - val_loss: 11.8297 - val_mae: 25.1178 - val_mape: 10.7488 - lr: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 12.3459 - mae: 29.4602 - mape: 11.2689 - val_loss: 13.2113 - val_mae: 26.6148 - val_mape: 12.1369 - lr: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 12.5028 - mae: 30.4510 - mape: 11.4299 - val_loss: 12.3731 - val_mae: 32.2811 - val_mape: 11.3011 - lr: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 12.2626 - mae: 29.1449 - mape: 11.1924 - val_loss: 12.0623 - val_mae: 19.9406 - val_mape: 10.9925 - lr: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 12.3275 - mae: 31.9116 - mape: 11.2597 - val_loss: 12.0787 - val_mae: 25.4994 - val_mape: 11.0100 - lr: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.5159 - mae: 30.5342 - mape: 11.4482\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 12.5159 - mae: 30.5342 - mape: 11.4482 - val_loss: 11.6556 - val_mae: 21.6051 - val_mape: 10.5907 - lr: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 12.0818 - mae: 28.8427 - mape: 11.0187 - val_loss: 11.7187 - val_mae: 24.1247 - val_mape: 10.6565 - lr: 3.0000e-05\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 12.2858 - mae: 30.0952 - mape: 11.2244 - val_loss: 11.6599 - val_mae: 24.3171 - val_mape: 10.5970 - lr: 3.0000e-05\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 12.0057 - mae: 29.3470 - mape: 10.9447 - val_loss: 11.9682 - val_mae: 20.3278 - val_mape: 10.9081 - lr: 3.0000e-05\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 12.1162 - mae: 30.0640 - mape: 11.0571 - val_loss: 12.1227 - val_mae: 23.5707 - val_mape: 11.0642 - lr: 3.0000e-05\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 12.2576 - mae: 30.8265 - mape: 11.1988 - val_loss: 11.7281 - val_mae: 20.8362 - val_mape: 10.6701 - lr: 3.0000e-05\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 11.9960 - mae: 32.1073 - mape: 10.9394 - val_loss: 12.1263 - val_mae: 25.0867 - val_mape: 11.0720 - lr: 3.0000e-05\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 12.3060 - mae: 30.4659 - mape: 11.2521 - val_loss: 11.8779 - val_mae: 28.1907 - val_mape: 10.8252 - lr: 3.0000e-05\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 12.2040 - mae: 31.7261 - mape: 11.1521 - val_loss: 12.0365 - val_mae: 25.1290 - val_mape: 10.9843 - lr: 3.0000e-05\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 39s 449ms/step - loss: 12.1532 - mae: 30.8217 - mape: 11.1009 - val_loss: 12.0825 - val_mae: 22.6845 - val_mape: 11.0313 - lr: 3.0000e-05\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 13s 145ms/step - loss: 12.2344 - mae: 29.2068 - mape: 11.1836 - val_loss: 11.9963 - val_mae: 21.8866 - val_mape: 10.9450 - lr: 3.0000e-05\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 11.8443 - mae: 26.6479 - mape: 10.7936 - val_loss: 11.8940 - val_mae: 23.7298 - val_mape: 10.8441 - lr: 3.0000e-05\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 11.9660 - mae: 30.0180 - mape: 10.9173 - val_loss: 11.9457 - val_mae: 23.1779 - val_mape: 10.8978 - lr: 3.0000e-05\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 12.1479 - mae: 31.0836 - mape: 11.1004 - val_loss: 12.1058 - val_mae: 27.1525 - val_mape: 11.0599 - lr: 3.0000e-05\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 12.1085 - mae: 30.2860 - mape: 11.0618 - val_loss: 12.5467 - val_mae: 27.2315 - val_mape: 11.5009 - lr: 3.0000e-05\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 12.2922 - mae: 31.3065 - mape: 11.2462 - val_loss: 11.6500 - val_mae: 20.4913 - val_mape: 10.6047 - lr: 3.0000e-05\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 11s 129ms/step - loss: 11.9805 - mae: 30.5348 - mape: 10.9360 - val_loss: 12.1489 - val_mae: 22.9441 - val_mape: 11.1046 - lr: 3.0000e-05\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 12.2859 - mae: 29.8559 - mape: 11.2435 - val_loss: 12.1419 - val_mae: 26.4320 - val_mape: 11.1014 - lr: 3.0000e-05\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 11s 120ms/step - loss: 12.1789 - mae: 27.8836 - mape: 11.1381 - val_loss: 12.0019 - val_mae: 21.6582 - val_mape: 10.9616 - lr: 3.0000e-05\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 12.0660 - mae: 29.6874 - mape: 11.0267 - val_loss: 12.1144 - val_mae: 25.1951 - val_mape: 11.0762 - lr: 3.0000e-05\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 11.8992 - mae: 30.2082 - mape: 10.8613 - val_loss: 11.6345 - val_mae: 23.9061 - val_mape: 10.5953 - lr: 3.0000e-05\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 12.1076 - mae: 30.4482 - mape: 11.0690 - val_loss: 12.0736 - val_mae: 25.6667 - val_mape: 11.0362 - lr: 3.0000e-05\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 12.2547 - mae: 29.7928 - mape: 11.2181 - val_loss: 12.0573 - val_mae: 28.4670 - val_mape: 11.0205 - lr: 3.0000e-05\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 11.9199 - mae: 27.7084 - mape: 10.8837 - val_loss: 11.6706 - val_mae: 21.1350 - val_mape: 10.6349 - lr: 3.0000e-05\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 12.2061 - mae: 27.2325 - mape: 11.1717 - val_loss: 12.4777 - val_mae: 26.9863 - val_mape: 11.4448 - lr: 3.0000e-05\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 12.0219 - mae: 32.6019 - mape: 10.9893 - val_loss: 11.9817 - val_mae: 27.3518 - val_mape: 10.9499 - lr: 3.0000e-05\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 18s 205ms/step - loss: 12.2755 - mae: 31.5230 - mape: 11.2431 - val_loss: 11.7811 - val_mae: 24.0874 - val_mape: 10.7489 - lr: 3.0000e-05\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 12.0959 - mae: 30.0060 - mape: 11.0646 - val_loss: 11.6701 - val_mae: 20.8777 - val_mape: 10.6390 - lr: 3.0000e-05\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 12.1242 - mae: 29.7202 - mape: 11.0927 - val_loss: 12.3440 - val_mae: 28.1734 - val_mape: 11.3136 - lr: 3.0000e-05\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 12.1145 - mae: 28.8419 - mape: 11.0831 - val_loss: 11.9775 - val_mae: 22.5515 - val_mape: 10.9463 - lr: 3.0000e-05\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.0177 - mae: 29.3168 - mape: 10.9872\n",
      "Epoch 176: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 12.0177 - mae: 29.3168 - mape: 10.9872 - val_loss: 11.7958 - val_mae: 20.9689 - val_mape: 10.7656 - lr: 3.0000e-05\n",
      "Epoch 176: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 13.32945728302002; mae of 22.22041130065918; mape of 9.1865816116333%;\n"
     ]
    }
   ],
   "source": [
    "#Hybrid additional\n",
    "model = keras.models.load_model(\"crossvalidationmodels/Hybrid_nosupp_freeze_4/\")\n",
    "make_trainable(model)\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model,'crossvalidationmodels/Hybrid_nosupp_additional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 12.125433921813965 - Mean average error: 19.60015296936035% - Mean percentage error: 8.480804443359375%\n",
      "    Score on unseen data: Loss: 17.519113540649414 - Mean average error: 33.19729232788086% - Mean percentage error: 13.874481201171875%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 11.35626220703125 - Mean average error: 18.092626571655273% - Mean percentage error: 8.3443021774292%\n",
      "    Score on unseen data: Loss: 16.965375900268555 - Mean average error: 36.46554946899414% - Mean percentage error: 13.95341682434082%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 11.315043449401855 - Mean average error: 16.840408325195312% - Mean percentage error: 7.731719017028809%\n",
      "    Score on unseen data: Loss: 17.549501419067383 - Mean average error: 35.615108489990234% - Mean percentage error: 13.966176986694336%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 11.753775596618652 - Mean average error: 20.91160774230957% - Mean percentage error: 7.9395670890808105%\n",
      "    Score on unseen data: Loss: 17.699918746948242 - Mean average error: 40.687400817871094% - Mean percentage error: 13.885709762573242%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 13.32945728302002 - Mean average error: 22.22041130065918% - Mean percentage error: 9.1865816116333%\n",
      "    Score on unseen data: Loss: 18.553390502929688 - Mean average error: 38.853145599365234% - Mean percentage error: 14.410513877868652%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 11.975994491577149\n",
      "> Mean average error: 19.533041381835936\n",
      "> Mean percentage error: 8.3365948677063\n",
      "> Unseen Loss: 17.657460021972657\n",
      "> Unseen Mean average error: 36.96369934082031\n",
      "> Unseen Mean percentage error: 14.018059730529785\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"baseline_nosupp_arch.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot mape\n",
    "plt.plot(model.history.history[\"mape\"], label='Train')\n",
    "plt.plot(model.history.history[\"val_mape\"], label='Validation')\n",
    "plt.legend()\n",
    "plt.title('model mean absolute percentage error')\n",
    "plt.ylabel('mape')\n",
    "plt.xlabel('epoch')\n",
    "#plt.ylim([35, 150])\n",
    "#plt.xlim([0, 250])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot learning rate\n",
    "plt.plot(model.history.history[\"lr\"])\n",
    "plt.title('model learning rate')\n",
    "plt.ylabel('learning rate')\n",
    "plt.xlabel('epoch')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('Baseline', 'Multi-input')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [21.92,17.57]\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Mean absolute percentage error')\n",
    "plt.title('Model error rates (lower is better)')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d217d37ed9247659b2812203162b84cdb779e33cccd1fe199abf14cba0e180e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
