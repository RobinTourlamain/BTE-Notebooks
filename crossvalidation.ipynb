{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd;\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras_tuner as kt\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint\n",
    "from spektral.data.utils import to_tf_signature, prepend_none\n",
    "from spektral.data import DisjointLoader, Dataset\n",
    "from spektral.layers import GlobalMaxPool, GlobalAvgPool, GCSConv\n",
    "from spektral.transforms import GCNFilter, NormalizeAdj\n",
    "import scipy.sparse\n",
    "from spektral.data.graph import Graph\n",
    "from keras.layers import Dense, concatenate, Dropout\n",
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('thingi10k_data.csv', index_col=0)\n",
    "adjpath = '../Data/stl/adjacency_stl_simplified/'\n",
    "cloudpath = '../Data/stl/nodefeatures_stl_simplified/'\n",
    "edgepath = '../Data/stl/edgefeaturesmatrix_stl_simplified/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom disjointloader\n",
    "def getFeatures(batch):\n",
    "    feats = []\n",
    "    for graph in batch:\n",
    "        feats.append(graph.__getattribute__('feats'))\n",
    "    return np.array(feats)\n",
    "\n",
    "class MyDisjointLoader(DisjointLoader):\n",
    "    def __init__(\n",
    "        self, dataset, node_level=False, batch_size=1, epochs=None, shuffle=True\n",
    "    ):\n",
    "        self.node_level = node_level\n",
    "        super().__init__(dataset, batch_size=batch_size, epochs=epochs, shuffle=shuffle)\n",
    "\n",
    "    def __next__(self):\n",
    "        nxt = self._generator.__next__()\n",
    "        feats = getFeatures(nxt)\n",
    "        #feats = nxt[0].__getattribute__('feats')\n",
    "        output, y = self.collate(nxt)\n",
    "        feats = (feats,)\n",
    "        output = output + feats\n",
    "        return   output, y\n",
    "    \n",
    "    def tf_signature(self):\n",
    "    \n",
    "        signature = self.dataset.signature\n",
    "        if \"y\" in signature:\n",
    "            signature[\"y\"][\"shape\"] = prepend_none(signature[\"y\"][\"shape\"])\n",
    "        if \"a\" in signature:\n",
    "            signature[\"a\"][\"spec\"] = tf.SparseTensorSpec\n",
    "\n",
    "        signature[\"i\"] = dict()\n",
    "        signature[\"i\"][\"spec\"] = tf.TensorSpec\n",
    "        signature[\"i\"][\"shape\"] = (None,)\n",
    "        signature[\"i\"][\"dtype\"] = tf.as_dtype(tf.int64)\n",
    "\n",
    "        sig = (tf.TensorSpec(shape=[None,13]),)\n",
    "        input = to_tf_signature(signature)\n",
    "        sig = input[0] + sig\n",
    "        return (sig, input[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data, drop unnecessary\n",
    "data = pd.read_csv('thingi10k_data.csv', index_col=0)\n",
    "\n",
    "df = data.copy()\n",
    "df.drop(\"source\", axis=1, inplace=True)\n",
    "df.drop(\"model_name\", axis=1, inplace=True)\n",
    "\n",
    "#Extract build times\n",
    "build_times = df[\"build_time\"]\n",
    "df.drop(\"build_time\", axis=1,inplace=True)\n",
    "\n",
    "#Make pipeline\n",
    "def log_transform(x):\n",
    "    return np.log(x + 1)\n",
    "\n",
    "def inv_log_transform(x):\n",
    "    return np.exp(x) - 1 \n",
    "\n",
    "logtransformer = FunctionTransformer(func=log_transform, inverse_func=inv_log_transform, check_inverse=False)\n",
    "pipe = Pipeline(steps=[ ('logtransformer', logtransformer)])\n",
    "\n",
    "#Log transform\n",
    "transformed = pipe.fit_transform(df)\n",
    "df = np.asarray(transformed)\n",
    "build_times = np.asarray(build_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, centroids, dev, index, **kwargs):\n",
    "        self.centroids = centroids\n",
    "        self.dev = dev\n",
    "        self.index = index\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def read(self):\n",
    "        output = []\n",
    "        for i in self.index:\n",
    "            if(os.path.isfile(adjpath + f'{features[\"model_name\"][i]}.npz')):\n",
    "                point_cloud = np.load(cloudpath + f'{features[\"model_name\"][i]}.npy').reshape(-1,3)\n",
    "                edgefeat = scipy.sparse.load_npz(edgepath + f'{features[\"model_name\"][i]}.npz')\n",
    "                output.append(\n",
    "                    Graph(x=((point_cloud-self.centroids)/self.dev), a=edgefeat, y=features[\"build_time\"][i], feats=df[i])\n",
    "                )\n",
    "            else:\n",
    "                print(f'object {i} missing!')\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split_graphs(trainindex, testindex):\n",
    "    print(\"Getting split...\")\n",
    "    coords = np.empty((1,3))\n",
    "\n",
    "    for i in trainindex:\n",
    "        if(os.path.isfile(adjpath + f'{features[\"model_name\"][i]}.npz')):\n",
    "            point_cloud = np.load(cloudpath + f'{features[\"model_name\"][i]}.npy').reshape(-1,3)\n",
    "            coords = np.concatenate((coords,point_cloud))\n",
    "            \n",
    "\n",
    "    coords = np.delete(coords,0,0)\n",
    "    centroids = np.mean(coords,0)\n",
    "    coordscentered = coords - centroids\n",
    "    dev = np.max(np.sqrt(np.sum(coordscentered**2,axis=-1) / (trainindex.shape[0] - 1)))\n",
    "\n",
    "    train = MyDataset(centroids, dev, trainindex)\n",
    "    test = MyDataset(centroids, dev, testindex)\n",
    "    validation = MyDataset(centroids, dev, range(3478,3661))\n",
    "    train.apply(NormalizeAdj())\n",
    "    test.apply(NormalizeAdj())\n",
    "    validation.apply(NormalizeAdj())\n",
    "    train = MyDisjointLoader(train, batch_size=32)\n",
    "    test = MyDisjointLoader(test, batch_size=32)\n",
    "    validation = MyDisjointLoader(validation, batch_size=32)\n",
    "    \n",
    "    return train, test, validation\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define callbacks\n",
    "def get_callbacks(weights_file, patience, lr_factor):\n",
    "  return [\n",
    "      # Only save the weights that correspond to the minimum mape.\n",
    "      ModelCheckpoint(filepath= weights_file,\n",
    "                      monitor=\"val_mape\", \n",
    "                      mode=\"min\",\n",
    "                      save_best_only=True, \n",
    "                      save_weights_only=False),\n",
    "      # If val_loss doesn't improve for a number of epochs set with 'patience' var \n",
    "      # training will stop to avoid overfitting.    \n",
    "      EarlyStopping(monitor=\"val_loss\",\n",
    "                    mode=\"min\",\n",
    "                    patience = patience,\n",
    "                    verbose=1),\n",
    "      # Learning rate is reduced by 'lr_factor' if val_loss stagnates\n",
    "      # for a number of epochs set with 'patience/2' var.     \n",
    "      ReduceLROnPlateau(monitor=\"val_loss\", mode=\"min\",\n",
    "                        factor=lr_factor, min_lr=1e-8, patience=patience//2, verbose=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#util\n",
    "def reset_model(model):\n",
    "    import keras.backend as K\n",
    "    session = K.get_session()\n",
    "    for layer in model.layers: \n",
    "        if hasattr(layer, 'kernel.initializer') and layer.trainable: \n",
    "            layer.kernel.initializer.run(session=session)\n",
    "        if hasattr(layer, 'bias.initializer') and layer.trainable:\n",
    "            layer.bias.initializer.run(session=session)\n",
    "\n",
    "def make_trainable(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "def cross_validate(model, dir):\n",
    "    loss_per_fold = []\n",
    "    mae_per_fold = []\n",
    "    mape_per_fold = []\n",
    "    validation_per_fold = []\n",
    "    batch_size = 32\n",
    "    verbosity = 1\n",
    "    no_epochs = 1000\n",
    "    kfold = KFold(n_splits=5, shuffle=True)\n",
    "    basemodel = model\n",
    "\n",
    "    if len(model.inputs) == 1:\n",
    "        print('Baselinemodel')\n",
    "\n",
    "        fold_no = 1\n",
    "        for train, test in kfold.split(df[0:3478], build_times[0:3478]):\n",
    "\n",
    "            reset_model(model)\n",
    "\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "            model.compile(loss='mape',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), \n",
    "                metrics=['mae','mape']\n",
    "            )\n",
    "\n",
    "            history = model.fit(df[train], build_times[train], validation_data=(df[test], build_times[test]),\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity,\n",
    "              callbacks=get_callbacks(f'{dir}_{fold_no}',\n",
    "                                            patience=60,\n",
    "                                            lr_factor=0.3))\n",
    "            model = keras.models.load_model(f\"{dir}_{fold_no}\")\n",
    "\n",
    "            # Generate generalization metrics\n",
    "            valscores = model.evaluate(df[3478:3661], build_times[3478:3661], batch_size=32, verbose=0)\n",
    "            validation_per_fold.append(valscores)\n",
    "            scores = model.evaluate(df[test], build_times[test], batch_size= 32, verbose=0)\n",
    "            print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}%;')\n",
    "            loss_per_fold.append(scores[0])\n",
    "            mae_per_fold.append(scores[1])\n",
    "            mape_per_fold.append(scores[2])\n",
    "\n",
    "            # Increase fold number\n",
    "            fold_no = fold_no + 1\n",
    "    else:\n",
    "        print('multi-input')\n",
    "        fold_no = 1\n",
    "        for train, test in kfold.split(df[0:3478], build_times[0:3478]):\n",
    "\n",
    "            #reset_model(model) #wegcommenten voor additional training\n",
    "            model = basemodel\n",
    "\n",
    "            trainloader, testloader, validationloader = get_split_graphs(train, test)\n",
    "\n",
    "            print('------------------------------------------------------------------------')\n",
    "            print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "            model.compile(loss='mape',\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), #0.001\n",
    "                metrics=['mae','mape']\n",
    "            )\n",
    "            history = model.fit(trainloader.load(), validation_data=testloader.load(), validation_steps=testloader.steps_per_epoch, steps_per_epoch=trainloader.steps_per_epoch,\n",
    "              batch_size=batch_size,\n",
    "              epochs=no_epochs,\n",
    "              verbose=verbosity,\n",
    "              callbacks=get_callbacks(f'{dir}_{fold_no}',\n",
    "                                            patience=60,\n",
    "                                            lr_factor=0.3))\n",
    "            model = keras.models.load_model(f\"{dir}_{fold_no}\")\n",
    "        \n",
    "            # Generate generalization metrics\n",
    "            valscores = model.evaluate(validationloader.load(), steps=validationloader.steps_per_epoch, batch_size=32, verbose=0)\n",
    "            validation_per_fold.append(valscores)\n",
    "            scores = model.evaluate(testloader.load(), steps=testloader.steps_per_epoch, batch_size=32, verbose=0)\n",
    "            print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]}; {model.metrics_names[2]} of {scores[2]}%;')\n",
    "            loss_per_fold.append(scores[0])\n",
    "            mae_per_fold.append(scores[1])\n",
    "            mape_per_fold.append(scores[2])\n",
    "\n",
    "            # Increase fold number\n",
    "            fold_no = fold_no + 1\n",
    "    return loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print scores\n",
    "def print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold):\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Score per fold')\n",
    "    for i in range(0, len(loss_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Mean average error: {mae_per_fold[i]}% - Mean percentage error: {mape_per_fold[i]}%')\n",
    "        print(f'    Score on unseen data: Loss: {validation_per_fold[i][0]} - Mean average error: {validation_per_fold[i][1]}% - Mean percentage error: {validation_per_fold[i][2]}%')\n",
    "        print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print(f'> Mean average error: {np.mean(mae_per_fold)}')\n",
    "    print(f'> Mean percentage error: {np.mean(mape_per_fold)}')\n",
    "    print(f'> Unseen Loss: {np.mean(np.asarray(validation_per_fold)[:,0])}')\n",
    "    print(f'> Unseen Mean average error: {np.mean(np.asarray(validation_per_fold)[:,1])}')\n",
    "    print(f'> Unseen Mean percentage error: {np.mean(np.asarray(validation_per_fold)[:,2])}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 9.9581 - mae: 23.4316 - mape: 9.9575"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 102ms/step - loss: 9.9586 - mae: 23.3561 - mape: 9.9580 - val_loss: 6.9249 - val_mae: 24.5102 - val_mape: 6.9241 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 10.2252 - mae: 25.3246 - mape: 10.2244 - val_loss: 7.2605 - val_mae: 22.6558 - val_mape: 7.2595 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8602 - mae: 22.2137 - mape: 9.8593 - val_loss: 7.3945 - val_mae: 27.8980 - val_mape: 7.3935 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.2246 - mae: 25.1223 - mape: 10.2236 - val_loss: 6.9939 - val_mae: 13.8827 - val_mape: 6.9930 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.9842 - mae: 22.6407 - mape: 9.9832 - val_loss: 7.2023 - val_mae: 13.8487 - val_mape: 7.2013 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.0300 - mae: 23.0363 - mape: 10.0290 - val_loss: 6.9575 - val_mae: 16.7506 - val_mape: 6.9566 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.0719 - mae: 23.4834 - mape: 10.0710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 97ms/step - loss: 10.0719 - mae: 23.4834 - mape: 10.0710 - val_loss: 6.7548 - val_mae: 15.4859 - val_mape: 6.7538 - lr: 0.0010\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9657 - mae: 23.5259 - mape: 9.9648 - val_loss: 6.9360 - val_mae: 17.9413 - val_mape: 6.9351 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.9976 - mae: 23.1716 - mape: 9.9966 - val_loss: 6.8406 - val_mae: 12.7444 - val_mape: 6.8396 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8000 - mae: 24.5831 - mape: 9.7990 - val_loss: 6.9069 - val_mae: 16.1262 - val_mape: 6.9060 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.1034 - mae: 24.6794 - mape: 10.1024 - val_loss: 7.2797 - val_mae: 16.6634 - val_mape: 7.2785 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.7949 - mae: 23.2026 - mape: 9.7937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 9.7949 - mae: 23.2026 - mape: 9.7937 - val_loss: 6.7210 - val_mae: 17.4777 - val_mape: 6.7198 - lr: 0.0010\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9301 - mae: 23.2849 - mape: 9.9291 - val_loss: 6.7738 - val_mae: 13.4859 - val_mape: 6.7728 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.1910 - mae: 26.4011 - mape: 10.1900 - val_loss: 7.5818 - val_mae: 16.4773 - val_mape: 7.5809 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.9496 - mae: 26.1090 - mape: 9.9487 - val_loss: 7.2078 - val_mae: 20.1203 - val_mape: 7.2069 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.1376 - mae: 25.2473 - mape: 10.1367 - val_loss: 7.5253 - val_mae: 15.4695 - val_mape: 7.5243 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7780 - mae: 21.4830 - mape: 9.7770 - val_loss: 7.3074 - val_mae: 13.6587 - val_mape: 7.3062 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8616 - mae: 24.2937 - mape: 9.8604 - val_loss: 6.7356 - val_mae: 16.4051 - val_mape: 6.7345 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8796 - mae: 23.5505 - mape: 9.8785 - val_loss: 7.6452 - val_mae: 29.4541 - val_mape: 7.6440 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8079 - mae: 23.7981 - mape: 9.8068 - val_loss: 6.8146 - val_mae: 14.3408 - val_mape: 6.8135 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8063 - mae: 22.6747 - mape: 9.8052 - val_loss: 7.4964 - val_mae: 17.2205 - val_mape: 7.4953 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9302 - mae: 23.4396 - mape: 9.9292 - val_loss: 6.8196 - val_mae: 16.6995 - val_mape: 6.8185 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8656 - mae: 24.9476 - mape: 9.8646 - val_loss: 7.8795 - val_mae: 14.4076 - val_mape: 7.8786 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9870 - mae: 23.2789 - mape: 9.9861 - val_loss: 6.9001 - val_mae: 17.8949 - val_mape: 6.8993 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.0216 - mae: 23.0737 - mape: 10.0208 - val_loss: 7.1320 - val_mae: 14.2338 - val_mape: 7.1311 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.8501 - mae: 22.0665 - mape: 9.8493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 9.8501 - mae: 22.0665 - mape: 9.8493 - val_loss: 6.5635 - val_mae: 13.5586 - val_mape: 6.5627 - lr: 0.0010\n",
      "Epoch 27/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8188 - mae: 23.8249 - mape: 9.8180 - val_loss: 7.2049 - val_mae: 14.9687 - val_mape: 7.2041 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.0398 - mae: 24.5106 - mape: 10.0390 - val_loss: 8.0181 - val_mae: 24.4425 - val_mape: 8.0173 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7984 - mae: 23.9364 - mape: 9.7976 - val_loss: 6.8685 - val_mae: 14.9008 - val_mape: 6.8677 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9250 - mae: 23.5723 - mape: 9.9243 - val_loss: 6.5816 - val_mae: 13.7479 - val_mape: 6.5809 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9143 - mae: 23.1226 - mape: 9.9138 - val_loss: 6.8467 - val_mae: 13.7228 - val_mape: 6.8462 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8122 - mae: 23.8896 - mape: 9.8118 - val_loss: 7.6701 - val_mae: 21.5985 - val_mape: 7.6695 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8382 - mae: 22.6569 - mape: 9.8377 - val_loss: 8.2453 - val_mae: 30.8327 - val_mape: 8.2448 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7966 - mae: 22.6993 - mape: 9.7962 - val_loss: 6.7581 - val_mae: 13.3809 - val_mape: 6.7577 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6670 - mae: 24.8388 - mape: 9.6666 - val_loss: 6.7063 - val_mae: 16.2266 - val_mape: 6.7058 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.9593 - mae: 23.9875 - mape: 9.9588 - val_loss: 7.6255 - val_mae: 27.2322 - val_mape: 7.6250 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9173 - mae: 22.8589 - mape: 9.9168 - val_loss: 7.7295 - val_mae: 17.3976 - val_mape: 7.7290 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8547 - mae: 26.9968 - mape: 9.8541 - val_loss: 6.9865 - val_mae: 19.9352 - val_mape: 6.9859 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6482 - mae: 23.8983 - mape: 9.6476 - val_loss: 6.8431 - val_mae: 13.9724 - val_mape: 6.8425 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6947 - mae: 21.9701 - mape: 9.6941 - val_loss: 7.0301 - val_mae: 18.9813 - val_mape: 7.0295 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9682 - mae: 23.9484 - mape: 9.9676 - val_loss: 6.7253 - val_mae: 13.0410 - val_mape: 6.7248 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8857 - mae: 24.9474 - mape: 9.8851 - val_loss: 6.8782 - val_mae: 18.0479 - val_mape: 6.8775 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7682 - mae: 21.6983 - mape: 9.7675 - val_loss: 7.8347 - val_mae: 21.6729 - val_mape: 7.8340 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.1586 - mae: 26.0837 - mape: 10.1579 - val_loss: 6.8702 - val_mae: 14.2458 - val_mape: 6.8695 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.9362 - mae: 25.2075 - mape: 9.9356 - val_loss: 7.6065 - val_mae: 25.2212 - val_mape: 7.6059 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0731 - mae: 24.2697 - mape: 10.0725 - val_loss: 6.7287 - val_mae: 17.1413 - val_mape: 6.7282 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6356 - mae: 22.9725 - mape: 9.6350 - val_loss: 6.7645 - val_mae: 15.2964 - val_mape: 6.7640 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8853 - mae: 24.0524 - mape: 9.8849 - val_loss: 7.4834 - val_mae: 26.7117 - val_mape: 7.4830 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9584 - mae: 23.3390 - mape: 9.9580 - val_loss: 7.4657 - val_mae: 16.7254 - val_mape: 7.4653 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6849 - mae: 22.4217 - mape: 9.6845 - val_loss: 6.8614 - val_mae: 13.7792 - val_mape: 6.8610 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7284 - mae: 23.5163 - mape: 9.7279 - val_loss: 7.2282 - val_mae: 21.4560 - val_mape: 7.2277 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6109 - mae: 23.1125 - mape: 9.6105 - val_loss: 6.8206 - val_mae: 16.4674 - val_mape: 6.8202 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7718 - mae: 22.4439 - mape: 9.7714 - val_loss: 6.9814 - val_mae: 25.7626 - val_mape: 6.9810 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8866 - mae: 25.0109 - mape: 9.8861 - val_loss: 6.8445 - val_mae: 19.3681 - val_mape: 6.8439 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7182 - mae: 24.5047 - mape: 9.7177 - val_loss: 6.7770 - val_mae: 15.5355 - val_mape: 6.7766 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.8742 - mae: 22.6712 - mape: 9.8737\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8742 - mae: 22.6712 - mape: 9.8737 - val_loss: 7.9056 - val_mae: 18.1625 - val_mape: 7.9052 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6394 - mae: 22.3557 - mape: 9.6389 - val_loss: 6.9257 - val_mae: 15.7970 - val_mape: 6.9252 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4002 - mae: 22.6453 - mape: 9.3997 - val_loss: 6.7298 - val_mae: 14.3523 - val_mape: 6.7293 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4827 - mae: 21.6929 - mape: 9.4822 - val_loss: 6.7728 - val_mae: 16.3658 - val_mape: 6.7723 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4090 - mae: 22.7715 - mape: 9.4086 - val_loss: 6.6614 - val_mae: 12.7763 - val_mape: 6.6609 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4360 - mae: 23.3834 - mape: 9.4356 - val_loss: 6.6730 - val_mae: 13.4185 - val_mape: 6.6725 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7185 - mae: 21.9707 - mape: 9.7180 - val_loss: 6.6422 - val_mae: 13.9990 - val_mape: 6.6417 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5374 - mae: 22.7646 - mape: 9.5370 - val_loss: 6.7977 - val_mae: 16.9288 - val_mape: 6.7973 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6381 - mae: 24.2853 - mape: 9.6377 - val_loss: 7.4497 - val_mae: 19.4353 - val_mape: 7.4492 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5055 - mae: 23.6479 - mape: 9.5051 - val_loss: 6.7969 - val_mae: 13.9680 - val_mape: 6.7964 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4454 - mae: 21.9210 - mape: 9.4449 - val_loss: 6.6577 - val_mae: 14.5658 - val_mape: 6.6573 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5686 - mae: 23.5683 - mape: 9.5682 - val_loss: 6.6304 - val_mae: 12.6228 - val_mape: 6.6300 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5881 - mae: 23.7758 - mape: 9.5877 - val_loss: 6.7574 - val_mae: 15.5617 - val_mape: 6.7570 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6138 - mae: 22.2841 - mape: 9.6134 - val_loss: 6.6391 - val_mae: 12.2957 - val_mape: 6.6388 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4178 - mae: 22.7693 - mape: 9.4175 - val_loss: 6.6532 - val_mae: 12.2217 - val_mape: 6.6528 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5509 - mae: 23.1768 - mape: 9.5506 - val_loss: 6.6266 - val_mae: 14.4949 - val_mape: 6.6263 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3891 - mae: 23.0417 - mape: 9.3889 - val_loss: 6.9757 - val_mae: 17.7300 - val_mape: 6.9754 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4549 - mae: 21.7992 - mape: 9.4546 - val_loss: 6.6193 - val_mae: 12.2046 - val_mape: 6.6191 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5754 - mae: 19.5983 - mape: 9.5752 - val_loss: 6.8301 - val_mae: 19.9960 - val_mape: 6.8298 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4777 - mae: 21.7816 - mape: 9.4774 - val_loss: 6.6752 - val_mae: 15.0251 - val_mape: 6.6749 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5112 - mae: 22.7233 - mape: 9.5109 - val_loss: 7.0063 - val_mae: 13.7623 - val_mape: 7.0060 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5765 - mae: 20.8975 - mape: 9.5763 - val_loss: 6.6488 - val_mae: 13.8702 - val_mape: 6.6486 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4691 - mae: 23.6795 - mape: 9.4689 - val_loss: 7.2184 - val_mae: 20.8446 - val_mape: 7.2181 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3772 - mae: 23.3594 - mape: 9.3769 - val_loss: 6.7294 - val_mae: 12.7316 - val_mape: 6.7292 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6680 - mae: 24.1588 - mape: 9.6678 - val_loss: 6.7564 - val_mae: 13.7695 - val_mape: 6.7562 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5032 - mae: 23.4316 - mape: 9.5029 - val_loss: 6.6766 - val_mae: 12.1455 - val_mape: 6.6763 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3617 - mae: 22.7095 - mape: 9.3615 - val_loss: 6.9275 - val_mae: 14.3516 - val_mape: 6.9273 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3717 - mae: 20.8489 - mape: 9.3715 - val_loss: 6.6536 - val_mae: 13.1057 - val_mape: 6.6534 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5224 - mae: 21.3875 - mape: 9.5222 - val_loss: 6.7134 - val_mae: 14.9759 - val_mape: 6.7132 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3575 - mae: 20.9747 - mape: 9.3573 - val_loss: 7.0609 - val_mae: 15.8303 - val_mape: 7.0607 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.4994 - mae: 23.5216 - mape: 9.4991\n",
      "Epoch 86: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4994 - mae: 23.5216 - mape: 9.4991 - val_loss: 6.6517 - val_mae: 15.7029 - val_mape: 6.6515 - lr: 3.0000e-04\n",
      "Epoch 86: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 6.563482761383057; mae of 13.558576583862305; mape of 6.562680244445801%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n",
      " 3/87 [>.............................] - ETA: 5s - loss: 11.9198 - mae: 41.3462 - mape: 11.9190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 10.3174 - mae: 27.6048 - mape: 10.3166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 102ms/step - loss: 10.3174 - mae: 27.6048 - mape: 10.3166 - val_loss: 6.1663 - val_mae: 8.7360 - val_mape: 6.1656 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.8252 - mae: 25.5899 - mape: 9.8246"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 101ms/step - loss: 9.8252 - mae: 25.5899 - mape: 9.8246 - val_loss: 6.0617 - val_mae: 10.2139 - val_mape: 6.0610 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 10.0593 - mae: 25.9917 - mape: 10.0588 - val_loss: 6.4173 - val_mae: 12.1758 - val_mape: 6.4168 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.9221 - mae: 26.4539 - mape: 9.9215 - val_loss: 7.2072 - val_mae: 10.3291 - val_mape: 7.2066 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.0953 - mae: 26.3870 - mape: 10.0946 - val_loss: 6.6305 - val_mae: 16.0750 - val_mape: 6.6299 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.1580 - mae: 24.4196 - mape: 10.1573 - val_loss: 6.2816 - val_mae: 12.2344 - val_mape: 6.2809 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9463 - mae: 22.6022 - mape: 9.9457 - val_loss: 6.1186 - val_mae: 11.0074 - val_mape: 6.1180 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.0623 - mae: 26.9698 - mape: 10.0617 - val_loss: 7.4852 - val_mae: 25.3439 - val_mape: 7.4845 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9035 - mae: 25.7223 - mape: 9.9028 - val_loss: 6.5981 - val_mae: 17.0451 - val_mape: 6.5974 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.9114 - mae: 25.8111 - mape: 9.9108 - val_loss: 6.6757 - val_mae: 14.8973 - val_mape: 6.6751 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.2450 - mae: 25.3353 - mape: 10.2444 - val_loss: 6.1212 - val_mae: 11.3646 - val_mape: 6.1206 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.0437 - mae: 26.7739 - mape: 10.0431 - val_loss: 6.2512 - val_mae: 10.3255 - val_mape: 6.2506 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9514 - mae: 25.7720 - mape: 9.9508 - val_loss: 7.3450 - val_mae: 14.4267 - val_mape: 7.3445 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.0067 - mae: 24.4028 - mape: 10.0062 - val_loss: 6.4120 - val_mae: 15.2221 - val_mape: 6.4116 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.9407 - mae: 26.1204 - mape: 9.9404 - val_loss: 6.1084 - val_mae: 7.9299 - val_mape: 6.1080 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9771 - mae: 26.6633 - mape: 9.9766 - val_loss: 7.3487 - val_mae: 17.9148 - val_mape: 7.3482 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.0138 - mae: 27.4450 - mape: 10.0132 - val_loss: 6.1104 - val_mae: 8.3165 - val_mape: 6.1098 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7587 - mae: 24.1159 - mape: 9.7581 - val_loss: 7.0217 - val_mae: 9.6008 - val_mape: 7.0212 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7522 - mae: 25.6661 - mape: 9.7517 - val_loss: 6.1481 - val_mae: 8.9876 - val_mape: 6.1476 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9275 - mae: 24.8023 - mape: 9.9270 - val_loss: 6.2297 - val_mae: 9.9100 - val_mape: 6.2292 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7305 - mae: 24.2072 - mape: 9.7300 - val_loss: 6.5187 - val_mae: 9.4108 - val_mape: 6.5184 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.9678 - mae: 25.2184 - mape: 9.9674 - val_loss: 6.1896 - val_mae: 9.0048 - val_mape: 6.1893 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8114 - mae: 24.5669 - mape: 9.8110 - val_loss: 6.4169 - val_mae: 18.9136 - val_mape: 6.4165 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8412 - mae: 24.6869 - mape: 9.8407 - val_loss: 6.3528 - val_mae: 14.1732 - val_mape: 6.3524 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8131 - mae: 26.1827 - mape: 9.8127 - val_loss: 6.3020 - val_mae: 10.9512 - val_mape: 6.3017 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.1487 - mae: 26.3812 - mape: 10.1483 - val_loss: 6.2252 - val_mae: 10.6037 - val_mape: 6.2249 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8406 - mae: 24.1244 - mape: 9.8403 - val_loss: 6.4629 - val_mae: 12.2107 - val_mape: 6.4626 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6942 - mae: 24.5140 - mape: 9.6938 - val_loss: 6.5876 - val_mae: 18.3664 - val_mape: 6.5872 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8234 - mae: 23.7365 - mape: 9.8230 - val_loss: 6.5163 - val_mae: 14.9008 - val_mape: 6.5159 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9998 - mae: 25.0144 - mape: 9.9994 - val_loss: 6.3114 - val_mae: 11.6076 - val_mape: 6.3110 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8711 - mae: 25.9008 - mape: 9.8708 - val_loss: 6.4776 - val_mae: 12.4734 - val_mape: 6.4773 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.1225 - mae: 26.5966 - mape: 10.1222\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.1225 - mae: 26.5966 - mape: 10.1222 - val_loss: 6.5634 - val_mae: 15.5996 - val_mape: 6.5631 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6655 - mae: 24.7069 - mape: 9.6652 - val_loss: 6.5819 - val_mae: 8.3792 - val_mape: 6.5816 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7437 - mae: 26.2287 - mape: 9.7435 - val_loss: 6.1686 - val_mae: 9.1413 - val_mape: 6.1683 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6419 - mae: 25.0528 - mape: 9.6416 - val_loss: 6.3257 - val_mae: 9.7643 - val_mape: 6.3254 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6141 - mae: 23.3853 - mape: 9.6138 - val_loss: 6.1412 - val_mae: 8.9506 - val_mape: 6.1409 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 9.6364 - mae: 22.7356 - mape: 9.6361 - val_loss: 6.1089 - val_mae: 8.4661 - val_mape: 6.1086 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6706 - mae: 23.1852 - mape: 9.6703 - val_loss: 6.2850 - val_mae: 10.8324 - val_mape: 6.2848 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7160 - mae: 23.9844 - mape: 9.7158 - val_loss: 6.6975 - val_mae: 8.3804 - val_mape: 6.6973 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6122 - mae: 23.5261 - mape: 9.6119 - val_loss: 6.8680 - val_mae: 12.2094 - val_mape: 6.8677 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6141 - mae: 23.9665 - mape: 9.6139 - val_loss: 6.2259 - val_mae: 12.1927 - val_mape: 6.2257 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5510 - mae: 23.7240 - mape: 9.5508 - val_loss: 6.3269 - val_mae: 8.8957 - val_mape: 6.3267 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6073 - mae: 24.1540 - mape: 9.6071 - val_loss: 6.4575 - val_mae: 9.1931 - val_mape: 6.4572 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6406 - mae: 23.8999 - mape: 9.6404 - val_loss: 6.1024 - val_mae: 8.5356 - val_mape: 6.1022 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4780 - mae: 23.6733 - mape: 9.4778 - val_loss: 6.0970 - val_mae: 7.9384 - val_mape: 6.0968 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8353 - mae: 23.5841 - mape: 9.8351 - val_loss: 6.1047 - val_mae: 8.7593 - val_mape: 6.1045 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.4524 - mae: 21.0719 - mape: 9.4522"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 9.4524 - mae: 20.9391 - mape: 9.4522 - val_loss: 6.0591 - val_mae: 7.9169 - val_mape: 6.0589 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      " 1/87 [..............................] - ETA: 6s - loss: 9.4755 - mae: 66.1563 - mape: 9.4753"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7108 - mae: 23.3178 - mape: 9.7106 - val_loss: 6.1155 - val_mae: 9.4908 - val_mape: 6.1153 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.4907 - mae: 24.3014 - mape: 9.4905"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 9.5016 - mae: 24.1668 - mape: 9.5014 - val_loss: 6.0578 - val_mae: 7.6169 - val_mape: 6.0576 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4116 - mae: 23.7674 - mape: 9.4114 - val_loss: 6.7477 - val_mae: 10.9176 - val_mape: 6.7476 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7652 - mae: 26.1394 - mape: 9.7650 - val_loss: 6.2607 - val_mae: 8.1398 - val_mape: 6.2605 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6466 - mae: 23.1775 - mape: 9.6464 - val_loss: 6.0657 - val_mae: 7.1996 - val_mape: 6.0656 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5325 - mae: 25.4741 - mape: 9.5323 - val_loss: 6.2266 - val_mae: 7.4413 - val_mape: 6.2265 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5558 - mae: 24.9643 - mape: 9.5557 - val_loss: 6.1841 - val_mae: 8.1076 - val_mape: 6.1839 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7104 - mae: 25.7429 - mape: 9.7102 - val_loss: 6.0919 - val_mae: 7.5797 - val_mape: 6.0917 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5506 - mae: 25.2703 - mape: 9.5505 - val_loss: 6.1737 - val_mae: 9.0245 - val_mape: 6.1736 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4856 - mae: 24.1150 - mape: 9.4855 - val_loss: 6.1914 - val_mae: 9.3232 - val_mape: 6.1912 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6714 - mae: 24.9208 - mape: 9.6712 - val_loss: 6.1411 - val_mae: 8.4027 - val_mape: 6.1410 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5591 - mae: 23.1888 - mape: 9.5590 - val_loss: 6.6727 - val_mae: 10.2390 - val_mape: 6.6726 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4832 - mae: 24.1676 - mape: 9.4831 - val_loss: 6.0849 - val_mae: 9.0895 - val_mape: 6.0848 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5552 - mae: 23.9356 - mape: 9.5551 - val_loss: 6.4934 - val_mae: 11.3574 - val_mape: 6.4933 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6172 - mae: 25.3133 - mape: 9.6171 - val_loss: 6.4847 - val_mae: 9.1185 - val_mape: 6.4846 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6058 - mae: 23.9734 - mape: 9.6057 - val_loss: 6.0920 - val_mae: 7.0443 - val_mape: 6.0919 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5578 - mae: 23.7322 - mape: 9.5577 - val_loss: 6.1776 - val_mae: 10.0108 - val_mape: 6.1775 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6217 - mae: 24.0032 - mape: 9.6215 - val_loss: 6.1819 - val_mae: 8.1119 - val_mape: 6.1817 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5471 - mae: 23.7637 - mape: 9.5470 - val_loss: 6.1317 - val_mae: 9.1729 - val_mape: 6.1316 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6229 - mae: 23.9405 - mape: 9.6228 - val_loss: 6.3977 - val_mae: 9.0484 - val_mape: 6.3975 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3002 - mae: 21.7264 - mape: 9.3001 - val_loss: 6.2639 - val_mae: 8.0791 - val_mape: 6.2637 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4444 - mae: 25.8833 - mape: 9.4443 - val_loss: 6.7435 - val_mae: 14.8306 - val_mape: 6.7433 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4228 - mae: 23.0713 - mape: 9.4227 - val_loss: 6.3373 - val_mae: 7.4886 - val_mape: 6.3372 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.5909 - mae: 24.8943 - mape: 9.5908 - val_loss: 6.1415 - val_mae: 8.3072 - val_mape: 6.1414 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3935 - mae: 22.9052 - mape: 9.3934 - val_loss: 6.4159 - val_mae: 8.8437 - val_mape: 6.4158 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7079 - mae: 23.9025 - mape: 9.7078 - val_loss: 6.2760 - val_mae: 7.9456 - val_mape: 6.2759 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4592 - mae: 23.9765 - mape: 9.4591 - val_loss: 6.1973 - val_mae: 10.2049 - val_mape: 6.1972 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.5394 - mae: 25.1973 - mape: 9.5393 - val_loss: 6.0854 - val_mae: 7.7087 - val_mape: 6.0853 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.5971 - mae: 22.3896 - mape: 9.5970 - val_loss: 6.1807 - val_mae: 9.0387 - val_mape: 6.1806 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4933 - mae: 22.2334 - mape: 9.4931 - val_loss: 6.2469 - val_mae: 9.6614 - val_mape: 6.2468 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4641 - mae: 22.4202 - mape: 9.4639 - val_loss: 6.2460 - val_mae: 12.2734 - val_mape: 6.2458 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.5542 - mae: 22.9566 - mape: 9.5540\n",
      "Epoch 79: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5542 - mae: 22.9566 - mape: 9.5540 - val_loss: 6.1978 - val_mae: 8.6207 - val_mape: 6.1977 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5122 - mae: 24.7717 - mape: 9.5120 - val_loss: 6.1960 - val_mae: 8.9423 - val_mape: 6.1959 - lr: 9.0000e-05\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5596 - mae: 23.3390 - mape: 9.5595 - val_loss: 6.2110 - val_mae: 9.7478 - val_mape: 6.2109 - lr: 9.0000e-05\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5973 - mae: 24.0893 - mape: 9.5972 - val_loss: 6.0987 - val_mae: 8.3775 - val_mape: 6.0986 - lr: 9.0000e-05\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4769 - mae: 23.6769 - mape: 9.4768 - val_loss: 6.1191 - val_mae: 7.9376 - val_mape: 6.1190 - lr: 9.0000e-05\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5259 - mae: 21.6453 - mape: 9.5257 - val_loss: 6.0815 - val_mae: 8.1611 - val_mape: 6.0814 - lr: 9.0000e-05\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.3284 - mae: 22.2023 - mape: 9.3282 - val_loss: 6.1519 - val_mae: 8.3306 - val_mape: 6.1518 - lr: 9.0000e-05\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2904 - mae: 21.1610 - mape: 9.2903 - val_loss: 6.2854 - val_mae: 9.6386 - val_mape: 6.2853 - lr: 9.0000e-05\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5070 - mae: 23.3332 - mape: 9.5069 - val_loss: 6.4243 - val_mae: 8.1568 - val_mape: 6.4241 - lr: 9.0000e-05\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 9.4413 - mae: 23.2304 - mape: 9.4412 - val_loss: 6.3878 - val_mae: 11.0203 - val_mape: 6.3877 - lr: 9.0000e-05\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.4051 - mae: 22.6461 - mape: 9.4050 - val_loss: 6.3563 - val_mae: 9.1669 - val_mape: 6.3562 - lr: 9.0000e-05\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5229 - mae: 22.5703 - mape: 9.5228 - val_loss: 6.3322 - val_mae: 11.0323 - val_mape: 6.3321 - lr: 9.0000e-05\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6789 - mae: 25.1071 - mape: 9.6788 - val_loss: 6.1052 - val_mae: 7.7776 - val_mape: 6.1051 - lr: 9.0000e-05\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3925 - mae: 23.3768 - mape: 9.3924 - val_loss: 6.4810 - val_mae: 12.1996 - val_mape: 6.4809 - lr: 9.0000e-05\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6262 - mae: 22.1053 - mape: 9.6261 - val_loss: 6.2523 - val_mae: 8.9871 - val_mape: 6.2522 - lr: 9.0000e-05\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.3608 - mae: 23.1833 - mape: 9.3607 - val_loss: 6.1143 - val_mae: 7.8867 - val_mape: 6.1142 - lr: 9.0000e-05\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4291 - mae: 24.2208 - mape: 9.4290 - val_loss: 6.5467 - val_mae: 12.3757 - val_mape: 6.5465 - lr: 9.0000e-05\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.3562 - mae: 23.2922 - mape: 9.3560 - val_loss: 6.0578 - val_mae: 8.5244 - val_mape: 6.0577 - lr: 9.0000e-05\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3062 - mae: 23.7593 - mape: 9.3061 - val_loss: 6.1891 - val_mae: 7.6249 - val_mape: 6.1890 - lr: 9.0000e-05\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6695 - mae: 24.6928 - mape: 9.6694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 101ms/step - loss: 9.6695 - mae: 24.6928 - mape: 9.6694 - val_loss: 6.0476 - val_mae: 7.3012 - val_mape: 6.0475 - lr: 9.0000e-05\n",
      "Epoch 99/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 9.2832 - mae: 23.9695 - mape: 9.2831 - val_loss: 6.1089 - val_mae: 8.0131 - val_mape: 6.1088 - lr: 9.0000e-05\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.1706 - mae: 21.3785 - mape: 9.1705 - val_loss: 6.0702 - val_mae: 7.3384 - val_mape: 6.0700 - lr: 9.0000e-05\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4115 - mae: 22.0583 - mape: 9.4114 - val_loss: 6.1577 - val_mae: 8.9034 - val_mape: 6.1576 - lr: 9.0000e-05\n",
      "Epoch 102/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.3067 - mae: 22.6661 - mape: 9.3066"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 9.2892 - mae: 22.5580 - mape: 9.2891 - val_loss: 6.0328 - val_mae: 7.1427 - val_mape: 6.0327 - lr: 9.0000e-05\n",
      "Epoch 103/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5443 - mae: 23.2367 - mape: 9.5442 - val_loss: 6.2225 - val_mae: 7.7073 - val_mape: 6.2224 - lr: 9.0000e-05\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3010 - mae: 21.5767 - mape: 9.3009 - val_loss: 6.4619 - val_mae: 10.0482 - val_mape: 6.4618 - lr: 9.0000e-05\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4970 - mae: 25.1359 - mape: 9.4969 - val_loss: 6.1273 - val_mae: 8.0190 - val_mape: 6.1272 - lr: 9.0000e-05\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.3705 - mae: 21.7817 - mape: 9.3704 - val_loss: 6.0611 - val_mae: 8.2263 - val_mape: 6.0610 - lr: 9.0000e-05\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4050 - mae: 23.7485 - mape: 9.4049 - val_loss: 6.1913 - val_mae: 7.9792 - val_mape: 6.1912 - lr: 9.0000e-05\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3311 - mae: 22.0372 - mape: 9.3310 - val_loss: 6.0966 - val_mae: 7.7528 - val_mape: 6.0965 - lr: 9.0000e-05\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3980 - mae: 22.6954 - mape: 9.3979 - val_loss: 6.2248 - val_mae: 7.7675 - val_mape: 6.2247 - lr: 9.0000e-05\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3638 - mae: 22.0072 - mape: 9.3637 - val_loss: 6.1752 - val_mae: 9.0340 - val_mape: 6.1752 - lr: 9.0000e-05\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3620 - mae: 23.6967 - mape: 9.3619 - val_loss: 6.1656 - val_mae: 8.1088 - val_mape: 6.1655 - lr: 9.0000e-05\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3512 - mae: 20.9023 - mape: 9.3511 - val_loss: 6.5264 - val_mae: 10.9486 - val_mape: 6.5263 - lr: 9.0000e-05\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6481 - mae: 25.2220 - mape: 9.6480 - val_loss: 6.2541 - val_mae: 9.5632 - val_mape: 6.2540 - lr: 9.0000e-05\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4999 - mae: 22.9214 - mape: 9.4998 - val_loss: 6.0751 - val_mae: 7.6059 - val_mape: 6.0751 - lr: 9.0000e-05\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3938 - mae: 21.7195 - mape: 9.3937 - val_loss: 6.0854 - val_mae: 8.6891 - val_mape: 6.0853 - lr: 9.0000e-05\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3127 - mae: 22.7811 - mape: 9.3126 - val_loss: 6.2556 - val_mae: 8.4200 - val_mape: 6.2555 - lr: 9.0000e-05\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3832 - mae: 21.0348 - mape: 9.3831 - val_loss: 6.0729 - val_mae: 8.3628 - val_mape: 6.0728 - lr: 9.0000e-05\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.3437 - mae: 21.4323 - mape: 9.3436 - val_loss: 6.1758 - val_mae: 8.1102 - val_mape: 6.1757 - lr: 9.0000e-05\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3640 - mae: 23.1705 - mape: 9.3639 - val_loss: 6.1227 - val_mae: 8.2657 - val_mape: 6.1226 - lr: 9.0000e-05\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5693 - mae: 21.3601 - mape: 9.5692 - val_loss: 6.2662 - val_mae: 9.4565 - val_mape: 6.2661 - lr: 9.0000e-05\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.1904 - mae: 20.7996 - mape: 9.1903 - val_loss: 6.4039 - val_mae: 9.7399 - val_mape: 6.4039 - lr: 9.0000e-05\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3406 - mae: 22.3726 - mape: 9.3406 - val_loss: 6.1740 - val_mae: 8.0432 - val_mape: 6.1739 - lr: 9.0000e-05\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.2938 - mae: 23.7116 - mape: 9.2937 - val_loss: 6.1037 - val_mae: 8.1734 - val_mape: 6.1036 - lr: 9.0000e-05\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3356 - mae: 23.6597 - mape: 9.3356 - val_loss: 6.2372 - val_mae: 8.6142 - val_mape: 6.2371 - lr: 9.0000e-05\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3846 - mae: 22.2958 - mape: 9.3845 - val_loss: 6.2454 - val_mae: 8.9600 - val_mape: 6.2453 - lr: 9.0000e-05\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3676 - mae: 23.9825 - mape: 9.3675 - val_loss: 6.2395 - val_mae: 9.2936 - val_mape: 6.2394 - lr: 9.0000e-05\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5858 - mae: 23.2283 - mape: 9.5857 - val_loss: 6.1045 - val_mae: 8.0297 - val_mape: 6.1045 - lr: 9.0000e-05\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4669 - mae: 26.0145 - mape: 9.4668 - val_loss: 6.5197 - val_mae: 11.4046 - val_mape: 6.5196 - lr: 9.0000e-05\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4144 - mae: 23.4729 - mape: 9.4143 - val_loss: 6.2599 - val_mae: 11.7156 - val_mape: 6.2598 - lr: 9.0000e-05\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.2612 - mae: 22.9605 - mape: 9.2612 - val_loss: 6.0984 - val_mae: 9.0043 - val_mape: 6.0983 - lr: 9.0000e-05\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6209 - mae: 24.6148 - mape: 9.6208 - val_loss: 6.1179 - val_mae: 8.7257 - val_mape: 6.1178 - lr: 9.0000e-05\n",
      "Epoch 132/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.3953 - mae: 22.1936 - mape: 9.3953\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.3965 - mae: 22.1262 - mape: 9.3965 - val_loss: 6.1786 - val_mae: 8.3826 - val_mape: 6.1785 - lr: 9.0000e-05\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4812 - mae: 22.2878 - mape: 9.4811 - val_loss: 6.1293 - val_mae: 8.3359 - val_mape: 6.1292 - lr: 2.7000e-05\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3666 - mae: 24.1628 - mape: 9.3665 - val_loss: 6.1300 - val_mae: 8.5314 - val_mape: 6.1299 - lr: 2.7000e-05\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.2536 - mae: 22.6475 - mape: 9.2536 - val_loss: 6.1228 - val_mae: 8.6212 - val_mape: 6.1228 - lr: 2.7000e-05\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3756 - mae: 23.6336 - mape: 9.3756 - val_loss: 6.3654 - val_mae: 11.0381 - val_mape: 6.3653 - lr: 2.7000e-05\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.3866 - mae: 21.9060 - mape: 9.3866 - val_loss: 6.2041 - val_mae: 8.7664 - val_mape: 6.2040 - lr: 2.7000e-05\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.3984 - mae: 24.0854 - mape: 9.3983 - val_loss: 6.1199 - val_mae: 7.7257 - val_mape: 6.1199 - lr: 2.7000e-05\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4154 - mae: 25.2474 - mape: 9.4154 - val_loss: 6.1264 - val_mae: 7.9220 - val_mape: 6.1263 - lr: 2.7000e-05\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.2572 - mae: 20.3389 - mape: 9.2572 - val_loss: 6.2298 - val_mae: 8.8204 - val_mape: 6.2297 - lr: 2.7000e-05\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6482 - mae: 22.4635 - mape: 9.6481 - val_loss: 6.1825 - val_mae: 8.4171 - val_mape: 6.1825 - lr: 2.7000e-05\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3400 - mae: 24.4266 - mape: 9.3400 - val_loss: 6.2420 - val_mae: 9.9673 - val_mape: 6.2420 - lr: 2.7000e-05\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4440 - mae: 22.7656 - mape: 9.4439 - val_loss: 6.1017 - val_mae: 7.9578 - val_mape: 6.1016 - lr: 2.7000e-05\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.2936 - mae: 21.2586 - mape: 9.2935 - val_loss: 6.0921 - val_mae: 7.9470 - val_mape: 6.0920 - lr: 2.7000e-05\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5407 - mae: 22.4040 - mape: 9.5407 - val_loss: 6.2088 - val_mae: 9.1110 - val_mape: 6.2087 - lr: 2.7000e-05\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2808 - mae: 21.8422 - mape: 9.2807 - val_loss: 6.1240 - val_mae: 8.2918 - val_mape: 6.1240 - lr: 2.7000e-05\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5653 - mae: 22.5993 - mape: 9.5652 - val_loss: 6.1776 - val_mae: 7.9235 - val_mape: 6.1776 - lr: 2.7000e-05\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4788 - mae: 24.6371 - mape: 9.4787 - val_loss: 6.1107 - val_mae: 7.9099 - val_mape: 6.1106 - lr: 2.7000e-05\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3760 - mae: 21.7126 - mape: 9.3760 - val_loss: 6.2865 - val_mae: 8.9028 - val_mape: 6.2864 - lr: 2.7000e-05\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3314 - mae: 22.7696 - mape: 9.3313 - val_loss: 6.1188 - val_mae: 7.7235 - val_mape: 6.1187 - lr: 2.7000e-05\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3775 - mae: 24.1598 - mape: 9.3774 - val_loss: 6.1170 - val_mae: 7.5287 - val_mape: 6.1169 - lr: 2.7000e-05\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3895 - mae: 23.4586 - mape: 9.3894 - val_loss: 6.1870 - val_mae: 7.6599 - val_mape: 6.1869 - lr: 2.7000e-05\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3020 - mae: 21.4976 - mape: 9.3020 - val_loss: 6.1146 - val_mae: 7.4524 - val_mape: 6.1146 - lr: 2.7000e-05\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5077 - mae: 24.0458 - mape: 9.5076 - val_loss: 6.1915 - val_mae: 9.2203 - val_mape: 6.1915 - lr: 2.7000e-05\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3826 - mae: 23.0854 - mape: 9.3826 - val_loss: 6.2118 - val_mae: 8.5074 - val_mape: 6.2117 - lr: 2.7000e-05\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3725 - mae: 22.7771 - mape: 9.3725 - val_loss: 6.2103 - val_mae: 9.1162 - val_mape: 6.2102 - lr: 2.7000e-05\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3423 - mae: 23.0757 - mape: 9.3422 - val_loss: 6.1768 - val_mae: 8.1779 - val_mape: 6.1767 - lr: 2.7000e-05\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4096 - mae: 23.7841 - mape: 9.4095 - val_loss: 6.2473 - val_mae: 8.6684 - val_mape: 6.2472 - lr: 2.7000e-05\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3134 - mae: 23.3042 - mape: 9.3133 - val_loss: 6.1546 - val_mae: 7.5728 - val_mape: 6.1545 - lr: 2.7000e-05\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2381 - mae: 21.8910 - mape: 9.2381 - val_loss: 6.1659 - val_mae: 8.1833 - val_mape: 6.1658 - lr: 2.7000e-05\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.1969 - mae: 23.1099 - mape: 9.1968 - val_loss: 6.2352 - val_mae: 8.4011 - val_mape: 6.2351 - lr: 2.7000e-05\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.5516 - mae: 23.1515 - mape: 9.5515\n",
      "Epoch 162: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5516 - mae: 23.1515 - mape: 9.5515 - val_loss: 6.0871 - val_mae: 7.7734 - val_mape: 6.0870 - lr: 2.7000e-05\n",
      "Epoch 162: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 6.0328474044799805; mae of 7.1426825523376465; mape of 6.032748699188232%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n",
      " 3/87 [>.............................] - ETA: 5s - loss: 9.4713 - mae: 24.5862 - mape: 9.4712 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.7132 - mae: 23.5235 - mape: 9.7131"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 9.7132 - mae: 23.5235 - mape: 9.7131 - val_loss: 6.1953 - val_mae: 12.3200 - val_mape: 6.1951 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6987 - mae: 22.8859 - mape: 9.6985 - val_loss: 6.3289 - val_mae: 12.3676 - val_mape: 6.3288 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.0378 - mae: 23.9447 - mape: 10.0377 - val_loss: 6.9281 - val_mae: 13.1308 - val_mape: 6.9279 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5929 - mae: 22.8744 - mape: 9.5927 - val_loss: 6.7963 - val_mae: 37.3550 - val_mape: 6.7961 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.0356 - mae: 24.8293 - mape: 10.0354 - val_loss: 7.7790 - val_mae: 14.9966 - val_mape: 7.7787 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6334 - mae: 23.9592 - mape: 9.6332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 9.6334 - mae: 23.9592 - mape: 9.6332 - val_loss: 6.1412 - val_mae: 14.0368 - val_mape: 6.1410 - lr: 0.0010\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8621 - mae: 23.9442 - mape: 9.8619 - val_loss: 6.7835 - val_mae: 36.3497 - val_mape: 6.7833 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5274 - mae: 22.9660 - mape: 9.5272 - val_loss: 7.4173 - val_mae: 29.1745 - val_mape: 7.4171 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7482 - mae: 24.5976 - mape: 9.7480 - val_loss: 8.5385 - val_mae: 18.9646 - val_mape: 8.5383 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6058 - mae: 21.5515 - mape: 9.6055 - val_loss: 6.4408 - val_mae: 10.0013 - val_mape: 6.4405 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7300 - mae: 25.1688 - mape: 9.7298 - val_loss: 6.1645 - val_mae: 10.2090 - val_mape: 6.1643 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8095 - mae: 24.6062 - mape: 9.8093 - val_loss: 6.4222 - val_mae: 14.0431 - val_mape: 6.4220 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8414 - mae: 22.5559 - mape: 9.8412 - val_loss: 6.8046 - val_mae: 18.2005 - val_mape: 6.8043 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8047 - mae: 23.9129 - mape: 9.8045 - val_loss: 6.4989 - val_mae: 20.2946 - val_mape: 6.4987 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6244 - mae: 22.9824 - mape: 9.6242 - val_loss: 7.9150 - val_mae: 26.9276 - val_mape: 7.9148 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8036 - mae: 23.9834 - mape: 9.8034 - val_loss: 6.4791 - val_mae: 14.1759 - val_mape: 6.4789 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6665 - mae: 23.5119 - mape: 9.6664 - val_loss: 6.8053 - val_mae: 19.4976 - val_mape: 6.8051 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8307 - mae: 23.8839 - mape: 9.8306 - val_loss: 6.7456 - val_mae: 22.1984 - val_mape: 6.7455 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7375 - mae: 25.1418 - mape: 9.7374 - val_loss: 8.7683 - val_mae: 29.4982 - val_mape: 8.7682 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5506 - mae: 22.7495 - mape: 9.5505 - val_loss: 6.8893 - val_mae: 33.6754 - val_mape: 6.8891 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6201 - mae: 24.8715 - mape: 9.6199 - val_loss: 6.4573 - val_mae: 10.2848 - val_mape: 6.4571 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6376 - mae: 26.1828 - mape: 9.6373 - val_loss: 7.0527 - val_mae: 13.7194 - val_mape: 7.0525 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8525 - mae: 26.1609 - mape: 9.8523 - val_loss: 6.5332 - val_mae: 11.6349 - val_mape: 6.5329 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5799 - mae: 23.4901 - mape: 9.5796 - val_loss: 6.5708 - val_mae: 9.9506 - val_mape: 6.5706 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7110 - mae: 23.8145 - mape: 9.7108 - val_loss: 6.6485 - val_mae: 25.7287 - val_mape: 6.6482 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5741 - mae: 23.9462 - mape: 9.5739 - val_loss: 6.3121 - val_mae: 9.4035 - val_mape: 6.3118 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4642 - mae: 23.1242 - mape: 9.4640 - val_loss: 7.5133 - val_mae: 31.8309 - val_mape: 7.5131 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6820 - mae: 23.9909 - mape: 9.6818 - val_loss: 6.3756 - val_mae: 9.8388 - val_mape: 6.3754 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5086 - mae: 24.5652 - mape: 9.5083 - val_loss: 6.6560 - val_mae: 19.7743 - val_mape: 6.6558 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4377 - mae: 22.2716 - mape: 9.4374 - val_loss: 6.3557 - val_mae: 13.4420 - val_mape: 6.3554 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7693 - mae: 26.0548 - mape: 9.7690 - val_loss: 6.6138 - val_mae: 14.3880 - val_mape: 6.6135 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7262 - mae: 24.4597 - mape: 9.7259 - val_loss: 6.7737 - val_mae: 25.2222 - val_mape: 6.7735 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8999 - mae: 23.4966 - mape: 9.8996 - val_loss: 6.4480 - val_mae: 11.9673 - val_mape: 6.4478 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6871 - mae: 24.5970 - mape: 9.6868 - val_loss: 6.5486 - val_mae: 11.5710 - val_mape: 6.5483 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7904 - mae: 24.2006 - mape: 9.7901 - val_loss: 7.5559 - val_mae: 13.3348 - val_mape: 7.5556 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.5233 - mae: 22.8034 - mape: 9.5231\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5233 - mae: 22.8034 - mape: 9.5231 - val_loss: 6.7354 - val_mae: 14.9618 - val_mape: 6.7352 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5101 - mae: 20.9455 - mape: 9.5099 - val_loss: 6.8236 - val_mae: 15.4524 - val_mape: 6.8234 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.3789 - mae: 19.4921 - mape: 9.3787 - val_loss: 6.6663 - val_mae: 15.4580 - val_mape: 6.6661 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4003 - mae: 22.7619 - mape: 9.4001 - val_loss: 6.3675 - val_mae: 9.5544 - val_mape: 6.3673 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4081 - mae: 21.7563 - mape: 9.4079 - val_loss: 6.2497 - val_mae: 12.4108 - val_mape: 6.2495 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2997 - mae: 21.5628 - mape: 9.2995 - val_loss: 6.2513 - val_mae: 11.2469 - val_mape: 6.2511 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3469 - mae: 21.3473 - mape: 9.3467 - val_loss: 6.3744 - val_mae: 13.4585 - val_mape: 6.3742 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3565 - mae: 22.0628 - mape: 9.3563 - val_loss: 6.2112 - val_mae: 11.3816 - val_mape: 6.2110 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4830 - mae: 22.0443 - mape: 9.4828 - val_loss: 6.2557 - val_mae: 10.7164 - val_mape: 6.2555 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3914 - mae: 21.5505 - mape: 9.3913 - val_loss: 7.0843 - val_mae: 17.1693 - val_mape: 7.0841 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.1666 - mae: 20.2195 - mape: 9.1665 - val_loss: 6.2219 - val_mae: 10.3289 - val_mape: 6.2217 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2626 - mae: 20.8548 - mape: 9.2625 - val_loss: 6.2715 - val_mae: 12.1550 - val_mape: 6.2713 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3317 - mae: 22.9092 - mape: 9.3316 - val_loss: 6.2281 - val_mae: 9.8521 - val_mape: 6.2280 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.2995 - mae: 22.1789 - mape: 9.2994 - val_loss: 6.8347 - val_mae: 10.5299 - val_mape: 6.8346 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5062 - mae: 22.1676 - mape: 9.5060 - val_loss: 6.3717 - val_mae: 15.6261 - val_mape: 6.3716 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3340 - mae: 21.9473 - mape: 9.3338 - val_loss: 6.2178 - val_mae: 10.6350 - val_mape: 6.2177 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.3136 - mae: 21.4451 - mape: 9.3134 - val_loss: 6.1789 - val_mae: 11.1223 - val_mape: 6.1787 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.1909 - mae: 21.4009 - mape: 9.1907 - val_loss: 6.3195 - val_mae: 10.4888 - val_mape: 6.3193 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4504 - mae: 22.3649 - mape: 9.4503 - val_loss: 6.2430 - val_mae: 10.4841 - val_mape: 6.2429 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5423 - mae: 21.6362 - mape: 9.5422 - val_loss: 6.3604 - val_mae: 14.7187 - val_mape: 6.3603 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.2560 - mae: 20.5063 - mape: 9.2559 - val_loss: 6.3845 - val_mae: 15.1847 - val_mape: 6.3844 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4655 - mae: 22.8431 - mape: 9.4653 - val_loss: 6.3714 - val_mae: 13.4289 - val_mape: 6.3712 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.3010 - mae: 22.2379 - mape: 9.3009 - val_loss: 6.4047 - val_mae: 14.3674 - val_mape: 6.4045 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4816 - mae: 21.4884 - mape: 9.4815 - val_loss: 6.2127 - val_mae: 10.4630 - val_mape: 6.2126 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4693 - mae: 23.3087 - mape: 9.4692 - val_loss: 6.3916 - val_mae: 12.7242 - val_mape: 6.3915 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3672 - mae: 22.4842 - mape: 9.3670 - val_loss: 6.2952 - val_mae: 12.1217 - val_mape: 6.2950 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3974 - mae: 21.1194 - mape: 9.3973 - val_loss: 6.5853 - val_mae: 17.5078 - val_mape: 6.5852 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5287 - mae: 23.9999 - mape: 9.5286 - val_loss: 6.3919 - val_mae: 10.9525 - val_mape: 6.3918 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.2231 - mae: 22.5174 - mape: 9.2230 - val_loss: 7.2461 - val_mae: 14.6177 - val_mape: 7.2460 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4028 - mae: 19.6336 - mape: 9.4026 - val_loss: 7.4248 - val_mae: 23.4854 - val_mape: 7.4247 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.3561 - mae: 20.8586 - mape: 9.3560\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3561 - mae: 20.8586 - mape: 9.3560 - val_loss: 6.8155 - val_mae: 12.5218 - val_mape: 6.8154 - lr: 3.0000e-04\n",
      "Epoch 66: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 6.141181468963623; mae of 14.036847114562988; mape of 6.140955448150635%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n",
      " 2/87 [..............................] - ETA: 4s - loss: 8.5069 - mae: 17.7842 - mape: 8.5067  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.7582 - mae: 24.0250 - mape: 9.7580"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 9.7582 - mae: 24.0250 - mape: 9.7580 - val_loss: 7.7300 - val_mae: 27.7213 - val_mape: 7.7299 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.7873 - mae: 23.8937 - mape: 9.7871"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 98ms/step - loss: 9.7873 - mae: 23.8937 - mape: 9.7871 - val_loss: 6.2423 - val_mae: 12.8082 - val_mape: 6.2421 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7398 - mae: 25.3088 - mape: 9.7396 - val_loss: 6.3772 - val_mae: 12.1651 - val_mape: 6.3769 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5724 - mae: 23.1362 - mape: 9.5722 - val_loss: 6.9661 - val_mae: 24.8134 - val_mape: 6.9658 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9193 - mae: 25.6180 - mape: 9.9191 - val_loss: 8.4500 - val_mae: 13.3812 - val_mape: 8.4497 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7104 - mae: 24.2630 - mape: 9.7101 - val_loss: 6.5330 - val_mae: 12.3571 - val_mape: 6.5328 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5117 - mae: 23.8781 - mape: 9.5115 - val_loss: 6.4504 - val_mae: 11.4869 - val_mape: 6.4502 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6915 - mae: 23.9937 - mape: 9.6913 - val_loss: 7.4269 - val_mae: 14.8156 - val_mape: 7.4267 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5600 - mae: 25.9738 - mape: 9.5598 - val_loss: 6.7735 - val_mae: 18.1484 - val_mape: 6.7733 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6034 - mae: 24.1399 - mape: 9.6032 - val_loss: 6.6704 - val_mae: 12.9482 - val_mape: 6.6702 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6521 - mae: 23.8674 - mape: 9.6519 - val_loss: 7.0025 - val_mae: 12.3743 - val_mape: 7.0023 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7752 - mae: 24.7014 - mape: 9.7750 - val_loss: 7.8306 - val_mae: 16.5559 - val_mape: 7.8304 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3753 - mae: 22.6645 - mape: 9.3751 - val_loss: 6.9266 - val_mae: 21.1238 - val_mape: 6.9264 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5642 - mae: 23.2653 - mape: 9.5640 - val_loss: 6.7376 - val_mae: 17.4914 - val_mape: 6.7374 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6940 - mae: 23.4077 - mape: 9.6938 - val_loss: 7.0941 - val_mae: 18.5371 - val_mape: 7.0939 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6361 - mae: 26.5622 - mape: 9.6359 - val_loss: 6.5586 - val_mae: 15.8840 - val_mape: 6.5584 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5647 - mae: 25.3166 - mape: 9.5645 - val_loss: 6.7692 - val_mae: 16.1864 - val_mape: 6.7690 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7536 - mae: 24.5848 - mape: 9.7534 - val_loss: 6.8263 - val_mae: 15.9755 - val_mape: 6.8261 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8298 - mae: 25.4408 - mape: 9.8297 - val_loss: 7.5628 - val_mae: 14.2714 - val_mape: 7.5626 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7571 - mae: 24.0583 - mape: 9.7569 - val_loss: 6.9701 - val_mae: 13.7119 - val_mape: 6.9699 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8946 - mae: 25.9807 - mape: 9.8944 - val_loss: 6.6402 - val_mae: 13.3297 - val_mape: 6.6400 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5377 - mae: 23.1040 - mape: 9.5375 - val_loss: 6.8385 - val_mae: 14.3077 - val_mape: 6.8383 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7836 - mae: 23.9085 - mape: 9.7833 - val_loss: 6.7912 - val_mae: 19.0222 - val_mape: 6.7909 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5759 - mae: 24.7208 - mape: 9.5757 - val_loss: 6.7545 - val_mae: 14.3855 - val_mape: 6.7543 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7900 - mae: 24.2272 - mape: 9.7898 - val_loss: 6.6646 - val_mae: 13.6061 - val_mape: 6.6644 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4159 - mae: 22.7319 - mape: 9.4157 - val_loss: 6.9570 - val_mae: 17.6172 - val_mape: 6.9568 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4501 - mae: 22.5227 - mape: 9.4499 - val_loss: 6.8874 - val_mae: 17.4411 - val_mape: 6.8873 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7937 - mae: 26.8514 - mape: 9.7936 - val_loss: 6.8884 - val_mae: 12.8982 - val_mape: 6.8882 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5280 - mae: 22.5628 - mape: 9.5279 - val_loss: 6.5960 - val_mae: 12.1194 - val_mape: 6.5958 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9625 - mae: 23.2108 - mape: 9.9624 - val_loss: 6.6904 - val_mae: 11.9808 - val_mape: 6.6903 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7412 - mae: 27.7179 - mape: 9.7411 - val_loss: 7.6191 - val_mae: 16.6104 - val_mape: 7.6189 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6699 - mae: 23.6610 - mape: 9.6698\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6699 - mae: 23.6610 - mape: 9.6698 - val_loss: 6.4932 - val_mae: 11.9458 - val_mape: 6.4931 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2675 - mae: 22.8637 - mape: 9.2674 - val_loss: 6.9958 - val_mae: 16.8979 - val_mape: 6.9956 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4074 - mae: 24.6603 - mape: 9.4072 - val_loss: 6.5958 - val_mae: 14.1880 - val_mape: 6.5957 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.3167 - mae: 21.9416 - mape: 9.3165 - val_loss: 6.9555 - val_mae: 14.6917 - val_mape: 6.9554 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.3274 - mae: 23.6833 - mape: 9.3273 - val_loss: 6.4539 - val_mae: 12.9404 - val_mape: 6.4538 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2257 - mae: 23.7264 - mape: 9.2255 - val_loss: 6.5392 - val_mae: 12.4886 - val_mape: 6.5391 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.2665 - mae: 21.8743 - mape: 9.2664 - val_loss: 6.4689 - val_mae: 11.5713 - val_mape: 6.4688 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3733 - mae: 23.0685 - mape: 9.3732 - val_loss: 6.8174 - val_mae: 14.9129 - val_mape: 6.8173 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.2598 - mae: 21.3273 - mape: 9.2597 - val_loss: 6.5681 - val_mae: 12.2033 - val_mape: 6.5680 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2608 - mae: 21.9333 - mape: 9.2607 - val_loss: 6.6754 - val_mae: 16.4352 - val_mape: 6.6753 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4546 - mae: 22.0604 - mape: 9.4545 - val_loss: 6.6386 - val_mae: 11.7388 - val_mape: 6.6385 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4038 - mae: 22.0929 - mape: 9.4037 - val_loss: 6.5746 - val_mae: 13.9681 - val_mape: 6.5745 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.2220 - mae: 22.3267 - mape: 9.2219 - val_loss: 6.6977 - val_mae: 12.3123 - val_mape: 6.6976 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4888 - mae: 23.5838 - mape: 9.4887 - val_loss: 6.8200 - val_mae: 12.2725 - val_mape: 6.8199 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3810 - mae: 21.9464 - mape: 9.3809 - val_loss: 6.5184 - val_mae: 11.7657 - val_mape: 6.5183 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.1059 - mae: 21.9048 - mape: 9.1058 - val_loss: 6.6091 - val_mae: 12.7068 - val_mape: 6.6090 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2844 - mae: 24.4046 - mape: 9.2843 - val_loss: 6.5594 - val_mae: 12.5554 - val_mape: 6.5593 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4535 - mae: 21.6529 - mape: 9.4534 - val_loss: 6.5618 - val_mae: 12.5807 - val_mape: 6.5617 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3223 - mae: 24.5472 - mape: 9.3223 - val_loss: 7.0298 - val_mae: 12.6931 - val_mape: 7.0297 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3358 - mae: 21.1401 - mape: 9.3357 - val_loss: 6.7097 - val_mae: 11.8924 - val_mape: 6.7097 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.0716 - mae: 20.7776 - mape: 9.0715 - val_loss: 6.7422 - val_mae: 14.1731 - val_mape: 6.7422 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3718 - mae: 23.3499 - mape: 9.3718 - val_loss: 6.9268 - val_mae: 16.5254 - val_mape: 6.9267 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.2846 - mae: 22.5932 - mape: 9.2845 - val_loss: 6.6251 - val_mae: 12.8341 - val_mape: 6.6251 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3767 - mae: 23.0315 - mape: 9.3766 - val_loss: 6.7615 - val_mae: 15.6829 - val_mape: 6.7614 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.2187 - mae: 23.3355 - mape: 9.2186 - val_loss: 7.3202 - val_mae: 18.4335 - val_mape: 7.3201 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3365 - mae: 22.7628 - mape: 9.3365 - val_loss: 7.1891 - val_mae: 15.1164 - val_mape: 7.1891 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.5551 - mae: 23.5952 - mape: 9.5551 - val_loss: 6.6462 - val_mae: 12.4539 - val_mape: 6.6462 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.2236 - mae: 22.6047 - mape: 9.2235 - val_loss: 6.8805 - val_mae: 12.4185 - val_mape: 6.8805 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.1721 - mae: 22.1095 - mape: 9.1721 - val_loss: 6.6975 - val_mae: 13.1300 - val_mape: 6.6975 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3751 - mae: 22.7180 - mape: 9.3750 - val_loss: 6.6392 - val_mae: 11.8119 - val_mape: 6.6391 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.4027 - mae: 23.4814 - mape: 9.4026\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4027 - mae: 23.4814 - mape: 9.4026 - val_loss: 6.6702 - val_mae: 12.8719 - val_mape: 6.6702 - lr: 3.0000e-04\n",
      "Epoch 62: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 6.242271900177002; mae of 12.808208465576172; mape of 6.242065906524658%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n",
      " 3/87 [>.............................] - ETA: 5s - loss: 10.4079 - mae: 29.6649 - mape: 10.4077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 10.0272 - mae: 27.0973 - mape: 10.0269"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 10.0272 - mae: 27.0973 - mape: 10.0269 - val_loss: 5.9920 - val_mae: 12.2460 - val_mape: 5.9917 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 87ms/step - loss: 9.8891 - mae: 24.4911 - mape: 9.8889 - val_loss: 5.9942 - val_mae: 8.1002 - val_mape: 5.9939 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8859 - mae: 23.1646 - mape: 9.8856 - val_loss: 6.1464 - val_mae: 17.2958 - val_mape: 6.1461 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.9408 - mae: 27.4452 - mape: 9.9405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 9.9408 - mae: 27.4452 - mape: 9.9405 - val_loss: 5.7211 - val_mae: 7.9583 - val_mape: 5.7209 - lr: 0.0010\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 84ms/step - loss: 9.9944 - mae: 26.1672 - mape: 9.9942 - val_loss: 6.4340 - val_mae: 16.2942 - val_mape: 6.4338 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9082 - mae: 23.6090 - mape: 9.9080 - val_loss: 6.1566 - val_mae: 8.6280 - val_mape: 6.1563 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.9102 - mae: 25.4147 - mape: 9.9100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 98ms/step - loss: 9.9102 - mae: 25.4147 - mape: 9.9100 - val_loss: 5.6070 - val_mae: 8.7541 - val_mape: 5.6068 - lr: 0.0010\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9430 - mae: 24.8849 - mape: 9.9428 - val_loss: 5.9015 - val_mae: 10.2139 - val_mape: 5.9012 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9007 - mae: 23.6770 - mape: 9.9005 - val_loss: 6.2317 - val_mae: 9.3731 - val_mape: 6.2314 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9165 - mae: 27.6351 - mape: 9.9162 - val_loss: 5.9161 - val_mae: 9.8239 - val_mape: 5.9158 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7702 - mae: 23.6187 - mape: 9.7700 - val_loss: 5.8665 - val_mae: 9.2614 - val_mape: 5.8663 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9722 - mae: 23.4119 - mape: 9.9720 - val_loss: 6.3746 - val_mae: 18.5219 - val_mape: 6.3744 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9049 - mae: 25.5846 - mape: 9.9047 - val_loss: 5.7593 - val_mae: 7.9160 - val_mape: 5.7590 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8035 - mae: 26.1818 - mape: 9.8033 - val_loss: 5.8276 - val_mae: 9.0592 - val_mape: 5.8274 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9376 - mae: 26.2874 - mape: 9.9374 - val_loss: 5.8355 - val_mae: 8.1546 - val_mape: 5.8353 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7819 - mae: 24.6181 - mape: 9.7817 - val_loss: 6.9180 - val_mae: 20.7302 - val_mape: 6.9179 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8227 - mae: 23.8136 - mape: 9.8226 - val_loss: 5.8292 - val_mae: 8.3320 - val_mape: 5.8290 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.0021 - mae: 25.4713 - mape: 10.0019 - val_loss: 6.0490 - val_mae: 15.6351 - val_mape: 6.0489 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6981 - mae: 24.8172 - mape: 9.6980 - val_loss: 5.7704 - val_mae: 8.5404 - val_mape: 5.7703 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6284 - mae: 23.0169 - mape: 9.6283 - val_loss: 5.8071 - val_mae: 9.8662 - val_mape: 5.8070 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8099 - mae: 23.5311 - mape: 9.8098 - val_loss: 5.7946 - val_mae: 8.7996 - val_mape: 5.7945 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5940 - mae: 24.6748 - mape: 9.5939 - val_loss: 6.2689 - val_mae: 12.8188 - val_mape: 6.2688 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8992 - mae: 25.5822 - mape: 9.8991 - val_loss: 6.0845 - val_mae: 9.2648 - val_mape: 6.0844 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.8796 - mae: 25.1575 - mape: 9.8795 - val_loss: 5.9799 - val_mae: 8.4010 - val_mape: 5.9798 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8725 - mae: 22.4963 - mape: 9.8724 - val_loss: 6.1060 - val_mae: 9.8980 - val_mape: 6.1059 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7683 - mae: 24.8462 - mape: 9.7682 - val_loss: 6.3571 - val_mae: 19.7531 - val_mape: 6.3570 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4660 - mae: 24.3974 - mape: 9.4659 - val_loss: 5.8323 - val_mae: 8.0839 - val_mape: 5.8321 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.8357 - mae: 24.5930 - mape: 9.8356 - val_loss: 6.2937 - val_mae: 17.5586 - val_mape: 6.2936 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9008 - mae: 25.5150 - mape: 9.9007 - val_loss: 5.8732 - val_mae: 9.9542 - val_mape: 5.8731 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 9.5681 - mae: 23.7368 - mape: 9.5680 - val_loss: 5.9508 - val_mae: 10.0582 - val_mape: 5.9507 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5829 - mae: 24.1573 - mape: 9.5829 - val_loss: 6.1900 - val_mae: 10.0638 - val_mape: 6.1899 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6595 - mae: 26.4325 - mape: 9.6594 - val_loss: 5.7099 - val_mae: 8.5106 - val_mape: 5.7098 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6733 - mae: 26.0142 - mape: 9.6732 - val_loss: 6.2013 - val_mae: 9.5369 - val_mape: 6.2013 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5185 - mae: 24.6151 - mape: 9.5185 - val_loss: 7.0389 - val_mae: 10.6457 - val_mape: 7.0389 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4866 - mae: 25.7723 - mape: 9.4865 - val_loss: 5.9865 - val_mae: 9.4991 - val_mape: 5.9864 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9047 - mae: 27.1939 - mape: 9.9047 - val_loss: 6.0625 - val_mae: 11.3886 - val_mape: 6.0624 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6833 - mae: 22.7691 - mape: 9.6833\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6833 - mae: 22.7691 - mape: 9.6833 - val_loss: 6.4648 - val_mae: 10.6845 - val_mape: 6.4648 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3803 - mae: 22.7185 - mape: 9.3802 - val_loss: 5.8920 - val_mae: 9.6329 - val_mape: 5.8920 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5315 - mae: 23.7882 - mape: 9.5314 - val_loss: 5.7437 - val_mae: 8.6604 - val_mape: 5.7436 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3816 - mae: 22.1202 - mape: 9.3816 - val_loss: 5.7154 - val_mae: 9.2332 - val_mape: 5.7154 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5985 - mae: 23.5110 - mape: 9.5984 - val_loss: 5.7507 - val_mae: 9.4959 - val_mape: 5.7507 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4963 - mae: 23.8688 - mape: 9.4963 - val_loss: 5.6708 - val_mae: 8.4229 - val_mape: 5.6707 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4677 - mae: 23.0273 - mape: 9.4677 - val_loss: 5.8833 - val_mae: 8.8438 - val_mape: 5.8833 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4755 - mae: 23.8694 - mape: 9.4755 - val_loss: 5.7727 - val_mae: 7.4847 - val_mape: 5.7726 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4366 - mae: 23.7343 - mape: 9.4366 - val_loss: 6.4958 - val_mae: 16.2753 - val_mape: 6.4958 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3531 - mae: 24.6534 - mape: 9.3531 - val_loss: 5.7564 - val_mae: 8.1830 - val_mape: 5.7563 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4800 - mae: 24.6754 - mape: 9.4800 - val_loss: 5.8313 - val_mae: 9.2603 - val_mape: 5.8313 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4872 - mae: 21.6547 - mape: 9.4872 - val_loss: 5.7666 - val_mae: 12.2225 - val_mape: 5.7665 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5613 - mae: 25.1568 - mape: 9.5612 - val_loss: 5.7011 - val_mae: 8.4725 - val_mape: 5.7011 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6370 - mae: 23.8155 - mape: 9.6370 - val_loss: 5.7863 - val_mae: 7.5502 - val_mape: 5.7863 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5174 - mae: 23.5716 - mape: 9.5173 - val_loss: 6.1234 - val_mae: 14.8013 - val_mape: 6.1234 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3150 - mae: 23.3562 - mape: 9.3150 - val_loss: 5.6649 - val_mae: 7.6373 - val_mape: 5.6649 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.3094 - mae: 23.5622 - mape: 9.3094 - val_loss: 5.7972 - val_mae: 8.2008 - val_mape: 5.7972 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6218 - mae: 23.8057 - mape: 9.6218 - val_loss: 6.0419 - val_mae: 14.3706 - val_mape: 6.0419 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.2562 - mae: 22.6967 - mape: 9.2562 - val_loss: 5.8651 - val_mae: 9.5974 - val_mape: 5.8650 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6161 - mae: 24.2620 - mape: 9.6161 - val_loss: 5.6537 - val_mae: 7.8981 - val_mape: 5.6537 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4841 - mae: 25.2235 - mape: 9.4841 - val_loss: 5.8453 - val_mae: 9.3387 - val_mape: 5.8453 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4161 - mae: 22.0266 - mape: 9.4161 - val_loss: 5.6904 - val_mae: 8.0140 - val_mape: 5.6904 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5512 - mae: 25.3237 - mape: 9.5512 - val_loss: 5.8414 - val_mae: 10.5439 - val_mape: 5.8414 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4333 - mae: 23.8314 - mape: 9.4333 - val_loss: 5.6829 - val_mae: 7.6572 - val_mape: 5.6829 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4103 - mae: 22.2021 - mape: 9.4103 - val_loss: 5.7621 - val_mae: 8.7748 - val_mape: 5.7621 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.4905 - mae: 24.1591 - mape: 9.4905 - val_loss: 5.8096 - val_mae: 8.3749 - val_mape: 5.8096 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3613 - mae: 23.4709 - mape: 9.3613 - val_loss: 5.8528 - val_mae: 7.5549 - val_mape: 5.8527 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4605 - mae: 24.1815 - mape: 9.4604 - val_loss: 5.8115 - val_mae: 9.2820 - val_mape: 5.8115 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.3202 - mae: 23.4655 - mape: 9.3201 - val_loss: 5.7688 - val_mae: 9.5897 - val_mape: 5.7688 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5491 - mae: 20.5260 - mape: 9.5491 - val_loss: 5.8136 - val_mae: 8.8469 - val_mape: 5.8135 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.5929 - mae: 24.3699 - mape: 9.5929\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5929 - mae: 24.3699 - mape: 9.5929 - val_loss: 5.7312 - val_mae: 9.3842 - val_mape: 5.7311 - lr: 3.0000e-04\n",
      "Epoch 67: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 5.606991291046143; mae of 8.754107475280762; mape of 5.606761455535889%;\n"
     ]
    }
   ],
   "source": [
    "#Hybrid Reset\n",
    "model = keras.models.load_model(\"savedmodels/Multi_input_reset/\")\n",
    "make_trainable(model)\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, \"crossvalidationmodels/Hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 6.563482761383057 - Mean average error: 13.558576583862305% - Mean percentage error: 6.562680244445801%\n",
      "    Score on unseen data: Loss: 8.262116432189941 - Mean average error: 24.822660446166992% - Mean percentage error: 8.261313438415527%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 6.0328474044799805 - Mean average error: 7.1426825523376465% - Mean percentage error: 6.032748699188232%\n",
      "    Score on unseen data: Loss: 8.2923002243042 - Mean average error: 18.00579261779785% - Mean percentage error: 8.292201042175293%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 6.141181468963623 - Mean average error: 14.036847114562988% - Mean percentage error: 6.140955448150635%\n",
      "    Score on unseen data: Loss: 8.262323379516602 - Mean average error: 19.565610885620117% - Mean percentage error: 8.262097358703613%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 6.242271900177002 - Mean average error: 12.808208465576172% - Mean percentage error: 6.242065906524658%\n",
      "    Score on unseen data: Loss: 8.533177375793457 - Mean average error: 22.184568405151367% - Mean percentage error: 8.532971382141113%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 5.606991291046143 - Mean average error: 8.754107475280762% - Mean percentage error: 5.606761455535889%\n",
      "    Score on unseen data: Loss: 8.473061561584473 - Mean average error: 26.733665466308594% - Mean percentage error: 8.472832679748535%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 6.117354965209961\n",
      "> Mean average error: 11.260084438323975\n",
      "> Mean percentage error: 6.117042350769043\n",
      "> Unseen Loss: 8.364595794677735\n",
      "> Unseen Mean average error: 22.262459564208985\n",
      "> Unseen Mean percentage error: 8.364283180236816\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 2s - loss: 57.1316 - mae: 203.6752 - mape: 53.1697"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 192s 2s/step - loss: 56.8093 - mae: 202.0179 - mape: 52.8493 - val_loss: 19.1112 - val_mae: 87.1285 - val_mape: 15.3355 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 20.7527 - mae: 53.6359 - mape: 17.1640"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 124ms/step - loss: 20.7527 - mae: 53.6359 - mape: 17.1640 - val_loss: 11.9449 - val_mae: 27.1342 - val_mape: 8.5146 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 17.5771 - mae: 42.6336 - mape: 14.2727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 138s 2s/step - loss: 17.5771 - mae: 42.6336 - mape: 14.2727 - val_loss: 10.4699 - val_mae: 24.8025 - val_mape: 7.2872 - lr: 0.0010\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 116ms/step - loss: 16.2517 - mae: 37.7022 - mape: 13.1785 - val_loss: 10.3142 - val_mae: 31.2456 - val_mape: 7.3517 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 15.3228 - mae: 32.3680 - mape: 12.4596 - val_loss: 10.9568 - val_mae: 28.3464 - val_mape: 8.1939 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 14.6973 - mae: 33.7802 - mape: 12.0235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 56s 646ms/step - loss: 14.6973 - mae: 33.7802 - mape: 12.0235 - val_loss: 9.3651 - val_mae: 19.2549 - val_mape: 6.7880 - lr: 0.0010\n",
      "Epoch 7/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 14.3175 - mae: 33.1620 - mape: 11.8288"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 140ms/step - loss: 14.3175 - mae: 33.1620 - mape: 11.8288 - val_loss: 9.1871 - val_mae: 17.4378 - val_mape: 6.7861 - lr: 0.0010\n",
      "Epoch 8/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 117ms/step - loss: 13.8477 - mae: 33.2803 - mape: 11.5261 - val_loss: 9.7680 - val_mae: 24.1247 - val_mape: 7.5272 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 13.7211 - mae: 31.0251 - mape: 11.5583 - val_loss: 8.9511 - val_mae: 17.5494 - val_mape: 6.8621 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 13.5582 - mae: 35.2669 - mape: 11.5408 - val_loss: 9.7528 - val_mae: 17.7831 - val_mape: 7.8038 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 13.2592 - mae: 29.5987 - mape: 11.3783 - val_loss: 8.6394 - val_mae: 20.6834 - val_mape: 6.8256 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.8970 - mae: 32.6646 - mape: 11.1436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 133ms/step - loss: 12.8970 - mae: 32.6646 - mape: 11.1436 - val_loss: 8.2179 - val_mae: 15.6120 - val_mape: 6.5271 - lr: 0.0010\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 123ms/step - loss: 12.7405 - mae: 30.8407 - mape: 11.1064 - val_loss: 8.1386 - val_mae: 14.6492 - val_mape: 6.5618 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 12.8032 - mae: 29.2246 - mape: 11.2785 - val_loss: 8.2618 - val_mae: 17.5233 - val_mape: 6.7896 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 16s 187ms/step - loss: 12.5293 - mae: 29.0081 - mape: 11.1079 - val_loss: 7.9830 - val_mae: 15.7630 - val_mape: 6.6118 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 20s 232ms/step - loss: 12.3760 - mae: 31.4623 - mape: 11.0507 - val_loss: 8.1119 - val_mae: 16.5626 - val_mape: 6.8307 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 12.2889 - mae: 31.2421 - mape: 11.0507"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 21s 242ms/step - loss: 12.2889 - mae: 31.2421 - mape: 11.0507 - val_loss: 7.6472 - val_mae: 13.6859 - val_mape: 6.4533 - lr: 0.0010\n",
      "Epoch 18/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 20s 231ms/step - loss: 11.8724 - mae: 31.5054 - mape: 10.7179 - val_loss: 7.9945 - val_mae: 16.0891 - val_mape: 6.8806 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 28s 325ms/step - loss: 11.9544 - mae: 29.1085 - mape: 10.8774 - val_loss: 8.0098 - val_mae: 20.6161 - val_mape: 6.9701 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 11.9027 - mae: 25.9005 - mape: 10.8959"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 22s 260ms/step - loss: 11.9027 - mae: 25.9005 - mape: 10.8959 - val_loss: 7.4125 - val_mae: 12.6861 - val_mape: 6.4392 - lr: 0.0010\n",
      "Epoch 21/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 20s 229ms/step - loss: 11.8105 - mae: 28.4816 - mape: 10.8686 - val_loss: 7.7796 - val_mae: 14.8464 - val_mape: 6.8704 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 19s 222ms/step - loss: 11.6897 - mae: 29.2076 - mape: 10.8104 - val_loss: 7.5159 - val_mae: 18.1490 - val_mape: 6.6659 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 22s 254ms/step - loss: 11.4016 - mae: 28.1087 - mape: 10.5775 - val_loss: 7.5356 - val_mae: 15.3466 - val_mape: 6.7370 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 20s 233ms/step - loss: 11.6035 - mae: 29.5227 - mape: 10.8302 - val_loss: 7.6990 - val_mae: 18.2283 - val_mape: 6.9515 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 20s 236ms/step - loss: 11.4875 - mae: 28.6082 - mape: 10.7647 - val_loss: 7.3087 - val_mae: 12.6607 - val_mape: 6.6115 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 20s 231ms/step - loss: 11.3875 - mae: 30.0276 - mape: 10.7129 - val_loss: 7.3106 - val_mae: 14.9284 - val_mape: 6.6583 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 27s 314ms/step - loss: 11.1120 - mae: 28.6857 - mape: 10.4798 - val_loss: 7.0693 - val_mae: 11.8411 - val_mape: 6.4585 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 20s 236ms/step - loss: 11.2632 - mae: 26.8447 - mape: 10.6704 - val_loss: 7.2538 - val_mae: 16.3784 - val_mape: 6.6784 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 21s 239ms/step - loss: 11.0429 - mae: 25.7943 - mape: 10.4847 - val_loss: 7.2177 - val_mae: 16.6972 - val_mape: 6.6768 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 21s 239ms/step - loss: 11.1620 - mae: 28.3002 - mape: 10.6405 - val_loss: 7.3780 - val_mae: 12.3605 - val_mape: 6.8748 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 20s 229ms/step - loss: 11.3563 - mae: 28.5887 - mape: 10.8702 - val_loss: 7.3059 - val_mae: 17.7373 - val_mape: 6.8370 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 20s 229ms/step - loss: 11.2265 - mae: 27.2104 - mape: 10.7731 - val_loss: 7.8413 - val_mae: 15.5242 - val_mape: 7.4031 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 21s 246ms/step - loss: 11.3257 - mae: 26.6069 - mape: 10.9005 - val_loss: 7.6022 - val_mae: 23.1859 - val_mape: 7.1913 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 20s 235ms/step - loss: 10.7361 - mae: 29.3890 - mape: 10.3393 - val_loss: 6.9547 - val_mae: 11.0363 - val_mape: 6.5708 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 20s 227ms/step - loss: 11.0121 - mae: 26.5957 - mape: 10.6414 - val_loss: 6.8231 - val_mae: 11.6012 - val_mape: 6.4658 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 20s 231ms/step - loss: 11.2427 - mae: 27.7771 - mape: 10.8975 - val_loss: 8.1847 - val_mae: 26.7224 - val_mape: 7.8514 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 20s 237ms/step - loss: 10.9476 - mae: 27.7033 - mape: 10.6247 - val_loss: 7.5816 - val_mae: 18.9544 - val_mape: 7.2698 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 20s 232ms/step - loss: 10.8847 - mae: 25.9657 - mape: 10.5831 - val_loss: 7.4826 - val_mae: 13.1480 - val_mape: 7.1917 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 11.0329 - mae: 25.6201 - mape: 10.7513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 21s 245ms/step - loss: 11.0329 - mae: 25.6201 - mape: 10.7513 - val_loss: 6.5981 - val_mae: 10.3300 - val_mape: 6.3263 - lr: 0.0010\n",
      "Epoch 40/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 20s 231ms/step - loss: 11.0298 - mae: 27.5690 - mape: 10.7654 - val_loss: 7.2368 - val_mae: 15.2797 - val_mape: 6.9815 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 21s 242ms/step - loss: 10.7915 - mae: 27.8098 - mape: 10.5454 - val_loss: 7.7074 - val_mae: 22.3941 - val_mape: 7.4702 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 26s 302ms/step - loss: 10.7565 - mae: 28.1575 - mape: 10.5271 - val_loss: 7.5584 - val_mae: 24.1219 - val_mape: 7.3373 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 14s 159ms/step - loss: 10.8856 - mae: 27.1634 - mape: 10.6719 - val_loss: 7.2461 - val_mae: 28.3457 - val_mape: 7.0391 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 10.7436 - mae: 27.8091 - mape: 10.5440 - val_loss: 6.6081 - val_mae: 11.0628 - val_mape: 6.4163 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 10.8325 - mae: 29.3408 - mape: 10.6471 - val_loss: 6.6857 - val_mae: 11.3227 - val_mape: 6.5067 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 10.6292 - mae: 26.0821 - mape: 10.4571 - val_loss: 6.7324 - val_mae: 9.8697 - val_mape: 6.5673 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 10.9047 - mae: 26.8309 - mape: 10.7464 - val_loss: 6.9300 - val_mae: 11.7513 - val_mape: 6.7784 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.4953 - mae: 24.8868 - mape: 10.3491 - val_loss: 6.6943 - val_mae: 11.4117 - val_mape: 6.5533 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 10.8383 - mae: 27.8169 - mape: 10.7020 - val_loss: 6.4963 - val_mae: 11.4902 - val_mape: 6.3654 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 10.6090 - mae: 24.8540 - mape: 10.4835 - val_loss: 7.0390 - val_mae: 20.5040 - val_mape: 6.9185 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 10.5248 - mae: 27.2026 - mape: 10.4085 - val_loss: 6.6272 - val_mae: 11.8630 - val_mape: 6.5155 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 10.8386 - mae: 27.1569 - mape: 10.7315 - val_loss: 7.0068 - val_mae: 14.2697 - val_mape: 6.9041 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.6540 - mae: 26.0062 - mape: 10.5558"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 126ms/step - loss: 10.6540 - mae: 26.0062 - mape: 10.5558 - val_loss: 6.3696 - val_mae: 10.2908 - val_mape: 6.2755 - lr: 0.0010\n",
      "Epoch 54/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 106ms/step - loss: 10.6426 - mae: 24.1978 - mape: 10.5519 - val_loss: 6.8122 - val_mae: 12.8876 - val_mape: 6.7253 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 10.6250 - mae: 27.5324 - mape: 10.5420 - val_loss: 6.4929 - val_mae: 11.1383 - val_mape: 6.4133 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.4883 - mae: 26.0752 - mape: 10.4121 - val_loss: 6.9624 - val_mae: 14.6373 - val_mape: 6.8898 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 10.5093 - mae: 26.0233 - mape: 10.4400 - val_loss: 6.9259 - val_mae: 14.0549 - val_mape: 6.8600 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 10.5966 - mae: 26.5972 - mape: 10.5337 - val_loss: 6.6482 - val_mae: 12.4220 - val_mape: 6.5881 - lr: 0.0010\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 10.5446 - mae: 25.1347 - mape: 10.4872 - val_loss: 6.5725 - val_mae: 11.6223 - val_mape: 6.5177 - lr: 0.0010\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 10.6683 - mae: 28.1596 - mape: 10.6160 - val_loss: 6.8443 - val_mae: 15.7215 - val_mape: 6.7944 - lr: 0.0010\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 16s 187ms/step - loss: 10.5524 - mae: 26.9704 - mape: 10.5047 - val_loss: 6.8744 - val_mae: 23.3694 - val_mape: 6.8290 - lr: 0.0010\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 20s 233ms/step - loss: 10.5542 - mae: 29.2944 - mape: 10.5108 - val_loss: 6.6340 - val_mae: 16.1684 - val_mape: 6.5925 - lr: 0.0010\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 10.5180 - mae: 26.5211 - mape: 10.4787 - val_loss: 7.3647 - val_mae: 17.5331 - val_mape: 7.3274 - lr: 0.0010\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.6480 - mae: 25.5556 - mape: 10.6121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 21s 238ms/step - loss: 10.6480 - mae: 25.5556 - mape: 10.6121 - val_loss: 6.2483 - val_mae: 9.5537 - val_mape: 6.2140 - lr: 0.0010\n",
      "Epoch 65/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 20s 226ms/step - loss: 10.3512 - mae: 26.6440 - mape: 10.3185 - val_loss: 6.6742 - val_mae: 9.8225 - val_mape: 6.6432 - lr: 0.0010\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 20s 237ms/step - loss: 10.3216 - mae: 25.1711 - mape: 10.2918 - val_loss: 6.5746 - val_mae: 12.0837 - val_mape: 6.5461 - lr: 0.0010\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 20s 224ms/step - loss: 10.3592 - mae: 24.5910 - mape: 10.3320 - val_loss: 6.4553 - val_mae: 10.9959 - val_mape: 6.4290 - lr: 0.0010\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 20s 230ms/step - loss: 10.4753 - mae: 30.3135 - mape: 10.4500 - val_loss: 6.6261 - val_mae: 15.7635 - val_mape: 6.6020 - lr: 0.0010\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 10.6728 - mae: 26.2935 - mape: 10.6498 - val_loss: 6.5823 - val_mae: 19.3230 - val_mape: 6.5598 - lr: 0.0010\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 20s 171ms/step - loss: 10.5533 - mae: 27.9928 - mape: 10.5313 - val_loss: 7.2266 - val_mae: 20.1759 - val_mape: 7.2056 - lr: 0.0010\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 20s 231ms/step - loss: 10.4418 - mae: 25.6719 - mape: 10.4215 - val_loss: 6.5444 - val_mae: 11.0712 - val_mape: 6.5248 - lr: 0.0010\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 24s 279ms/step - loss: 10.2859 - mae: 24.7385 - mape: 10.2674 - val_loss: 6.7135 - val_mae: 15.2019 - val_mape: 6.6959 - lr: 0.0010\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 23s 240ms/step - loss: 10.1760 - mae: 24.4775 - mape: 10.1588 - val_loss: 6.5902 - val_mae: 10.8048 - val_mape: 6.5734 - lr: 0.0010\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 20s 233ms/step - loss: 10.3779 - mae: 26.2499 - mape: 10.3622 - val_loss: 6.7014 - val_mae: 11.4611 - val_mape: 6.6861 - lr: 0.0010\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 10.3735 - mae: 27.0938 - mape: 10.3590 - val_loss: 7.1915 - val_mae: 19.0489 - val_mape: 7.1776 - lr: 0.0010\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 10.2816 - mae: 27.5355 - mape: 10.2680 - val_loss: 7.2373 - val_mae: 18.8681 - val_mape: 7.2240 - lr: 0.0010\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 20s 230ms/step - loss: 10.3055 - mae: 23.5718 - mape: 10.2922 - val_loss: 6.9152 - val_mae: 19.4101 - val_mape: 6.9028 - lr: 0.0010\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 19s 223ms/step - loss: 10.5983 - mae: 24.9643 - mape: 10.5869 - val_loss: 6.5796 - val_mae: 17.3049 - val_mape: 6.5687 - lr: 0.0010\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 20s 225ms/step - loss: 10.1507 - mae: 25.4574 - mape: 10.1402 - val_loss: 7.5741 - val_mae: 29.1878 - val_mape: 7.5644 - lr: 0.0010\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 20s 236ms/step - loss: 10.2796 - mae: 24.6833 - mape: 10.2700 - val_loss: 6.6488 - val_mae: 11.9413 - val_mape: 6.6396 - lr: 0.0010\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 29s 330ms/step - loss: 10.5122 - mae: 26.4418 - mape: 10.5034 - val_loss: 6.8663 - val_mae: 23.8164 - val_mape: 6.8576 - lr: 0.0010\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 52s 603ms/step - loss: 10.1370 - mae: 28.5431 - mape: 10.1282 - val_loss: 6.6156 - val_mae: 10.6580 - val_mape: 6.6072 - lr: 0.0010\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 351s 4s/step - loss: 10.3644 - mae: 27.9061 - mape: 10.3563 - val_loss: 7.9315 - val_mae: 24.1275 - val_mape: 7.9237 - lr: 0.0010\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 332s 4s/step - loss: 10.2335 - mae: 24.5971 - mape: 10.2263 - val_loss: 6.4723 - val_mae: 10.5775 - val_mape: 6.4657 - lr: 0.0010\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 61s 645ms/step - loss: 10.2674 - mae: 25.6997 - mape: 10.2611 - val_loss: 6.4418 - val_mae: 9.9487 - val_mape: 6.4356 - lr: 0.0010\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 10.3604 - mae: 29.9051 - mape: 10.3546 - val_loss: 6.6561 - val_mae: 13.2025 - val_mape: 6.6505 - lr: 0.0010\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 96s 1s/step - loss: 10.2492 - mae: 24.9838 - mape: 10.2437 - val_loss: 6.5799 - val_mae: 16.7756 - val_mape: 6.5744 - lr: 0.0010\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 10.5129 - mae: 24.6346 - mape: 10.5078 - val_loss: 6.6485 - val_mae: 17.6379 - val_mape: 6.6436 - lr: 0.0010\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 10.4154 - mae: 25.0462 - mape: 10.4106 - val_loss: 7.3643 - val_mae: 10.9948 - val_mape: 7.3599 - lr: 0.0010\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 10.1923 - mae: 24.8735 - mape: 10.1880 - val_loss: 6.4289 - val_mae: 10.1252 - val_mape: 6.4248 - lr: 0.0010\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 10.3776 - mae: 23.0761 - mape: 10.3737 - val_loss: 6.4252 - val_mae: 10.2882 - val_mape: 6.4213 - lr: 0.0010\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 10.4610 - mae: 27.6768 - mape: 10.4569 - val_loss: 6.4562 - val_mae: 11.2835 - val_mape: 6.4521 - lr: 0.0010\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 14s 165ms/step - loss: 10.2619 - mae: 22.7977 - mape: 10.2582 - val_loss: 7.8152 - val_mae: 22.4298 - val_mape: 7.8117 - lr: 0.0010\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.2120 - mae: 24.6906 - mape: 10.2087\n",
      "Epoch 94: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 14s 159ms/step - loss: 10.2120 - mae: 24.6906 - mape: 10.2087 - val_loss: 6.8651 - val_mae: 22.6931 - val_mape: 6.8618 - lr: 0.0010\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 13s 156ms/step - loss: 10.2467 - mae: 26.8850 - mape: 10.2435 - val_loss: 6.3178 - val_mae: 9.2710 - val_mape: 6.3148 - lr: 3.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 9.8027 - mae: 24.7413 - mape: 9.7997 - val_loss: 6.5130 - val_mae: 9.3952 - val_mape: 6.5101 - lr: 3.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 13s 152ms/step - loss: 9.8832 - mae: 23.7408 - mape: 9.8803 - val_loss: 6.6693 - val_mae: 11.3955 - val_mape: 6.6663 - lr: 3.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 14s 164ms/step - loss: 10.1765 - mae: 25.1874 - mape: 10.1735 - val_loss: 6.3617 - val_mae: 9.3915 - val_mape: 6.3588 - lr: 3.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 9.9436 - mae: 26.4428 - mape: 9.9408 - val_loss: 6.3426 - val_mae: 11.2264 - val_mape: 6.3399 - lr: 3.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 15s 175ms/step - loss: 10.1029 - mae: 25.1408 - mape: 10.1002 - val_loss: 6.6588 - val_mae: 18.3376 - val_mape: 6.6562 - lr: 3.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 13s 154ms/step - loss: 9.8125 - mae: 25.0667 - mape: 9.8100 - val_loss: 6.5077 - val_mae: 11.3122 - val_mape: 6.5052 - lr: 3.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 16s 177ms/step - loss: 10.0610 - mae: 22.8978 - mape: 10.0586 - val_loss: 6.3689 - val_mae: 9.6509 - val_mape: 6.3665 - lr: 3.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 15s 177ms/step - loss: 9.9481 - mae: 23.7107 - mape: 9.9459 - val_loss: 6.3910 - val_mae: 9.1699 - val_mape: 6.3888 - lr: 3.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 15s 174ms/step - loss: 9.9134 - mae: 24.6426 - mape: 9.9113 - val_loss: 6.5231 - val_mae: 10.8020 - val_mape: 6.5210 - lr: 3.0000e-04\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 13s 155ms/step - loss: 9.8395 - mae: 24.6512 - mape: 9.8375 - val_loss: 6.3316 - val_mae: 11.5619 - val_mape: 6.3296 - lr: 3.0000e-04\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 9.8390 - mae: 24.0911 - mape: 9.8370 - val_loss: 6.3964 - val_mae: 10.0781 - val_mape: 6.3944 - lr: 3.0000e-04\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 14s 159ms/step - loss: 10.1944 - mae: 25.5979 - mape: 10.1925 - val_loss: 6.4563 - val_mae: 12.1229 - val_mape: 6.4544 - lr: 3.0000e-04\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 9.9342 - mae: 23.4256 - mape: 9.9323 - val_loss: 6.4561 - val_mae: 11.3878 - val_mape: 6.4542 - lr: 3.0000e-04\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 9.9572 - mae: 24.1761 - mape: 9.9553 - val_loss: 6.4294 - val_mae: 12.3864 - val_mape: 6.4275 - lr: 3.0000e-04\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 14s 157ms/step - loss: 9.9924 - mae: 25.1320 - mape: 9.9905 - val_loss: 6.4872 - val_mae: 10.0876 - val_mape: 6.4853 - lr: 3.0000e-04\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 10.0616 - mae: 27.2193 - mape: 10.0598 - val_loss: 6.6718 - val_mae: 13.4169 - val_mape: 6.6700 - lr: 3.0000e-04\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 9.8857 - mae: 24.1749 - mape: 9.8838 - val_loss: 6.5630 - val_mae: 11.6077 - val_mape: 6.5611 - lr: 3.0000e-04\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 15s 170ms/step - loss: 9.8799 - mae: 23.0781 - mape: 9.8781 - val_loss: 6.4178 - val_mae: 10.2541 - val_mape: 6.4159 - lr: 3.0000e-04\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 15s 161ms/step - loss: 10.0430 - mae: 22.3770 - mape: 10.0411 - val_loss: 6.8138 - val_mae: 10.7755 - val_mape: 6.8119 - lr: 3.0000e-04\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 15s 179ms/step - loss: 9.8313 - mae: 26.8728 - mape: 9.8295 - val_loss: 6.4642 - val_mae: 11.1788 - val_mape: 6.4624 - lr: 3.0000e-04\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 10.0570 - mae: 23.6134 - mape: 10.0551 - val_loss: 6.3576 - val_mae: 11.2326 - val_mape: 6.3555 - lr: 3.0000e-04\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 17s 191ms/step - loss: 9.9339 - mae: 23.5711 - mape: 9.9319 - val_loss: 6.3458 - val_mae: 11.1112 - val_mape: 6.3438 - lr: 3.0000e-04\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 10.0360 - mae: 27.3779 - mape: 10.0341 - val_loss: 6.2425 - val_mae: 11.1522 - val_mape: 6.2406 - lr: 3.0000e-04\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 9.9552 - mae: 23.7055 - mape: 9.9535 - val_loss: 6.4528 - val_mae: 10.0681 - val_mape: 6.4511 - lr: 3.0000e-04\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 14s 163ms/step - loss: 9.8187 - mae: 26.6249 - mape: 9.8169 - val_loss: 6.3489 - val_mae: 12.8745 - val_mape: 6.3470 - lr: 3.0000e-04\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 14s 162ms/step - loss: 9.9839 - mae: 22.5845 - mape: 9.9820 - val_loss: 6.3886 - val_mae: 9.6815 - val_mape: 6.3868 - lr: 3.0000e-04\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 14s 162ms/step - loss: 9.8487 - mae: 21.7371 - mape: 9.8469 - val_loss: 6.2887 - val_mae: 10.4362 - val_mape: 6.2869 - lr: 3.0000e-04\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 13s 153ms/step - loss: 10.0675 - mae: 25.2908 - mape: 10.0656 - val_loss: 6.2696 - val_mae: 11.3273 - val_mape: 6.2676 - lr: 3.0000e-04\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 10.0078 - mae: 22.1888 - mape: 10.0059 - val_loss: 6.4184 - val_mae: 11.1876 - val_mape: 6.4167 - lr: 3.0000e-04\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 15s 171ms/step - loss: 9.9626 - mae: 25.9725 - mape: 9.9610 - val_loss: 6.3373 - val_mae: 11.6270 - val_mape: 6.3357 - lr: 3.0000e-04\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 14s 161ms/step - loss: 10.0907 - mae: 24.2091 - mape: 10.0892 - val_loss: 6.8513 - val_mae: 18.8937 - val_mape: 6.8498 - lr: 3.0000e-04\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 15s 172ms/step - loss: 10.0238 - mae: 24.4968 - mape: 10.0223 - val_loss: 6.6181 - val_mae: 12.3645 - val_mape: 6.6166 - lr: 3.0000e-04\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 10.0345 - mae: 24.8354 - mape: 10.0330 - val_loss: 6.2983 - val_mae: 9.1381 - val_mape: 6.2968 - lr: 3.0000e-04\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 14s 162ms/step - loss: 10.0909 - mae: 26.3705 - mape: 10.0894 - val_loss: 6.8556 - val_mae: 11.1637 - val_mape: 6.8541 - lr: 3.0000e-04\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 15s 168ms/step - loss: 10.1002 - mae: 23.8068 - mape: 10.0988 - val_loss: 6.4053 - val_mae: 9.6195 - val_mape: 6.4039 - lr: 3.0000e-04\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 14s 158ms/step - loss: 10.1124 - mae: 23.5404 - mape: 10.1110 - val_loss: 6.5757 - val_mae: 11.1277 - val_mape: 6.5744 - lr: 3.0000e-04\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 13s 144ms/step - loss: 10.0472 - mae: 23.9080 - mape: 10.0458 - val_loss: 6.2840 - val_mae: 12.6858 - val_mape: 6.2827 - lr: 3.0000e-04\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 17s 194ms/step - loss: 9.7743 - mae: 24.5995 - mape: 9.7729 - val_loss: 6.3088 - val_mae: 9.2259 - val_mape: 6.3074 - lr: 3.0000e-04\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 16s 184ms/step - loss: 9.9155 - mae: 24.5342 - mape: 9.9140 - val_loss: 6.3329 - val_mae: 11.5698 - val_mape: 6.3315 - lr: 3.0000e-04\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 9.6555 - mae: 23.9651 - mape: 9.6541 - val_loss: 6.3881 - val_mae: 10.2477 - val_mape: 6.3868 - lr: 3.0000e-04\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 10.1029 - mae: 24.4508 - mape: 10.1016 - val_loss: 6.6028 - val_mae: 20.4279 - val_mape: 6.6015 - lr: 3.0000e-04\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 10.0546 - mae: 24.9112 - mape: 10.0533 - val_loss: 6.3232 - val_mae: 10.9711 - val_mape: 6.3219 - lr: 3.0000e-04\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 10.0187 - mae: 25.3064 - mape: 10.0174 - val_loss: 6.8654 - val_mae: 14.6207 - val_mape: 6.8641 - lr: 3.0000e-04\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 10s 120ms/step - loss: 9.8253 - mae: 24.6360 - mape: 9.8240 - val_loss: 6.5524 - val_mae: 11.1630 - val_mape: 6.5511 - lr: 3.0000e-04\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 13s 150ms/step - loss: 9.6760 - mae: 23.7720 - mape: 9.6747 - val_loss: 6.3907 - val_mae: 9.3505 - val_mape: 6.3894 - lr: 3.0000e-04\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 10.0244 - mae: 24.8068 - mape: 10.0231 - val_loss: 6.3367 - val_mae: 9.3675 - val_mape: 6.3354 - lr: 3.0000e-04\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 10.1803 - mae: 24.9156 - mape: 10.1790 - val_loss: 6.4263 - val_mae: 10.1919 - val_mape: 6.4251 - lr: 3.0000e-04\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 9.8834 - mae: 24.9906 - mape: 9.8821 - val_loss: 6.4134 - val_mae: 9.9087 - val_mape: 6.4121 - lr: 3.0000e-04\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 9.8970 - mae: 25.9266 - mape: 9.8958 - val_loss: 6.4007 - val_mae: 13.9591 - val_mape: 6.3995 - lr: 3.0000e-04\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 9.8815 - mae: 24.7276 - mape: 9.8803 - val_loss: 6.4172 - val_mae: 9.9605 - val_mape: 6.4161 - lr: 3.0000e-04\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 9.9001 - mae: 21.6784 - mape: 9.8989 - val_loss: 6.7528 - val_mae: 13.7060 - val_mape: 6.7517 - lr: 3.0000e-04\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 12s 135ms/step - loss: 10.0111 - mae: 23.0154 - mape: 10.0100 - val_loss: 6.5138 - val_mae: 12.1611 - val_mape: 6.5127 - lr: 3.0000e-04\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.9736 - mae: 25.2104 - mape: 9.9725\n",
      "Epoch 148: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 9.9736 - mae: 25.2104 - mape: 9.9725 - val_loss: 6.3364 - val_mae: 11.1546 - val_mape: 6.3352 - lr: 3.0000e-04\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 10s 121ms/step - loss: 9.8452 - mae: 23.1620 - mape: 9.8441 - val_loss: 6.5063 - val_mae: 9.4072 - val_mape: 6.5052 - lr: 9.0000e-05\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 9.8094 - mae: 23.0049 - mape: 9.8083 - val_loss: 6.4609 - val_mae: 11.8242 - val_mape: 6.4598 - lr: 9.0000e-05\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 9.7453 - mae: 23.8003 - mape: 9.7442 - val_loss: 6.2933 - val_mae: 9.5757 - val_mape: 6.2922 - lr: 9.0000e-05\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 9.8785 - mae: 22.9236 - mape: 9.8774 - val_loss: 6.2742 - val_mae: 9.1008 - val_mape: 6.2732 - lr: 9.0000e-05\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 12s 138ms/step - loss: 9.9243 - mae: 21.8987 - mape: 9.9232 - val_loss: 6.3701 - val_mae: 10.5340 - val_mape: 6.3691 - lr: 9.0000e-05\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 9.9244 - mae: 22.4332 - mape: 9.9234 - val_loss: 6.3485 - val_mae: 9.5280 - val_mape: 6.3475 - lr: 9.0000e-05\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 9.8279 - mae: 22.8316 - mape: 9.8270 - val_loss: 6.3868 - val_mae: 9.6681 - val_mape: 6.3858 - lr: 9.0000e-05\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 10s 120ms/step - loss: 9.9211 - mae: 23.9410 - mape: 9.9201 - val_loss: 6.5722 - val_mae: 10.7044 - val_mape: 6.5712 - lr: 9.0000e-05\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 9.9965 - mae: 22.8236 - mape: 9.9955 - val_loss: 6.3218 - val_mae: 9.1926 - val_mape: 6.3208 - lr: 9.0000e-05\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 9.9504 - mae: 23.7387 - mape: 9.9494 - val_loss: 6.4041 - val_mae: 9.9170 - val_mape: 6.4031 - lr: 9.0000e-05\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 9.8880 - mae: 25.4275 - mape: 9.8870 - val_loss: 6.5748 - val_mae: 9.9041 - val_mape: 6.5739 - lr: 9.0000e-05\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 10.1307 - mae: 23.6579 - mape: 10.1297 - val_loss: 6.4177 - val_mae: 9.6228 - val_mape: 6.4167 - lr: 9.0000e-05\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 9.7910 - mae: 22.3241 - mape: 9.7900 - val_loss: 6.4764 - val_mae: 9.8899 - val_mape: 6.4753 - lr: 9.0000e-05\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 9.7470 - mae: 21.4341 - mape: 9.7460 - val_loss: 6.5227 - val_mae: 10.0001 - val_mape: 6.5217 - lr: 9.0000e-05\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 9.8994 - mae: 24.8745 - mape: 9.8984 - val_loss: 6.3386 - val_mae: 9.5967 - val_mape: 6.3377 - lr: 9.0000e-05\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 9.7802 - mae: 23.8656 - mape: 9.7792 - val_loss: 6.3694 - val_mae: 9.3737 - val_mape: 6.3685 - lr: 9.0000e-05\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 9.9334 - mae: 24.5855 - mape: 9.9324 - val_loss: 6.6346 - val_mae: 10.3422 - val_mape: 6.6337 - lr: 9.0000e-05\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 12s 144ms/step - loss: 9.8182 - mae: 21.9340 - mape: 9.8172 - val_loss: 6.5397 - val_mae: 11.8496 - val_mape: 6.5387 - lr: 9.0000e-05\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 9.8470 - mae: 22.6673 - mape: 9.8460 - val_loss: 6.3164 - val_mae: 10.4585 - val_mape: 6.3155 - lr: 9.0000e-05\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 10.0805 - mae: 24.5301 - mape: 10.0796 - val_loss: 6.3716 - val_mae: 10.0710 - val_mape: 6.3707 - lr: 9.0000e-05\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 9.7363 - mae: 22.8048 - mape: 9.7354 - val_loss: 6.3542 - val_mae: 9.8761 - val_mape: 6.3533 - lr: 9.0000e-05\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 11s 120ms/step - loss: 10.1176 - mae: 23.9425 - mape: 10.1167 - val_loss: 6.5956 - val_mae: 10.1726 - val_mape: 6.5947 - lr: 9.0000e-05\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 9.9486 - mae: 23.8777 - mape: 9.9478 - val_loss: 6.4276 - val_mae: 9.7578 - val_mape: 6.4267 - lr: 9.0000e-05\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 9.9059 - mae: 23.2392 - mape: 9.9050 - val_loss: 6.3852 - val_mae: 9.7997 - val_mape: 6.3844 - lr: 9.0000e-05\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 9.9253 - mae: 25.5737 - mape: 9.9244 - val_loss: 6.3625 - val_mae: 9.7915 - val_mape: 6.3616 - lr: 9.0000e-05\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 17s 189ms/step - loss: 9.8425 - mae: 23.7783 - mape: 9.8416 - val_loss: 6.5047 - val_mae: 11.8195 - val_mape: 6.5038 - lr: 9.0000e-05\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 9.6570 - mae: 24.3444 - mape: 9.6561 - val_loss: 6.3311 - val_mae: 9.8149 - val_mape: 6.3302 - lr: 9.0000e-05\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 9.6162 - mae: 21.4356 - mape: 9.6153 - val_loss: 6.3356 - val_mae: 9.5877 - val_mape: 6.3347 - lr: 9.0000e-05\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 9.8189 - mae: 24.0291 - mape: 9.8180 - val_loss: 6.3900 - val_mae: 11.2864 - val_mape: 6.3892 - lr: 9.0000e-05\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.9392 - mae: 23.4580 - mape: 9.9384\n",
      "Epoch 178: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 9.9392 - mae: 23.4580 - mape: 9.9384 - val_loss: 6.4802 - val_mae: 10.3720 - val_mape: 6.4794 - lr: 9.0000e-05\n",
      "Epoch 178: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 6.248281002044678; mae of 9.55369758605957; mape of 6.214001655578613%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 10.7669 - mae: 27.2570 - mape: 10.7492"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 14s 145ms/step - loss: 10.7472 - mae: 27.2821 - mape: 10.7296 - val_loss: 6.3452 - val_mae: 14.1561 - val_mape: 6.3359 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 126ms/step - loss: 10.5034 - mae: 26.5876 - mape: 10.4963 - val_loss: 6.7705 - val_mae: 15.0889 - val_mape: 6.7648 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 10.4113 - mae: 25.9649 - mape: 10.4063 - val_loss: 7.1102 - val_mae: 15.6215 - val_mape: 7.1063 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 14s 156ms/step - loss: 10.4009 - mae: 28.2696 - mape: 10.3973 - val_loss: 6.5299 - val_mae: 14.9776 - val_mape: 6.5263 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 13s 146ms/step - loss: 10.3070 - mae: 25.1750 - mape: 10.3032 - val_loss: 6.9316 - val_mae: 20.9205 - val_mape: 6.9282 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 10.5890 - mae: 26.5128 - mape: 10.5858 - val_loss: 7.5202 - val_mae: 19.7353 - val_mape: 7.5168 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 11s 122ms/step - loss: 10.4399 - mae: 26.0575 - mape: 10.4365 - val_loss: 6.7774 - val_mae: 14.1918 - val_mape: 6.7741 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 10.7483 - mae: 28.3746 - mape: 10.7450 - val_loss: 6.8616 - val_mae: 19.4855 - val_mape: 6.8586 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.3585 - mae: 27.7401 - mape: 10.3554"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 128ms/step - loss: 10.3585 - mae: 27.7401 - mape: 10.3554 - val_loss: 6.1781 - val_mae: 13.4316 - val_mape: 6.1751 - lr: 0.0010\n",
      "Epoch 10/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 110ms/step - loss: 10.3081 - mae: 27.4874 - mape: 10.3050 - val_loss: 7.1414 - val_mae: 18.5774 - val_mape: 7.1379 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 10.2550 - mae: 27.6305 - mape: 10.2517 - val_loss: 6.3986 - val_mae: 13.9043 - val_mape: 6.3956 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.4258 - mae: 24.3940 - mape: 10.4228 - val_loss: 6.2536 - val_mae: 13.2293 - val_mape: 6.2504 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 10.5412 - mae: 28.4253 - mape: 10.5381 - val_loss: 6.4565 - val_mae: 16.6276 - val_mape: 6.4538 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 10.2929 - mae: 25.2877 - mape: 10.2901 - val_loss: 6.9675 - val_mae: 18.2584 - val_mape: 6.9648 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 10.3908 - mae: 24.6513 - mape: 10.3882 - val_loss: 6.4265 - val_mae: 13.2406 - val_mape: 6.4239 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 10.1795 - mae: 24.2720 - mape: 10.1766 - val_loss: 6.3384 - val_mae: 14.8158 - val_mape: 6.3357 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 10.7797 - mae: 26.4683 - mape: 10.7771 - val_loss: 6.7819 - val_mae: 17.7224 - val_mape: 6.7794 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 10.4987 - mae: 26.5050 - mape: 10.4962 - val_loss: 7.9214 - val_mae: 27.7580 - val_mape: 7.9191 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 10.4210 - mae: 28.7932 - mape: 10.4188 - val_loss: 6.6150 - val_mae: 15.5108 - val_mape: 6.6129 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 10.4471 - mae: 27.2206 - mape: 10.4449 - val_loss: 6.3736 - val_mae: 15.4752 - val_mape: 6.3714 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 10.3057 - mae: 26.0575 - mape: 10.3035 - val_loss: 6.5225 - val_mae: 13.2943 - val_mape: 6.5204 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 10.1664 - mae: 24.4458 - mape: 10.1642 - val_loss: 6.8747 - val_mae: 20.1660 - val_mape: 6.8725 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 10.4199 - mae: 24.3011 - mape: 10.4176 - val_loss: 6.3590 - val_mae: 13.7242 - val_mape: 6.3566 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 10.4567 - mae: 26.1351 - mape: 10.4544 - val_loss: 7.0482 - val_mae: 18.2214 - val_mape: 7.0459 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 10.4213 - mae: 25.5492 - mape: 10.4190 - val_loss: 6.7549 - val_mae: 13.7622 - val_mape: 6.7527 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 10.1376 - mae: 27.0304 - mape: 10.1354 - val_loss: 6.5236 - val_mae: 13.5523 - val_mape: 6.5214 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 10.0698 - mae: 26.5204 - mape: 10.0676 - val_loss: 6.4536 - val_mae: 14.3093 - val_mape: 6.4512 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 10s 121ms/step - loss: 10.1856 - mae: 24.3936 - mape: 10.1833 - val_loss: 6.7545 - val_mae: 18.8375 - val_mape: 6.7523 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 10.4849 - mae: 25.5113 - mape: 10.4825 - val_loss: 6.5010 - val_mae: 14.7996 - val_mape: 6.4987 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 9.9212 - mae: 25.8819 - mape: 9.9189 - val_loss: 6.6721 - val_mae: 15.3266 - val_mape: 6.6699 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 10.3220 - mae: 26.6608 - mape: 10.3199 - val_loss: 6.3837 - val_mae: 12.8675 - val_mape: 6.3816 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 10.3916 - mae: 26.4131 - mape: 10.3895 - val_loss: 6.4463 - val_mae: 14.7326 - val_mape: 6.4442 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 10.4962 - mae: 27.3422 - mape: 10.4938 - val_loss: 7.1086 - val_mae: 16.9963 - val_mape: 7.1062 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 11s 130ms/step - loss: 9.9361 - mae: 23.4625 - mape: 9.9339 - val_loss: 6.4129 - val_mae: 14.0343 - val_mape: 6.4108 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 10.2436 - mae: 26.5339 - mape: 10.2415 - val_loss: 6.9278 - val_mae: 21.9765 - val_mape: 6.9258 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 10.4009 - mae: 29.2120 - mape: 10.3988 - val_loss: 6.5501 - val_mae: 15.4925 - val_mape: 6.5481 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 10.2764 - mae: 28.0474 - mape: 10.2743 - val_loss: 6.7085 - val_mae: 14.0292 - val_mape: 6.7063 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 10.2393 - mae: 26.3343 - mape: 10.2372 - val_loss: 7.0720 - val_mae: 19.0435 - val_mape: 7.0700 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.0935 - mae: 24.7486 - mape: 10.0915\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 10.0935 - mae: 24.7486 - mape: 10.0915 - val_loss: 6.6330 - val_mae: 16.8043 - val_mape: 6.6310 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.8631 - mae: 24.6913 - mape: 9.8610 - val_loss: 6.6217 - val_mae: 19.6806 - val_mape: 6.6197 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 9.9880 - mae: 25.4423 - mape: 9.9860 - val_loss: 6.3826 - val_mae: 13.8386 - val_mape: 6.3807 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.8475 - mae: 24.7717 - mape: 9.8456 - val_loss: 6.2898 - val_mae: 13.9047 - val_mape: 6.2880 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 9.9083 - mae: 24.0204 - mape: 9.9065 - val_loss: 6.3720 - val_mae: 15.3023 - val_mape: 6.3702 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 10s 121ms/step - loss: 10.2031 - mae: 25.0480 - mape: 10.2014 - val_loss: 6.8859 - val_mae: 19.4000 - val_mape: 6.8843 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 10.1662 - mae: 26.5557 - mape: 10.1646 - val_loss: 6.8676 - val_mae: 13.8679 - val_mape: 6.8660 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 10.1608 - mae: 26.4396 - mape: 10.1593 - val_loss: 6.5727 - val_mae: 17.3866 - val_mape: 6.5712 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 9.9069 - mae: 23.2713 - mape: 9.9055 - val_loss: 6.6422 - val_mae: 15.5168 - val_mape: 6.6407 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 9.8433 - mae: 22.6816 - mape: 9.8418 - val_loss: 6.2792 - val_mae: 13.1383 - val_mape: 6.2778 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 11s 121ms/step - loss: 9.9871 - mae: 25.9137 - mape: 9.9857 - val_loss: 6.3305 - val_mae: 13.7295 - val_mape: 6.3290 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 9.7972 - mae: 22.7403 - mape: 9.7958 - val_loss: 6.3327 - val_mae: 14.8964 - val_mape: 6.3313 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 13s 151ms/step - loss: 10.0415 - mae: 23.4515 - mape: 10.0401 - val_loss: 6.5160 - val_mae: 13.4694 - val_mape: 6.5146 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 9.9130 - mae: 22.2092 - mape: 9.9116 - val_loss: 6.2787 - val_mae: 13.6685 - val_mape: 6.2774 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 12s 134ms/step - loss: 9.9580 - mae: 23.3714 - mape: 9.9566 - val_loss: 6.3569 - val_mae: 12.9470 - val_mape: 6.3556 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 10.0020 - mae: 24.9450 - mape: 10.0006 - val_loss: 6.3019 - val_mae: 12.8863 - val_mape: 6.3005 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 12s 141ms/step - loss: 9.8079 - mae: 23.4574 - mape: 9.8065 - val_loss: 6.3493 - val_mae: 13.2206 - val_mape: 6.3479 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 9.9758 - mae: 24.7584 - mape: 9.9746 - val_loss: 6.6908 - val_mae: 17.0427 - val_mape: 6.6896 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 13s 151ms/step - loss: 10.0136 - mae: 25.3908 - mape: 10.0125 - val_loss: 6.3448 - val_mae: 14.3132 - val_mape: 6.3437 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 9.9089 - mae: 23.2137 - mape: 9.9078 - val_loss: 6.2316 - val_mae: 13.0792 - val_mape: 6.2305 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 9.8779 - mae: 24.1785 - mape: 9.8769 - val_loss: 6.2942 - val_mae: 13.1250 - val_mape: 6.2931 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 9.6455 - mae: 23.4995 - mape: 9.6445 - val_loss: 6.5276 - val_mae: 14.1877 - val_mape: 6.5266 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 9.7427 - mae: 21.9236 - mape: 9.7417 - val_loss: 6.5695 - val_mae: 14.7549 - val_mape: 6.5685 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 10.0305 - mae: 25.0299 - mape: 10.0295 - val_loss: 6.2568 - val_mae: 12.9607 - val_mape: 6.2559 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 10.1272 - mae: 24.2283 - mape: 10.1263 - val_loss: 6.2379 - val_mae: 13.0978 - val_mape: 6.2369 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 9.8898 - mae: 24.7414 - mape: 9.8889 - val_loss: 6.9368 - val_mae: 15.8993 - val_mape: 6.9359 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 11s 125ms/step - loss: 9.7822 - mae: 23.1394 - mape: 9.7812 - val_loss: 6.8377 - val_mae: 14.9052 - val_mape: 6.8368 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 10.1175 - mae: 25.2551 - mape: 10.1166 - val_loss: 6.4551 - val_mae: 14.1812 - val_mape: 6.4542 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 12s 142ms/step - loss: 9.8632 - mae: 21.9589 - mape: 9.8623 - val_loss: 6.4565 - val_mae: 16.6926 - val_mape: 6.4556 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 9.8804 - mae: 23.8487 - mape: 9.8795 - val_loss: 6.6522 - val_mae: 14.9471 - val_mape: 6.6512 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.0301 - mae: 24.9295 - mape: 10.0292\n",
      "Epoch 69: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 10.0301 - mae: 24.9295 - mape: 10.0292 - val_loss: 6.2706 - val_mae: 13.0021 - val_mape: 6.2697 - lr: 3.0000e-04\n",
      "Epoch 69: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 6.178133010864258; mae of 13.431587219238281; mape of 6.175069808959961%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 10.5249 - mae: 27.3333 - mape: 10.5217"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 15s 162ms/step - loss: 10.5249 - mae: 27.3333 - mape: 10.5217 - val_loss: 7.8624 - val_mae: 17.3761 - val_mape: 7.8590 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 10.4817 - mae: 25.3150 - mape: 10.4781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 13s 148ms/step - loss: 10.4817 - mae: 25.3150 - mape: 10.4781 - val_loss: 7.0148 - val_mae: 11.9192 - val_mape: 7.0118 - lr: 0.0010\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 128ms/step - loss: 10.3921 - mae: 28.4616 - mape: 10.3891 - val_loss: 8.1027 - val_mae: 24.4541 - val_mape: 8.0998 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 10.3969 - mae: 24.6680 - mape: 10.3937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 126ms/step - loss: 10.3935 - mae: 24.5333 - mape: 10.3903 - val_loss: 6.7577 - val_mae: 12.5375 - val_mape: 6.7547 - lr: 0.0010\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 126ms/step - loss: 10.2774 - mae: 25.8531 - mape: 10.2747 - val_loss: 7.0801 - val_mae: 12.1731 - val_mape: 7.0775 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 10.3810 - mae: 24.5304 - mape: 10.3783 - val_loss: 6.7921 - val_mae: 12.6731 - val_mape: 6.7894 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 10.2711 - mae: 24.9663 - mape: 10.2681 - val_loss: 6.7591 - val_mae: 11.5367 - val_mape: 6.7559 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 11s 128ms/step - loss: 10.5080 - mae: 25.7844 - mape: 10.5045 - val_loss: 6.8881 - val_mae: 11.5618 - val_mape: 6.8846 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 10.2068 - mae: 24.1015 - mape: 10.2032 - val_loss: 7.9837 - val_mae: 20.7637 - val_mape: 7.9796 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 10.4628 - mae: 27.6850 - mape: 10.4589 - val_loss: 7.4440 - val_mae: 11.8034 - val_mape: 7.4402 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 11s 123ms/step - loss: 10.2169 - mae: 26.8706 - mape: 10.2132 - val_loss: 8.4812 - val_mae: 22.3309 - val_mape: 8.4776 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 10.4396 - mae: 28.3925 - mape: 10.4361 - val_loss: 7.5477 - val_mae: 24.6911 - val_mape: 7.5444 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 10.3418 - mae: 29.2345 - mape: 10.3383 - val_loss: 7.2136 - val_mae: 13.4704 - val_mape: 7.2101 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 10.4749 - mae: 27.3240 - mape: 10.4718 - val_loss: 6.9811 - val_mae: 11.5901 - val_mape: 6.9782 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 14s 160ms/step - loss: 9.9860 - mae: 28.0837 - mape: 9.9833 - val_loss: 6.8470 - val_mae: 11.0181 - val_mape: 6.8442 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 10.1289 - mae: 28.2639 - mape: 10.1263 - val_loss: 7.0397 - val_mae: 13.6402 - val_mape: 7.0371 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 10.4544 - mae: 28.1563 - mape: 10.4520 - val_loss: 7.3606 - val_mae: 16.9749 - val_mape: 7.3583 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.0449 - mae: 26.4108 - mape: 10.0427"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 127ms/step - loss: 10.0449 - mae: 26.4108 - mape: 10.0427 - val_loss: 6.6054 - val_mae: 10.7382 - val_mape: 6.6031 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      " 1/87 [..............................] - ETA: 6s - loss: 9.4091 - mae: 41.7872 - mape: 9.4068"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 110ms/step - loss: 10.5278 - mae: 28.9317 - mape: 10.5249 - val_loss: 6.8483 - val_mae: 11.7151 - val_mape: 6.8451 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 11s 131ms/step - loss: 10.2953 - mae: 24.4942 - mape: 10.2924 - val_loss: 7.0527 - val_mae: 14.3405 - val_mape: 7.0502 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 9.9853 - mae: 26.7095 - mape: 9.9830 - val_loss: 7.3949 - val_mae: 14.3832 - val_mape: 7.3926 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 11s 129ms/step - loss: 10.2879 - mae: 27.8070 - mape: 10.2853 - val_loss: 6.8646 - val_mae: 10.9677 - val_mape: 6.8621 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 10.1062 - mae: 25.0983 - mape: 10.1038 - val_loss: 6.7552 - val_mae: 13.2774 - val_mape: 6.7528 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 12s 132ms/step - loss: 9.6610 - mae: 25.1918 - mape: 9.6584 - val_loss: 6.9625 - val_mae: 15.7776 - val_mape: 6.9601 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 22s 256ms/step - loss: 10.1989 - mae: 27.0742 - mape: 10.1960 - val_loss: 7.0497 - val_mae: 13.3613 - val_mape: 7.0463 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 10.1207 - mae: 25.5207 - mape: 10.1174 - val_loss: 7.0344 - val_mae: 12.0813 - val_mape: 7.0315 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.4862 - mae: 27.8489 - mape: 10.4830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 128ms/step - loss: 10.4862 - mae: 27.8489 - mape: 10.4830 - val_loss: 6.5998 - val_mae: 10.2868 - val_mape: 6.5968 - lr: 0.0010\n",
      "Epoch 28/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 118ms/step - loss: 10.3932 - mae: 31.0248 - mape: 10.3905 - val_loss: 7.1559 - val_mae: 16.3618 - val_mape: 7.1535 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 11s 126ms/step - loss: 10.0450 - mae: 25.3592 - mape: 10.0426 - val_loss: 6.8266 - val_mae: 10.9039 - val_mape: 6.8242 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 10.0852 - mae: 28.1039 - mape: 10.0828 - val_loss: 7.2078 - val_mae: 11.5496 - val_mape: 7.2056 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 10s 120ms/step - loss: 10.3902 - mae: 26.0601 - mape: 10.3881 - val_loss: 8.0384 - val_mae: 18.6164 - val_mape: 8.0363 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 10.0441 - mae: 26.6130 - mape: 10.0418 - val_loss: 6.6522 - val_mae: 10.6779 - val_mape: 6.6500 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.9629 - mae: 27.9284 - mape: 9.9607 - val_loss: 6.7627 - val_mae: 12.9685 - val_mape: 6.7605 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 10.4049 - mae: 29.6201 - mape: 10.4027 - val_loss: 7.1609 - val_mae: 16.7176 - val_mape: 7.1587 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 10.3257 - mae: 27.9732 - mape: 10.3236 - val_loss: 7.0874 - val_mae: 11.3362 - val_mape: 7.0853 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 10.0794 - mae: 25.1976 - mape: 10.0772 - val_loss: 7.1739 - val_mae: 12.5174 - val_mape: 7.1716 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.9511 - mae: 26.7759 - mape: 9.9489 - val_loss: 7.3757 - val_mae: 20.3068 - val_mape: 7.3735 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.1176 - mae: 26.8321 - mape: 10.1154 - val_loss: 6.9880 - val_mae: 14.5426 - val_mape: 6.9858 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 12s 133ms/step - loss: 9.9542 - mae: 27.5231 - mape: 9.9522 - val_loss: 6.9663 - val_mae: 13.8370 - val_mape: 6.9645 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 12s 137ms/step - loss: 9.9298 - mae: 23.2345 - mape: 9.9279 - val_loss: 6.9467 - val_mae: 11.7381 - val_mape: 6.9447 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 10.0691 - mae: 29.4669 - mape: 10.0670 - val_loss: 6.9190 - val_mae: 18.5196 - val_mape: 6.9171 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.8626 - mae: 25.1390 - mape: 9.8607 - val_loss: 6.9067 - val_mae: 11.5273 - val_mape: 6.9049 - lr: 0.0010\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 10.0545 - mae: 25.6926 - mape: 10.0528 - val_loss: 7.0272 - val_mae: 11.8279 - val_mape: 7.0256 - lr: 0.0010\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 11s 127ms/step - loss: 10.1320 - mae: 26.9895 - mape: 10.1303 - val_loss: 6.8293 - val_mae: 11.4859 - val_mape: 6.8276 - lr: 0.0010\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 9.8713 - mae: 26.9423 - mape: 9.8695 - val_loss: 7.1649 - val_mae: 15.1189 - val_mape: 7.1630 - lr: 0.0010\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 11s 132ms/step - loss: 9.8480 - mae: 26.1183 - mape: 9.8461 - val_loss: 6.8996 - val_mae: 14.2249 - val_mape: 6.8979 - lr: 0.0010\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.0247 - mae: 26.7484 - mape: 10.0231 - val_loss: 7.0879 - val_mae: 13.4518 - val_mape: 7.0864 - lr: 0.0010\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.9314 - mae: 24.8842 - mape: 9.9300 - val_loss: 7.6681 - val_mae: 11.9997 - val_mape: 7.6667 - lr: 0.0010\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 10s 118ms/step - loss: 9.9692 - mae: 26.8057 - mape: 9.9678 - val_loss: 6.8012 - val_mae: 15.0839 - val_mape: 6.7999 - lr: 0.0010\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 10s 113ms/step - loss: 9.8902 - mae: 24.5139 - mape: 9.8889 - val_loss: 7.1476 - val_mae: 13.8273 - val_mape: 7.1463 - lr: 0.0010\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 13s 149ms/step - loss: 10.0570 - mae: 29.7673 - mape: 10.0557 - val_loss: 6.9402 - val_mae: 14.7585 - val_mape: 6.9389 - lr: 0.0010\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 12s 140ms/step - loss: 9.8944 - mae: 28.0525 - mape: 9.8932 - val_loss: 7.0002 - val_mae: 13.3030 - val_mape: 6.9989 - lr: 0.0010\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 79s 922ms/step - loss: 10.2257 - mae: 28.0814 - mape: 10.2243 - val_loss: 8.8321 - val_mae: 21.9473 - val_mape: 8.8306 - lr: 0.0010\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 103s 1s/step - loss: 10.0809 - mae: 28.6852 - mape: 10.0793 - val_loss: 6.9356 - val_mae: 13.8887 - val_mape: 6.9340 - lr: 0.0010\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 9.8411 - mae: 23.5320 - mape: 9.8393 - val_loss: 7.1890 - val_mae: 15.1218 - val_mape: 7.1873 - lr: 0.0010\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 9.9651 - mae: 25.6063 - mape: 9.9634 - val_loss: 6.8043 - val_mae: 12.1707 - val_mape: 6.8022 - lr: 0.0010\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6904 - mae: 25.9817 - mape: 9.6885\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 9.6904 - mae: 25.9817 - mape: 9.6885 - val_loss: 7.8346 - val_mae: 12.0564 - val_mape: 7.8328 - lr: 0.0010\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 9.7610 - mae: 26.0112 - mape: 9.7593 - val_loss: 6.7955 - val_mae: 11.0452 - val_mape: 6.7938 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 9.5779 - mae: 24.6590 - mape: 9.5763 - val_loss: 6.9689 - val_mae: 12.8537 - val_mape: 6.9674 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 9.8637 - mae: 24.6002 - mape: 9.8622 - val_loss: 6.9282 - val_mae: 12.3009 - val_mape: 6.9267 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.7945 - mae: 25.3636 - mape: 9.7931 - val_loss: 6.9274 - val_mae: 12.8045 - val_mape: 6.9260 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 11s 124ms/step - loss: 9.5390 - mae: 23.3656 - mape: 9.5375 - val_loss: 6.7787 - val_mae: 11.1007 - val_mape: 6.7773 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 10s 116ms/step - loss: 9.6094 - mae: 25.2640 - mape: 9.6080 - val_loss: 6.9076 - val_mae: 12.0500 - val_mape: 6.9062 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 10s 119ms/step - loss: 9.6331 - mae: 25.0506 - mape: 9.6317 - val_loss: 6.8185 - val_mae: 12.7765 - val_mape: 6.8172 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 13s 147ms/step - loss: 10.0007 - mae: 25.0343 - mape: 9.9994 - val_loss: 6.9193 - val_mae: 14.4197 - val_mape: 6.9180 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 16s 180ms/step - loss: 9.8558 - mae: 25.7923 - mape: 9.8545 - val_loss: 6.7606 - val_mae: 11.2675 - val_mape: 6.7594 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 20s 229ms/step - loss: 9.5510 - mae: 25.2873 - mape: 9.5498 - val_loss: 6.9050 - val_mae: 11.7357 - val_mape: 6.9038 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 21s 241ms/step - loss: 9.7616 - mae: 24.8819 - mape: 9.7605 - val_loss: 6.8665 - val_mae: 13.0166 - val_mape: 6.8654 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 21s 247ms/step - loss: 9.7362 - mae: 24.4605 - mape: 9.7351 - val_loss: 6.8960 - val_mae: 11.5217 - val_mape: 6.8949 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 19s 221ms/step - loss: 9.8379 - mae: 25.1593 - mape: 9.8368 - val_loss: 6.8151 - val_mae: 12.7356 - val_mape: 6.8140 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 21s 239ms/step - loss: 9.7119 - mae: 25.5893 - mape: 9.7107 - val_loss: 6.8110 - val_mae: 11.3399 - val_mape: 6.8099 - lr: 3.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 20s 237ms/step - loss: 9.6610 - mae: 26.1511 - mape: 9.6599 - val_loss: 6.9991 - val_mae: 14.6226 - val_mape: 6.9981 - lr: 3.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 20s 230ms/step - loss: 9.5102 - mae: 22.8882 - mape: 9.5092 - val_loss: 6.8487 - val_mae: 13.3624 - val_mape: 6.8477 - lr: 3.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 20s 235ms/step - loss: 9.8074 - mae: 24.3403 - mape: 9.8064 - val_loss: 7.4849 - val_mae: 14.0227 - val_mape: 7.4839 - lr: 3.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 20s 226ms/step - loss: 9.5431 - mae: 25.8812 - mape: 9.5421 - val_loss: 6.7617 - val_mae: 11.3826 - val_mape: 6.7607 - lr: 3.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 20s 232ms/step - loss: 9.7118 - mae: 21.3675 - mape: 9.7108 - val_loss: 7.1589 - val_mae: 12.1592 - val_mape: 7.1579 - lr: 3.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 19s 221ms/step - loss: 9.5400 - mae: 22.7742 - mape: 9.5390 - val_loss: 6.8626 - val_mae: 11.0605 - val_mape: 6.8615 - lr: 3.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 19s 225ms/step - loss: 9.7280 - mae: 25.4176 - mape: 9.7270 - val_loss: 6.8565 - val_mae: 11.3092 - val_mape: 6.8554 - lr: 3.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 20s 227ms/step - loss: 9.6601 - mae: 24.9256 - mape: 9.6591 - val_loss: 7.0146 - val_mae: 11.5243 - val_mape: 7.0136 - lr: 3.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 20s 231ms/step - loss: 9.6178 - mae: 24.5673 - mape: 9.6168 - val_loss: 7.4537 - val_mae: 19.3637 - val_mape: 7.4527 - lr: 3.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 20s 227ms/step - loss: 9.6146 - mae: 25.8420 - mape: 9.6136 - val_loss: 6.8740 - val_mae: 10.9264 - val_mape: 6.8730 - lr: 3.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 21s 238ms/step - loss: 9.5201 - mae: 23.7988 - mape: 9.5191 - val_loss: 6.8250 - val_mae: 11.0701 - val_mape: 6.8240 - lr: 3.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 20s 233ms/step - loss: 9.7934 - mae: 25.8584 - mape: 9.7924 - val_loss: 7.0209 - val_mae: 13.0001 - val_mape: 7.0199 - lr: 3.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 20s 230ms/step - loss: 9.5586 - mae: 23.9596 - mape: 9.5576 - val_loss: 6.9463 - val_mae: 10.9500 - val_mape: 6.9453 - lr: 3.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 21s 241ms/step - loss: 9.7510 - mae: 26.9157 - mape: 9.7500 - val_loss: 6.9426 - val_mae: 11.1213 - val_mape: 6.9417 - lr: 3.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 21s 246ms/step - loss: 9.5005 - mae: 21.6629 - mape: 9.4995 - val_loss: 6.7898 - val_mae: 11.8722 - val_mape: 6.7889 - lr: 3.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6776 - mae: 24.2530 - mape: 9.6767\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 20s 230ms/step - loss: 9.6776 - mae: 24.2530 - mape: 9.6767 - val_loss: 6.8675 - val_mae: 10.9252 - val_mape: 6.8666 - lr: 3.0000e-04\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 6.599841117858887; mae of 10.28681755065918; mape of 6.596828460693359%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n",
      " 1/87 [..............................] - ETA: 1:11 - loss: 11.2963 - mae: 34.9602 - mape: 11.2933"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 10.4963 - mae: 28.0926 - mape: 10.4939"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 22s 249ms/step - loss: 10.5115 - mae: 27.8842 - mape: 10.5090 - val_loss: 6.4425 - val_mae: 10.3473 - val_mape: 6.4403 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      " 1/87 [..............................] - ETA: 6s - loss: 10.6936 - mae: 11.5453 - mape: 10.6914"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 20s 231ms/step - loss: 10.3850 - mae: 26.7144 - mape: 10.3827 - val_loss: 6.7799 - val_mae: 21.1911 - val_mape: 6.7775 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 20s 228ms/step - loss: 10.1619 - mae: 24.6058 - mape: 10.1597 - val_loss: 6.5068 - val_mae: 12.6740 - val_mape: 6.5046 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 20s 231ms/step - loss: 10.0051 - mae: 28.3435 - mape: 10.0029 - val_loss: 7.0044 - val_mae: 16.8834 - val_mape: 7.0021 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 22s 248ms/step - loss: 10.1824 - mae: 24.8045 - mape: 10.1801 - val_loss: 6.7633 - val_mae: 13.5078 - val_mape: 6.7610 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 9.6505 - mae: 23.2545 - mape: 9.6482 - val_loss: 6.7120 - val_mae: 13.2309 - val_mape: 6.7097 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 10.2212 - mae: 26.5185 - mape: 10.2188 - val_loss: 7.0548 - val_mae: 27.0323 - val_mape: 7.0524 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 10.1843 - mae: 26.1200 - mape: 10.1819 - val_loss: 7.0017 - val_mae: 13.8464 - val_mape: 6.9993 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.9786 - mae: 23.8990 - mape: 9.9762 - val_loss: 7.2014 - val_mae: 17.7519 - val_mape: 7.1992 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 20s 232ms/step - loss: 10.1076 - mae: 24.4846 - mape: 10.1055 - val_loss: 6.6757 - val_mae: 13.1118 - val_mape: 6.6734 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 9.8561 - mae: 25.0800 - mape: 9.8539 - val_loss: 6.9242 - val_mae: 19.5693 - val_mape: 6.9220 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 10.1443 - mae: 26.5625 - mape: 10.1421 - val_loss: 7.0984 - val_mae: 12.6099 - val_mape: 7.0963 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.8349 - mae: 23.9578 - mape: 9.8329 - val_loss: 6.5521 - val_mae: 12.5908 - val_mape: 6.5499 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 10.2185 - mae: 24.8246 - mape: 10.2164 - val_loss: 7.1823 - val_mae: 21.0691 - val_mape: 7.1801 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 10.2159 - mae: 23.6431 - mape: 10.2139 - val_loss: 6.8797 - val_mae: 11.4421 - val_mape: 6.8779 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 10.1540 - mae: 24.5393 - mape: 10.1523 - val_loss: 7.1622 - val_mae: 12.2083 - val_mape: 7.1605 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 9.8880 - mae: 24.2777 - mape: 9.8864 - val_loss: 6.8664 - val_mae: 12.4256 - val_mape: 6.8648 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 10.2630 - mae: 25.4237 - mape: 10.2610 - val_loss: 6.7166 - val_mae: 11.2442 - val_mape: 6.7145 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 10.3553 - mae: 24.5313 - mape: 10.3533 - val_loss: 7.2253 - val_mae: 25.0654 - val_mape: 7.2235 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 10.1080 - mae: 25.1471 - mape: 10.1061 - val_loss: 6.8659 - val_mae: 10.0115 - val_mape: 6.8641 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 10.1276 - mae: 26.9348 - mape: 10.1260 - val_loss: 6.8674 - val_mae: 15.1127 - val_mape: 6.8659 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 10.0417 - mae: 25.9520 - mape: 10.0402 - val_loss: 7.5379 - val_mae: 23.9551 - val_mape: 7.5364 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.7776 - mae: 23.2584 - mape: 9.7761 - val_loss: 7.1174 - val_mae: 11.5277 - val_mape: 7.1160 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.6418 - mae: 25.5243 - mape: 9.6403 - val_loss: 6.8558 - val_mae: 16.0401 - val_mape: 6.8543 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 10.0604 - mae: 27.1551 - mape: 10.0589 - val_loss: 6.8249 - val_mae: 17.4293 - val_mape: 6.8234 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.9435 - mae: 26.9815 - mape: 9.9420 - val_loss: 6.5828 - val_mae: 10.2194 - val_mape: 6.5812 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 10s 117ms/step - loss: 9.8610 - mae: 23.5583 - mape: 9.8594 - val_loss: 7.0362 - val_mae: 16.6027 - val_mape: 7.0348 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.8668 - mae: 25.9194 - mape: 9.8655 - val_loss: 7.1094 - val_mae: 15.8580 - val_mape: 7.1081 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.1268 - mae: 24.1074 - mape: 10.1253 - val_loss: 6.7875 - val_mae: 13.7995 - val_mape: 6.7861 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 10.1709 - mae: 24.5295 - mape: 10.1695 - val_loss: 6.7334 - val_mae: 11.7303 - val_mape: 6.7320 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.7695 - mae: 26.0104 - mape: 9.7680\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.7700 - mae: 25.9801 - mape: 9.7685 - val_loss: 7.1579 - val_mae: 11.1420 - val_mape: 7.1564 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 9.7438 - mae: 23.5414 - mape: 9.7423 - val_loss: 6.5954 - val_mae: 11.8482 - val_mape: 6.5939 - lr: 3.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 9.7338 - mae: 24.3789 - mape: 9.7324 - val_loss: 6.5984 - val_mae: 10.3595 - val_mape: 6.5970 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 9.7235 - mae: 22.2039 - mape: 9.7222 - val_loss: 6.5175 - val_mae: 10.1864 - val_mape: 6.5162 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 9.7004 - mae: 22.4199 - mape: 9.6992 - val_loss: 6.5164 - val_mae: 10.6859 - val_mape: 6.5152 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 9.6928 - mae: 23.4920 - mape: 9.6916 - val_loss: 6.9390 - val_mae: 22.7523 - val_mape: 6.9379 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 10s 114ms/step - loss: 9.8050 - mae: 24.9343 - mape: 9.8039 - val_loss: 6.8800 - val_mae: 15.5752 - val_mape: 6.8789 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 9.5205 - mae: 24.6793 - mape: 9.5195 - val_loss: 6.7030 - val_mae: 17.4125 - val_mape: 6.7020 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.8876 - mae: 23.3709 - mape: 9.8866 - val_loss: 6.6527 - val_mae: 13.1554 - val_mape: 6.6517 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 9.6412 - mae: 22.8534 - mape: 9.6401 - val_loss: 6.7162 - val_mae: 15.2025 - val_mape: 6.7152 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 9.8531 - mae: 23.0861 - mape: 9.8521 - val_loss: 6.5246 - val_mae: 10.3974 - val_mape: 6.5237 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 9.7737 - mae: 21.3397 - mape: 9.7728 - val_loss: 6.5589 - val_mae: 11.3180 - val_mape: 6.5580 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.5751 - mae: 23.3024 - mape: 9.5742 - val_loss: 6.8311 - val_mae: 20.5602 - val_mape: 6.8302 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 9.7132 - mae: 21.5065 - mape: 9.7124 - val_loss: 6.4975 - val_mae: 10.1905 - val_mape: 6.4966 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 9.6396 - mae: 24.7487 - mape: 9.6388 - val_loss: 6.5118 - val_mae: 9.7080 - val_mape: 6.5111 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 9.7351 - mae: 21.6034 - mape: 9.7344 - val_loss: 6.5481 - val_mae: 10.1328 - val_mape: 6.5473 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 9.7485 - mae: 24.2555 - mape: 9.7478 - val_loss: 6.5313 - val_mae: 11.3485 - val_mape: 6.5306 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 9.8875 - mae: 24.4671 - mape: 9.8867 - val_loss: 7.3053 - val_mae: 18.6985 - val_mape: 7.3045 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.8275 - mae: 24.4551 - mape: 9.8268 - val_loss: 7.0507 - val_mae: 11.0968 - val_mape: 7.0499 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 10.0098 - mae: 24.5976 - mape: 10.0091 - val_loss: 6.8321 - val_mae: 13.5132 - val_mape: 6.8313 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.4779 - mae: 21.9257 - mape: 9.4772 - val_loss: 6.5938 - val_mae: 11.1009 - val_mape: 6.5930 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 9.8268 - mae: 22.4056 - mape: 9.8260 - val_loss: 6.6953 - val_mae: 10.1205 - val_mape: 6.6946 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.5239 - mae: 23.3560 - mape: 9.5232 - val_loss: 6.5969 - val_mae: 10.6516 - val_mape: 6.5961 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.4935 - mae: 23.4685 - mape: 9.4928 - val_loss: 6.6125 - val_mae: 13.5337 - val_mape: 6.6118 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.5940 - mae: 23.4467 - mape: 9.5934 - val_loss: 6.6072 - val_mae: 12.7286 - val_mape: 6.6066 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.5496 - mae: 22.4870 - mape: 9.5490 - val_loss: 6.6576 - val_mae: 10.5689 - val_mape: 6.6569 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.5037 - mae: 24.5112 - mape: 9.5030 - val_loss: 6.5895 - val_mae: 11.4849 - val_mape: 6.5889 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.5392 - mae: 23.6547 - mape: 9.5386 - val_loss: 6.6708 - val_mae: 10.4468 - val_mape: 6.6702 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 9.7199 - mae: 25.2646 - mape: 9.7193 - val_loss: 6.8920 - val_mae: 15.4309 - val_mape: 6.8914 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.5823 - mae: 25.3569 - mape: 9.5816 - val_loss: 6.6124 - val_mae: 12.0048 - val_mape: 6.6118 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.5765 - mae: 22.3073 - mape: 9.5759\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.5798 - mae: 22.3784 - mape: 9.5792 - val_loss: 6.8490 - val_mae: 13.7028 - val_mape: 6.8484 - lr: 3.0000e-04\n",
      "Epoch 61: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 6.442468643188477; mae of 10.347328186035156; mape of 6.440290451049805%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 10.2850 - mae: 22.5964 - mape: 10.2826"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 12s 127ms/step - loss: 10.2850 - mae: 22.5964 - mape: 10.2826 - val_loss: 6.0213 - val_mae: 18.7006 - val_mape: 6.0190 - lr: 0.0010\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 114ms/step - loss: 10.2271 - mae: 24.1180 - mape: 10.2248 - val_loss: 6.3083 - val_mae: 20.8969 - val_mape: 6.3055 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.1987 - mae: 24.4316 - mape: 10.1962 - val_loss: 6.7929 - val_mae: 15.9135 - val_mape: 6.7905 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 10.3104 - mae: 25.1926 - mape: 10.3081 - val_loss: 6.3628 - val_mae: 20.7362 - val_mape: 6.3606 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.3030 - mae: 23.6513 - mape: 10.3010 - val_loss: 6.3838 - val_mae: 22.1355 - val_mape: 6.3818 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 10.1314 - mae: 23.5052 - mape: 10.1291 - val_loss: 6.1021 - val_mae: 12.5587 - val_mape: 6.0997 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 10.3581 - mae: 23.2455 - mape: 10.3557 - val_loss: 6.9746 - val_mae: 17.9099 - val_mape: 6.9724 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.0938 - mae: 23.2622 - mape: 10.0916"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 120ms/step - loss: 10.0938 - mae: 23.2622 - mape: 10.0916 - val_loss: 5.9584 - val_mae: 16.0271 - val_mape: 5.9562 - lr: 0.0010\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 9.9910 - mae: 23.7649 - mape: 9.9888 - val_loss: 6.1425 - val_mae: 13.7865 - val_mape: 6.1404 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 10.1933 - mae: 23.7789 - mape: 10.1913 - val_loss: 6.2043 - val_mae: 20.2798 - val_mape: 6.2023 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 10.0104 - mae: 25.9103 - mape: 10.0084"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_1l_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 10s 117ms/step - loss: 10.0104 - mae: 25.9103 - mape: 10.0084 - val_loss: 5.8869 - val_mae: 13.3037 - val_mape: 5.8848 - lr: 0.0010\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 107ms/step - loss: 10.2452 - mae: 24.8082 - mape: 10.2434 - val_loss: 7.2185 - val_mae: 25.3501 - val_mape: 7.2168 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 10.3261 - mae: 24.4220 - mape: 10.3243 - val_loss: 6.2617 - val_mae: 13.7528 - val_mape: 6.2599 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 10.4030 - mae: 24.9152 - mape: 10.4010 - val_loss: 6.3551 - val_mae: 17.7766 - val_mape: 6.3532 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 10.3193 - mae: 25.3068 - mape: 10.3175 - val_loss: 6.3711 - val_mae: 13.2359 - val_mape: 6.3694 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 10.3059 - mae: 25.1143 - mape: 10.3043 - val_loss: 6.2512 - val_mae: 20.4460 - val_mape: 6.2497 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 10.3107 - mae: 26.3245 - mape: 10.3092 - val_loss: 6.3845 - val_mae: 18.9042 - val_mape: 6.3829 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 10.4060 - mae: 25.8288 - mape: 10.4045 - val_loss: 6.8666 - val_mae: 28.3087 - val_mape: 6.8652 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.9230 - mae: 23.3620 - mape: 9.9211 - val_loss: 6.2590 - val_mae: 16.9589 - val_mape: 6.2571 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.9577 - mae: 22.6999 - mape: 9.9558 - val_loss: 6.6186 - val_mae: 21.9595 - val_mape: 6.6167 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.9685 - mae: 22.1391 - mape: 9.9667 - val_loss: 6.4976 - val_mae: 19.8788 - val_mape: 6.4959 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 10.0483 - mae: 23.9548 - mape: 10.0466 - val_loss: 6.4723 - val_mae: 15.1402 - val_mape: 6.4708 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 10.0776 - mae: 23.1569 - mape: 10.0761 - val_loss: 6.3219 - val_mae: 17.9643 - val_mape: 6.3203 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.8915 - mae: 23.7705 - mape: 9.8901 - val_loss: 6.1098 - val_mae: 13.9526 - val_mape: 6.1084 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 10.2679 - mae: 26.9594 - mape: 10.2665 - val_loss: 6.1057 - val_mae: 13.6278 - val_mape: 6.1043 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 10.0765 - mae: 23.6602 - mape: 10.0752 - val_loss: 6.8329 - val_mae: 21.5602 - val_mape: 6.8317 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 9.9566 - mae: 23.6009 - mape: 9.9553 - val_loss: 6.1365 - val_mae: 13.6022 - val_mape: 6.1353 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 10.1274 - mae: 23.1678 - mape: 10.1263 - val_loss: 6.4176 - val_mae: 13.8526 - val_mape: 6.4165 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.3860 - mae: 25.8463 - mape: 10.3850 - val_loss: 6.7488 - val_mae: 21.0314 - val_mape: 6.7479 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.9297 - mae: 23.8425 - mape: 9.9288 - val_loss: 6.2625 - val_mae: 13.3929 - val_mape: 6.2616 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 10s 112ms/step - loss: 10.1343 - mae: 25.0838 - mape: 10.1335 - val_loss: 6.2908 - val_mae: 14.4949 - val_mape: 6.2900 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 10.3923 - mae: 24.9461 - mape: 10.3914 - val_loss: 7.9966 - val_mae: 24.4637 - val_mape: 7.9957 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 10.1125 - mae: 26.2143 - mape: 10.1116 - val_loss: 6.2209 - val_mae: 13.4196 - val_mape: 6.2200 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 10.0771 - mae: 23.5173 - mape: 10.0762 - val_loss: 7.1092 - val_mae: 21.1808 - val_mape: 7.1084 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 9.8717 - mae: 24.4568 - mape: 9.8709 - val_loss: 6.5893 - val_mae: 15.5996 - val_mape: 6.5885 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.9473 - mae: 24.7609 - mape: 9.9465 - val_loss: 6.2242 - val_mae: 15.3148 - val_mape: 6.2234 - lr: 0.0010\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 10s 115ms/step - loss: 9.8820 - mae: 23.7459 - mape: 9.8812 - val_loss: 7.4886 - val_mae: 19.2004 - val_mape: 7.4878 - lr: 0.0010\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 9s 102ms/step - loss: 9.9238 - mae: 23.3501 - mape: 9.9229 - val_loss: 6.9160 - val_mae: 15.3944 - val_mape: 6.9152 - lr: 0.0010\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 9.9096 - mae: 22.9300 - mape: 9.9088 - val_loss: 6.3448 - val_mae: 16.6498 - val_mape: 6.3440 - lr: 0.0010\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.9287 - mae: 24.6464 - mape: 9.9279 - val_loss: 6.2705 - val_mae: 14.2637 - val_mape: 6.2698 - lr: 0.0010\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.8330 - mae: 23.1708 - mape: 9.8323\n",
      "Epoch 41: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 9.8330 - mae: 23.1708 - mape: 9.8323 - val_loss: 6.7069 - val_mae: 15.1044 - val_mape: 6.7063 - lr: 0.0010\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 9.9220 - mae: 21.8547 - mape: 9.9214 - val_loss: 6.1481 - val_mae: 14.4074 - val_mape: 6.1475 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.6577 - mae: 21.1581 - mape: 9.6571 - val_loss: 6.1434 - val_mae: 14.5891 - val_mape: 6.1428 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.7343 - mae: 22.9131 - mape: 9.7337 - val_loss: 6.2760 - val_mae: 14.0920 - val_mape: 6.2755 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 9s 107ms/step - loss: 9.9271 - mae: 24.0905 - mape: 9.9266 - val_loss: 6.3006 - val_mae: 18.7882 - val_mape: 6.3001 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.7850 - mae: 26.1831 - mape: 9.7845 - val_loss: 6.1643 - val_mae: 13.9066 - val_mape: 6.1638 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.9210 - mae: 24.2724 - mape: 9.9205 - val_loss: 6.2213 - val_mae: 15.1137 - val_mape: 6.2209 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 10.0393 - mae: 22.4314 - mape: 10.0388 - val_loss: 6.2324 - val_mae: 15.0436 - val_mape: 6.2319 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 9.9496 - mae: 23.0401 - mape: 9.9491 - val_loss: 6.1684 - val_mae: 14.4606 - val_mape: 6.1680 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 9s 105ms/step - loss: 9.7907 - mae: 23.5811 - mape: 9.7902 - val_loss: 6.1779 - val_mae: 14.1519 - val_mape: 6.1775 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 9.6780 - mae: 20.4738 - mape: 9.6776 - val_loss: 6.2398 - val_mae: 14.9789 - val_mape: 6.2393 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.5762 - mae: 21.7754 - mape: 9.5758 - val_loss: 6.6834 - val_mae: 16.6904 - val_mape: 6.6830 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 8s 97ms/step - loss: 9.6957 - mae: 23.7254 - mape: 9.6953 - val_loss: 6.2567 - val_mae: 14.1895 - val_mape: 6.2563 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 9.7754 - mae: 22.6842 - mape: 9.7751 - val_loss: 6.1467 - val_mae: 13.3154 - val_mape: 6.1463 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.8284 - mae: 22.5505 - mape: 9.8280 - val_loss: 6.1704 - val_mae: 13.3440 - val_mape: 6.1701 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 9s 108ms/step - loss: 9.8735 - mae: 23.6328 - mape: 9.8731 - val_loss: 6.3525 - val_mae: 13.6490 - val_mape: 6.3521 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 10s 109ms/step - loss: 9.8083 - mae: 23.0435 - mape: 9.8079 - val_loss: 6.3254 - val_mae: 14.9807 - val_mape: 6.3250 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.8580 - mae: 25.4139 - mape: 9.8576 - val_loss: 6.4023 - val_mae: 17.7702 - val_mape: 6.4019 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 9.7536 - mae: 21.7534 - mape: 9.7532 - val_loss: 6.4402 - val_mae: 16.2746 - val_mape: 6.4398 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 9s 109ms/step - loss: 9.5517 - mae: 22.4614 - mape: 9.5513 - val_loss: 6.1966 - val_mae: 13.6555 - val_mape: 6.1963 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 9s 103ms/step - loss: 9.7307 - mae: 22.4237 - mape: 9.7303 - val_loss: 6.1679 - val_mae: 14.3166 - val_mape: 6.1676 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 9s 98ms/step - loss: 9.7862 - mae: 22.1469 - mape: 9.7858 - val_loss: 6.2022 - val_mae: 14.3214 - val_mape: 6.2018 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 9s 100ms/step - loss: 9.7628 - mae: 21.5897 - mape: 9.7625 - val_loss: 6.4347 - val_mae: 16.8472 - val_mape: 6.4344 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 9s 99ms/step - loss: 9.6767 - mae: 23.2557 - mape: 9.6764 - val_loss: 6.2441 - val_mae: 13.6425 - val_mape: 6.2438 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 10s 110ms/step - loss: 9.6257 - mae: 22.2420 - mape: 9.6254 - val_loss: 6.2603 - val_mae: 13.9329 - val_mape: 6.2600 - lr: 3.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 9s 101ms/step - loss: 9.9343 - mae: 24.3677 - mape: 9.9340 - val_loss: 6.3020 - val_mae: 14.0545 - val_mape: 6.3017 - lr: 3.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 9s 106ms/step - loss: 9.8700 - mae: 23.9000 - mape: 9.8697 - val_loss: 6.2631 - val_mae: 15.7712 - val_mape: 6.2628 - lr: 3.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.7606 - mae: 22.0201 - mape: 9.7603 - val_loss: 6.3795 - val_mae: 16.1656 - val_mape: 6.3792 - lr: 3.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.7963 - mae: 23.5821 - mape: 9.7960 - val_loss: 6.2361 - val_mae: 13.2290 - val_mape: 6.2358 - lr: 3.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 10s 111ms/step - loss: 9.6123 - mae: 23.4731 - mape: 9.6120 - val_loss: 6.2936 - val_mae: 13.7166 - val_mape: 6.2934 - lr: 3.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6395 - mae: 21.5275 - mape: 9.6393\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 9s 104ms/step - loss: 9.6395 - mae: 21.5275 - mape: 9.6393 - val_loss: 6.3097 - val_mae: 14.3857 - val_mape: 6.3095 - lr: 3.0000e-04\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 5.886852264404297; mae of 13.303743362426758; mape of 5.8848490715026855%;\n"
     ]
    }
   ],
   "source": [
    "#Hybrid reset 1 layer\n",
    "nnmodel = keras.models.load_model('savedmodels/Baseline_thesis')\n",
    "gcnmodel = keras.models.load_model('savedmodels/GCN_simplified_normalized')\n",
    "\n",
    "combined = concatenate([nnmodel.get_layer('dense_30').output, gcnmodel.get_layer('dropgcn').output], name='join')\n",
    "z = Dense(64,'relu', name='dense4')(combined)\n",
    "z = Dropout(0.2, name='finaldrop')(z)\n",
    "z = Dense(1, 'linear', name='regress')(z)\n",
    "model = Model(inputs = [gcnmodel.input, nnmodel.input], outputs = z)\n",
    "\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, \"crossvalidationmodels/Hybrid_1l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 6.248281002044678 - Mean average error: 9.55369758605957% - Mean percentage error: 6.214001655578613%\n",
      "    Score on unseen data: Loss: 8.677267074584961 - Mean average error: 27.790813446044922% - Mean percentage error: 8.642987251281738%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 6.178133010864258 - Mean average error: 13.431587219238281% - Mean percentage error: 6.175069808959961%\n",
      "    Score on unseen data: Loss: 8.378702163696289 - Mean average error: 28.868024826049805% - Mean percentage error: 8.375638008117676%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 6.599841117858887 - Mean average error: 10.28681755065918% - Mean percentage error: 6.596828460693359%\n",
      "    Score on unseen data: Loss: 8.586453437805176 - Mean average error: 25.950511932373047% - Mean percentage error: 8.583442687988281%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 6.442468643188477 - Mean average error: 10.347328186035156% - Mean percentage error: 6.440290451049805%\n",
      "    Score on unseen data: Loss: 8.385286331176758 - Mean average error: 26.346691131591797% - Mean percentage error: 8.383109092712402%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 5.886852264404297 - Mean average error: 13.303743362426758% - Mean percentage error: 5.8848490715026855%\n",
      "    Score on unseen data: Loss: 8.565253257751465 - Mean average error: 25.86756706237793% - Mean percentage error: 8.563251495361328%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 6.2711152076721195\n",
      "> Mean average error: 11.38463478088379\n",
      "> Mean percentage error: 6.262207889556885\n",
      "> Unseen Loss: 8.51859245300293\n",
      "> Unseen Mean average error: 26.9647216796875\n",
      "> Unseen Mean percentage error: 8.509685707092284\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hybrid freeze\n",
    "nnmodel = keras.models.load_model('crossvalidationmodels/Baseline_5/')\n",
    "for layer in nnmodel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "gcnmodel = keras.models.load_model('savedmodels/GCN_simplified_normalized')\n",
    "for layer in gcnmodel.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "combined = concatenate([nnmodel.get_layer('dense_30').output, gcnmodel.get_layer('dropgcn').output], name='join')\n",
    "z = Dense(128,'relu', name='dense1')(combined)\n",
    "z = Dense(64,'relu', name='dense4')(z)\n",
    "z = Dropout(0.2, name='finaldrop')(z)\n",
    "z = Dense(1, 'linear', name='regress')(z)\n",
    "model = Model(inputs = [gcnmodel.input, nnmodel.input], outputs = z)\n",
    "\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, \"crossvalidationmodels/Hybrid_freeze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 10.276529312133789 - Mean average error: 10.527552604675293% - Mean percentage error: 6.205561637878418%\n",
      "    Score on unseen data: Loss: 12.774991989135742 - Mean average error: 23.66372299194336% - Mean percentage error: 8.704025268554688%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 10.236482620239258 - Mean average error: 10.25425910949707% - Mean percentage error: 6.165515422821045%\n",
      "    Score on unseen data: Loss: 12.578315734863281 - Mean average error: 22.456287384033203% - Mean percentage error: 8.507349014282227%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 10.180620193481445 - Mean average error: 13.243836402893066% - Mean percentage error: 6.109654903411865%\n",
      "    Score on unseen data: Loss: 12.628849029541016 - Mean average error: 23.274282455444336% - Mean percentage error: 8.557881355285645%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 9.897299766540527 - Mean average error: 6.890294075012207% - Mean percentage error: 5.826333999633789%\n",
      "    Score on unseen data: Loss: 12.652356147766113 - Mean average error: 22.840063095092773% - Mean percentage error: 8.581388473510742%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 9.281121253967285 - Mean average error: 7.694222927093506% - Mean percentage error: 5.210156440734863%\n",
      "    Score on unseen data: Loss: 12.57103157043457 - Mean average error: 21.643413543701172% - Mean percentage error: 8.500062942504883%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 9.97441062927246\n",
      "> Mean average error: 9.722033023834229\n",
      "> Mean percentage error: 5.903444480895996\n",
      "> Unseen Loss: 12.641108894348145\n",
      "> Unseen Mean average error: 22.775553894042968\n",
      "> Unseen Mean percentage error: 8.570141410827636\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "multi-input\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 13.6143 - mae: 23.6403 - mape: 9.6302"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 11s 101ms/step - loss: 13.6143 - mae: 23.6403 - mape: 9.6302 - val_loss: 10.2394 - val_mae: 8.4002 - val_mape: 6.3392 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 13.6658 - mae: 25.5057 - mape: 9.8436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 101ms/step - loss: 13.6658 - mae: 25.5057 - mape: 9.8436 - val_loss: 9.9475 - val_mae: 7.6229 - val_mape: 6.2026 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 13.4344 - mae: 24.2829 - mape: 9.7631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 102ms/step - loss: 13.4344 - mae: 24.2829 - mape: 9.7631 - val_loss: 9.7986 - val_mae: 7.7445 - val_mape: 6.1992 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 87ms/step - loss: 13.1712 - mae: 23.8800 - mape: 9.6399 - val_loss: 9.8019 - val_mae: 8.4261 - val_mape: 6.3390 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 13.1079 - mae: 24.1186 - mape: 9.7094 - val_loss: 9.5682 - val_mae: 8.0435 - val_mape: 6.2351 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.9128 - mae: 24.8230 - mape: 9.6403 - val_loss: 9.4785 - val_mae: 7.6834 - val_mape: 6.2667 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 12.7555 - mae: 24.5001 - mape: 9.6019 - val_loss: 9.4898 - val_mae: 8.9696 - val_mape: 6.3962 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 12.7216 - mae: 23.6325 - mape: 9.6817 - val_loss: 9.4239 - val_mae: 8.2073 - val_mape: 6.4388 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 12.5147 - mae: 22.0919 - mape: 9.5800 - val_loss: 9.0876 - val_mae: 7.7434 - val_mape: 6.2031 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.4917 - mae: 24.6045 - mape: 9.6560 - val_loss: 9.0522 - val_mae: 7.6015 - val_mape: 6.2649 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.3731 - mae: 24.6998 - mape: 9.6329 - val_loss: 8.9889 - val_mae: 8.1956 - val_mape: 6.2948 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.2288 - mae: 24.3847 - mape: 9.5790 - val_loss: 9.0203 - val_mae: 10.5011 - val_mape: 6.4145 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.2183 - mae: 24.4748 - mape: 9.6534 - val_loss: 8.9088 - val_mae: 8.0918 - val_mape: 6.3849 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 12.1724 - mae: 25.2024 - mape: 9.6869 - val_loss: 8.7523 - val_mae: 8.2953 - val_mape: 6.3041 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 11.8972 - mae: 25.0627 - mape: 9.4864 - val_loss: 8.8691 - val_mae: 9.5556 - val_mape: 6.4955 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 12.1782 - mae: 25.3508 - mape: 9.8389 - val_loss: 8.7555 - val_mae: 8.8587 - val_mape: 6.4515 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 11.8991 - mae: 23.5464 - mape: 9.6271 - val_loss: 8.4596 - val_mae: 7.9024 - val_mape: 6.2195 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 11.7287 - mae: 23.2551 - mape: 9.5195 - val_loss: 8.4411 - val_mae: 8.2415 - val_mape: 6.2618 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 11.7071 - mae: 22.3938 - mape: 9.5566 - val_loss: 8.6479 - val_mae: 8.8808 - val_mape: 6.5259 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 11.7187 - mae: 23.3361 - mape: 9.6247 - val_loss: 8.3305 - val_mae: 7.6029 - val_mape: 6.2636 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.7410 - mae: 24.1355 - mape: 9.7005 - val_loss: 8.2577 - val_mae: 7.5903 - val_mape: 6.2429 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.6684 - mae: 23.2650 - mape: 9.6782 - val_loss: 8.2606 - val_mae: 7.7480 - val_mape: 6.2959 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.3673 - mae: 24.7904 - mape: 9.4262 - val_loss: 8.4968 - val_mae: 10.5082 - val_mape: 6.5797 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 11.5567 - mae: 22.9180 - mape: 9.6614 - val_loss: 8.1434 - val_mae: 7.7866 - val_mape: 6.2701 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 11.3712 - mae: 22.5097 - mape: 9.5197 - val_loss: 8.1647 - val_mae: 8.1655 - val_mape: 6.3351 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.2928 - mae: 23.4885 - mape: 9.4842 - val_loss: 8.2189 - val_mae: 10.1411 - val_mape: 6.4306 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.2767 - mae: 23.3593 - mape: 9.5081 - val_loss: 8.1155 - val_mae: 8.3645 - val_mape: 6.3671 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.2610 - mae: 23.1085 - mape: 9.5311 - val_loss: 8.1459 - val_mae: 8.3865 - val_mape: 6.4349 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.3335 - mae: 24.9080 - mape: 9.6400 - val_loss: 7.9552 - val_mae: 7.7496 - val_mape: 6.2801 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.1163 - mae: 24.0370 - mape: 9.4591 - val_loss: 8.1570 - val_mae: 11.5796 - val_mape: 6.5175 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 11.0227 - mae: 23.1520 - mape: 9.4000 - val_loss: 7.9747 - val_mae: 8.1109 - val_mape: 6.3693 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 11.0697 - mae: 25.1928 - mape: 9.4800 - val_loss: 7.9862 - val_mae: 8.3392 - val_mape: 6.4131 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 11.4244 - mae: 24.1078 - mape: 9.8665 - val_loss: 7.8667 - val_mae: 8.1493 - val_mape: 6.3240 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 11.0249 - mae: 24.8960 - mape: 9.4975 - val_loss: 7.8349 - val_mae: 9.3550 - val_mape: 6.3230 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 11.1377 - mae: 25.6815 - mape: 9.6404 - val_loss: 7.8135 - val_mae: 8.6917 - val_mape: 6.3304 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 10.7722 - mae: 24.7259 - mape: 9.3029 - val_loss: 7.7621 - val_mae: 8.0063 - val_mape: 6.3068 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 10.8488 - mae: 23.3163 - mape: 9.4061 - val_loss: 7.9149 - val_mae: 10.3406 - val_mape: 6.4854 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.8955 - mae: 23.6700 - mape: 9.4791 - val_loss: 7.8915 - val_mae: 9.1404 - val_mape: 6.4881 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.9145 - mae: 25.0444 - mape: 9.5238 - val_loss: 7.7191 - val_mae: 8.3406 - val_mape: 6.3410 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.9381 - mae: 24.4786 - mape: 9.5722 - val_loss: 7.7699 - val_mae: 9.2716 - val_mape: 6.4169 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.8214 - mae: 24.4326 - mape: 9.4801 - val_loss: 7.7479 - val_mae: 8.1430 - val_mape: 6.4186 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.8870 - mae: 21.6388 - mape: 9.5690 - val_loss: 7.7237 - val_mae: 8.4994 - val_mape: 6.4170 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 10.9437 - mae: 23.7127 - mape: 9.6479 - val_loss: 7.8124 - val_mae: 8.5142 - val_mape: 6.5274 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 10.8309 - mae: 24.6735 - mape: 9.5566 - val_loss: 7.8561 - val_mae: 10.6143 - val_mape: 6.5928 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 10.7670 - mae: 22.5203 - mape: 9.5139 - val_loss: 7.6300 - val_mae: 9.3353 - val_mape: 6.3876 - lr: 1.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 10.7163 - mae: 23.2891 - mape: 9.4841 - val_loss: 7.7316 - val_mae: 8.8726 - val_mape: 6.5095 - lr: 1.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 10.4409 - mae: 23.7768 - mape: 9.2284 - val_loss: 7.5644 - val_mae: 8.0327 - val_mape: 6.3623 - lr: 1.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 10.7011 - mae: 22.3894 - mape: 9.5088 - val_loss: 7.5219 - val_mae: 8.1405 - val_mape: 6.3396 - lr: 1.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 10.7137 - mae: 24.7309 - mape: 9.5403 - val_loss: 7.4862 - val_mae: 8.0248 - val_mape: 6.3219 - lr: 1.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.7543 - mae: 24.0738 - mape: 9.5995 - val_loss: 7.5967 - val_mae: 9.4026 - val_mape: 6.4509 - lr: 1.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.9656 - mae: 26.4833 - mape: 9.8286 - val_loss: 7.5865 - val_mae: 10.3063 - val_mape: 6.4585 - lr: 1.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.4344 - mae: 22.3521 - mape: 9.3146 - val_loss: 7.4229 - val_mae: 8.2128 - val_mape: 6.3115 - lr: 1.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.5680 - mae: 24.8267 - mape: 9.4644 - val_loss: 7.5193 - val_mae: 8.1509 - val_mape: 6.4234 - lr: 1.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 10.5581 - mae: 24.1856 - mape: 9.4706 - val_loss: 7.5976 - val_mae: 9.2408 - val_mape: 6.5179 - lr: 1.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 10.5897 - mae: 25.6846 - mape: 9.5178 - val_loss: 7.3897 - val_mae: 8.1692 - val_mape: 6.3253 - lr: 1.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 10.7890 - mae: 24.0414 - mape: 9.7322 - val_loss: 7.4640 - val_mae: 11.2848 - val_mape: 6.4148 - lr: 1.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 10.5441 - mae: 22.5780 - mape: 9.5021 - val_loss: 7.6496 - val_mae: 10.7884 - val_mape: 6.6154 - lr: 1.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.7144 - mae: 23.1092 - mape: 9.6870 - val_loss: 7.3491 - val_mae: 8.0264 - val_mape: 6.3288 - lr: 1.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.6933 - mae: 24.9416 - mape: 9.6799 - val_loss: 7.3665 - val_mae: 8.0098 - val_mape: 6.3600 - lr: 1.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.4509 - mae: 24.8330 - mape: 9.4513 - val_loss: 7.3190 - val_mae: 7.9616 - val_mape: 6.3261 - lr: 1.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.4463 - mae: 23.9462 - mape: 9.4601 - val_loss: 7.3510 - val_mae: 9.1257 - val_mape: 6.3714 - lr: 1.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.5667 - mae: 21.9641 - mape: 9.5935 - val_loss: 7.5660 - val_mae: 11.0225 - val_mape: 6.5990 - lr: 1.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 10.4970 - mae: 23.2025 - mape: 9.5360 - val_loss: 7.2692 - val_mae: 7.9688 - val_mape: 6.3142 - lr: 1.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.4838 - mae: 26.1655 - mape: 9.5350 - val_loss: 7.3416 - val_mae: 8.3819 - val_mape: 6.3994 - lr: 1.0000e-04\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.4035 - mae: 23.0882 - mape: 9.4670 - val_loss: 7.3853 - val_mae: 10.4956 - val_mape: 6.4546 - lr: 1.0000e-04\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.4842 - mae: 23.1014 - mape: 9.5600 - val_loss: 7.2905 - val_mae: 9.1156 - val_mape: 6.3720 - lr: 1.0000e-04\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.4862 - mae: 23.0564 - mape: 9.5731 - val_loss: 7.5141 - val_mae: 8.7397 - val_mape: 6.6066 - lr: 1.0000e-04\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.3501 - mae: 24.8355 - mape: 9.4478 - val_loss: 7.7110 - val_mae: 10.5615 - val_mape: 6.8141 - lr: 1.0000e-04\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 10.4682 - mae: 23.2940 - mape: 9.5767 - val_loss: 7.2757 - val_mae: 9.5706 - val_mape: 6.3898 - lr: 1.0000e-04\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.3829 - mae: 22.7968 - mape: 9.5023 - val_loss: 7.2665 - val_mae: 8.3268 - val_mape: 6.3913 - lr: 1.0000e-04\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.2909 - mae: 23.0479 - mape: 9.4208 - val_loss: 7.2798 - val_mae: 9.2647 - val_mape: 6.4149 - lr: 1.0000e-04\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.2336 - mae: 20.6907 - mape: 9.3738 - val_loss: 7.6816 - val_mae: 12.7468 - val_mape: 6.8269 - lr: 1.0000e-04\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 10.3395 - mae: 22.5565 - mape: 9.4894 - val_loss: 7.2781 - val_mae: 8.5507 - val_mape: 6.4330 - lr: 1.0000e-04\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 10.4590 - mae: 24.1749 - mape: 9.6186 - val_loss: 7.5324 - val_mae: 12.1812 - val_mape: 6.6970 - lr: 1.0000e-04\n",
      "Epoch 75/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.2878 - mae: 23.8236 - mape: 9.4571 - val_loss: 7.2385 - val_mae: 9.0554 - val_mape: 6.4118 - lr: 1.0000e-04\n",
      "Epoch 76/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.3781 - mae: 24.5032 - mape: 9.5563 - val_loss: 7.1491 - val_mae: 8.1629 - val_mape: 6.3321 - lr: 1.0000e-04\n",
      "Epoch 77/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.3088 - mae: 23.1730 - mape: 9.4963 - val_loss: 7.3753 - val_mae: 10.5126 - val_mape: 6.5670 - lr: 1.0000e-04\n",
      "Epoch 78/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 10.3429 - mae: 23.9157 - mape: 9.5388 - val_loss: 7.2505 - val_mae: 8.6902 - val_mape: 6.4507 - lr: 1.0000e-04\n",
      "Epoch 79/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.2734 - mae: 22.4840 - mape: 9.4779 - val_loss: 7.2060 - val_mae: 9.0245 - val_mape: 6.4146 - lr: 1.0000e-04\n",
      "Epoch 80/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.4417 - mae: 26.2912 - mape: 9.6544 - val_loss: 7.3296 - val_mae: 10.4650 - val_mape: 6.5463 - lr: 1.0000e-04\n",
      "Epoch 81/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.2404 - mae: 24.0767 - mape: 9.4614 - val_loss: 7.2604 - val_mae: 9.5924 - val_mape: 6.4862 - lr: 1.0000e-04\n",
      "Epoch 82/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.3995 - mae: 24.8361 - mape: 9.6292 - val_loss: 7.1569 - val_mae: 8.7117 - val_mape: 6.3906 - lr: 1.0000e-04\n",
      "Epoch 83/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.3349 - mae: 25.3377 - mape: 9.5729 - val_loss: 7.0827 - val_mae: 7.9561 - val_mape: 6.3248 - lr: 1.0000e-04\n",
      "Epoch 84/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.2205 - mae: 24.6459 - mape: 9.4667 - val_loss: 7.3980 - val_mae: 9.4097 - val_mape: 6.6482 - lr: 1.0000e-04\n",
      "Epoch 85/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.3768 - mae: 25.0559 - mape: 9.6310 - val_loss: 7.1313 - val_mae: 8.1948 - val_mape: 6.3892 - lr: 1.0000e-04\n",
      "Epoch 86/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.3245 - mae: 24.1510 - mape: 9.5863 - val_loss: 7.2508 - val_mae: 9.9670 - val_mape: 6.5160 - lr: 1.0000e-04\n",
      "Epoch 87/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.0440 - mae: 24.3753 - mape: 9.3129 - val_loss: 7.0786 - val_mae: 8.1533 - val_mape: 6.3514 - lr: 1.0000e-04\n",
      "Epoch 88/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.2774 - mae: 23.6082 - mape: 9.5537 - val_loss: 7.0901 - val_mae: 8.6611 - val_mape: 6.3703 - lr: 1.0000e-04\n",
      "Epoch 89/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.2714 - mae: 23.9056 - mape: 9.5550 - val_loss: 7.4269 - val_mae: 10.7767 - val_mape: 6.7140 - lr: 1.0000e-04\n",
      "Epoch 90/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.1034 - mae: 24.9992 - mape: 9.3940 - val_loss: 7.0598 - val_mae: 7.9502 - val_mape: 6.3537 - lr: 1.0000e-04\n",
      "Epoch 91/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 10.3034 - mae: 23.3455 - mape: 9.6006 - val_loss: 7.0929 - val_mae: 8.0322 - val_mape: 6.3935 - lr: 1.0000e-04\n",
      "Epoch 92/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.1169 - mae: 20.4418 - mape: 9.4210 - val_loss: 7.1208 - val_mae: 8.5151 - val_mape: 6.4284 - lr: 1.0000e-04\n",
      "Epoch 93/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.2077 - mae: 21.6797 - mape: 9.5186 - val_loss: 7.1978 - val_mae: 10.0809 - val_mape: 6.5123 - lr: 1.0000e-04\n",
      "Epoch 94/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.4218 - mae: 22.8428 - mape: 9.7397 - val_loss: 7.1149 - val_mae: 9.2221 - val_mape: 6.4361 - lr: 1.0000e-04\n",
      "Epoch 95/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.9476 - mae: 23.2238 - mape: 9.2715 - val_loss: 7.1035 - val_mae: 9.2543 - val_mape: 6.4305 - lr: 1.0000e-04\n",
      "Epoch 96/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.1334 - mae: 23.7946 - mape: 9.4640 - val_loss: 7.1081 - val_mae: 9.1276 - val_mape: 6.4421 - lr: 1.0000e-04\n",
      "Epoch 97/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 10.0528 - mae: 20.8268 - mape: 9.3903 - val_loss: 7.1593 - val_mae: 10.0172 - val_mape: 6.5000 - lr: 1.0000e-04\n",
      "Epoch 98/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.0437 - mae: 23.1839 - mape: 9.3873 - val_loss: 7.2396 - val_mae: 9.8820 - val_mape: 6.5864 - lr: 1.0000e-04\n",
      "Epoch 99/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0298 - mae: 22.2520 - mape: 9.3798 - val_loss: 7.0788 - val_mae: 8.8394 - val_mape: 6.4321 - lr: 1.0000e-04\n",
      "Epoch 100/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 10.0465 - mae: 24.8923 - mape: 9.4026 - val_loss: 7.0293 - val_mae: 8.3545 - val_mape: 6.3883 - lr: 1.0000e-04\n",
      "Epoch 101/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.0988 - mae: 22.0854 - mape: 9.4611 - val_loss: 7.0148 - val_mae: 8.3839 - val_mape: 6.3798 - lr: 1.0000e-04\n",
      "Epoch 102/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 10.1357 - mae: 23.5289 - mape: 9.5035 - val_loss: 7.0745 - val_mae: 9.9644 - val_mape: 6.4450 - lr: 1.0000e-04\n",
      "Epoch 103/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.0332 - mae: 23.1039 - mape: 9.4063 - val_loss: 7.1486 - val_mae: 9.1050 - val_mape: 6.5243 - lr: 1.0000e-04\n",
      "Epoch 104/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 10.0802 - mae: 25.9516 - mape: 9.4583 - val_loss: 6.9567 - val_mae: 8.1726 - val_mape: 6.3376 - lr: 1.0000e-04\n",
      "Epoch 105/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.0771 - mae: 21.9185 - mape: 9.4608 - val_loss: 6.9592 - val_mae: 8.3367 - val_mape: 6.3458 - lr: 1.0000e-04\n",
      "Epoch 106/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.1879 - mae: 24.1706 - mape: 9.5770 - val_loss: 7.2057 - val_mae: 10.0410 - val_mape: 6.5973 - lr: 1.0000e-04\n",
      "Epoch 107/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0889 - mae: 22.9942 - mape: 9.4830 - val_loss: 6.9601 - val_mae: 8.3008 - val_mape: 6.3568 - lr: 1.0000e-04\n",
      "Epoch 108/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.2353 - mae: 24.9132 - mape: 9.6342 - val_loss: 7.0962 - val_mae: 9.3116 - val_mape: 6.4974 - lr: 1.0000e-04\n",
      "Epoch 109/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 10.1890 - mae: 23.6642 - mape: 9.5928 - val_loss: 7.0920 - val_mae: 8.6484 - val_mape: 6.4985 - lr: 1.0000e-04\n",
      "Epoch 110/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 10.1894 - mae: 23.1108 - mape: 9.5980 - val_loss: 7.1280 - val_mae: 10.1479 - val_mape: 6.5391 - lr: 1.0000e-04\n",
      "Epoch 111/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.1788 - mae: 24.7090 - mape: 9.5924 - val_loss: 6.9796 - val_mae: 8.3865 - val_mape: 6.3955 - lr: 1.0000e-04\n",
      "Epoch 112/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.1706 - mae: 22.4977 - mape: 9.5885 - val_loss: 7.0124 - val_mae: 9.8852 - val_mape: 6.4326 - lr: 1.0000e-04\n",
      "Epoch 113/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.8691 - mae: 20.2845 - mape: 9.2920 - val_loss: 7.1644 - val_mae: 9.8365 - val_mape: 6.5900 - lr: 1.0000e-04\n",
      "Epoch 114/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8864 - mae: 23.7612 - mape: 9.3143 - val_loss: 7.1143 - val_mae: 9.9397 - val_mape: 6.5446 - lr: 1.0000e-04\n",
      "Epoch 115/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.3518 - mae: 26.6133 - mape: 9.7842 - val_loss: 7.0979 - val_mae: 9.9496 - val_mape: 6.5327 - lr: 1.0000e-04\n",
      "Epoch 116/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.1501 - mae: 26.0659 - mape: 9.5869 - val_loss: 6.9420 - val_mae: 8.2485 - val_mape: 6.3810 - lr: 1.0000e-04\n",
      "Epoch 117/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.0783 - mae: 22.6266 - mape: 9.5195 - val_loss: 7.2496 - val_mae: 10.9678 - val_mape: 6.6932 - lr: 1.0000e-04\n",
      "Epoch 118/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.0898 - mae: 24.7538 - mape: 9.5349 - val_loss: 7.0493 - val_mae: 10.3506 - val_mape: 6.4962 - lr: 1.0000e-04\n",
      "Epoch 119/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.0281 - mae: 23.2997 - mape: 9.4770 - val_loss: 7.0412 - val_mae: 10.2459 - val_mape: 6.4919 - lr: 1.0000e-04\n",
      "Epoch 120/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 10.1164 - mae: 23.2361 - mape: 9.5689 - val_loss: 7.2446 - val_mae: 11.9917 - val_mape: 6.6995 - lr: 1.0000e-04\n",
      "Epoch 121/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.9308 - mae: 23.5521 - mape: 9.3870 - val_loss: 7.0144 - val_mae: 9.2586 - val_mape: 6.4724 - lr: 1.0000e-04\n",
      "Epoch 122/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8696 - mae: 21.0969 - mape: 9.3295 - val_loss: 6.9777 - val_mae: 8.6505 - val_mape: 6.4397 - lr: 1.0000e-04\n",
      "Epoch 123/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 10.2134 - mae: 24.3916 - mape: 9.6770 - val_loss: 6.9228 - val_mae: 8.9036 - val_mape: 6.3882 - lr: 1.0000e-04\n",
      "Epoch 124/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.9566 - mae: 24.9921 - mape: 9.4235 - val_loss: 7.2122 - val_mae: 10.5599 - val_mape: 6.6808 - lr: 1.0000e-04\n",
      "Epoch 125/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9591 - mae: 23.5938 - mape: 9.4293 - val_loss: 7.0447 - val_mae: 10.1485 - val_mape: 6.5168 - lr: 1.0000e-04\n",
      "Epoch 126/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0324 - mae: 22.7327 - mape: 9.5066 - val_loss: 6.9749 - val_mae: 8.9740 - val_mape: 6.4508 - lr: 1.0000e-04\n",
      "Epoch 127/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7303 - mae: 24.9724 - mape: 9.2077 - val_loss: 6.9157 - val_mae: 8.4427 - val_mape: 6.3947 - lr: 1.0000e-04\n",
      "Epoch 128/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0094 - mae: 23.5777 - mape: 9.4900 - val_loss: 6.9267 - val_mae: 8.1136 - val_mape: 6.4090 - lr: 1.0000e-04\n",
      "Epoch 129/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9981 - mae: 21.7319 - mape: 9.4822 - val_loss: 7.0339 - val_mae: 10.2054 - val_mape: 6.5199 - lr: 1.0000e-04\n",
      "Epoch 130/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.2155 - mae: 21.6360 - mape: 9.7029 - val_loss: 7.0149 - val_mae: 8.7427 - val_mape: 6.5041 - lr: 1.0000e-04\n",
      "Epoch 131/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 10.1148 - mae: 23.1268 - mape: 9.6056 - val_loss: 7.1126 - val_mae: 9.7743 - val_mape: 6.6049 - lr: 1.0000e-04\n",
      "Epoch 132/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8714 - mae: 21.6259 - mape: 9.3650 - val_loss: 7.0413 - val_mae: 9.8414 - val_mape: 6.5361 - lr: 1.0000e-04\n",
      "Epoch 133/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.9143 - mae: 22.8110 - mape: 9.4105 - val_loss: 6.9682 - val_mae: 9.7734 - val_mape: 6.4662 - lr: 1.0000e-04\n",
      "Epoch 134/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.3322 - mae: 25.5127 - mape: 9.8318 - val_loss: 6.8921 - val_mae: 8.4671 - val_mape: 6.3934 - lr: 1.0000e-04\n",
      "Epoch 135/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7995 - mae: 22.8115 - mape: 9.3022 - val_loss: 6.9703 - val_mae: 9.9112 - val_mape: 6.4746 - lr: 1.0000e-04\n",
      "Epoch 136/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.0139 - mae: 23.3839 - mape: 9.5199 - val_loss: 7.1465 - val_mae: 9.2153 - val_mape: 6.6542 - lr: 1.0000e-04\n",
      "Epoch 137/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9002 - mae: 19.9938 - mape: 9.4093 - val_loss: 7.0044 - val_mae: 9.3522 - val_mape: 6.5148 - lr: 1.0000e-04\n",
      "Epoch 138/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.1114 - mae: 23.5835 - mape: 9.6233 - val_loss: 6.9208 - val_mae: 8.7764 - val_mape: 6.4341 - lr: 1.0000e-04\n",
      "Epoch 139/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9224 - mae: 21.2983 - mape: 9.4371 - val_loss: 6.9811 - val_mae: 8.0528 - val_mape: 6.4969 - lr: 1.0000e-04\n",
      "Epoch 140/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0131 - mae: 21.5409 - mape: 9.5306 - val_loss: 7.0922 - val_mae: 12.0684 - val_mape: 6.6111 - lr: 1.0000e-04\n",
      "Epoch 141/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.0858 - mae: 23.7428 - mape: 9.6065 - val_loss: 7.1278 - val_mae: 10.5328 - val_mape: 6.6501 - lr: 1.0000e-04\n",
      "Epoch 142/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.0218 - mae: 23.6515 - mape: 9.5453 - val_loss: 7.1255 - val_mae: 10.6528 - val_mape: 6.6504 - lr: 1.0000e-04\n",
      "Epoch 143/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.7248 - mae: 23.2765 - mape: 9.2509 - val_loss: 7.0788 - val_mae: 12.0401 - val_mape: 6.6062 - lr: 1.0000e-04\n",
      "Epoch 144/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.8330 - mae: 21.4574 - mape: 9.3617 - val_loss: 6.9585 - val_mae: 10.1597 - val_mape: 6.4885 - lr: 1.0000e-04\n",
      "Epoch 145/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 10.2744 - mae: 24.2474 - mape: 9.8062 - val_loss: 7.3220 - val_mae: 13.2065 - val_mape: 6.8556 - lr: 1.0000e-04\n",
      "Epoch 146/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.0543 - mae: 24.7836 - mape: 9.5893 - val_loss: 6.8856 - val_mae: 8.5239 - val_mape: 6.4221 - lr: 1.0000e-04\n",
      "Epoch 147/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.0962 - mae: 21.8581 - mape: 9.6345 - val_loss: 6.8973 - val_mae: 8.7218 - val_mape: 6.4371 - lr: 1.0000e-04\n",
      "Epoch 148/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.9850 - mae: 24.1777 - mape: 9.5260 - val_loss: 6.9262 - val_mae: 8.7168 - val_mape: 6.4688 - lr: 1.0000e-04\n",
      "Epoch 149/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6933 - mae: 21.4238 - mape: 9.2370 - val_loss: 6.8248 - val_mae: 8.3902 - val_mape: 6.3697 - lr: 1.0000e-04\n",
      "Epoch 150/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 10.0431 - mae: 25.4479 - mape: 9.5893 - val_loss: 6.8594 - val_mae: 9.1459 - val_mape: 6.4070 - lr: 1.0000e-04\n",
      "Epoch 151/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8661 - mae: 23.2133 - mape: 9.4146 - val_loss: 6.9857 - val_mae: 10.2206 - val_mape: 6.5355 - lr: 1.0000e-04\n",
      "Epoch 152/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5648 - mae: 21.4910 - mape: 9.1155 - val_loss: 6.9094 - val_mae: 9.6344 - val_mape: 6.4611 - lr: 1.0000e-04\n",
      "Epoch 153/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9546 - mae: 24.8440 - mape: 9.5077 - val_loss: 7.0503 - val_mae: 12.1594 - val_mape: 6.6046 - lr: 1.0000e-04\n",
      "Epoch 154/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.9666 - mae: 23.3454 - mape: 9.5225 - val_loss: 7.0454 - val_mae: 11.0076 - val_mape: 6.6030 - lr: 1.0000e-04\n",
      "Epoch 155/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0205 - mae: 23.9478 - mape: 9.5792 - val_loss: 6.8532 - val_mae: 8.7221 - val_mape: 6.4127 - lr: 1.0000e-04\n",
      "Epoch 156/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.8727 - mae: 25.1687 - mape: 9.4335 - val_loss: 6.9111 - val_mae: 9.7959 - val_mape: 6.4734 - lr: 1.0000e-04\n",
      "Epoch 157/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8380 - mae: 24.2887 - mape: 9.4016 - val_loss: 7.2037 - val_mae: 9.7571 - val_mape: 6.7687 - lr: 1.0000e-04\n",
      "Epoch 158/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9511 - mae: 24.1754 - mape: 9.5170 - val_loss: 6.8074 - val_mae: 8.2277 - val_mape: 6.3747 - lr: 1.0000e-04\n",
      "Epoch 159/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.8317 - mae: 22.1135 - mape: 9.4000 - val_loss: 6.8714 - val_mae: 9.0331 - val_mape: 6.4408 - lr: 1.0000e-04\n",
      "Epoch 160/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8260 - mae: 22.2095 - mape: 9.3967 - val_loss: 7.1184 - val_mae: 12.5531 - val_mape: 6.6905 - lr: 1.0000e-04\n",
      "Epoch 161/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.0665 - mae: 24.2576 - mape: 9.6398 - val_loss: 6.8080 - val_mae: 8.2768 - val_mape: 6.3825 - lr: 1.0000e-04\n",
      "Epoch 162/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7963 - mae: 23.4904 - mape: 9.3719 - val_loss: 6.8351 - val_mae: 8.4174 - val_mape: 6.4117 - lr: 1.0000e-04\n",
      "Epoch 163/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.8208 - mae: 23.8646 - mape: 9.3986 - val_loss: 6.8241 - val_mae: 8.5178 - val_mape: 6.4029 - lr: 1.0000e-04\n",
      "Epoch 164/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8263 - mae: 23.9288 - mape: 9.4062 - val_loss: 7.0549 - val_mae: 10.5760 - val_mape: 6.6360 - lr: 1.0000e-04\n",
      "Epoch 165/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0419 - mae: 23.5577 - mape: 9.6241 - val_loss: 6.8672 - val_mae: 8.9667 - val_mape: 6.4507 - lr: 1.0000e-04\n",
      "Epoch 166/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8711 - mae: 22.3741 - mape: 9.4556 - val_loss: 6.8289 - val_mae: 8.6618 - val_mape: 6.4146 - lr: 1.0000e-04\n",
      "Epoch 167/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.7522 - mae: 22.8477 - mape: 9.3389 - val_loss: 6.8506 - val_mae: 8.6152 - val_mape: 6.4386 - lr: 1.0000e-04\n",
      "Epoch 168/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.8233 - mae: 24.9108 - mape: 9.4124 - val_loss: 7.1548 - val_mae: 11.7583 - val_mape: 6.7450 - lr: 1.0000e-04\n",
      "Epoch 169/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 10.0001 - mae: 22.9114 - mape: 9.5914 - val_loss: 6.9012 - val_mae: 9.9070 - val_mape: 6.4936 - lr: 1.0000e-04\n",
      "Epoch 170/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7765 - mae: 23.7276 - mape: 9.3702 - val_loss: 6.9127 - val_mae: 10.6222 - val_mape: 6.5077 - lr: 1.0000e-04\n",
      "Epoch 171/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.9093 - mae: 23.1869 - mape: 9.5055 - val_loss: 6.9300 - val_mae: 8.9411 - val_mape: 6.5274 - lr: 1.0000e-04\n",
      "Epoch 172/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.9843 - mae: 23.3658 - mape: 9.5825 - val_loss: 7.0813 - val_mae: 11.4998 - val_mape: 6.6805 - lr: 1.0000e-04\n",
      "Epoch 173/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 10.0661 - mae: 25.5676 - mape: 9.6662 - val_loss: 7.0262 - val_mae: 10.8237 - val_mape: 6.6275 - lr: 1.0000e-04\n",
      "Epoch 174/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8690 - mae: 23.6388 - mape: 9.4714 - val_loss: 6.8759 - val_mae: 9.5175 - val_mape: 6.4796 - lr: 1.0000e-04\n",
      "Epoch 175/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7713 - mae: 22.2127 - mape: 9.3760 - val_loss: 6.8390 - val_mae: 8.3348 - val_mape: 6.4444 - lr: 1.0000e-04\n",
      "Epoch 176/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8517 - mae: 22.9831 - mape: 9.4584 - val_loss: 6.8698 - val_mae: 8.7099 - val_mape: 6.4776 - lr: 1.0000e-04\n",
      "Epoch 177/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 10.1021 - mae: 23.9698 - mape: 9.7110 - val_loss: 7.0095 - val_mae: 10.8403 - val_mape: 6.6194 - lr: 1.0000e-04\n",
      "Epoch 178/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7560 - mae: 23.2912 - mape: 9.3666 - val_loss: 6.8687 - val_mae: 8.8188 - val_mape: 6.4804 - lr: 1.0000e-04\n",
      "Epoch 179/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.9316 - mae: 25.1512 - mape: 9.5440 - val_loss: 6.8325 - val_mae: 9.0072 - val_mape: 6.4460 - lr: 1.0000e-04\n",
      "Epoch 180/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 10.1508 - mae: 25.9839 - mape: 9.7653 - val_loss: 6.8845 - val_mae: 9.9068 - val_mape: 6.4999 - lr: 1.0000e-04\n",
      "Epoch 181/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 10.0162 - mae: 24.5883 - mape: 9.6325 - val_loss: 7.2388 - val_mae: 11.9398 - val_mape: 6.8560 - lr: 1.0000e-04\n",
      "Epoch 182/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8869 - mae: 23.4344 - mape: 9.5048 - val_loss: 6.8361 - val_mae: 8.7666 - val_mape: 6.4548 - lr: 1.0000e-04\n",
      "Epoch 183/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.8090 - mae: 24.0597 - mape: 9.4290 - val_loss: 6.9580 - val_mae: 11.1398 - val_mape: 6.5792 - lr: 1.0000e-04\n",
      "Epoch 184/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7448 - mae: 22.9582 - mape: 9.3666 - val_loss: 6.9366 - val_mae: 11.0632 - val_mape: 6.5590 - lr: 1.0000e-04\n",
      "Epoch 185/1000\n",
      "87/87 [==============================] - 8s 95ms/step - loss: 9.7909 - mae: 24.0668 - mape: 9.4139 - val_loss: 6.7959 - val_mae: 8.4401 - val_mape: 6.4196 - lr: 1.0000e-04\n",
      "Epoch 186/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.8540 - mae: 21.9913 - mape: 9.4788 - val_loss: 6.9827 - val_mae: 10.0167 - val_mape: 6.6084 - lr: 1.0000e-04\n",
      "Epoch 187/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 9.6789 - mae: 22.5950 - mape: 9.3057 - val_loss: 6.8443 - val_mae: 9.5005 - val_mape: 6.4721 - lr: 1.0000e-04\n",
      "Epoch 188/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9542 - mae: 25.4237 - mape: 9.5831 - val_loss: 6.9856 - val_mae: 9.9936 - val_mape: 6.6157 - lr: 1.0000e-04\n",
      "Epoch 189/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 9.8566 - mae: 22.8162 - mape: 9.4874 - val_loss: 6.8347 - val_mae: 8.9040 - val_mape: 6.4661 - lr: 1.0000e-04\n",
      "Epoch 190/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8486 - mae: 22.9405 - mape: 9.4807 - val_loss: 6.7892 - val_mae: 8.4444 - val_mape: 6.4222 - lr: 1.0000e-04\n",
      "Epoch 191/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7376 - mae: 23.6908 - mape: 9.3715 - val_loss: 6.8415 - val_mae: 9.3782 - val_mape: 6.4761 - lr: 1.0000e-04\n",
      "Epoch 192/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9766 - mae: 25.4144 - mape: 9.6122 - val_loss: 6.8490 - val_mae: 8.9915 - val_mape: 6.4854 - lr: 1.0000e-04\n",
      "Epoch 193/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7558 - mae: 24.7778 - mape: 9.3929 - val_loss: 6.9284 - val_mae: 10.0085 - val_mape: 6.5663 - lr: 1.0000e-04\n",
      "Epoch 194/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.8314 - mae: 23.3597 - mape: 9.4701 - val_loss: 6.8014 - val_mae: 8.7045 - val_mape: 6.4409 - lr: 1.0000e-04\n",
      "Epoch 195/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 10.1754 - mae: 23.2039 - mape: 9.8156 - val_loss: 6.9371 - val_mae: 10.3140 - val_mape: 6.5780 - lr: 1.0000e-04\n",
      "Epoch 196/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8697 - mae: 26.0763 - mape: 9.5116 - val_loss: 6.7873 - val_mae: 8.4780 - val_mape: 6.4301 - lr: 1.0000e-04\n",
      "Epoch 197/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.9349 - mae: 24.2119 - mape: 9.5783 - val_loss: 6.9622 - val_mae: 10.0238 - val_mape: 6.6062 - lr: 1.0000e-04\n",
      "Epoch 198/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.8883 - mae: 24.3101 - mape: 9.5331 - val_loss: 6.7940 - val_mae: 9.2414 - val_mape: 6.4399 - lr: 1.0000e-04\n",
      "Epoch 199/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8137 - mae: 22.5487 - mape: 9.4603 - val_loss: 7.2712 - val_mae: 12.2110 - val_mape: 6.9187 - lr: 1.0000e-04\n",
      "Epoch 200/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 9.9199 - mae: 23.8333 - mape: 9.5680 - val_loss: 6.8746 - val_mae: 9.8717 - val_mape: 6.5237 - lr: 1.0000e-04\n",
      "Epoch 201/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8067 - mae: 25.3451 - mape: 9.4567 - val_loss: 6.9930 - val_mae: 11.5229 - val_mape: 6.6437 - lr: 1.0000e-04\n",
      "Epoch 202/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 10.0615 - mae: 23.8741 - mape: 9.7127 - val_loss: 6.8857 - val_mae: 8.7160 - val_mape: 6.5375 - lr: 1.0000e-04\n",
      "Epoch 203/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7512 - mae: 24.4176 - mape: 9.4038 - val_loss: 7.1147 - val_mae: 12.9225 - val_mape: 6.7680 - lr: 1.0000e-04\n",
      "Epoch 204/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8909 - mae: 24.8164 - mape: 9.5450 - val_loss: 6.8304 - val_mae: 10.0467 - val_mape: 6.4852 - lr: 1.0000e-04\n",
      "Epoch 205/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.9416 - mae: 23.7065 - mape: 9.5969 - val_loss: 6.7820 - val_mae: 9.3299 - val_mape: 6.4381 - lr: 1.0000e-04\n",
      "Epoch 206/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6435 - mae: 23.2231 - mape: 9.3004 - val_loss: 6.8428 - val_mae: 8.9615 - val_mape: 6.5004 - lr: 1.0000e-04\n",
      "Epoch 207/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.9263 - mae: 23.0922 - mape: 9.5848 - val_loss: 6.7779 - val_mae: 8.3454 - val_mape: 6.4371 - lr: 1.0000e-04\n",
      "Epoch 208/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.8417 - mae: 24.1370 - mape: 9.5016 - val_loss: 7.1105 - val_mae: 10.5698 - val_mape: 6.7712 - lr: 1.0000e-04\n",
      "Epoch 209/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7789 - mae: 23.6687 - mape: 9.4403 - val_loss: 6.8005 - val_mae: 8.4071 - val_mape: 6.4627 - lr: 1.0000e-04\n",
      "Epoch 210/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7242 - mae: 20.8561 - mape: 9.3868 - val_loss: 6.8107 - val_mae: 8.3729 - val_mape: 6.4740 - lr: 1.0000e-04\n",
      "Epoch 211/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7168 - mae: 21.8036 - mape: 9.3807 - val_loss: 6.8423 - val_mae: 9.0408 - val_mape: 6.5069 - lr: 1.0000e-04\n",
      "Epoch 212/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9376 - mae: 23.9327 - mape: 9.6026 - val_loss: 6.9614 - val_mae: 10.3749 - val_mape: 6.6268 - lr: 1.0000e-04\n",
      "Epoch 213/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8594 - mae: 22.9874 - mape: 9.5255 - val_loss: 6.9132 - val_mae: 9.7472 - val_mape: 6.5801 - lr: 1.0000e-04\n",
      "Epoch 214/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.9272 - mae: 22.4187 - mape: 9.5947 - val_loss: 6.7440 - val_mae: 8.4959 - val_mape: 6.4120 - lr: 1.0000e-04\n",
      "Epoch 215/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7863 - mae: 20.5985 - mape: 9.4550 - val_loss: 6.7702 - val_mae: 8.6442 - val_mape: 6.4396 - lr: 1.0000e-04\n",
      "Epoch 216/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7876 - mae: 22.0182 - mape: 9.4579 - val_loss: 7.2723 - val_mae: 11.5697 - val_mape: 6.9435 - lr: 1.0000e-04\n",
      "Epoch 217/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.8341 - mae: 25.0545 - mape: 9.5059 - val_loss: 6.7907 - val_mae: 8.6432 - val_mape: 6.4631 - lr: 1.0000e-04\n",
      "Epoch 218/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.9208 - mae: 24.4279 - mape: 9.5939 - val_loss: 6.8072 - val_mae: 8.7968 - val_mape: 6.4807 - lr: 1.0000e-04\n",
      "Epoch 219/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6843 - mae: 24.9588 - mape: 9.3585 - val_loss: 6.8052 - val_mae: 9.1504 - val_mape: 6.4799 - lr: 1.0000e-04\n",
      "Epoch 220/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8583 - mae: 21.9253 - mape: 9.5339 - val_loss: 6.8628 - val_mae: 10.5484 - val_mape: 6.5390 - lr: 1.0000e-04\n",
      "Epoch 221/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6807 - mae: 23.1507 - mape: 9.3576 - val_loss: 6.8143 - val_mae: 9.2481 - val_mape: 6.4918 - lr: 1.0000e-04\n",
      "Epoch 222/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6473 - mae: 23.2691 - mape: 9.3252 - val_loss: 6.8696 - val_mae: 9.3234 - val_mape: 6.5479 - lr: 1.0000e-04\n",
      "Epoch 223/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6537 - mae: 24.3660 - mape: 9.3327 - val_loss: 7.1978 - val_mae: 11.5752 - val_mape: 6.8773 - lr: 1.0000e-04\n",
      "Epoch 224/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.9256 - mae: 24.0602 - mape: 9.6059 - val_loss: 6.9670 - val_mae: 10.4772 - val_mape: 6.6481 - lr: 1.0000e-04\n",
      "Epoch 225/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 9.5231 - mae: 23.5298 - mape: 9.2050 - val_loss: 6.7874 - val_mae: 8.8597 - val_mape: 6.4701 - lr: 1.0000e-04\n",
      "Epoch 226/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7193 - mae: 23.4266 - mape: 9.4027 - val_loss: 6.8298 - val_mae: 9.8008 - val_mape: 6.5138 - lr: 1.0000e-04\n",
      "Epoch 227/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8112 - mae: 24.0914 - mape: 9.4959 - val_loss: 6.8162 - val_mae: 9.5586 - val_mape: 6.5014 - lr: 1.0000e-04\n",
      "Epoch 228/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7117 - mae: 22.7537 - mape: 9.3977 - val_loss: 6.8149 - val_mae: 8.5912 - val_mape: 6.5015 - lr: 1.0000e-04\n",
      "Epoch 229/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7856 - mae: 23.9143 - mape: 9.4728 - val_loss: 7.1057 - val_mae: 11.9615 - val_mape: 6.7937 - lr: 1.0000e-04\n",
      "Epoch 230/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.8429 - mae: 24.5037 - mape: 9.5314 - val_loss: 6.7546 - val_mae: 8.6102 - val_mape: 6.4438 - lr: 1.0000e-04\n",
      "Epoch 231/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.4949 - mae: 23.0765 - mape: 9.1845 - val_loss: 6.7679 - val_mae: 8.9285 - val_mape: 6.4580 - lr: 1.0000e-04\n",
      "Epoch 232/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.7478 - mae: 24.7130 - mape: 9.4385 - val_loss: 6.7752 - val_mae: 9.4075 - val_mape: 6.4666 - lr: 1.0000e-04\n",
      "Epoch 233/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 10.0107 - mae: 22.7467 - mape: 9.7028 - val_loss: 6.7335 - val_mae: 8.5412 - val_mape: 6.4262 - lr: 1.0000e-04\n",
      "Epoch 234/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4846 - mae: 22.3207 - mape: 9.1778 - val_loss: 6.9086 - val_mae: 11.4119 - val_mape: 6.6023 - lr: 1.0000e-04\n",
      "Epoch 235/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5887 - mae: 23.7188 - mape: 9.2830 - val_loss: 6.8761 - val_mae: 9.9085 - val_mape: 6.5709 - lr: 1.0000e-04\n",
      "Epoch 236/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7471 - mae: 25.1387 - mape: 9.4426 - val_loss: 6.8398 - val_mae: 9.4927 - val_mape: 6.5361 - lr: 1.0000e-04\n",
      "Epoch 237/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7394 - mae: 24.0684 - mape: 9.4362 - val_loss: 6.7845 - val_mae: 8.7566 - val_mape: 6.4816 - lr: 1.0000e-04\n",
      "Epoch 238/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.5586 - mae: 23.9652 - mape: 9.2561 - val_loss: 6.7980 - val_mae: 9.7981 - val_mape: 6.4958 - lr: 1.0000e-04\n",
      "Epoch 239/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.7411 - mae: 24.9226 - mape: 9.4393 - val_loss: 6.7497 - val_mae: 8.8849 - val_mape: 6.4482 - lr: 1.0000e-04\n",
      "Epoch 240/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8717 - mae: 25.2545 - mape: 9.5708 - val_loss: 6.7677 - val_mae: 8.7883 - val_mape: 6.4674 - lr: 1.0000e-04\n",
      "Epoch 241/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6952 - mae: 26.4195 - mape: 9.3956 - val_loss: 6.7976 - val_mae: 8.6187 - val_mape: 6.4987 - lr: 1.0000e-04\n",
      "Epoch 242/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8984 - mae: 23.7402 - mape: 9.5997 - val_loss: 6.8417 - val_mae: 10.4317 - val_mape: 6.5436 - lr: 1.0000e-04\n",
      "Epoch 243/1000\n",
      "87/87 [==============================] - 7s 75ms/step - loss: 9.6465 - mae: 22.2716 - mape: 9.3488 - val_loss: 7.1322 - val_mae: 10.7155 - val_mape: 6.8356 - lr: 1.0000e-04\n",
      "Epoch 244/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5442 - mae: 23.4719 - mape: 9.2481 - val_loss: 6.8498 - val_mae: 11.1880 - val_mape: 6.5542 - lr: 1.0000e-04\n",
      "Epoch 245/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.7514 - mae: 24.5531 - mape: 9.4563 - val_loss: 6.7380 - val_mae: 8.5760 - val_mape: 6.4435 - lr: 1.0000e-04\n",
      "Epoch 246/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7292 - mae: 22.2071 - mape: 9.4352 - val_loss: 6.8330 - val_mae: 9.2275 - val_mape: 6.5394 - lr: 1.0000e-04\n",
      "Epoch 247/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7121 - mae: 22.1698 - mape: 9.4190 - val_loss: 6.9206 - val_mae: 11.1693 - val_mape: 6.6279 - lr: 1.0000e-04\n",
      "Epoch 248/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.8127 - mae: 24.5785 - mape: 9.5207 - val_loss: 6.7977 - val_mae: 9.7627 - val_mape: 6.5059 - lr: 1.0000e-04\n",
      "Epoch 249/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6737 - mae: 23.1012 - mape: 9.3824 - val_loss: 6.8752 - val_mae: 11.0334 - val_mape: 6.5844 - lr: 1.0000e-04\n",
      "Epoch 250/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7434 - mae: 23.6973 - mape: 9.4530 - val_loss: 7.0473 - val_mae: 12.1142 - val_mape: 6.7574 - lr: 1.0000e-04\n",
      "Epoch 251/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5826 - mae: 24.1658 - mape: 9.2934 - val_loss: 6.7618 - val_mae: 8.9174 - val_mape: 6.4731 - lr: 1.0000e-04\n",
      "Epoch 252/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.7036 - mae: 24.5361 - mape: 9.4152 - val_loss: 6.8248 - val_mae: 10.1489 - val_mape: 6.5366 - lr: 1.0000e-04\n",
      "Epoch 253/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7112 - mae: 22.1656 - mape: 9.4236 - val_loss: 6.7838 - val_mae: 10.0825 - val_mape: 6.4968 - lr: 1.0000e-04\n",
      "Epoch 254/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.9380 - mae: 22.1527 - mape: 9.6516 - val_loss: 6.8619 - val_mae: 9.4962 - val_mape: 6.5759 - lr: 1.0000e-04\n",
      "Epoch 255/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8093 - mae: 23.9087 - mape: 9.5241 - val_loss: 6.8961 - val_mae: 11.9691 - val_mape: 6.6114 - lr: 1.0000e-04\n",
      "Epoch 256/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6255 - mae: 23.2907 - mape: 9.3414 - val_loss: 6.7179 - val_mae: 8.5669 - val_mape: 6.4343 - lr: 1.0000e-04\n",
      "Epoch 257/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6625 - mae: 21.7608 - mape: 9.3793 - val_loss: 6.7810 - val_mae: 8.8706 - val_mape: 6.4981 - lr: 1.0000e-04\n",
      "Epoch 258/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.6266 - mae: 24.0529 - mape: 9.3443 - val_loss: 6.8025 - val_mae: 9.3699 - val_mape: 6.5204 - lr: 1.0000e-04\n",
      "Epoch 259/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7557 - mae: 23.0012 - mape: 9.4739 - val_loss: 6.8853 - val_mae: 10.8486 - val_mape: 6.6039 - lr: 1.0000e-04\n",
      "Epoch 260/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7765 - mae: 22.2844 - mape: 9.4956 - val_loss: 6.7847 - val_mae: 8.8385 - val_mape: 6.5042 - lr: 1.0000e-04\n",
      "Epoch 261/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.7733 - mae: 24.8115 - mape: 9.4931 - val_loss: 6.8650 - val_mae: 9.3597 - val_mape: 6.5854 - lr: 1.0000e-04\n",
      "Epoch 262/1000\n",
      "87/87 [==============================] - 7s 77ms/step - loss: 9.7090 - mae: 23.4358 - mape: 9.4298 - val_loss: 6.7131 - val_mae: 8.6802 - val_mape: 6.4342 - lr: 1.0000e-04\n",
      "Epoch 263/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7374 - mae: 23.7085 - mape: 9.4591 - val_loss: 6.7379 - val_mae: 8.7444 - val_mape: 6.4601 - lr: 1.0000e-04\n",
      "Epoch 264/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.4998 - mae: 22.1093 - mape: 9.2225 - val_loss: 6.7106 - val_mae: 8.6178 - val_mape: 6.4336 - lr: 1.0000e-04\n",
      "Epoch 265/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4423 - mae: 22.1443 - mape: 9.1658 - val_loss: 6.7606 - val_mae: 9.4508 - val_mape: 6.4846 - lr: 1.0000e-04\n",
      "Epoch 266/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7118 - mae: 26.3004 - mape: 9.4363 - val_loss: 6.7044 - val_mae: 8.9993 - val_mape: 6.4294 - lr: 1.0000e-04\n",
      "Epoch 267/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6901 - mae: 24.7864 - mape: 9.4157 - val_loss: 7.2071 - val_mae: 14.4312 - val_mape: 6.9330 - lr: 1.0000e-04\n",
      "Epoch 268/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.7305 - mae: 23.6651 - mape: 9.4568 - val_loss: 6.7238 - val_mae: 8.6145 - val_mape: 6.4506 - lr: 1.0000e-04\n",
      "Epoch 269/1000\n",
      "87/87 [==============================] - 8s 93ms/step - loss: 9.7568 - mae: 24.9680 - mape: 9.4840 - val_loss: 7.0091 - val_mae: 10.8921 - val_mape: 6.7368 - lr: 1.0000e-04\n",
      "Epoch 270/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6554 - mae: 23.8538 - mape: 9.3836 - val_loss: 6.7245 - val_mae: 8.4108 - val_mape: 6.4534 - lr: 1.0000e-04\n",
      "Epoch 271/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.7850 - mae: 24.9702 - mape: 9.5142 - val_loss: 6.8537 - val_mae: 11.5194 - val_mape: 6.5831 - lr: 1.0000e-04\n",
      "Epoch 272/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7500 - mae: 23.8829 - mape: 9.4801 - val_loss: 7.3194 - val_mae: 13.4983 - val_mape: 7.0502 - lr: 1.0000e-04\n",
      "Epoch 273/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7458 - mae: 25.7012 - mape: 9.4767 - val_loss: 6.9285 - val_mae: 9.6422 - val_mape: 6.6597 - lr: 1.0000e-04\n",
      "Epoch 274/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6785 - mae: 23.9919 - mape: 9.4101 - val_loss: 6.8518 - val_mae: 8.9204 - val_mape: 6.5838 - lr: 1.0000e-04\n",
      "Epoch 275/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.6666 - mae: 22.6086 - mape: 9.3991 - val_loss: 6.7276 - val_mae: 8.5385 - val_mape: 6.4606 - lr: 1.0000e-04\n",
      "Epoch 276/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7282 - mae: 23.3416 - mape: 9.4616 - val_loss: 6.7137 - val_mae: 8.4373 - val_mape: 6.4473 - lr: 1.0000e-04\n",
      "Epoch 277/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8104 - mae: 25.9641 - mape: 9.5443 - val_loss: 7.1866 - val_mae: 13.5886 - val_mape: 6.9209 - lr: 1.0000e-04\n",
      "Epoch 278/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.7682 - mae: 23.7297 - mape: 9.5028 - val_loss: 6.8235 - val_mae: 9.6816 - val_mape: 6.5584 - lr: 1.0000e-04\n",
      "Epoch 279/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.6344 - mae: 23.7469 - mape: 9.3696 - val_loss: 6.7658 - val_mae: 9.4138 - val_mape: 6.5015 - lr: 1.0000e-04\n",
      "Epoch 280/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4732 - mae: 22.9102 - mape: 9.2092 - val_loss: 6.7660 - val_mae: 9.0372 - val_mape: 6.5022 - lr: 1.0000e-04\n",
      "Epoch 281/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7015 - mae: 23.8414 - mape: 9.4381 - val_loss: 6.6918 - val_mae: 8.4022 - val_mape: 6.4292 - lr: 1.0000e-04\n",
      "Epoch 282/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.7748 - mae: 25.3392 - mape: 9.5124 - val_loss: 7.1069 - val_mae: 10.2389 - val_mape: 6.8449 - lr: 1.0000e-04\n",
      "Epoch 283/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8070 - mae: 23.8088 - mape: 9.5452 - val_loss: 6.7397 - val_mae: 8.5961 - val_mape: 6.4784 - lr: 1.0000e-04\n",
      "Epoch 284/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.5766 - mae: 23.7275 - mape: 9.3156 - val_loss: 6.8197 - val_mae: 9.6239 - val_mape: 6.5592 - lr: 1.0000e-04\n",
      "Epoch 285/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4281 - mae: 23.9548 - mape: 9.1681 - val_loss: 7.0574 - val_mae: 10.0976 - val_mape: 6.7979 - lr: 1.0000e-04\n",
      "Epoch 286/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6170 - mae: 26.1405 - mape: 9.3581 - val_loss: 6.7441 - val_mae: 9.0305 - val_mape: 6.4856 - lr: 1.0000e-04\n",
      "Epoch 287/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.8698 - mae: 23.5803 - mape: 9.6118 - val_loss: 6.7512 - val_mae: 9.1815 - val_mape: 6.4935 - lr: 1.0000e-04\n",
      "Epoch 288/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.5087 - mae: 23.0452 - mape: 9.2515 - val_loss: 6.7833 - val_mae: 8.9456 - val_mape: 6.5265 - lr: 1.0000e-04\n",
      "Epoch 289/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.8408 - mae: 23.1418 - mape: 9.5843 - val_loss: 6.7686 - val_mae: 9.2331 - val_mape: 6.5123 - lr: 1.0000e-04\n",
      "Epoch 290/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6445 - mae: 22.2413 - mape: 9.3889 - val_loss: 7.0578 - val_mae: 13.1314 - val_mape: 6.8027 - lr: 1.0000e-04\n",
      "Epoch 291/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8127 - mae: 24.1267 - mape: 9.5578 - val_loss: 7.1312 - val_mae: 11.8109 - val_mape: 6.8767 - lr: 1.0000e-04\n",
      "Epoch 292/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.5484 - mae: 24.0821 - mape: 9.2941 - val_loss: 6.8602 - val_mae: 9.8020 - val_mape: 6.6062 - lr: 1.0000e-04\n",
      "Epoch 293/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.7583 - mae: 24.4862 - mape: 9.5044 - val_loss: 6.8176 - val_mae: 8.8721 - val_mape: 6.5639 - lr: 1.0000e-04\n",
      "Epoch 294/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6911 - mae: 23.2306 - mape: 9.4377 - val_loss: 6.7459 - val_mae: 8.3355 - val_mape: 6.4927 - lr: 1.0000e-04\n",
      "Epoch 295/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.4674 - mae: 21.3484 - mape: 9.2144 - val_loss: 6.8555 - val_mae: 9.5593 - val_mape: 6.6028 - lr: 1.0000e-04\n",
      "Epoch 296/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.7778 - mae: 23.5429 - mape: 9.5254 - val_loss: 6.8123 - val_mae: 9.2116 - val_mape: 6.5602 - lr: 1.0000e-04\n",
      "Epoch 297/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6573 - mae: 25.3700 - mape: 9.4059 - val_loss: 6.9592 - val_mae: 12.4668 - val_mape: 6.7081 - lr: 1.0000e-04\n",
      "Epoch 298/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6149 - mae: 24.6950 - mape: 9.3642 - val_loss: 7.0012 - val_mae: 11.3558 - val_mape: 6.7511 - lr: 1.0000e-04\n",
      "Epoch 299/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5740 - mae: 24.0306 - mape: 9.3244 - val_loss: 6.7986 - val_mae: 8.8044 - val_mape: 6.5494 - lr: 1.0000e-04\n",
      "Epoch 300/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5588 - mae: 24.5687 - mape: 9.3099 - val_loss: 6.8864 - val_mae: 10.6779 - val_mape: 6.6378 - lr: 1.0000e-04\n",
      "Epoch 301/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.8067 - mae: 21.3537 - mape: 9.5583 - val_loss: 6.9120 - val_mae: 12.4778 - val_mape: 6.6639 - lr: 1.0000e-04\n",
      "Epoch 302/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6534 - mae: 24.8375 - mape: 9.4056 - val_loss: 6.7238 - val_mae: 8.4485 - val_mape: 6.4762 - lr: 1.0000e-04\n",
      "Epoch 303/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.6161 - mae: 24.4476 - mape: 9.3685 - val_loss: 6.8234 - val_mae: 9.9252 - val_mape: 6.5759 - lr: 1.0000e-04\n",
      "Epoch 304/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5097 - mae: 22.4484 - mape: 9.2626 - val_loss: 6.7287 - val_mae: 8.3455 - val_mape: 6.4816 - lr: 1.0000e-04\n",
      "Epoch 305/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.8030 - mae: 23.9242 - mape: 9.5566 - val_loss: 6.7304 - val_mae: 8.6194 - val_mape: 6.4844 - lr: 1.0000e-04\n",
      "Epoch 306/1000\n",
      "87/87 [==============================] - 7s 79ms/step - loss: 9.5784 - mae: 21.0755 - mape: 9.3329 - val_loss: 7.1382 - val_mae: 13.1387 - val_mape: 6.8929 - lr: 1.0000e-04\n",
      "Epoch 307/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6949 - mae: 22.8259 - mape: 9.4499 - val_loss: 6.8259 - val_mae: 9.4885 - val_mape: 6.5811 - lr: 1.0000e-04\n",
      "Epoch 308/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7296 - mae: 23.1997 - mape: 9.4851 - val_loss: 6.8340 - val_mae: 10.4185 - val_mape: 6.5894 - lr: 1.0000e-04\n",
      "Epoch 309/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5341 - mae: 25.4109 - mape: 9.2900 - val_loss: 7.0159 - val_mae: 13.3964 - val_mape: 6.7722 - lr: 1.0000e-04\n",
      "Epoch 310/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6586 - mae: 23.2885 - mape: 9.4152 - val_loss: 6.8572 - val_mae: 10.0232 - val_mape: 6.6139 - lr: 1.0000e-04\n",
      "Epoch 311/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.7294 - mae: 23.0908 - mape: 9.4865\n",
      "Epoch 311: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.7294 - mae: 23.0908 - mape: 9.4865 - val_loss: 6.9047 - val_mae: 9.0356 - val_mape: 6.6624 - lr: 1.0000e-04\n",
      "Epoch 312/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.9470 - mae: 24.3863 - mape: 9.7048 - val_loss: 6.7936 - val_mae: 8.7317 - val_mape: 6.5515 - lr: 3.0000e-05\n",
      "Epoch 313/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.6395 - mae: 23.6418 - mape: 9.3975 - val_loss: 6.8514 - val_mae: 9.1352 - val_mape: 6.6096 - lr: 3.0000e-05\n",
      "Epoch 314/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.5881 - mae: 24.2978 - mape: 9.3464 - val_loss: 6.7945 - val_mae: 8.8259 - val_mape: 6.5528 - lr: 3.0000e-05\n",
      "Epoch 315/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.5266 - mae: 23.0712 - mape: 9.2849 - val_loss: 6.8815 - val_mae: 10.5131 - val_mape: 6.6399 - lr: 3.0000e-05\n",
      "Epoch 316/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7288 - mae: 24.2069 - mape: 9.4873 - val_loss: 6.7755 - val_mae: 8.8781 - val_mape: 6.5342 - lr: 3.0000e-05\n",
      "Epoch 317/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.6722 - mae: 23.6668 - mape: 9.4309 - val_loss: 6.9618 - val_mae: 11.2600 - val_mape: 6.7205 - lr: 3.0000e-05\n",
      "Epoch 318/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7941 - mae: 26.1698 - mape: 9.5529 - val_loss: 6.7898 - val_mae: 8.9907 - val_mape: 6.5486 - lr: 3.0000e-05\n",
      "Epoch 319/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.7417 - mae: 23.8477 - mape: 9.5005 - val_loss: 6.8439 - val_mae: 9.1917 - val_mape: 6.6029 - lr: 3.0000e-05\n",
      "Epoch 320/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.5459 - mae: 23.3012 - mape: 9.3050 - val_loss: 6.8133 - val_mae: 9.2841 - val_mape: 6.5724 - lr: 3.0000e-05\n",
      "Epoch 321/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.2991 - mae: 22.0859 - mape: 9.0582 - val_loss: 6.8782 - val_mae: 10.0837 - val_mape: 6.6374 - lr: 3.0000e-05\n",
      "Epoch 322/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.6699 - mae: 23.8413 - mape: 9.4292 - val_loss: 6.7524 - val_mae: 8.7407 - val_mape: 6.5118 - lr: 3.0000e-05\n",
      "Epoch 323/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.5798 - mae: 23.7611 - mape: 9.3394 - val_loss: 6.8757 - val_mae: 9.8156 - val_mape: 6.6354 - lr: 3.0000e-05\n",
      "Epoch 324/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7168 - mae: 24.0737 - mape: 9.4767 - val_loss: 6.8127 - val_mae: 9.3809 - val_mape: 6.5726 - lr: 3.0000e-05\n",
      "Epoch 325/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5395 - mae: 22.4160 - mape: 9.2994 - val_loss: 6.8596 - val_mae: 10.0076 - val_mape: 6.6196 - lr: 3.0000e-05\n",
      "Epoch 326/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7025 - mae: 23.3410 - mape: 9.4626 - val_loss: 6.9167 - val_mae: 10.6874 - val_mape: 6.6769 - lr: 3.0000e-05\n",
      "Epoch 327/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5956 - mae: 22.4908 - mape: 9.3558 - val_loss: 7.0260 - val_mae: 11.4956 - val_mape: 6.7862 - lr: 3.0000e-05\n",
      "Epoch 328/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.5704 - mae: 22.2445 - mape: 9.3307 - val_loss: 6.8088 - val_mae: 9.8907 - val_mape: 6.5692 - lr: 3.0000e-05\n",
      "Epoch 329/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.8000 - mae: 21.9086 - mape: 9.5605 - val_loss: 6.8125 - val_mae: 9.7585 - val_mape: 6.5730 - lr: 3.0000e-05\n",
      "Epoch 330/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7909 - mae: 22.0800 - mape: 9.5514 - val_loss: 6.8692 - val_mae: 10.5526 - val_mape: 6.6297 - lr: 3.0000e-05\n",
      "Epoch 331/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.4175 - mae: 22.2744 - mape: 9.1781 - val_loss: 6.7769 - val_mae: 8.8897 - val_mape: 6.5375 - lr: 3.0000e-05\n",
      "Epoch 332/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5131 - mae: 23.4945 - mape: 9.2738 - val_loss: 6.7782 - val_mae: 8.6961 - val_mape: 6.5390 - lr: 3.0000e-05\n",
      "Epoch 333/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8004 - mae: 22.5448 - mape: 9.5614 - val_loss: 6.7734 - val_mae: 8.7003 - val_mape: 6.5344 - lr: 3.0000e-05\n",
      "Epoch 334/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.5190 - mae: 26.6388 - mape: 9.2801 - val_loss: 6.8027 - val_mae: 8.9064 - val_mape: 6.5638 - lr: 3.0000e-05\n",
      "Epoch 335/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 9.5911 - mae: 21.1899 - mape: 9.3524 - val_loss: 6.8872 - val_mae: 10.3204 - val_mape: 6.6485 - lr: 3.0000e-05\n",
      "Epoch 336/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.6302 - mae: 23.1170 - mape: 9.3916 - val_loss: 6.7636 - val_mae: 8.6750 - val_mape: 6.5251 - lr: 3.0000e-05\n",
      "Epoch 337/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4101 - mae: 23.7604 - mape: 9.1716 - val_loss: 6.8042 - val_mae: 9.0944 - val_mape: 6.5658 - lr: 3.0000e-05\n",
      "Epoch 338/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.8073 - mae: 22.7134 - mape: 9.5689 - val_loss: 6.8227 - val_mae: 9.2734 - val_mape: 6.5845 - lr: 3.0000e-05\n",
      "Epoch 339/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.5461 - mae: 21.8202 - mape: 9.3080 - val_loss: 6.8280 - val_mae: 9.3473 - val_mape: 6.5900 - lr: 3.0000e-05\n",
      "Epoch 340/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6568 - mae: 23.7825 - mape: 9.4190 - val_loss: 6.9664 - val_mae: 11.6311 - val_mape: 6.7286 - lr: 3.0000e-05\n",
      "Epoch 341/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.7133 - mae: 24.9142 - mape: 9.4756\n",
      "Epoch 341: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 9.7054 - mae: 24.7803 - mape: 9.4677 - val_loss: 6.8448 - val_mae: 9.5517 - val_mape: 6.6071 - lr: 3.0000e-05\n",
      "Epoch 341: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 1: loss of 9.798641204833984; mae of 7.744525909423828; mape of 6.199242115020752%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n",
      " 2/87 [..............................] - ETA: 6s - loss: 11.3511 - mae: 31.9645 - mape: 11.1135 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.8523 - mae: 21.0898 - mape: 9.6153"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 96ms/step - loss: 9.8523 - mae: 21.0898 - mape: 9.6153 - val_loss: 5.9794 - val_mae: 9.7204 - val_mape: 5.7430 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 7s 78ms/step - loss: 9.8850 - mae: 22.4272 - mape: 9.6491 - val_loss: 5.9969 - val_mae: 12.0764 - val_mape: 5.7615 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 7s 81ms/step - loss: 9.8273 - mae: 23.1973 - mape: 9.5921 - val_loss: 6.0773 - val_mae: 10.4650 - val_mape: 5.8426 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.7894 - mae: 22.8764 - mape: 9.5553 - val_loss: 6.3877 - val_mae: 11.2652 - val_mape: 6.1540 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5114 - mae: 22.8053 - mape: 9.2780 - val_loss: 6.2014 - val_mae: 11.0409 - val_mape: 5.9686 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 78ms/step - loss: 9.7189 - mae: 21.4123 - mape: 9.4865 - val_loss: 6.2192 - val_mae: 9.7234 - val_mape: 5.9872 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8001 - mae: 23.7808 - mape: 9.5683 - val_loss: 6.3373 - val_mae: 14.7722 - val_mape: 6.1056 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.8515 - mae: 21.9589 - mape: 9.6202 - val_loss: 6.0662 - val_mae: 9.9914 - val_mape: 5.8353 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8426 - mae: 22.1414 - mape: 9.6120 - val_loss: 6.6352 - val_mae: 16.1199 - val_mape: 6.4050 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7641 - mae: 21.4500 - mape: 9.5344 - val_loss: 6.0606 - val_mae: 9.1830 - val_mape: 5.8316 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6227 - mae: 20.8390 - mape: 9.3942 - val_loss: 6.0222 - val_mae: 9.6553 - val_mape: 5.7940 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.9494 - mae: 23.5370 - mape: 9.7215 - val_loss: 6.1657 - val_mae: 10.0050 - val_mape: 5.9381 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.7545 - mae: 20.0028 - mape: 9.5273"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 103ms/step - loss: 9.7545 - mae: 20.0028 - mape: 9.5273 - val_loss: 5.9556 - val_mae: 8.9608 - val_mape: 5.7290 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.6795 - mae: 22.8984 - mape: 9.4534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 102ms/step - loss: 9.6795 - mae: 22.8984 - mape: 9.4534 - val_loss: 5.9368 - val_mae: 8.9493 - val_mape: 5.7111 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 86ms/step - loss: 9.7508 - mae: 23.4757 - mape: 9.5256 - val_loss: 6.1894 - val_mae: 10.0780 - val_mape: 5.9648 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.5863 - mae: 22.6997 - mape: 9.3620 - val_loss: 5.9430 - val_mae: 9.3707 - val_mape: 5.7189 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6739 - mae: 22.7147 - mape: 9.4499 - val_loss: 6.2757 - val_mae: 11.8534 - val_mape: 6.0519 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7121 - mae: 19.8442 - mape: 9.4887 - val_loss: 6.6323 - val_mae: 17.3892 - val_mape: 6.4094 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6899 - mae: 22.0495 - mape: 9.4673 - val_loss: 6.0169 - val_mae: 9.5126 - val_mape: 5.7944 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7863 - mae: 21.0104 - mape: 9.5642 - val_loss: 6.1640 - val_mae: 13.4174 - val_mape: 5.9423 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6795 - mae: 22.6597 - mape: 9.4581 - val_loss: 6.0648 - val_mae: 9.2553 - val_mape: 5.8438 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7346 - mae: 22.0916 - mape: 9.5138 - val_loss: 6.3444 - val_mae: 12.3000 - val_mape: 6.1238 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.6905 - mae: 21.6332 - mape: 9.4700 - val_loss: 6.2118 - val_mae: 9.4680 - val_mape: 5.9917 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7402 - mae: 22.2635 - mape: 9.5206 - val_loss: 6.1344 - val_mae: 10.4157 - val_mape: 5.9149 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6811 - mae: 23.2843 - mape: 9.4622 - val_loss: 6.1113 - val_mae: 9.6227 - val_mape: 5.8929 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6607 - mae: 20.2367 - mape: 9.4426 - val_loss: 6.1783 - val_mae: 9.1796 - val_mape: 5.9606 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.6526 - mae: 22.0457 - mape: 9.4351 - val_loss: 6.0668 - val_mae: 9.7654 - val_mape: 5.8495 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 87ms/step - loss: 9.6279 - mae: 21.5082 - mape: 9.4109 - val_loss: 5.9855 - val_mae: 9.0306 - val_mape: 5.7690 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.8224 - mae: 22.0713 - mape: 9.6062 - val_loss: 6.0898 - val_mae: 9.2778 - val_mape: 5.8738 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7008 - mae: 22.0777 - mape: 9.4853 - val_loss: 6.3163 - val_mae: 12.7671 - val_mape: 6.1011 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6381 - mae: 23.5583 - mape: 9.4233 - val_loss: 6.0909 - val_mae: 9.7222 - val_mape: 5.8762 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5880 - mae: 21.7667 - mape: 9.3737 - val_loss: 6.0378 - val_mae: 10.4276 - val_mape: 5.8239 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5918 - mae: 21.1125 - mape: 9.3781 - val_loss: 6.0477 - val_mae: 9.2599 - val_mape: 5.8340 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7070 - mae: 22.9408 - mape: 9.4938 - val_loss: 6.1189 - val_mae: 9.1765 - val_mape: 5.9061 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7968 - mae: 23.4906 - mape: 9.5844 - val_loss: 6.0098 - val_mae: 9.6806 - val_mape: 5.7976 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6271 - mae: 23.5534 - mape: 9.4151 - val_loss: 6.1395 - val_mae: 10.7548 - val_mape: 5.9276 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.9159 - mae: 21.5979 - mape: 9.7045 - val_loss: 6.0657 - val_mae: 11.3015 - val_mape: 5.8548 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5276 - mae: 22.1385 - mape: 9.3169 - val_loss: 6.2485 - val_mae: 9.8178 - val_mape: 6.0381 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7965 - mae: 21.1798 - mape: 9.5862 - val_loss: 6.3109 - val_mae: 10.8703 - val_mape: 6.1009 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8011 - mae: 23.6120 - mape: 9.5914 - val_loss: 6.3224 - val_mae: 11.8818 - val_mape: 6.1130 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6854 - mae: 20.4032 - mape: 9.4763 - val_loss: 6.5609 - val_mae: 20.0095 - val_mape: 6.3521 - lr: 1.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.6493 - mae: 22.0896 - mape: 9.4407 - val_loss: 6.2543 - val_mae: 10.0089 - val_mape: 6.0460 - lr: 1.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.8337 - mae: 22.7207 - mape: 9.6257 - val_loss: 6.2485 - val_mae: 9.8647 - val_mape: 6.0409 - lr: 1.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.8318 - mae: 22.7978 - mape: 9.6244\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8318 - mae: 22.7978 - mape: 9.6244 - val_loss: 6.2125 - val_mae: 11.4643 - val_mape: 6.0052 - lr: 1.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.6710 - mae: 20.0122 - mape: 9.4639 - val_loss: 6.1043 - val_mae: 9.2923 - val_mape: 5.8972 - lr: 3.0000e-05\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4299 - mae: 22.5308 - mape: 9.2228 - val_loss: 6.1631 - val_mae: 9.6761 - val_mape: 5.9562 - lr: 3.0000e-05\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.5974 - mae: 21.7086 - mape: 9.3906 - val_loss: 6.0465 - val_mae: 9.2410 - val_mape: 5.8398 - lr: 3.0000e-05\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7286 - mae: 23.1189 - mape: 9.5219 - val_loss: 6.2370 - val_mae: 11.8110 - val_mape: 6.0304 - lr: 3.0000e-05\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7257 - mae: 21.2244 - mape: 9.5191 - val_loss: 6.0990 - val_mae: 9.2781 - val_mape: 5.8925 - lr: 3.0000e-05\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8437 - mae: 22.4446 - mape: 9.6373 - val_loss: 6.1600 - val_mae: 11.2886 - val_mape: 5.9536 - lr: 3.0000e-05\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.5637 - mae: 22.4107 - mape: 9.3574 - val_loss: 6.3167 - val_mae: 11.0037 - val_mape: 6.1106 - lr: 3.0000e-05\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7041 - mae: 21.4626 - mape: 9.4980 - val_loss: 6.1397 - val_mae: 9.3631 - val_mape: 5.9336 - lr: 3.0000e-05\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5726 - mae: 21.2176 - mape: 9.3665 - val_loss: 6.1504 - val_mae: 10.3166 - val_mape: 5.9444 - lr: 3.0000e-05\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.7004 - mae: 21.2920 - mape: 9.4945 - val_loss: 6.1121 - val_mae: 9.6860 - val_mape: 5.9061 - lr: 3.0000e-05\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.8450 - mae: 23.4151 - mape: 9.6392 - val_loss: 6.0933 - val_mae: 9.2116 - val_mape: 5.8875 - lr: 3.0000e-05\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.4554 - mae: 20.3759 - mape: 9.2498 - val_loss: 6.2680 - val_mae: 9.9246 - val_mape: 6.0624 - lr: 3.0000e-05\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.7080 - mae: 22.6635 - mape: 9.5025 - val_loss: 6.1591 - val_mae: 9.6924 - val_mape: 5.9536 - lr: 3.0000e-05\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6414 - mae: 23.2202 - mape: 9.4360 - val_loss: 6.0716 - val_mae: 9.0949 - val_mape: 5.8662 - lr: 3.0000e-05\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6694 - mae: 21.8423 - mape: 9.4640 - val_loss: 6.0475 - val_mae: 8.9488 - val_mape: 5.8422 - lr: 3.0000e-05\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.3293 - mae: 20.3301 - mape: 9.1240 - val_loss: 6.0892 - val_mae: 9.0841 - val_mape: 5.8840 - lr: 3.0000e-05\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.3347 - mae: 19.7385 - mape: 9.1296 - val_loss: 6.1696 - val_mae: 10.4927 - val_mape: 5.9646 - lr: 3.0000e-05\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 9.5135 - mae: 20.8784 - mape: 9.3085 - val_loss: 6.1399 - val_mae: 10.2228 - val_mape: 5.9349 - lr: 3.0000e-05\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 8s 96ms/step - loss: 9.4769 - mae: 22.2591 - mape: 9.2720 - val_loss: 6.1933 - val_mae: 9.5902 - val_mape: 5.9884 - lr: 3.0000e-05\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.7350 - mae: 25.6629 - mape: 9.5302 - val_loss: 6.4012 - val_mae: 10.0374 - val_mape: 6.1966 - lr: 3.0000e-05\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8288 - mae: 22.5686 - mape: 9.6242 - val_loss: 6.1357 - val_mae: 9.2741 - val_mape: 5.9312 - lr: 3.0000e-05\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.7210 - mae: 23.9182 - mape: 9.5165 - val_loss: 6.3143 - val_mae: 12.2423 - val_mape: 6.1098 - lr: 3.0000e-05\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 9.7807 - mae: 22.4978 - mape: 9.5763 - val_loss: 6.1344 - val_mae: 9.3565 - val_mape: 5.9301 - lr: 3.0000e-05\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5566 - mae: 21.8788 - mape: 9.3522 - val_loss: 6.1723 - val_mae: 10.0378 - val_mape: 5.9681 - lr: 3.0000e-05\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4113 - mae: 20.7299 - mape: 9.2071 - val_loss: 6.2010 - val_mae: 11.5490 - val_mape: 5.9968 - lr: 3.0000e-05\n",
      "Epoch 70/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6251 - mae: 23.7655 - mape: 9.4209 - val_loss: 6.1554 - val_mae: 9.9743 - val_mape: 5.9514 - lr: 3.0000e-05\n",
      "Epoch 71/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.4315 - mae: 22.0059 - mape: 9.2276 - val_loss: 6.1948 - val_mae: 9.9852 - val_mape: 5.9909 - lr: 3.0000e-05\n",
      "Epoch 72/1000\n",
      "87/87 [==============================] - 8s 92ms/step - loss: 9.5082 - mae: 22.4204 - mape: 9.3044 - val_loss: 6.1792 - val_mae: 9.6064 - val_mape: 5.9755 - lr: 3.0000e-05\n",
      "Epoch 73/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.7028 - mae: 21.6611 - mape: 9.4992 - val_loss: 6.1233 - val_mae: 9.4143 - val_mape: 5.9196 - lr: 3.0000e-05\n",
      "Epoch 74/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6538 - mae: 20.6004 - mape: 9.4502\n",
      "Epoch 74: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6538 - mae: 20.6004 - mape: 9.4502 - val_loss: 6.0803 - val_mae: 9.0771 - val_mape: 5.8767 - lr: 3.0000e-05\n",
      "Epoch 74: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 2: loss of 5.936761856079102; mae of 8.949280738830566; mape of 5.711127758026123%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n",
      " 1/87 [..............................] - ETA: 1:07 - loss: 8.5020 - mae: 9.1713 - mape: 8.2984"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.5963 - mae: 24.0628 - mape: 9.3929"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 100ms/step - loss: 9.5963 - mae: 24.0628 - mape: 9.3929 - val_loss: 6.5257 - val_mae: 8.3881 - val_mape: 6.3226 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.9097 - mae: 25.4241 - mape: 9.7071"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 103ms/step - loss: 9.9097 - mae: 25.4241 - mape: 9.7071 - val_loss: 6.3814 - val_mae: 8.2329 - val_mape: 6.1791 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 87ms/step - loss: 9.5894 - mae: 24.6599 - mape: 9.3873 - val_loss: 6.4382 - val_mae: 8.2095 - val_mape: 6.2366 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.7018 - mae: 22.9158 - mape: 9.5003"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 102ms/step - loss: 9.7018 - mae: 22.9158 - mape: 9.5003 - val_loss: 6.3560 - val_mae: 8.0001 - val_mape: 6.1545 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 86ms/step - loss: 9.5675 - mae: 22.3999 - mape: 9.3663 - val_loss: 6.5532 - val_mae: 8.9060 - val_mape: 6.3523 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4965 - mae: 21.8769 - mape: 9.2959 - val_loss: 6.4900 - val_mae: 8.2880 - val_mape: 6.2899 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.6596 - mae: 23.6187 - mape: 9.4595 - val_loss: 6.4715 - val_mae: 8.8839 - val_mape: 6.2716 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6660 - mae: 23.8144 - mape: 9.4665 - val_loss: 6.4650 - val_mae: 8.1861 - val_mape: 6.2656 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5059 - mae: 22.4057 - mape: 9.3069 - val_loss: 6.3537 - val_mae: 8.4214 - val_mape: 6.1549 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4815 - mae: 22.9464 - mape: 9.2832 - val_loss: 6.3526 - val_mae: 8.2293 - val_mape: 6.1546 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6384 - mae: 25.4408 - mape: 9.4405 - val_loss: 6.4827 - val_mae: 8.4918 - val_mape: 6.2850 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.9565 - mae: 24.0352 - mape: 9.7592 - val_loss: 6.5847 - val_mae: 11.1241 - val_mape: 6.3874 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5600 - mae: 22.1834 - mape: 9.3627 - val_loss: 6.4996 - val_mae: 8.8619 - val_mape: 6.3024 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6408 - mae: 24.6917 - mape: 9.4436 - val_loss: 6.5324 - val_mae: 8.4520 - val_mape: 6.3352 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6999 - mae: 24.7059 - mape: 9.5032 - val_loss: 6.7813 - val_mae: 9.5516 - val_mape: 6.5849 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.6218 - mae: 20.6780 - mape: 9.4255 - val_loss: 6.4991 - val_mae: 8.5263 - val_mape: 6.3029 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7377 - mae: 23.1493 - mape: 9.5419 - val_loss: 6.4761 - val_mae: 8.4049 - val_mape: 6.2805 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7145 - mae: 24.2715 - mape: 9.5188 - val_loss: 6.5706 - val_mae: 8.3864 - val_mape: 6.3751 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6915 - mae: 23.0590 - mape: 9.4962 - val_loss: 6.5942 - val_mae: 9.9674 - val_mape: 6.3988 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7005 - mae: 23.9087 - mape: 9.5053 - val_loss: 6.4376 - val_mae: 8.4057 - val_mape: 6.2427 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6163 - mae: 23.6229 - mape: 9.4216 - val_loss: 6.8186 - val_mae: 11.6841 - val_mape: 6.6244 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5454 - mae: 23.1686 - mape: 9.3514 - val_loss: 6.5040 - val_mae: 8.4809 - val_mape: 6.3102 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.4547 - mae: 21.9721 - mape: 9.2611 - val_loss: 6.4696 - val_mae: 9.7414 - val_mape: 6.2759 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6277 - mae: 22.6222 - mape: 9.4344 - val_loss: 6.6062 - val_mae: 8.6357 - val_mape: 6.4131 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7082 - mae: 23.6064 - mape: 9.5152 - val_loss: 6.5087 - val_mae: 8.0797 - val_mape: 6.3158 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4764 - mae: 22.2892 - mape: 9.2840 - val_loss: 6.4684 - val_mae: 8.6395 - val_mape: 6.2766 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7632 - mae: 22.8791 - mape: 9.5713 - val_loss: 6.5845 - val_mae: 10.5341 - val_mape: 6.3926 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.6741 - mae: 22.2833 - mape: 9.4825 - val_loss: 6.5045 - val_mae: 8.1051 - val_mape: 6.3131 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.3425 - mae: 23.5487 - mape: 9.1515 - val_loss: 6.7100 - val_mae: 9.2412 - val_mape: 6.5192 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7754 - mae: 23.7099 - mape: 9.5847 - val_loss: 6.7066 - val_mae: 8.4696 - val_mape: 6.5164 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4813 - mae: 22.7754 - mape: 9.2911 - val_loss: 6.5194 - val_mae: 8.4394 - val_mape: 6.3295 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5262 - mae: 23.0722 - mape: 9.3366 - val_loss: 6.6965 - val_mae: 8.3803 - val_mape: 6.5070 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4893 - mae: 22.5804 - mape: 9.2997 - val_loss: 6.4921 - val_mae: 10.6916 - val_mape: 6.3027 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6889 - mae: 23.0953 - mape: 9.4998 - val_loss: 6.6611 - val_mae: 9.2446 - val_mape: 6.4722 - lr: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3842 - mae: 22.9265 - mape: 9.1955 - val_loss: 6.6101 - val_mae: 8.6477 - val_mape: 6.4215 - lr: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5092 - mae: 23.1394 - mape: 9.3208 - val_loss: 6.4951 - val_mae: 8.5033 - val_mape: 6.3068 - lr: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7847 - mae: 23.1820 - mape: 9.5969 - val_loss: 6.5295 - val_mae: 8.9626 - val_mape: 6.3419 - lr: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.6231 - mae: 24.9935 - mape: 9.4357 - val_loss: 6.8657 - val_mae: 10.5331 - val_mape: 6.6787 - lr: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3856 - mae: 21.7023 - mape: 9.1985 - val_loss: 6.7037 - val_mae: 8.6704 - val_mape: 6.5168 - lr: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.7596 - mae: 22.4828 - mape: 9.5728\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7596 - mae: 22.4828 - mape: 9.5728 - val_loss: 6.4783 - val_mae: 8.4485 - val_mape: 6.2919 - lr: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5550 - mae: 24.4100 - mape: 9.3687 - val_loss: 6.5413 - val_mae: 8.3426 - val_mape: 6.3550 - lr: 3.0000e-05\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5030 - mae: 23.6524 - mape: 9.3167 - val_loss: 6.5070 - val_mae: 8.2129 - val_mape: 6.3207 - lr: 3.0000e-05\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7118 - mae: 22.6517 - mape: 9.5255 - val_loss: 6.7297 - val_mae: 9.0395 - val_mape: 6.5436 - lr: 3.0000e-05\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5102 - mae: 22.7073 - mape: 9.3240 - val_loss: 6.8653 - val_mae: 10.8117 - val_mape: 6.6792 - lr: 3.0000e-05\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.5030 - mae: 22.0470 - mape: 9.3169 - val_loss: 6.5593 - val_mae: 8.6198 - val_mape: 6.3733 - lr: 3.0000e-05\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3429 - mae: 23.1719 - mape: 9.1569 - val_loss: 6.5329 - val_mae: 8.3657 - val_mape: 6.3469 - lr: 3.0000e-05\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.5734 - mae: 27.2660 - mape: 9.3875 - val_loss: 6.6010 - val_mae: 8.9852 - val_mape: 6.4150 - lr: 3.0000e-05\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.3284 - mae: 22.7264 - mape: 9.1425 - val_loss: 6.5002 - val_mae: 8.3832 - val_mape: 6.3143 - lr: 3.0000e-05\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4378 - mae: 23.0429 - mape: 9.2520 - val_loss: 6.5823 - val_mae: 8.5238 - val_mape: 6.3966 - lr: 3.0000e-05\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4141 - mae: 24.6071 - mape: 9.2283 - val_loss: 6.5218 - val_mae: 8.2534 - val_mape: 6.3360 - lr: 3.0000e-05\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.4577 - mae: 23.1850 - mape: 9.2719 - val_loss: 6.7559 - val_mae: 9.6558 - val_mape: 6.5702 - lr: 3.0000e-05\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5472 - mae: 24.1027 - mape: 9.3615 - val_loss: 6.5037 - val_mae: 8.1302 - val_mape: 6.3180 - lr: 3.0000e-05\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6864 - mae: 22.4333 - mape: 9.5007 - val_loss: 6.4651 - val_mae: 8.1583 - val_mape: 6.2793 - lr: 3.0000e-05\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.2805 - mae: 22.1850 - mape: 9.0949 - val_loss: 6.5706 - val_mae: 8.2858 - val_mape: 6.3850 - lr: 3.0000e-05\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4005 - mae: 23.7724 - mape: 9.2149 - val_loss: 6.5882 - val_mae: 8.6110 - val_mape: 6.4027 - lr: 3.0000e-05\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6286 - mae: 25.0179 - mape: 9.4432 - val_loss: 6.5602 - val_mae: 8.5008 - val_mape: 6.3748 - lr: 3.0000e-05\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4576 - mae: 23.0348 - mape: 9.2723 - val_loss: 6.5895 - val_mae: 8.4657 - val_mape: 6.4041 - lr: 3.0000e-05\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.4190 - mae: 24.5341 - mape: 9.2336 - val_loss: 6.6159 - val_mae: 8.5455 - val_mape: 6.4305 - lr: 3.0000e-05\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.3939 - mae: 22.2793 - mape: 9.2085 - val_loss: 6.6759 - val_mae: 8.5065 - val_mape: 6.4907 - lr: 3.0000e-05\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.3718 - mae: 23.2385 - mape: 9.1865 - val_loss: 6.5540 - val_mae: 8.2677 - val_mape: 6.3686 - lr: 3.0000e-05\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.4007 - mae: 22.0222 - mape: 9.2154 - val_loss: 6.6854 - val_mae: 8.7344 - val_mape: 6.5001 - lr: 3.0000e-05\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4960 - mae: 23.0624 - mape: 9.3108 - val_loss: 6.6167 - val_mae: 8.7962 - val_mape: 6.4314 - lr: 3.0000e-05\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.5290 - mae: 22.3119 - mape: 9.3438 - val_loss: 6.4768 - val_mae: 8.1635 - val_mape: 6.2916 - lr: 3.0000e-05\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6444 - mae: 22.7081 - mape: 9.4593 - val_loss: 6.6413 - val_mae: 8.5225 - val_mape: 6.4563 - lr: 3.0000e-05\n",
      "Epoch 65/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6118 - mae: 22.2911 - mape: 9.4268 - val_loss: 6.5206 - val_mae: 8.2406 - val_mape: 6.3356 - lr: 3.0000e-05\n",
      "Epoch 66/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6198 - mae: 23.3036 - mape: 9.4348 - val_loss: 6.5936 - val_mae: 8.1812 - val_mape: 6.4086 - lr: 3.0000e-05\n",
      "Epoch 67/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6446 - mae: 22.8555 - mape: 9.4597 - val_loss: 6.5400 - val_mae: 8.2206 - val_mape: 6.3551 - lr: 3.0000e-05\n",
      "Epoch 68/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6135 - mae: 22.5004 - mape: 9.4287 - val_loss: 6.6482 - val_mae: 8.4350 - val_mape: 6.4635 - lr: 3.0000e-05\n",
      "Epoch 69/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.3138 - mae: 19.4219 - mape: 9.1291 - val_loss: 6.5867 - val_mae: 8.5155 - val_mape: 6.4020 - lr: 3.0000e-05\n",
      "Epoch 70/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 9.4985 - mae: 22.6674 - mape: 9.3139\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5023 - mae: 22.5810 - mape: 9.3177 - val_loss: 6.5208 - val_mae: 8.0108 - val_mape: 6.3362 - lr: 3.0000e-05\n",
      "Epoch 70: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 3: loss of 6.355964183807373; mae of 8.000141143798828; mape of 6.154524326324463%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.8593 - mae: 23.8497 - mape: 9.6749"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 97ms/step - loss: 9.8593 - mae: 23.8497 - mape: 9.6749 - val_loss: 5.6745 - val_mae: 10.2101 - val_mape: 5.4903 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86/87 [============================>.] - ETA: 0s - loss: 9.6728 - mae: 21.0728 - mape: 9.4888"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 99ms/step - loss: 9.6557 - mae: 21.2691 - mape: 9.4717 - val_loss: 5.3290 - val_mae: 9.7846 - val_mape: 5.1450 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 87ms/step - loss: 9.8188 - mae: 20.8249 - mape: 9.6350 - val_loss: 5.3500 - val_mae: 11.1475 - val_mape: 5.1662 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.8235 - mae: 20.4075 - mape: 9.6398 - val_loss: 5.6212 - val_mae: 16.9902 - val_mape: 5.4377 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7225 - mae: 21.8590 - mape: 9.5394 - val_loss: 5.5193 - val_mae: 13.7720 - val_mape: 5.3363 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.8489 - mae: 22.2498 - mape: 9.6661 - val_loss: 5.5433 - val_mae: 11.6838 - val_mape: 5.3609 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6479 - mae: 21.6440 - mape: 9.4656 - val_loss: 5.5303 - val_mae: 13.7450 - val_mape: 5.3481 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7399 - mae: 22.4620 - mape: 9.5578 - val_loss: 5.3427 - val_mae: 9.6772 - val_mape: 5.1605 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7114 - mae: 22.0738 - mape: 9.5293 - val_loss: 5.4962 - val_mae: 15.4095 - val_mape: 5.3140 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6977 - mae: 23.0003 - mape: 9.5159 - val_loss: 5.3876 - val_mae: 9.1949 - val_mape: 5.2062 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6147 - mae: 19.8410 - mape: 9.4332 - val_loss: 5.7176 - val_mae: 16.6554 - val_mape: 5.5362 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7601 - mae: 23.4531 - mape: 9.5787 - val_loss: 5.4429 - val_mae: 12.7922 - val_mape: 5.2614 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4456 - mae: 22.1826 - mape: 9.2644 - val_loss: 5.5526 - val_mae: 13.0588 - val_mape: 5.3716 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5932 - mae: 20.3035 - mape: 9.4124 - val_loss: 5.3797 - val_mae: 10.2787 - val_mape: 5.1993 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6136 - mae: 21.4031 - mape: 9.4335 - val_loss: 5.6746 - val_mae: 13.5256 - val_mape: 5.4947 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5694 - mae: 20.9242 - mape: 9.3893 - val_loss: 6.2747 - val_mae: 20.3970 - val_mape: 6.0948 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.7499 - mae: 22.7119 - mape: 9.5701 - val_loss: 5.4352 - val_mae: 9.5048 - val_mape: 5.2555 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6495 - mae: 21.9042 - mape: 9.4703 - val_loss: 5.6552 - val_mae: 13.3545 - val_mape: 5.4763 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6945 - mae: 22.2841 - mape: 9.5158 - val_loss: 5.4470 - val_mae: 10.9775 - val_mape: 5.2684 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.9240 - mae: 22.7704 - mape: 9.7455 - val_loss: 5.4407 - val_mae: 10.0258 - val_mape: 5.2622 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5869 - mae: 22.4622 - mape: 9.4088 - val_loss: 6.0731 - val_mae: 19.8313 - val_mape: 5.8954 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5947 - mae: 21.3942 - mape: 9.4171 - val_loss: 5.4374 - val_mae: 10.1573 - val_mape: 5.2599 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7097 - mae: 21.0775 - mape: 9.5325 - val_loss: 5.4803 - val_mae: 13.8421 - val_mape: 5.3032 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.8194 - mae: 20.1273 - mape: 9.6423 - val_loss: 5.5533 - val_mae: 16.4088 - val_mape: 5.3763 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6156 - mae: 20.5958 - mape: 9.4387 - val_loss: 5.5357 - val_mae: 12.2679 - val_mape: 5.3590 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6678 - mae: 22.3111 - mape: 9.4912 - val_loss: 5.3815 - val_mae: 10.0662 - val_mape: 5.2048 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7102 - mae: 21.5936 - mape: 9.5337 - val_loss: 5.5788 - val_mae: 10.2650 - val_mape: 5.4023 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.5978 - mae: 19.9541 - mape: 9.4213 - val_loss: 5.5463 - val_mae: 11.4815 - val_mape: 5.3699 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7772 - mae: 20.5979 - mape: 9.6011 - val_loss: 5.4219 - val_mae: 9.2671 - val_mape: 5.2461 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 8s 88ms/step - loss: 9.9259 - mae: 23.1073 - mape: 9.7501 - val_loss: 5.5087 - val_mae: 10.7356 - val_mape: 5.3329 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5662 - mae: 19.1566 - mape: 9.3905 - val_loss: 5.4007 - val_mae: 9.2157 - val_mape: 5.2249 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6427 - mae: 20.3693 - mape: 9.4670\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6427 - mae: 20.3693 - mape: 9.4670 - val_loss: 5.3471 - val_mae: 9.3201 - val_mape: 5.1715 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5531 - mae: 21.1429 - mape: 9.3777 - val_loss: 5.6386 - val_mae: 12.3080 - val_mape: 5.4633 - lr: 3.0000e-05\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.7048 - mae: 19.5109 - mape: 9.5294 - val_loss: 5.5116 - val_mae: 10.3955 - val_mape: 5.3363 - lr: 3.0000e-05\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5963 - mae: 22.3772 - mape: 9.4210 - val_loss: 5.4581 - val_mae: 10.4892 - val_mape: 5.2829 - lr: 3.0000e-05\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.4082 - mae: 20.1616 - mape: 9.2330 - val_loss: 5.4724 - val_mae: 10.0789 - val_mape: 5.2973 - lr: 3.0000e-05\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6649 - mae: 20.7068 - mape: 9.4898 - val_loss: 5.4377 - val_mae: 9.7142 - val_mape: 5.2627 - lr: 3.0000e-05\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.4606 - mae: 18.7537 - mape: 9.2855 - val_loss: 5.4897 - val_mae: 9.6651 - val_mape: 5.3147 - lr: 3.0000e-05\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.5634 - mae: 21.0260 - mape: 9.3884 - val_loss: 5.6444 - val_mae: 13.5509 - val_mape: 5.4694 - lr: 3.0000e-05\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6959 - mae: 19.7614 - mape: 9.5209 - val_loss: 5.5246 - val_mae: 12.9049 - val_mape: 5.3496 - lr: 3.0000e-05\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4775 - mae: 20.7706 - mape: 9.3027 - val_loss: 5.4283 - val_mae: 9.4542 - val_mape: 5.2535 - lr: 3.0000e-05\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.6950 - mae: 21.2162 - mape: 9.5203 - val_loss: 5.4810 - val_mae: 9.4506 - val_mape: 5.3063 - lr: 3.0000e-05\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5232 - mae: 20.8456 - mape: 9.3486 - val_loss: 5.4576 - val_mae: 12.3271 - val_mape: 5.2829 - lr: 3.0000e-05\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.6700 - mae: 21.7019 - mape: 9.4954 - val_loss: 5.5111 - val_mae: 12.9243 - val_mape: 5.3365 - lr: 3.0000e-05\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5803 - mae: 20.0672 - mape: 9.4058 - val_loss: 5.3731 - val_mae: 10.1074 - val_mape: 5.1986 - lr: 3.0000e-05\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8638 - mae: 21.9777 - mape: 9.6894 - val_loss: 5.5183 - val_mae: 11.4532 - val_mape: 5.3439 - lr: 3.0000e-05\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6345 - mae: 19.4018 - mape: 9.4601 - val_loss: 5.3820 - val_mae: 9.7031 - val_mape: 5.2076 - lr: 3.0000e-05\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 82ms/step - loss: 9.7048 - mae: 21.7254 - mape: 9.5305 - val_loss: 5.4452 - val_mae: 10.1767 - val_mape: 5.2709 - lr: 3.0000e-05\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5744 - mae: 22.7685 - mape: 9.4002 - val_loss: 5.4640 - val_mae: 11.5169 - val_mape: 5.2898 - lr: 3.0000e-05\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6183 - mae: 21.4388 - mape: 9.4442 - val_loss: 5.4901 - val_mae: 11.5964 - val_mape: 5.3160 - lr: 3.0000e-05\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6442 - mae: 21.7678 - mape: 9.4701 - val_loss: 5.4009 - val_mae: 9.8249 - val_mape: 5.2268 - lr: 3.0000e-05\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5922 - mae: 20.2249 - mape: 9.4181 - val_loss: 5.5821 - val_mae: 13.3025 - val_mape: 5.4080 - lr: 3.0000e-05\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5324 - mae: 21.0748 - mape: 9.3584 - val_loss: 5.7048 - val_mae: 15.0569 - val_mape: 5.5308 - lr: 3.0000e-05\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4969 - mae: 21.9247 - mape: 9.3229 - val_loss: 5.6307 - val_mae: 14.9770 - val_mape: 5.4567 - lr: 3.0000e-05\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5339 - mae: 21.1140 - mape: 9.3599 - val_loss: 5.4864 - val_mae: 12.6515 - val_mape: 5.3124 - lr: 3.0000e-05\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7723 - mae: 21.8761 - mape: 9.5985 - val_loss: 5.7035 - val_mae: 15.4643 - val_mape: 5.5297 - lr: 3.0000e-05\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6548 - mae: 21.1669 - mape: 9.4811 - val_loss: 5.4323 - val_mae: 10.1443 - val_mape: 5.2585 - lr: 3.0000e-05\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4971 - mae: 20.9637 - mape: 9.3232 - val_loss: 5.4094 - val_mae: 9.9368 - val_mape: 5.2355 - lr: 3.0000e-05\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6026 - mae: 23.0245 - mape: 9.4288 - val_loss: 5.5797 - val_mae: 11.3639 - val_mape: 5.4060 - lr: 3.0000e-05\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.7587 - mae: 21.0486 - mape: 9.5850 - val_loss: 5.5805 - val_mae: 12.6848 - val_mape: 5.4068 - lr: 3.0000e-05\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7882 - mae: 22.4739 - mape: 9.6145 - val_loss: 5.6171 - val_mae: 14.2608 - val_mape: 5.4434 - lr: 3.0000e-05\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6997 - mae: 21.0040 - mape: 9.5260\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6997 - mae: 21.0040 - mape: 9.5260 - val_loss: 5.4476 - val_mae: 11.8347 - val_mape: 5.2739 - lr: 3.0000e-05\n",
      "Epoch 62: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 4: loss of 5.329043388366699; mae of 9.784645080566406; mape of 5.144991397857666%;\n",
      "Getting split...\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n",
      " 1/87 [..............................] - ETA: 1:06 - loss: 9.8243 - mae: 20.1171 - mape: 9.6506"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.6691 - mae: 24.2564 - mape: 9.4956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 94ms/step - loss: 9.6691 - mae: 24.2564 - mape: 9.4956 - val_loss: 6.0958 - val_mae: 8.8886 - val_mape: 5.9225 - lr: 1.0000e-04\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.5856 - mae: 21.3464 - mape: 9.4124"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 104ms/step - loss: 9.5856 - mae: 21.3464 - mape: 9.4124 - val_loss: 5.8274 - val_mae: 8.1247 - val_mape: 5.6544 - lr: 1.0000e-04\n",
      "Epoch 3/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - ETA: 0s - loss: 9.6908 - mae: 24.5688 - mape: 9.5176"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_5 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Hybrid_additional_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 9s 103ms/step - loss: 9.6908 - mae: 24.5688 - mape: 9.5176 - val_loss: 5.7650 - val_mae: 7.8042 - val_mape: 5.5919 - lr: 1.0000e-04\n",
      "Epoch 4/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 8s 87ms/step - loss: 9.6840 - mae: 22.4652 - mape: 9.5111 - val_loss: 5.9303 - val_mae: 9.6683 - val_mape: 5.7574 - lr: 1.0000e-04\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6447 - mae: 22.9924 - mape: 9.4719 - val_loss: 5.7725 - val_mae: 8.0521 - val_mape: 5.5998 - lr: 1.0000e-04\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5247 - mae: 23.5354 - mape: 9.3520 - val_loss: 5.9645 - val_mae: 8.0851 - val_mape: 5.7918 - lr: 1.0000e-04\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.2385 - mae: 22.2028 - mape: 9.0660 - val_loss: 5.8137 - val_mae: 9.0237 - val_mape: 5.6411 - lr: 1.0000e-04\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6339 - mae: 22.1864 - mape: 9.4616 - val_loss: 5.7970 - val_mae: 9.1589 - val_mape: 5.6248 - lr: 1.0000e-04\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6243 - mae: 21.7042 - mape: 9.4525 - val_loss: 5.8084 - val_mae: 7.9213 - val_mape: 5.6367 - lr: 1.0000e-04\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.3729 - mae: 20.5766 - mape: 9.2013 - val_loss: 5.9196 - val_mae: 9.5295 - val_mape: 5.7484 - lr: 1.0000e-04\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5030 - mae: 23.3275 - mape: 9.3317 - val_loss: 6.3604 - val_mae: 12.1504 - val_mape: 6.1892 - lr: 1.0000e-04\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5142 - mae: 22.5218 - mape: 9.3433 - val_loss: 5.9865 - val_mae: 9.3333 - val_mape: 5.8157 - lr: 1.0000e-04\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7785 - mae: 23.9639 - mape: 9.6079 - val_loss: 5.8897 - val_mae: 8.4702 - val_mape: 5.7191 - lr: 1.0000e-04\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8858 - mae: 23.5097 - mape: 9.7151 - val_loss: 5.9340 - val_mae: 9.6984 - val_mape: 5.7634 - lr: 1.0000e-04\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.4263 - mae: 21.6191 - mape: 9.2558 - val_loss: 5.9754 - val_mae: 8.4801 - val_mape: 5.8051 - lr: 1.0000e-04\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6068 - mae: 21.9293 - mape: 9.4366 - val_loss: 5.8817 - val_mae: 9.6276 - val_mape: 5.7119 - lr: 1.0000e-04\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7442 - mae: 25.1722 - mape: 9.5745 - val_loss: 5.9887 - val_mae: 9.0524 - val_mape: 5.8191 - lr: 1.0000e-04\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6297 - mae: 22.6074 - mape: 9.4604 - val_loss: 5.9886 - val_mae: 8.8786 - val_mape: 5.8196 - lr: 1.0000e-04\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.2634 - mae: 21.6733 - mape: 9.0944 - val_loss: 6.2179 - val_mae: 10.2690 - val_mape: 6.0491 - lr: 1.0000e-04\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.6882 - mae: 22.8196 - mape: 9.5195 - val_loss: 5.9413 - val_mae: 9.8716 - val_mape: 5.7727 - lr: 1.0000e-04\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5939 - mae: 23.1233 - mape: 9.4253 - val_loss: 5.9769 - val_mae: 9.4479 - val_mape: 5.8083 - lr: 1.0000e-04\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5550 - mae: 22.8896 - mape: 9.3865 - val_loss: 5.9379 - val_mae: 8.3896 - val_mape: 5.7695 - lr: 1.0000e-04\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6621 - mae: 22.9787 - mape: 9.4938 - val_loss: 6.0231 - val_mae: 11.6372 - val_mape: 5.8549 - lr: 1.0000e-04\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.4767 - mae: 20.4170 - mape: 9.3087 - val_loss: 5.9121 - val_mae: 8.4628 - val_mape: 5.7442 - lr: 1.0000e-04\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.3573 - mae: 23.7705 - mape: 9.1895 - val_loss: 6.0714 - val_mae: 9.0346 - val_mape: 5.9037 - lr: 1.0000e-04\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6434 - mae: 21.4865 - mape: 9.4757 - val_loss: 6.1522 - val_mae: 9.3215 - val_mape: 5.9845 - lr: 1.0000e-04\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6744 - mae: 24.5436 - mape: 9.5068 - val_loss: 5.9933 - val_mae: 8.8144 - val_mape: 5.8257 - lr: 1.0000e-04\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.8533 - mae: 22.7813 - mape: 9.6858 - val_loss: 6.7270 - val_mae: 14.1027 - val_mape: 6.5599 - lr: 1.0000e-04\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.8447 - mae: 23.6759 - mape: 9.6776 - val_loss: 6.3980 - val_mae: 11.5611 - val_mape: 6.2310 - lr: 1.0000e-04\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6840 - mae: 21.6283 - mape: 9.5170 - val_loss: 6.1770 - val_mae: 8.7055 - val_mape: 6.0103 - lr: 1.0000e-04\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.5159 - mae: 22.6654 - mape: 9.3493 - val_loss: 5.9210 - val_mae: 8.3290 - val_mape: 5.7545 - lr: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5489 - mae: 22.7287 - mape: 9.3825 - val_loss: 6.3584 - val_mae: 10.1482 - val_mape: 6.1923 - lr: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.6366 - mae: 22.4790 - mape: 9.4704\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "87/87 [==============================] - 8s 86ms/step - loss: 9.6366 - mae: 22.4790 - mape: 9.4704 - val_loss: 6.2578 - val_mae: 11.4578 - val_mape: 6.0916 - lr: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5817 - mae: 22.8721 - mape: 9.4155 - val_loss: 6.1531 - val_mae: 9.5517 - val_mape: 5.9869 - lr: 3.0000e-05\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5941 - mae: 22.5830 - mape: 9.4279 - val_loss: 6.0006 - val_mae: 8.4805 - val_mape: 5.8345 - lr: 3.0000e-05\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5540 - mae: 23.6778 - mape: 9.3879 - val_loss: 5.9450 - val_mae: 8.1864 - val_mape: 5.7790 - lr: 3.0000e-05\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 7s 80ms/step - loss: 9.4090 - mae: 21.5839 - mape: 9.2430 - val_loss: 6.1740 - val_mae: 8.7955 - val_mape: 6.0081 - lr: 3.0000e-05\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4610 - mae: 22.8713 - mape: 9.2951 - val_loss: 5.9179 - val_mae: 8.1653 - val_mape: 5.7519 - lr: 3.0000e-05\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6789 - mae: 21.3052 - mape: 9.5130 - val_loss: 6.0562 - val_mae: 9.1256 - val_mape: 5.8903 - lr: 3.0000e-05\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.3129 - mae: 22.0568 - mape: 9.1470 - val_loss: 6.0183 - val_mae: 8.3521 - val_mape: 5.8524 - lr: 3.0000e-05\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4879 - mae: 19.9903 - mape: 9.3220 - val_loss: 5.8790 - val_mae: 8.4632 - val_mape: 5.7131 - lr: 3.0000e-05\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5704 - mae: 21.8309 - mape: 9.4046 - val_loss: 6.0653 - val_mae: 8.5530 - val_mape: 5.8995 - lr: 3.0000e-05\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6450 - mae: 24.4002 - mape: 9.4792 - val_loss: 5.9105 - val_mae: 8.2315 - val_mape: 5.7447 - lr: 3.0000e-05\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6732 - mae: 22.0865 - mape: 9.5074 - val_loss: 6.0380 - val_mae: 8.5629 - val_mape: 5.8722 - lr: 3.0000e-05\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.5098 - mae: 22.5418 - mape: 9.3440 - val_loss: 5.9144 - val_mae: 8.2035 - val_mape: 5.7486 - lr: 3.0000e-05\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.4173 - mae: 22.2698 - mape: 9.2516 - val_loss: 5.9640 - val_mae: 8.3664 - val_mape: 5.7983 - lr: 3.0000e-05\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5760 - mae: 24.1554 - mape: 9.4103 - val_loss: 6.0264 - val_mae: 8.6046 - val_mape: 5.8607 - lr: 3.0000e-05\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4822 - mae: 21.6381 - mape: 9.3165 - val_loss: 6.1012 - val_mae: 10.4369 - val_mape: 5.9355 - lr: 3.0000e-05\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.6201 - mae: 21.5978 - mape: 9.4543 - val_loss: 5.9643 - val_mae: 8.3822 - val_mape: 5.7986 - lr: 3.0000e-05\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.5494 - mae: 21.5393 - mape: 9.3836 - val_loss: 5.9815 - val_mae: 8.4569 - val_mape: 5.8158 - lr: 3.0000e-05\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.7364 - mae: 23.3397 - mape: 9.5707 - val_loss: 5.9826 - val_mae: 8.3342 - val_mape: 5.8171 - lr: 3.0000e-05\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 7s 84ms/step - loss: 9.4242 - mae: 22.1419 - mape: 9.2586 - val_loss: 6.0327 - val_mae: 8.5305 - val_mape: 5.8671 - lr: 3.0000e-05\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 7s 83ms/step - loss: 9.4939 - mae: 24.5566 - mape: 9.3283 - val_loss: 6.0056 - val_mae: 9.0037 - val_mape: 5.8401 - lr: 3.0000e-05\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.6936 - mae: 22.0423 - mape: 9.5280 - val_loss: 5.9867 - val_mae: 8.3480 - val_mape: 5.8212 - lr: 3.0000e-05\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 8s 89ms/step - loss: 9.4246 - mae: 22.7078 - mape: 9.2591 - val_loss: 5.8946 - val_mae: 8.1979 - val_mape: 5.7291 - lr: 3.0000e-05\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 9.6755 - mae: 21.1708 - mape: 9.5099 - val_loss: 6.0719 - val_mae: 9.5084 - val_mape: 5.9064 - lr: 3.0000e-05\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5227 - mae: 22.2954 - mape: 9.3572 - val_loss: 6.0057 - val_mae: 8.8250 - val_mape: 5.8402 - lr: 3.0000e-05\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.6536 - mae: 22.9296 - mape: 9.4881 - val_loss: 5.9799 - val_mae: 8.3371 - val_mape: 5.8145 - lr: 3.0000e-05\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.5384 - mae: 23.2225 - mape: 9.3730 - val_loss: 6.1697 - val_mae: 9.6859 - val_mape: 6.0043 - lr: 3.0000e-05\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 8s 90ms/step - loss: 9.7389 - mae: 22.1940 - mape: 9.5736 - val_loss: 6.1221 - val_mae: 10.2897 - val_mape: 5.9568 - lr: 3.0000e-05\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 7s 85ms/step - loss: 9.3718 - mae: 22.8110 - mape: 9.2065 - val_loss: 6.0576 - val_mae: 9.5284 - val_mape: 5.8923 - lr: 3.0000e-05\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 8s 87ms/step - loss: 9.4911 - mae: 21.0297 - mape: 9.3259 - val_loss: 6.0153 - val_mae: 8.4915 - val_mape: 5.8501 - lr: 3.0000e-05\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 9.7895 - mae: 23.0871 - mape: 9.6244\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "87/87 [==============================] - 7s 86ms/step - loss: 9.7895 - mae: 23.0871 - mape: 9.6244 - val_loss: 5.9511 - val_mae: 8.2261 - val_mape: 5.7861 - lr: 3.0000e-05\n",
      "Epoch 63: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Robin\\.conda\\envs\\tfenvironment\\lib\\site-packages\\spektral\\data\\utils.py:221: UserWarning: you are shuffling a 'MyDataset' object which is not a subclass of 'Sequence'; `shuffle` is not guaranteed to behave correctly. E.g., non-numpy array/tensor objects with view semantics may contain duplicates after shuffling.\n",
      "  np.random.shuffle(a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for fold 5: loss of 5.7650065422058105; mae of 7.8042168617248535; mape of 5.591925144195557%;\n"
     ]
    }
   ],
   "source": [
    "#Additional\n",
    "model = keras.models.load_model(\"crossvalidationmodels/Hybrid_freeze_5/\")\n",
    "make_trainable(model)\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model,'crossvalidationmodels/Hybrid_additional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 9.798641204833984 - Mean average error: 7.744525909423828% - Mean percentage error: 6.199242115020752%\n",
      "    Score on unseen data: Loss: 12.022106170654297 - Mean average error: 21.712295532226562% - Mean percentage error: 8.422706604003906%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 5.936761856079102 - Mean average error: 8.949280738830566% - Mean percentage error: 5.711127758026123%\n",
      "    Score on unseen data: Loss: 8.403227806091309 - Mean average error: 17.548826217651367% - Mean percentage error: 8.177593231201172%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 6.355964183807373 - Mean average error: 8.000141143798828% - Mean percentage error: 6.154524326324463%\n",
      "    Score on unseen data: Loss: 8.47793197631836 - Mean average error: 20.447635650634766% - Mean percentage error: 8.276491165161133%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 5.329043388366699 - Mean average error: 9.784645080566406% - Mean percentage error: 5.144991397857666%\n",
      "    Score on unseen data: Loss: 8.338922500610352 - Mean average error: 16.81370735168457% - Mean percentage error: 8.154870986938477%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 5.7650065422058105 - Mean average error: 7.8042168617248535% - Mean percentage error: 5.591925144195557%\n",
      "    Score on unseen data: Loss: 8.362988471984863 - Mean average error: 18.371522903442383% - Mean percentage error: 8.18990707397461%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 6.637083435058594\n",
      "> Mean average error: 8.456561946868897\n",
      "> Mean percentage error: 5.760362148284912\n",
      "> Unseen Loss: 9.121035385131837\n",
      "> Unseen Mean average error: 18.97879753112793\n",
      "> Unseen Mean percentage error: 8.244313812255859\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baselinemodel\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n",
      "75/87 [========================>.....] - ETA: 0s - loss: 6.3390 - mae: 12.4496 - mape: 6.3390INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_1\\assets\n",
      "87/87 [==============================] - 3s 15ms/step - loss: 6.3032 - mae: 12.4022 - mape: 6.3032 - val_loss: 6.0261 - val_mae: 11.7178 - val_mape: 6.0261 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "77/87 [=========================>....] - ETA: 0s - loss: 6.2203 - mae: 14.1206 - mape: 6.2203INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_1\\assets\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.2525 - mae: 13.7477 - mape: 6.2525 - val_loss: 5.9237 - val_mae: 8.2560 - val_mape: 5.9237 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.2818 - mae: 14.1832 - mape: 6.2818 - val_loss: 6.3190 - val_mae: 13.0683 - val_mape: 6.3190 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.2192 - mae: 12.7576 - mape: 6.2192 - val_loss: 6.0672 - val_mae: 8.7226 - val_mape: 6.0672 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.2017 - mae: 12.9865 - mape: 6.2017 - val_loss: 5.9868 - val_mae: 9.2240 - val_mape: 5.9868 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.1275 - mae: 11.7577 - mape: 6.1275 - val_loss: 6.0805 - val_mae: 10.6708 - val_mape: 6.0805 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1523 - mae: 12.0663 - mape: 6.1523 - val_loss: 6.5301 - val_mae: 14.0768 - val_mape: 6.5301 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1678 - mae: 12.9599 - mape: 6.1678 - val_loss: 6.5152 - val_mae: 18.5822 - val_mape: 6.5152 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1330 - mae: 12.4651 - mape: 6.1330 - val_loss: 6.1107 - val_mae: 8.5632 - val_mape: 6.1107 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1802 - mae: 12.8946 - mape: 6.1802 - val_loss: 6.2159 - val_mae: 8.7460 - val_mape: 6.2159 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1299 - mae: 12.4988 - mape: 6.1299 - val_loss: 6.4355 - val_mae: 17.0111 - val_mape: 6.4355 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0972 - mae: 11.6061 - mape: 6.0972 - val_loss: 6.3203 - val_mae: 11.5978 - val_mape: 6.3203 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1581 - mae: 12.6053 - mape: 6.1581 - val_loss: 6.0883 - val_mae: 10.5200 - val_mape: 6.0883 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1618 - mae: 13.0789 - mape: 6.1618 - val_loss: 6.3461 - val_mae: 10.5737 - val_mape: 6.3461 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1336 - mae: 12.2142 - mape: 6.1336 - val_loss: 6.2036 - val_mae: 9.2891 - val_mape: 6.2036 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0525 - mae: 10.9596 - mape: 6.0525 - val_loss: 6.4827 - val_mae: 8.8269 - val_mape: 6.4827 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1335 - mae: 12.1504 - mape: 6.1335 - val_loss: 6.3021 - val_mae: 8.9515 - val_mape: 6.3021 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0425 - mae: 11.5434 - mape: 6.0425 - val_loss: 6.1352 - val_mae: 8.7135 - val_mape: 6.1352 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1417 - mae: 12.6697 - mape: 6.1417 - val_loss: 6.3226 - val_mae: 10.6462 - val_mape: 6.3226 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1683 - mae: 13.9361 - mape: 6.1683 - val_loss: 6.1647 - val_mae: 9.3523 - val_mape: 6.1647 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1276 - mae: 12.2833 - mape: 6.1276 - val_loss: 6.3673 - val_mae: 10.8556 - val_mape: 6.3673 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1596 - mae: 13.4965 - mape: 6.1596 - val_loss: 6.0633 - val_mae: 8.1653 - val_mape: 6.0633 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0839 - mae: 12.2120 - mape: 6.0839 - val_loss: 6.4426 - val_mae: 11.2774 - val_mape: 6.4426 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0073 - mae: 10.9707 - mape: 6.0073 - val_loss: 6.1654 - val_mae: 8.3785 - val_mape: 6.1654 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1956 - mae: 13.5520 - mape: 6.1956 - val_loss: 6.2507 - val_mae: 11.5188 - val_mape: 6.2507 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0991 - mae: 12.0956 - mape: 6.0991 - val_loss: 6.2408 - val_mae: 8.8717 - val_mape: 6.2408 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0485 - mae: 11.9077 - mape: 6.0485 - val_loss: 6.4447 - val_mae: 10.1594 - val_mape: 6.4447 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1226 - mae: 13.2668 - mape: 6.1226 - val_loss: 6.4862 - val_mae: 13.0982 - val_mape: 6.4862 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1275 - mae: 13.0295 - mape: 6.1275 - val_loss: 6.4196 - val_mae: 11.7732 - val_mape: 6.4196 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0752 - mae: 12.3877 - mape: 6.0752 - val_loss: 6.3286 - val_mae: 10.1669 - val_mape: 6.3286 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0525 - mae: 12.3162 - mape: 6.0525 - val_loss: 6.2153 - val_mae: 10.4122 - val_mape: 6.2153 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 6.0542 - mae: 12.4930 - mape: 6.0542\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0774 - mae: 13.0231 - mape: 6.0774 - val_loss: 6.2429 - val_mae: 9.5061 - val_mape: 6.2429 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8997 - mae: 11.2566 - mape: 5.8997 - val_loss: 6.2239 - val_mae: 9.1833 - val_mape: 6.2239 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8436 - mae: 10.3284 - mape: 5.8436 - val_loss: 6.2117 - val_mae: 8.3715 - val_mape: 6.2117 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8339 - mae: 10.3679 - mape: 5.8339 - val_loss: 6.1643 - val_mae: 9.3718 - val_mape: 6.1643 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8363 - mae: 10.3933 - mape: 5.8363 - val_loss: 6.1522 - val_mae: 8.8765 - val_mape: 6.1522 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8317 - mae: 10.5577 - mape: 5.8317 - val_loss: 6.2180 - val_mae: 8.8396 - val_mape: 6.2180 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8585 - mae: 10.6636 - mape: 5.8585 - val_loss: 6.1896 - val_mae: 8.8169 - val_mape: 6.1896 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8479 - mae: 10.6052 - mape: 5.8479 - val_loss: 6.1845 - val_mae: 9.6386 - val_mape: 6.1845 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.8660 - mae: 10.6295 - mape: 5.8660 - val_loss: 6.2089 - val_mae: 9.0580 - val_mape: 6.2089 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8289 - mae: 10.6009 - mape: 5.8289 - val_loss: 6.2920 - val_mae: 9.1803 - val_mape: 6.2920 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8355 - mae: 10.1616 - mape: 5.8355 - val_loss: 6.1937 - val_mae: 8.8996 - val_mape: 6.1937 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8283 - mae: 10.2928 - mape: 5.8283 - val_loss: 6.1895 - val_mae: 8.5049 - val_mape: 6.1895 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8509 - mae: 10.4104 - mape: 5.8509 - val_loss: 6.2043 - val_mae: 9.5814 - val_mape: 6.2043 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.8324 - mae: 10.5478 - mape: 5.8324 - val_loss: 6.1929 - val_mae: 8.5573 - val_mape: 6.1929 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8510 - mae: 10.4638 - mape: 5.8510 - val_loss: 6.1942 - val_mae: 8.2929 - val_mape: 6.1942 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8034 - mae: 9.9838 - mape: 5.8034 - val_loss: 6.1868 - val_mae: 8.2547 - val_mape: 6.1868 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8142 - mae: 10.7154 - mape: 5.8142 - val_loss: 6.2069 - val_mae: 8.3077 - val_mape: 6.2069 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8117 - mae: 10.3011 - mape: 5.8117 - val_loss: 6.1917 - val_mae: 8.6981 - val_mape: 6.1917 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8265 - mae: 10.4859 - mape: 5.8265 - val_loss: 6.1922 - val_mae: 8.2155 - val_mape: 6.1922 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8080 - mae: 10.4259 - mape: 5.8080 - val_loss: 6.2298 - val_mae: 8.5141 - val_mape: 6.2298 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 5.8254 - mae: 10.5479 - mape: 5.8254 - val_loss: 6.1634 - val_mae: 8.0997 - val_mape: 6.1634 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8026 - mae: 10.4479 - mape: 5.8026 - val_loss: 6.2080 - val_mae: 8.0161 - val_mape: 6.2080 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.8063 - mae: 10.3973 - mape: 5.8063 - val_loss: 6.2013 - val_mae: 9.0934 - val_mape: 6.2013 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8189 - mae: 10.6279 - mape: 5.8189 - val_loss: 6.2536 - val_mae: 9.1670 - val_mape: 6.2536 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8246 - mae: 10.4976 - mape: 5.8246 - val_loss: 6.2119 - val_mae: 8.1249 - val_mape: 6.2119 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.8221 - mae: 10.3808 - mape: 5.8221 - val_loss: 6.2912 - val_mae: 10.0130 - val_mape: 6.2912 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.8221 - mae: 10.4560 - mape: 5.8221 - val_loss: 6.2201 - val_mae: 8.3563 - val_mape: 6.2201 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.8318 - mae: 10.2828 - mape: 5.8318 - val_loss: 6.2211 - val_mae: 8.2662 - val_mape: 6.2211 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8177 - mae: 10.4186 - mape: 5.8177 - val_loss: 6.1983 - val_mae: 8.3423 - val_mape: 6.1983 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7842 - mae: 10.2607 - mape: 5.7842 - val_loss: 6.1939 - val_mae: 9.8191 - val_mape: 6.1939 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 5.8074 - mae: 10.6825 - mape: 5.8074\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8198 - mae: 10.5624 - mape: 5.8198 - val_loss: 6.2229 - val_mae: 8.8618 - val_mape: 6.2229 - lr: 3.0000e-04\n",
      "Epoch 62: early stopping\n",
      "Score for fold 1: loss of 5.923693656921387; mae of 8.256022453308105; mape of 5.923693656921387%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 6.3018 - mae: 12.8145 - mape: 6.3018INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_2\\assets\n",
      "87/87 [==============================] - 2s 15ms/step - loss: 6.2466 - mae: 12.3725 - mape: 6.2466 - val_loss: 6.4615 - val_mae: 13.7954 - val_mape: 6.4615 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.0518 - mae: 10.4195 - mape: 6.0518 - val_loss: 6.5607 - val_mae: 16.3615 - val_mape: 6.5607 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - ETA: 0s - loss: 6.0391 - mae: 10.0993 - mape: 6.0391INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_2\\assets\n",
      "87/87 [==============================] - 2s 20ms/step - loss: 6.0391 - mae: 10.0993 - mape: 6.0391 - val_loss: 6.3426 - val_mae: 11.9007 - val_mape: 6.3426 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0530 - mae: 11.1182 - mape: 6.0530 - val_loss: 6.5455 - val_mae: 14.2495 - val_mape: 6.5455 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0375 - mae: 10.8530 - mape: 6.0375 - val_loss: 6.5874 - val_mae: 18.7777 - val_mape: 6.5874 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0251 - mae: 11.4500 - mape: 6.0251 - val_loss: 6.4442 - val_mae: 14.6569 - val_mape: 6.4442 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0245 - mae: 11.2701 - mape: 6.0245 - val_loss: 6.4083 - val_mae: 12.8274 - val_mape: 6.4083 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1113 - mae: 12.9491 - mape: 6.1113 - val_loss: 6.5046 - val_mae: 12.4328 - val_mape: 6.5046 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1473 - mae: 13.2820 - mape: 6.1473 - val_loss: 6.4793 - val_mae: 12.8837 - val_mape: 6.4793 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9751 - mae: 10.6561 - mape: 5.9751 - val_loss: 6.4362 - val_mae: 11.8454 - val_mape: 6.4362 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9499 - mae: 10.3624 - mape: 5.9499 - val_loss: 6.5661 - val_mae: 13.6514 - val_mape: 6.5661 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0383 - mae: 11.6846 - mape: 6.0383 - val_loss: 6.4006 - val_mae: 11.8150 - val_mape: 6.4006 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9941 - mae: 10.8158 - mape: 5.9941 - val_loss: 6.3884 - val_mae: 11.8891 - val_mape: 6.3884 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9185 - mae: 9.8844 - mape: 5.9185 - val_loss: 6.4708 - val_mae: 11.9790 - val_mape: 6.4708 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9957 - mae: 11.1338 - mape: 5.9957 - val_loss: 6.6254 - val_mae: 12.1480 - val_mape: 6.6254 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9695 - mae: 11.7186 - mape: 5.9695 - val_loss: 6.5851 - val_mae: 13.4196 - val_mape: 6.5851 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9900 - mae: 11.3835 - mape: 5.9900 - val_loss: 6.4058 - val_mae: 12.0796 - val_mape: 6.4058 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9184 - mae: 10.1518 - mape: 5.9184 - val_loss: 6.5736 - val_mae: 12.7894 - val_mape: 6.5736 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9609 - mae: 11.0531 - mape: 5.9609 - val_loss: 6.5478 - val_mae: 13.0963 - val_mape: 6.5478 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9565 - mae: 10.5673 - mape: 5.9565 - val_loss: 6.5755 - val_mae: 13.8340 - val_mape: 6.5755 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0897 - mae: 11.5350 - mape: 6.0897 - val_loss: 6.5221 - val_mae: 12.1202 - val_mape: 6.5221 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0673 - mae: 11.9056 - mape: 6.0673 - val_loss: 6.6419 - val_mae: 12.7544 - val_mape: 6.6419 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9862 - mae: 12.1478 - mape: 5.9862 - val_loss: 6.6230 - val_mae: 12.8061 - val_mape: 6.6230 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0252 - mae: 11.7057 - mape: 6.0252 - val_loss: 6.6429 - val_mae: 15.4881 - val_mape: 6.6429 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9810 - mae: 12.3167 - mape: 5.9810 - val_loss: 6.6472 - val_mae: 12.3735 - val_mape: 6.6472 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9424 - mae: 11.4866 - mape: 5.9424 - val_loss: 6.5432 - val_mae: 11.9081 - val_mape: 6.5432 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0412 - mae: 11.5482 - mape: 6.0412 - val_loss: 6.6316 - val_mae: 12.1359 - val_mape: 6.6316 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9522 - mae: 11.6109 - mape: 5.9522 - val_loss: 6.7051 - val_mae: 15.5304 - val_mape: 6.7051 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.9574 - mae: 11.4606 - mape: 5.9574 - val_loss: 6.7028 - val_mae: 17.2299 - val_mape: 6.7028 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9181 - mae: 10.7001 - mape: 5.9181 - val_loss: 6.6919 - val_mae: 12.8149 - val_mape: 6.6919 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9534 - mae: 11.5347 - mape: 5.9534 - val_loss: 6.7380 - val_mae: 15.7891 - val_mape: 6.7380 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9413 - mae: 10.3703 - mape: 5.9413 - val_loss: 6.5778 - val_mae: 12.1375 - val_mape: 6.5778 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 5.9121 - mae: 9.5575 - mape: 5.9121\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8890 - mae: 10.4746 - mape: 5.8890 - val_loss: 6.6175 - val_mae: 13.3357 - val_mape: 6.6175 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7626 - mae: 9.4532 - mape: 5.7626 - val_loss: 6.5655 - val_mae: 12.1673 - val_mape: 6.5655 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7243 - mae: 9.4794 - mape: 5.7243 - val_loss: 6.6010 - val_mae: 12.4886 - val_mape: 6.6010 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7480 - mae: 10.1893 - mape: 5.7480 - val_loss: 6.5366 - val_mae: 12.0909 - val_mape: 6.5366 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7441 - mae: 9.5972 - mape: 5.7441 - val_loss: 6.5278 - val_mae: 12.0465 - val_mape: 6.5278 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7478 - mae: 9.9162 - mape: 5.7478 - val_loss: 6.5724 - val_mae: 12.7909 - val_mape: 6.5724 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.6891 - mae: 9.5524 - mape: 5.6891 - val_loss: 6.5864 - val_mae: 13.9127 - val_mape: 6.5864 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7073 - mae: 9.5328 - mape: 5.7073 - val_loss: 6.5621 - val_mae: 11.9448 - val_mape: 6.5621 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6877 - mae: 9.2183 - mape: 5.6877 - val_loss: 6.5559 - val_mae: 12.7487 - val_mape: 6.5559 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7458 - mae: 9.6937 - mape: 5.7458 - val_loss: 6.5485 - val_mae: 12.3019 - val_mape: 6.5485 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7017 - mae: 9.3384 - mape: 5.7017 - val_loss: 6.5538 - val_mae: 12.0434 - val_mape: 6.5538 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7220 - mae: 9.5771 - mape: 5.7220 - val_loss: 6.7653 - val_mae: 16.3822 - val_mape: 6.7653 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 5.6945 - mae: 9.5879 - mape: 5.6945 - val_loss: 6.5398 - val_mae: 12.0404 - val_mape: 6.5398 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6937 - mae: 9.4315 - mape: 5.6937 - val_loss: 6.5651 - val_mae: 12.3174 - val_mape: 6.5651 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7196 - mae: 9.6782 - mape: 5.7196 - val_loss: 6.5769 - val_mae: 12.1608 - val_mape: 6.5769 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6928 - mae: 9.5756 - mape: 5.6928 - val_loss: 6.5348 - val_mae: 12.0801 - val_mape: 6.5348 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6740 - mae: 9.0961 - mape: 5.6740 - val_loss: 6.6463 - val_mae: 12.1913 - val_mape: 6.6463 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6992 - mae: 9.6535 - mape: 5.6992 - val_loss: 6.5809 - val_mae: 12.4062 - val_mape: 6.5809 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7032 - mae: 9.8641 - mape: 5.7032 - val_loss: 6.5547 - val_mae: 12.0229 - val_mape: 6.5547 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6965 - mae: 9.6315 - mape: 5.6965 - val_loss: 6.5809 - val_mae: 12.1596 - val_mape: 6.5809 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7003 - mae: 9.7177 - mape: 5.7003 - val_loss: 6.6653 - val_mae: 13.6774 - val_mape: 6.6653 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7033 - mae: 9.6307 - mape: 5.7033 - val_loss: 6.5804 - val_mae: 12.3402 - val_mape: 6.5804 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.6883 - mae: 9.5694 - mape: 5.6883 - val_loss: 6.5644 - val_mae: 12.1646 - val_mape: 6.5644 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6569 - mae: 9.0050 - mape: 5.6569 - val_loss: 6.5908 - val_mae: 12.5975 - val_mape: 6.5908 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6836 - mae: 9.3439 - mape: 5.6836 - val_loss: 6.5786 - val_mae: 12.0934 - val_mape: 6.5786 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6878 - mae: 9.2037 - mape: 5.6878 - val_loss: 6.5841 - val_mae: 12.9452 - val_mape: 6.5841 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6723 - mae: 9.2376 - mape: 5.6723 - val_loss: 6.5603 - val_mae: 12.0652 - val_mape: 6.5603 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6679 - mae: 9.0848 - mape: 5.6679 - val_loss: 6.5824 - val_mae: 12.0154 - val_mape: 6.5824 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6903 - mae: 9.3641 - mape: 5.6903 - val_loss: 6.5927 - val_mae: 12.2819 - val_mape: 6.5927 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.6964 - mae: 9.7237 - mape: 5.6964 - val_loss: 6.5777 - val_mae: 12.3249 - val_mape: 6.5777 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "74/87 [========================>.....] - ETA: 0s - loss: 5.6056 - mae: 8.9611 - mape: 5.6056\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.6600 - mae: 9.0757 - mape: 5.6600 - val_loss: 6.5827 - val_mae: 12.1399 - val_mape: 6.5827 - lr: 3.0000e-04\n",
      "Epoch 63: early stopping\n",
      "Score for fold 2: loss of 6.3426055908203125; mae of 11.900733947753906; mape of 6.3426055908203125%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 6.2130 - mae: 11.3849 - mape: 6.2130INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_3\\assets\n",
      "87/87 [==============================] - 1s 13ms/step - loss: 6.1974 - mae: 10.9577 - mape: 6.1974 - val_loss: 6.1537 - val_mae: 11.1907 - val_mape: 6.1537 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 6.1264 - mae: 11.4909 - mape: 6.1264INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_3\\assets\n",
      "87/87 [==============================] - 1s 12ms/step - loss: 6.1473 - mae: 11.4423 - mape: 6.1473 - val_loss: 6.0460 - val_mae: 11.4475 - val_mape: 6.0460 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 6.2366 - mae: 11.0180 - mape: 6.2366INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_3\\assets\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.1403 - mae: 11.2272 - mape: 6.1403 - val_loss: 5.9572 - val_mae: 10.6925 - val_mape: 5.9572 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 6.1909 - mae: 11.9346 - mape: 6.1909INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_3\\assets\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.1850 - mae: 12.3717 - mape: 6.1850 - val_loss: 5.9360 - val_mae: 10.8481 - val_mape: 5.9360 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0721 - mae: 10.4668 - mape: 6.0721 - val_loss: 5.9546 - val_mae: 10.7937 - val_mape: 5.9546 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1036 - mae: 12.0101 - mape: 6.1036 - val_loss: 6.0216 - val_mae: 11.3714 - val_mape: 6.0216 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.1258 - mae: 12.3390 - mape: 6.1258 - val_loss: 5.9894 - val_mae: 10.8669 - val_mape: 5.9894 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0974 - mae: 11.3659 - mape: 6.0974 - val_loss: 6.0209 - val_mae: 11.7006 - val_mape: 6.0209 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0869 - mae: 11.3014 - mape: 6.0869 - val_loss: 6.0919 - val_mae: 12.2906 - val_mape: 6.0919 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0966 - mae: 11.9209 - mape: 6.0966 - val_loss: 6.3107 - val_mae: 14.8225 - val_mape: 6.3107 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1656 - mae: 12.2010 - mape: 6.1656 - val_loss: 6.0319 - val_mae: 10.8926 - val_mape: 6.0319 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1203 - mae: 11.7874 - mape: 6.1203 - val_loss: 6.1478 - val_mae: 11.9773 - val_mape: 6.1478 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1115 - mae: 11.5634 - mape: 6.1115 - val_loss: 6.0608 - val_mae: 10.6756 - val_mape: 6.0608 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0061 - mae: 10.3838 - mape: 6.0061 - val_loss: 6.1012 - val_mae: 13.0627 - val_mape: 6.1012 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1135 - mae: 11.8058 - mape: 6.1135 - val_loss: 6.0873 - val_mae: 11.0062 - val_mape: 6.0873 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0393 - mae: 10.8256 - mape: 6.0393 - val_loss: 6.1463 - val_mae: 12.1478 - val_mape: 6.1463 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0584 - mae: 11.2863 - mape: 6.0584 - val_loss: 6.3232 - val_mae: 11.0066 - val_mape: 6.3232 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.2233 - mae: 12.5453 - mape: 6.2233 - val_loss: 6.0967 - val_mae: 10.8407 - val_mape: 6.0967 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1803 - mae: 13.0246 - mape: 6.1803 - val_loss: 6.0654 - val_mae: 11.3965 - val_mape: 6.0654 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1805 - mae: 13.6420 - mape: 6.1805 - val_loss: 6.1655 - val_mae: 13.3639 - val_mape: 6.1655 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0518 - mae: 11.5449 - mape: 6.0518 - val_loss: 6.0797 - val_mae: 11.7658 - val_mape: 6.0797 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9728 - mae: 10.5652 - mape: 5.9728 - val_loss: 6.1603 - val_mae: 11.1204 - val_mape: 6.1603 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0177 - mae: 11.6727 - mape: 6.0177 - val_loss: 6.1801 - val_mae: 11.8702 - val_mape: 6.1801 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0035 - mae: 10.9308 - mape: 6.0035 - val_loss: 6.4367 - val_mae: 19.3033 - val_mape: 6.4367 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0695 - mae: 11.0656 - mape: 6.0695 - val_loss: 6.1317 - val_mae: 11.0929 - val_mape: 6.1317 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0724 - mae: 12.1576 - mape: 6.0724 - val_loss: 6.3934 - val_mae: 15.5292 - val_mape: 6.3934 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 6.0315 - mae: 11.1417 - mape: 6.0315 - val_loss: 6.1330 - val_mae: 11.7672 - val_mape: 6.1330 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9996 - mae: 11.2447 - mape: 5.9996 - val_loss: 6.4148 - val_mae: 13.5865 - val_mape: 6.4148 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9923 - mae: 10.7266 - mape: 5.9923 - val_loss: 6.3341 - val_mae: 15.7517 - val_mape: 6.3341 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0430 - mae: 11.8092 - mape: 6.0430 - val_loss: 6.2020 - val_mae: 11.5052 - val_mape: 6.2020 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9735 - mae: 10.5891 - mape: 5.9735 - val_loss: 6.7691 - val_mae: 28.2953 - val_mape: 6.7691 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0718 - mae: 11.6524 - mape: 6.0718 - val_loss: 6.4875 - val_mae: 11.6048 - val_mape: 6.4875 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0320 - mae: 11.2944 - mape: 6.0320 - val_loss: 6.2020 - val_mae: 11.5793 - val_mape: 6.2020 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 6.0326 - mae: 10.7829 - mape: 6.0326\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0203 - mae: 11.2479 - mape: 6.0203 - val_loss: 6.1849 - val_mae: 11.0060 - val_mape: 6.1849 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8264 - mae: 9.6016 - mape: 5.8264 - val_loss: 6.1587 - val_mae: 11.0601 - val_mape: 6.1587 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8032 - mae: 9.6783 - mape: 5.8032 - val_loss: 6.1600 - val_mae: 11.9293 - val_mape: 6.1600 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7870 - mae: 9.7107 - mape: 5.7870 - val_loss: 6.1980 - val_mae: 11.4365 - val_mape: 6.1980 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 5.8242 - mae: 10.2970 - mape: 5.8242 - val_loss: 6.2367 - val_mae: 14.5407 - val_mape: 6.2367 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7982 - mae: 9.7661 - mape: 5.7982 - val_loss: 6.2205 - val_mae: 12.2293 - val_mape: 6.2205 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8028 - mae: 10.0804 - mape: 5.8028 - val_loss: 6.1779 - val_mae: 11.0675 - val_mape: 6.1779 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7808 - mae: 9.4143 - mape: 5.7808 - val_loss: 6.1682 - val_mae: 11.2834 - val_mape: 6.1682 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.8192 - mae: 10.2797 - mape: 5.8192 - val_loss: 6.1910 - val_mae: 11.3111 - val_mape: 6.1910 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7909 - mae: 9.5051 - mape: 5.7909 - val_loss: 6.1838 - val_mae: 12.3343 - val_mape: 6.1838 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7916 - mae: 9.8515 - mape: 5.7916 - val_loss: 6.1764 - val_mae: 11.1144 - val_mape: 6.1764 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7917 - mae: 9.4664 - mape: 5.7917 - val_loss: 6.2449 - val_mae: 11.7235 - val_mape: 6.2449 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7974 - mae: 10.0584 - mape: 5.7974 - val_loss: 6.1904 - val_mae: 11.2937 - val_mape: 6.1904 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7810 - mae: 9.5268 - mape: 5.7810 - val_loss: 6.1684 - val_mae: 11.0241 - val_mape: 6.1684 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7832 - mae: 9.6735 - mape: 5.7832 - val_loss: 6.1827 - val_mae: 10.9049 - val_mape: 6.1827 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7843 - mae: 9.7746 - mape: 5.7843 - val_loss: 6.1713 - val_mae: 11.4081 - val_mape: 6.1713 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7794 - mae: 9.4062 - mape: 5.7794 - val_loss: 6.1707 - val_mae: 11.0352 - val_mape: 6.1707 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 5.7742 - mae: 9.6571 - mape: 5.7742 - val_loss: 6.2523 - val_mae: 11.7184 - val_mape: 6.2523 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7734 - mae: 9.6751 - mape: 5.7734 - val_loss: 6.2028 - val_mae: 10.9310 - val_mape: 6.2028 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7621 - mae: 9.4090 - mape: 5.7621 - val_loss: 6.1835 - val_mae: 10.9591 - val_mape: 6.1835 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7879 - mae: 9.4117 - mape: 5.7879 - val_loss: 6.2158 - val_mae: 12.7394 - val_mape: 6.2158 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7859 - mae: 9.5667 - mape: 5.7859 - val_loss: 6.1924 - val_mae: 11.4086 - val_mape: 6.1924 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7630 - mae: 9.7570 - mape: 5.7630 - val_loss: 6.2044 - val_mae: 11.0022 - val_mape: 6.2044 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7732 - mae: 9.4273 - mape: 5.7732 - val_loss: 6.1998 - val_mae: 11.5151 - val_mape: 6.1998 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7633 - mae: 9.3179 - mape: 5.7633 - val_loss: 6.2057 - val_mae: 11.2613 - val_mape: 6.2057 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7827 - mae: 9.3018 - mape: 5.7827 - val_loss: 6.2126 - val_mae: 10.9377 - val_mape: 6.2126 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7645 - mae: 9.4293 - mape: 5.7645 - val_loss: 6.2603 - val_mae: 13.0485 - val_mape: 6.2603 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7380 - mae: 9.2278 - mape: 5.7380 - val_loss: 6.1963 - val_mae: 11.1059 - val_mape: 6.1963 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7738 - mae: 9.6989 - mape: 5.7738 - val_loss: 6.2015 - val_mae: 11.2721 - val_mape: 6.2015 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7669 - mae: 9.2981 - mape: 5.7669 - val_loss: 6.2168 - val_mae: 11.2706 - val_mape: 6.2168 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "75/87 [========================>.....] - ETA: 0s - loss: 5.7569 - mae: 10.0063 - mape: 5.7569\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7665 - mae: 9.7400 - mape: 5.7665 - val_loss: 6.2297 - val_mae: 12.3272 - val_mape: 6.2297 - lr: 3.0000e-04\n",
      "Epoch 64: early stopping\n",
      "Score for fold 3: loss of 5.935964107513428; mae of 10.848103523254395; mape of 5.935964107513428%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 6.3044 - mae: 13.0437 - mape: 6.3044INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_4\\assets\n",
      "87/87 [==============================] - 2s 16ms/step - loss: 6.2837 - mae: 12.8230 - mape: 6.2837 - val_loss: 5.9508 - val_mae: 10.5950 - val_mape: 5.9508 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.2186 - mae: 11.6601 - mape: 6.2186 - val_loss: 6.0557 - val_mae: 10.8072 - val_mape: 6.0557 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1256 - mae: 11.8596 - mape: 6.1256 - val_loss: 6.1790 - val_mae: 11.9400 - val_mape: 6.1790 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1179 - mae: 11.4509 - mape: 6.1179 - val_loss: 6.0881 - val_mae: 11.0621 - val_mape: 6.0881 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1514 - mae: 11.1377 - mape: 6.1514 - val_loss: 6.0741 - val_mae: 11.6368 - val_mape: 6.0741 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.1141 - mae: 10.8887 - mape: 6.1141 - val_loss: 6.1990 - val_mae: 12.6550 - val_mape: 6.1990 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1199 - mae: 12.4988 - mape: 6.1199 - val_loss: 5.9955 - val_mae: 11.1360 - val_mape: 5.9955 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1349 - mae: 11.9331 - mape: 6.1349 - val_loss: 6.0573 - val_mae: 11.1424 - val_mape: 6.0573 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1279 - mae: 12.8679 - mape: 6.1279 - val_loss: 5.9639 - val_mae: 12.1252 - val_mape: 5.9639 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1153 - mae: 11.6380 - mape: 6.1153 - val_loss: 6.4279 - val_mae: 11.8356 - val_mape: 6.4279 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1941 - mae: 12.9230 - mape: 6.1941 - val_loss: 6.4101 - val_mae: 16.6619 - val_mape: 6.4101 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.1579 - mae: 11.1991 - mape: 6.1579 - val_loss: 6.0895 - val_mae: 11.2536 - val_mape: 6.0895 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1705 - mae: 12.2627 - mape: 6.1705 - val_loss: 6.0905 - val_mae: 11.7137 - val_mape: 6.0905 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0873 - mae: 11.3540 - mape: 6.0873 - val_loss: 6.0215 - val_mae: 11.0092 - val_mape: 6.0215 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0439 - mae: 11.4533 - mape: 6.0439 - val_loss: 6.1026 - val_mae: 11.6960 - val_mape: 6.1026 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.1216 - mae: 12.8218 - mape: 6.1216 - val_loss: 6.4759 - val_mae: 14.4602 - val_mape: 6.4759 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1474 - mae: 12.2743 - mape: 6.1474 - val_loss: 6.3090 - val_mae: 13.6556 - val_mape: 6.3090 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0669 - mae: 11.6772 - mape: 6.0669 - val_loss: 6.1336 - val_mae: 11.6436 - val_mape: 6.1336 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0491 - mae: 10.7802 - mape: 6.0491 - val_loss: 6.0922 - val_mae: 11.9379 - val_mape: 6.0922 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0472 - mae: 11.0585 - mape: 6.0472 - val_loss: 6.1720 - val_mae: 11.8913 - val_mape: 6.1720 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0230 - mae: 10.8510 - mape: 6.0230 - val_loss: 6.3043 - val_mae: 12.0159 - val_mape: 6.3043 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0092 - mae: 10.2800 - mape: 6.0092 - val_loss: 6.1421 - val_mae: 12.5312 - val_mape: 6.1421 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0161 - mae: 11.1438 - mape: 6.0161 - val_loss: 6.1579 - val_mae: 11.5505 - val_mape: 6.1579 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.0772 - mae: 12.2567 - mape: 6.0772 - val_loss: 6.1180 - val_mae: 11.3039 - val_mape: 6.1180 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0337 - mae: 11.4323 - mape: 6.0337 - val_loss: 6.1359 - val_mae: 11.1232 - val_mape: 6.1359 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0727 - mae: 11.6856 - mape: 6.0727 - val_loss: 6.1908 - val_mae: 11.5510 - val_mape: 6.1908 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.0711 - mae: 12.4892 - mape: 6.0711 - val_loss: 6.3098 - val_mae: 11.5720 - val_mape: 6.3098 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0698 - mae: 12.5752 - mape: 6.0698 - val_loss: 6.2080 - val_mae: 11.4485 - val_mape: 6.2080 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.0454 - mae: 11.9735 - mape: 6.0454 - val_loss: 6.2214 - val_mae: 11.3479 - val_mape: 6.2214 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9793 - mae: 10.5634 - mape: 5.9793 - val_loss: 6.4725 - val_mae: 12.0216 - val_mape: 6.4725 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 6.0770 - mae: 11.4015 - mape: 6.0770\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0738 - mae: 11.4048 - mape: 6.0738 - val_loss: 6.2245 - val_mae: 11.4871 - val_mape: 6.2245 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.8686 - mae: 10.3027 - mape: 5.8686 - val_loss: 6.1879 - val_mae: 11.3886 - val_mape: 6.1879 - lr: 3.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8012 - mae: 9.4616 - mape: 5.8012 - val_loss: 6.1696 - val_mae: 11.2584 - val_mape: 6.1696 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8043 - mae: 9.8237 - mape: 5.8043 - val_loss: 6.1714 - val_mae: 11.3552 - val_mape: 6.1714 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7972 - mae: 9.6036 - mape: 5.7972 - val_loss: 6.2131 - val_mae: 11.4747 - val_mape: 6.2131 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7872 - mae: 9.6479 - mape: 5.7872 - val_loss: 6.1974 - val_mae: 11.3621 - val_mape: 6.1974 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7870 - mae: 9.4436 - mape: 5.7870 - val_loss: 6.2607 - val_mae: 11.8564 - val_mape: 6.2607 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7858 - mae: 9.6187 - mape: 5.7858 - val_loss: 6.1552 - val_mae: 11.3447 - val_mape: 6.1552 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7754 - mae: 9.2213 - mape: 5.7754 - val_loss: 6.1987 - val_mae: 11.3451 - val_mape: 6.1987 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7963 - mae: 9.6554 - mape: 5.7963 - val_loss: 6.2168 - val_mae: 11.4670 - val_mape: 6.2168 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7896 - mae: 9.4137 - mape: 5.7896 - val_loss: 6.1695 - val_mae: 11.2622 - val_mape: 6.1695 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7995 - mae: 9.5702 - mape: 5.7995 - val_loss: 6.2368 - val_mae: 11.7015 - val_mape: 6.2368 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7936 - mae: 9.6185 - mape: 5.7936 - val_loss: 6.1856 - val_mae: 11.7404 - val_mape: 6.1856 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7712 - mae: 9.8096 - mape: 5.7712 - val_loss: 6.1724 - val_mae: 11.2732 - val_mape: 6.1724 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7774 - mae: 9.2258 - mape: 5.7774 - val_loss: 6.1974 - val_mae: 11.2827 - val_mape: 6.1974 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7920 - mae: 9.4819 - mape: 5.7920 - val_loss: 6.2139 - val_mae: 11.2950 - val_mape: 6.2139 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7913 - mae: 9.5922 - mape: 5.7913 - val_loss: 6.2260 - val_mae: 11.4286 - val_mape: 6.2260 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7801 - mae: 9.3581 - mape: 5.7801 - val_loss: 6.1957 - val_mae: 11.8686 - val_mape: 6.1957 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7573 - mae: 9.3873 - mape: 5.7573 - val_loss: 6.2264 - val_mae: 11.3681 - val_mape: 6.2264 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7747 - mae: 9.6623 - mape: 5.7747 - val_loss: 6.3093 - val_mae: 11.5076 - val_mape: 6.3093 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7780 - mae: 9.7472 - mape: 5.7780 - val_loss: 6.2823 - val_mae: 11.9230 - val_mape: 6.2823 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8031 - mae: 10.0034 - mape: 5.8031 - val_loss: 6.2341 - val_mae: 11.9575 - val_mape: 6.2341 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8125 - mae: 10.5305 - mape: 5.8125 - val_loss: 6.2194 - val_mae: 11.1944 - val_mape: 6.2194 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7583 - mae: 9.0565 - mape: 5.7583 - val_loss: 6.2604 - val_mae: 11.4360 - val_mape: 6.2604 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7687 - mae: 9.4689 - mape: 5.7687 - val_loss: 6.2622 - val_mae: 11.3534 - val_mape: 6.2622 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7844 - mae: 9.6874 - mape: 5.7844 - val_loss: 6.2471 - val_mae: 12.6928 - val_mape: 6.2471 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7466 - mae: 9.4803 - mape: 5.7466 - val_loss: 6.2592 - val_mae: 11.3405 - val_mape: 6.2592 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7746 - mae: 9.4885 - mape: 5.7746 - val_loss: 6.2161 - val_mae: 11.1517 - val_mape: 6.2161 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7635 - mae: 9.3138 - mape: 5.7635 - val_loss: 6.2717 - val_mae: 11.8307 - val_mape: 6.2717 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7620 - mae: 9.1721 - mape: 5.7620 - val_loss: 6.2792 - val_mae: 12.2032 - val_mape: 6.2792 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 5.7580 - mae: 9.8958 - mape: 5.7580\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7541 - mae: 9.5373 - mape: 5.7541 - val_loss: 6.2123 - val_mae: 11.1116 - val_mape: 6.2123 - lr: 3.0000e-04\n",
      "Epoch 61: early stopping\n",
      "Score for fold 4: loss of 5.950839519500732; mae of 10.594961166381836; mape of 5.950839519500732%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 6.1232 - mae: 11.1401 - mape: 6.1232INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_5\\assets\n",
      "87/87 [==============================] - 2s 16ms/step - loss: 6.0847 - mae: 11.3932 - mape: 6.0847 - val_loss: 6.3284 - val_mae: 11.0269 - val_mape: 6.3284 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 6.0495 - mae: 11.8039 - mape: 6.0495INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_5\\assets\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.0918 - mae: 11.5866 - mape: 6.0918 - val_loss: 6.3258 - val_mae: 10.7852 - val_mape: 6.3258 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 6.0203 - mae: 11.4403 - mape: 6.0203INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_5\\assets\n",
      "87/87 [==============================] - 1s 14ms/step - loss: 6.0131 - mae: 11.4608 - mape: 6.0131 - val_loss: 6.3044 - val_mae: 11.6305 - val_mape: 6.3044 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 6.0341 - mae: 11.8113 - mape: 6.0341INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_5\\assets\n",
      "87/87 [==============================] - 1s 17ms/step - loss: 6.0415 - mae: 11.7421 - mape: 6.0415 - val_loss: 6.2773 - val_mae: 9.7293 - val_mape: 6.2773 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.9917 - mae: 11.0729 - mape: 5.9917 - val_loss: 6.3641 - val_mae: 9.7260 - val_mape: 6.3641 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0728 - mae: 11.8398 - mape: 6.0728 - val_loss: 6.7437 - val_mae: 17.3350 - val_mape: 6.7437 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.1246 - mae: 12.7520 - mape: 6.1246 - val_loss: 6.5714 - val_mae: 14.4723 - val_mape: 6.5714 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0187 - mae: 11.5229 - mape: 6.0187 - val_loss: 6.6508 - val_mae: 17.5142 - val_mape: 6.6508 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0502 - mae: 12.8620 - mape: 6.0502 - val_loss: 6.4091 - val_mae: 11.2740 - val_mape: 6.4091 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 6.0030 - mae: 11.7643 - mape: 6.0030 - val_loss: 6.3359 - val_mae: 9.9473 - val_mape: 6.3359 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0587 - mae: 12.5243 - mape: 6.0587 - val_loss: 6.8049 - val_mae: 15.9118 - val_mape: 6.8049 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 6.0420 - mae: 12.5219 - mape: 6.0420 - val_loss: 6.4635 - val_mae: 10.3546 - val_mape: 6.4635 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9545 - mae: 10.6909 - mape: 5.9545 - val_loss: 6.4327 - val_mae: 10.4965 - val_mape: 6.4327 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9874 - mae: 11.3279 - mape: 5.9874 - val_loss: 6.5699 - val_mae: 12.0136 - val_mape: 6.5699 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0932 - mae: 13.9737 - mape: 6.0932 - val_loss: 6.7176 - val_mae: 15.8470 - val_mape: 6.7176 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 6.0047 - mae: 12.3936 - mape: 6.0047 - val_loss: 6.5355 - val_mae: 11.3614 - val_mape: 6.5355 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9554 - mae: 10.5407 - mape: 5.9554 - val_loss: 6.4407 - val_mae: 9.5926 - val_mape: 6.4407 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9901 - mae: 11.7276 - mape: 5.9901 - val_loss: 6.4431 - val_mae: 9.8331 - val_mape: 6.4431 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9810 - mae: 11.7712 - mape: 5.9810 - val_loss: 6.4503 - val_mae: 11.2212 - val_mape: 6.4503 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.9301 - mae: 10.9144 - mape: 5.9301 - val_loss: 6.5942 - val_mae: 10.4663 - val_mape: 6.5942 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.9472 - mae: 11.1673 - mape: 5.9472 - val_loss: 6.6997 - val_mae: 12.7497 - val_mape: 6.6997 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9093 - mae: 10.7037 - mape: 5.9093 - val_loss: 6.5826 - val_mae: 9.9911 - val_mape: 6.5826 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9587 - mae: 11.9708 - mape: 5.9587 - val_loss: 6.8769 - val_mae: 10.3759 - val_mape: 6.8769 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 6.0869 - mae: 12.3305 - mape: 6.0869 - val_loss: 6.5096 - val_mae: 9.9983 - val_mape: 6.5096 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9305 - mae: 11.4845 - mape: 5.9305 - val_loss: 6.8000 - val_mae: 11.7962 - val_mape: 6.8000 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9975 - mae: 11.5852 - mape: 5.9975 - val_loss: 6.7060 - val_mae: 13.9029 - val_mape: 6.7060 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9776 - mae: 11.5167 - mape: 5.9776 - val_loss: 6.6674 - val_mae: 12.9528 - val_mape: 6.6674 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9657 - mae: 11.4201 - mape: 5.9657 - val_loss: 6.7480 - val_mae: 11.6472 - val_mape: 6.7480 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 5.9558 - mae: 10.8354 - mape: 5.9558 - val_loss: 6.5820 - val_mae: 11.3483 - val_mape: 6.5820 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.9076 - mae: 10.8343 - mape: 5.9076 - val_loss: 6.5961 - val_mae: 11.0840 - val_mape: 6.5961 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.8775 - mae: 10.5306 - mape: 5.8775 - val_loss: 6.6533 - val_mae: 10.3396 - val_mape: 6.6533 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9451 - mae: 10.9650 - mape: 5.9451 - val_loss: 6.5282 - val_mae: 9.7135 - val_mape: 6.5282 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.9698 - mae: 11.9513 - mape: 5.9698 - val_loss: 6.5732 - val_mae: 9.7963 - val_mape: 6.5732 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 5.9279 - mae: 10.6610 - mape: 5.9279\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.9565 - mae: 10.8031 - mape: 5.9565 - val_loss: 6.7521 - val_mae: 12.2210 - val_mape: 6.7521 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 5.7904 - mae: 10.2999 - mape: 5.7904 - val_loss: 6.5194 - val_mae: 10.1548 - val_mape: 6.5194 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7060 - mae: 9.7762 - mape: 5.7060 - val_loss: 6.5365 - val_mae: 11.2355 - val_mape: 6.5365 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7686 - mae: 10.8985 - mape: 5.7686 - val_loss: 6.5897 - val_mae: 11.6434 - val_mape: 6.5897 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7550 - mae: 10.3504 - mape: 5.7550 - val_loss: 6.5916 - val_mae: 10.5624 - val_mape: 6.5916 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 5.7395 - mae: 10.1290 - mape: 5.7395 - val_loss: 6.5612 - val_mae: 10.3764 - val_mape: 6.5612 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 5.7034 - mae: 9.8365 - mape: 5.7034 - val_loss: 6.6503 - val_mae: 12.5283 - val_mape: 6.6503 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7224 - mae: 9.6813 - mape: 5.7224 - val_loss: 6.5912 - val_mae: 11.2987 - val_mape: 6.5912 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6888 - mae: 9.5814 - mape: 5.6888 - val_loss: 6.4951 - val_mae: 9.6340 - val_mape: 6.4951 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6952 - mae: 9.7804 - mape: 5.6952 - val_loss: 6.5124 - val_mae: 9.9018 - val_mape: 6.5124 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6887 - mae: 9.7268 - mape: 5.6887 - val_loss: 6.5294 - val_mae: 9.6648 - val_mape: 6.5294 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7258 - mae: 10.3332 - mape: 5.7258 - val_loss: 6.5204 - val_mae: 9.8133 - val_mape: 6.5204 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6970 - mae: 9.8642 - mape: 5.6970 - val_loss: 6.4949 - val_mae: 9.6937 - val_mape: 6.4949 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7055 - mae: 9.7464 - mape: 5.7055 - val_loss: 6.5123 - val_mae: 9.7820 - val_mape: 6.5123 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6875 - mae: 9.5158 - mape: 5.6875 - val_loss: 6.5837 - val_mae: 10.5973 - val_mape: 6.5837 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7190 - mae: 10.3660 - mape: 5.7190 - val_loss: 6.6253 - val_mae: 11.3615 - val_mape: 6.6253 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.7417 - mae: 9.7901 - mape: 5.7417 - val_loss: 6.5504 - val_mae: 9.9613 - val_mape: 6.5504 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7369 - mae: 10.4331 - mape: 5.7369 - val_loss: 6.5223 - val_mae: 9.6799 - val_mape: 6.5223 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6919 - mae: 9.4784 - mape: 5.6919 - val_loss: 6.5699 - val_mae: 9.6123 - val_mape: 6.5699 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 5.7158 - mae: 9.9449 - mape: 5.7158 - val_loss: 6.5744 - val_mae: 9.6270 - val_mape: 6.5744 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6923 - mae: 10.2176 - mape: 5.6923 - val_loss: 6.5984 - val_mae: 11.2301 - val_mape: 6.5984 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6970 - mae: 9.7040 - mape: 5.6970 - val_loss: 6.5429 - val_mae: 10.2520 - val_mape: 6.5429 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6897 - mae: 9.7735 - mape: 5.6897 - val_loss: 6.5557 - val_mae: 9.8710 - val_mape: 6.5557 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6971 - mae: 9.8302 - mape: 5.6971 - val_loss: 6.5637 - val_mae: 9.9194 - val_mape: 6.5637 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.7009 - mae: 9.8939 - mape: 5.7009 - val_loss: 6.6157 - val_mae: 10.8562 - val_mape: 6.6157 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6833 - mae: 9.9372 - mape: 5.6833 - val_loss: 6.5627 - val_mae: 10.1164 - val_mape: 6.5627 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6730 - mae: 9.6237 - mape: 5.6730 - val_loss: 6.5806 - val_mae: 10.4611 - val_mape: 6.5806 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6849 - mae: 9.5202 - mape: 5.6849 - val_loss: 6.5388 - val_mae: 9.7811 - val_mape: 6.5388 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 5.6845 - mae: 9.8492 - mape: 5.6845 - val_loss: 6.6264 - val_mae: 11.0528 - val_mape: 6.6264 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6738 - mae: 9.6627 - mape: 5.6738 - val_loss: 6.6207 - val_mae: 11.4371 - val_mape: 6.6207 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 5.6444 - mae: 9.8416 - mape: 5.6444\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 5.6744 - mae: 9.8671 - mape: 5.6744 - val_loss: 6.7898 - val_mae: 14.0810 - val_mape: 6.7898 - lr: 3.0000e-04\n",
      "Epoch 64: early stopping\n",
      "Score for fold 5: loss of 6.2773308753967285; mae of 9.729349136352539; mape of 6.2773308753967285%;\n"
     ]
    }
   ],
   "source": [
    "#Baseline\n",
    "model = keras.models.load_model(\"savedmodels/Baseline_thesis/\")\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, 'crossvalidationmodels/Baseline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 5.923693656921387 - Mean average error: 8.256022453308105% - Mean percentage error: 5.923693656921387%\n",
      "    Score on unseen data: Loss: 8.403654098510742 - Mean average error: 24.413375854492188% - Mean percentage error: 8.403654098510742%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 6.3426055908203125 - Mean average error: 11.900733947753906% - Mean percentage error: 6.3426055908203125%\n",
      "    Score on unseen data: Loss: 8.492940902709961 - Mean average error: 24.959972381591797% - Mean percentage error: 8.492940902709961%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 5.935964107513428 - Mean average error: 10.848103523254395% - Mean percentage error: 5.935964107513428%\n",
      "    Score on unseen data: Loss: 8.360076904296875 - Mean average error: 24.671741485595703% - Mean percentage error: 8.360076904296875%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 5.950839519500732 - Mean average error: 10.594961166381836% - Mean percentage error: 5.950839519500732%\n",
      "    Score on unseen data: Loss: 8.602704048156738 - Mean average error: 25.333148956298828% - Mean percentage error: 8.602704048156738%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 6.2773308753967285 - Mean average error: 9.729349136352539% - Mean percentage error: 6.2773308753967285%\n",
      "    Score on unseen data: Loss: 8.497225761413574 - Mean average error: 25.165922164916992% - Mean percentage error: 8.497225761413574%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 6.086086750030518\n",
      "> Mean average error: 10.265834045410156\n",
      "> Mean percentage error: 6.086086750030518\n",
      "> Unseen Loss: 8.471320343017577\n",
      "> Unseen Mean average error: 24.908832168579103\n",
      "> Unseen Mean percentage error: 8.471320343017577\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baselinemodel\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 1 ...\n",
      "Epoch 1/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 8.3222 - mae: 35.0033 - mape: 8.3222"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 17ms/step - loss: 8.3324 - mae: 34.6007 - mape: 8.3324 - val_loss: 8.4858 - val_mae: 35.9282 - val_mape: 8.4858 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 8.3541 - mae: 34.1962 - mape: 8.3541"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 13ms/step - loss: 8.3174 - mae: 34.6086 - mape: 8.3174 - val_loss: 8.4618 - val_mae: 36.1693 - val_mape: 8.4618 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 8.3386 - mae: 34.8833 - mape: 8.3386"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 11ms/step - loss: 8.3197 - mae: 34.3266 - mape: 8.3197 - val_loss: 8.4020 - val_mae: 35.6185 - val_mape: 8.4020 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3253 - mae: 34.8372 - mape: 8.3253 - val_loss: 8.4770 - val_mae: 35.5090 - val_mape: 8.4770 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 8.2937 - mae: 32.8635 - mape: 8.2937"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 10ms/step - loss: 8.2637 - mae: 34.9216 - mape: 8.2637 - val_loss: 8.3945 - val_mae: 35.2706 - val_mape: 8.3945 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2955 - mae: 33.9901 - mape: 8.2955 - val_loss: 8.5291 - val_mae: 35.7938 - val_mape: 8.5291 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.3530 - mae: 35.0273 - mape: 8.3530 - val_loss: 8.4233 - val_mae: 35.8130 - val_mape: 8.4233 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2887 - mae: 34.0729 - mape: 8.2887 - val_loss: 8.4428 - val_mae: 35.3279 - val_mape: 8.4428 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2539 - mae: 34.1396 - mape: 8.2539 - val_loss: 8.4637 - val_mae: 35.5255 - val_mape: 8.4637 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2903 - mae: 34.1299 - mape: 8.2903 - val_loss: 8.4831 - val_mae: 35.2117 - val_mape: 8.4831 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2907 - mae: 34.7296 - mape: 8.2907 - val_loss: 8.4741 - val_mae: 35.8923 - val_mape: 8.4741 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2504 - mae: 33.6981 - mape: 8.2504 - val_loss: 8.5680 - val_mae: 35.7459 - val_mape: 8.5680 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2646 - mae: 34.0538 - mape: 8.2646 - val_loss: 8.7192 - val_mae: 37.3255 - val_mape: 8.7192 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2849 - mae: 35.1467 - mape: 8.2849 - val_loss: 8.6294 - val_mae: 36.3288 - val_mape: 8.6294 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2373 - mae: 33.9341 - mape: 8.2373 - val_loss: 8.4710 - val_mae: 35.2544 - val_mape: 8.4710 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2462 - mae: 34.3450 - mape: 8.2462 - val_loss: 8.5234 - val_mae: 35.3610 - val_mape: 8.5234 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3110 - mae: 34.0155 - mape: 8.3110 - val_loss: 8.6544 - val_mae: 36.6091 - val_mape: 8.6544 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2574 - mae: 33.9982 - mape: 8.2574 - val_loss: 8.6293 - val_mae: 35.4048 - val_mape: 8.6293 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2643 - mae: 34.8031 - mape: 8.2643 - val_loss: 8.4718 - val_mae: 35.9458 - val_mape: 8.4718 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2055 - mae: 34.3577 - mape: 8.2055 - val_loss: 8.6753 - val_mae: 36.3706 - val_mape: 8.6753 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2064 - mae: 33.3957 - mape: 8.2064 - val_loss: 8.7292 - val_mae: 36.7624 - val_mape: 8.7292 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2249 - mae: 34.0807 - mape: 8.2249 - val_loss: 8.4391 - val_mae: 36.3034 - val_mape: 8.4391 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2228 - mae: 34.2806 - mape: 8.2228 - val_loss: 8.5726 - val_mae: 35.9318 - val_mape: 8.5726 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2401 - mae: 34.0492 - mape: 8.2401 - val_loss: 8.9009 - val_mae: 36.1930 - val_mape: 8.9009 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2662 - mae: 34.1563 - mape: 8.2662 - val_loss: 8.6185 - val_mae: 35.8101 - val_mape: 8.6185 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1919 - mae: 33.9085 - mape: 8.1919 - val_loss: 8.5605 - val_mae: 36.3696 - val_mape: 8.5605 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1921 - mae: 33.8693 - mape: 8.1921 - val_loss: 8.7666 - val_mae: 36.2308 - val_mape: 8.7666 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2268 - mae: 33.7606 - mape: 8.2268 - val_loss: 8.5362 - val_mae: 35.8814 - val_mape: 8.5362 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 8.2335 - mae: 33.3007 - mape: 8.2335 - val_loss: 8.7011 - val_mae: 35.4556 - val_mape: 8.7011 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1611 - mae: 33.7883 - mape: 8.1611 - val_loss: 8.6383 - val_mae: 35.8735 - val_mape: 8.6383 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1672 - mae: 33.7468 - mape: 8.1672 - val_loss: 8.5636 - val_mae: 35.1609 - val_mape: 8.5636 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2483 - mae: 33.5137 - mape: 8.2483 - val_loss: 8.6372 - val_mae: 35.9951 - val_mape: 8.6372 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2399 - mae: 34.3739 - mape: 8.2399 - val_loss: 8.5609 - val_mae: 35.2393 - val_mape: 8.5609 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1895 - mae: 33.4061 - mape: 8.1895 - val_loss: 8.6730 - val_mae: 36.9154 - val_mape: 8.6730 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 8.2074 - mae: 35.1793 - mape: 8.2074\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1857 - mae: 34.2509 - mape: 8.1857 - val_loss: 8.6040 - val_mae: 35.1991 - val_mape: 8.6040 - lr: 0.0010\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0649 - mae: 32.7288 - mape: 8.0649 - val_loss: 8.4989 - val_mae: 35.7601 - val_mape: 8.4989 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0239 - mae: 33.4509 - mape: 8.0239 - val_loss: 8.5768 - val_mae: 35.4873 - val_mape: 8.5768 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0357 - mae: 33.3399 - mape: 8.0357 - val_loss: 8.4981 - val_mae: 35.6219 - val_mape: 8.4981 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0342 - mae: 33.5653 - mape: 8.0342 - val_loss: 8.5031 - val_mae: 35.1641 - val_mape: 8.5031 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0277 - mae: 33.2808 - mape: 8.0277 - val_loss: 8.4951 - val_mae: 35.3898 - val_mape: 8.4951 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0240 - mae: 33.1350 - mape: 8.0240 - val_loss: 8.5147 - val_mae: 35.2643 - val_mape: 8.5147 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0374 - mae: 33.5339 - mape: 8.0374 - val_loss: 8.5765 - val_mae: 35.3013 - val_mape: 8.5765 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0314 - mae: 33.2477 - mape: 8.0314 - val_loss: 8.5264 - val_mae: 35.0591 - val_mape: 8.5264 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0270 - mae: 33.2064 - mape: 8.0270 - val_loss: 8.5598 - val_mae: 35.5664 - val_mape: 8.5598 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0204 - mae: 33.4593 - mape: 8.0204 - val_loss: 8.5218 - val_mae: 35.3733 - val_mape: 8.5218 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0200 - mae: 33.1420 - mape: 8.0200 - val_loss: 8.5124 - val_mae: 35.5365 - val_mape: 8.5124 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0186 - mae: 33.3849 - mape: 8.0186 - val_loss: 8.5045 - val_mae: 35.3850 - val_mape: 8.5045 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0203 - mae: 33.1542 - mape: 8.0203 - val_loss: 8.5942 - val_mae: 35.9749 - val_mape: 8.5942 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0183 - mae: 33.4253 - mape: 8.0183 - val_loss: 8.5159 - val_mae: 35.3284 - val_mape: 8.5159 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0121 - mae: 33.4770 - mape: 8.0121 - val_loss: 8.5422 - val_mae: 35.2758 - val_mape: 8.5422 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0238 - mae: 33.1900 - mape: 8.0238 - val_loss: 8.5222 - val_mae: 35.5983 - val_mape: 8.5222 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0054 - mae: 33.3404 - mape: 8.0054 - val_loss: 8.5432 - val_mae: 35.3562 - val_mape: 8.5432 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0145 - mae: 33.1807 - mape: 8.0145 - val_loss: 8.5250 - val_mae: 35.5045 - val_mape: 8.5250 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0297 - mae: 33.5271 - mape: 8.0297 - val_loss: 8.5115 - val_mae: 35.1716 - val_mape: 8.5115 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0362 - mae: 33.2055 - mape: 8.0362 - val_loss: 8.5393 - val_mae: 35.4329 - val_mape: 8.5393 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0009 - mae: 33.0961 - mape: 8.0009 - val_loss: 8.5174 - val_mae: 35.7272 - val_mape: 8.5174 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0169 - mae: 33.3448 - mape: 8.0169 - val_loss: 8.5561 - val_mae: 35.5526 - val_mape: 8.5561 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9956 - mae: 33.3461 - mape: 7.9956 - val_loss: 8.5671 - val_mae: 35.5298 - val_mape: 8.5671 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0025 - mae: 33.1877 - mape: 8.0025 - val_loss: 8.5440 - val_mae: 35.4552 - val_mape: 8.5440 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0042 - mae: 33.3820 - mape: 8.0042 - val_loss: 8.5670 - val_mae: 35.4219 - val_mape: 8.5670 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9909 - mae: 33.1015 - mape: 7.9909 - val_loss: 8.5472 - val_mae: 35.1356 - val_mape: 8.5472 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0063 - mae: 33.2891 - mape: 8.0063 - val_loss: 8.5037 - val_mae: 35.1295 - val_mape: 8.5037 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0014 - mae: 33.2582 - mape: 8.0014 - val_loss: 8.6027 - val_mae: 35.9029 - val_mape: 8.6027 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0123 - mae: 33.5484 - mape: 8.0123 - val_loss: 8.5877 - val_mae: 35.5560 - val_mape: 8.5877 - lr: 3.0000e-04\n",
      "Epoch 65/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 7.9673 - mae: 33.5253 - mape: 7.9673\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9954 - mae: 32.9666 - mape: 7.9954 - val_loss: 8.5216 - val_mae: 35.2488 - val_mape: 8.5216 - lr: 3.0000e-04\n",
      "Epoch 65: early stopping\n",
      "Score for fold 1: loss of 8.394530296325684; mae of 35.270599365234375; mape of 8.394530296325684%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 2 ...\n",
      "Epoch 1/1000\n",
      "73/87 [========================>.....] - ETA: 0s - loss: 8.4596 - mae: 36.4582 - mape: 8.4596"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_2\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 11ms/step - loss: 8.4070 - mae: 35.3511 - mape: 8.4070 - val_loss: 8.0102 - val_mae: 33.2472 - val_mape: 8.0102 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.3925 - mae: 36.1053 - mape: 8.3925 - val_loss: 8.0919 - val_mae: 31.3413 - val_mape: 8.0919 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3815 - mae: 35.1455 - mape: 8.3815 - val_loss: 8.0280 - val_mae: 33.1843 - val_mape: 8.0280 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3851 - mae: 35.7902 - mape: 8.3851 - val_loss: 8.2473 - val_mae: 31.8967 - val_mape: 8.2473 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3742 - mae: 35.2473 - mape: 8.3742 - val_loss: 8.0716 - val_mae: 31.3445 - val_mape: 8.0716 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3238 - mae: 35.2696 - mape: 8.3238 - val_loss: 8.1087 - val_mae: 31.3229 - val_mape: 8.1087 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3589 - mae: 35.2162 - mape: 8.3589 - val_loss: 8.0546 - val_mae: 31.4937 - val_mape: 8.0546 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3615 - mae: 35.4906 - mape: 8.3615 - val_loss: 8.1856 - val_mae: 31.5753 - val_mape: 8.1856 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3672 - mae: 35.3091 - mape: 8.3672 - val_loss: 8.1475 - val_mae: 31.7577 - val_mape: 8.1475 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3850 - mae: 36.1218 - mape: 8.3850 - val_loss: 8.0359 - val_mae: 31.4448 - val_mape: 8.0359 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3412 - mae: 34.6843 - mape: 8.3412 - val_loss: 8.0925 - val_mae: 32.1062 - val_mape: 8.0925 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3805 - mae: 34.8926 - mape: 8.3805 - val_loss: 8.1981 - val_mae: 33.8344 - val_mape: 8.1981 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3954 - mae: 35.4043 - mape: 8.3954 - val_loss: 8.2745 - val_mae: 31.6113 - val_mape: 8.2745 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3428 - mae: 34.4772 - mape: 8.3428 - val_loss: 8.0829 - val_mae: 32.7133 - val_mape: 8.0829 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2968 - mae: 35.6252 - mape: 8.2968 - val_loss: 8.0874 - val_mae: 31.8355 - val_mape: 8.0874 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3128 - mae: 34.7822 - mape: 8.3128 - val_loss: 8.1224 - val_mae: 30.6866 - val_mape: 8.1224 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3682 - mae: 35.0538 - mape: 8.3682 - val_loss: 8.2391 - val_mae: 31.0099 - val_mape: 8.2391 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3313 - mae: 34.8373 - mape: 8.3313 - val_loss: 8.3001 - val_mae: 31.2846 - val_mape: 8.3001 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3336 - mae: 35.2371 - mape: 8.3336 - val_loss: 8.0864 - val_mae: 31.3042 - val_mape: 8.0864 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2760 - mae: 34.7747 - mape: 8.2760 - val_loss: 8.1635 - val_mae: 31.2437 - val_mape: 8.1635 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3031 - mae: 34.6330 - mape: 8.3031 - val_loss: 8.0817 - val_mae: 31.8735 - val_mape: 8.0817 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3358 - mae: 35.4093 - mape: 8.3358 - val_loss: 8.3463 - val_mae: 31.4882 - val_mape: 8.3463 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3029 - mae: 35.0201 - mape: 8.3029 - val_loss: 8.1404 - val_mae: 31.6305 - val_mape: 8.1404 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2942 - mae: 34.9926 - mape: 8.2942 - val_loss: 8.2025 - val_mae: 31.3620 - val_mape: 8.2025 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2869 - mae: 34.6305 - mape: 8.2869 - val_loss: 8.1440 - val_mae: 31.7813 - val_mape: 8.1440 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3086 - mae: 35.0284 - mape: 8.3086 - val_loss: 8.1546 - val_mae: 31.9905 - val_mape: 8.1546 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2764 - mae: 34.9825 - mape: 8.2764 - val_loss: 8.3453 - val_mae: 31.2869 - val_mape: 8.3453 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3253 - mae: 35.3398 - mape: 8.3253 - val_loss: 8.2687 - val_mae: 31.3248 - val_mape: 8.2687 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 6ms/step - loss: 8.3316 - mae: 34.8671 - mape: 8.3316 - val_loss: 8.2516 - val_mae: 31.4141 - val_mape: 8.2516 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3220 - mae: 35.5128 - mape: 8.3220 - val_loss: 8.1622 - val_mae: 31.6322 - val_mape: 8.1622 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "81/87 [==========================>...] - ETA: 0s - loss: 8.3039 - mae: 35.9240 - mape: 8.3039\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2603 - mae: 34.2893 - mape: 8.2603 - val_loss: 8.2984 - val_mae: 32.2928 - val_mape: 8.2984 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1667 - mae: 34.9650 - mape: 8.1667 - val_loss: 8.1227 - val_mae: 31.8467 - val_mape: 8.1227 - lr: 3.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1437 - mae: 34.4966 - mape: 8.1437 - val_loss: 8.1382 - val_mae: 31.8785 - val_mape: 8.1382 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1445 - mae: 34.7024 - mape: 8.1445 - val_loss: 8.1574 - val_mae: 31.7577 - val_mape: 8.1574 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1248 - mae: 34.3894 - mape: 8.1248 - val_loss: 8.0968 - val_mae: 31.3818 - val_mape: 8.0968 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1308 - mae: 34.2469 - mape: 8.1308 - val_loss: 8.1419 - val_mae: 32.0462 - val_mape: 8.1419 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1406 - mae: 34.3797 - mape: 8.1406 - val_loss: 8.1430 - val_mae: 31.4976 - val_mape: 8.1430 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1188 - mae: 34.5940 - mape: 8.1188 - val_loss: 8.1342 - val_mae: 31.3326 - val_mape: 8.1342 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1180 - mae: 34.4353 - mape: 8.1180 - val_loss: 8.1469 - val_mae: 31.7532 - val_mape: 8.1469 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1163 - mae: 34.3753 - mape: 8.1163 - val_loss: 8.1869 - val_mae: 31.7256 - val_mape: 8.1869 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1255 - mae: 34.4536 - mape: 8.1255 - val_loss: 8.1974 - val_mae: 31.6744 - val_mape: 8.1974 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1342 - mae: 34.2217 - mape: 8.1342 - val_loss: 8.1487 - val_mae: 31.7070 - val_mape: 8.1487 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1245 - mae: 34.4624 - mape: 8.1245 - val_loss: 8.2288 - val_mae: 31.3001 - val_mape: 8.2288 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1426 - mae: 34.4685 - mape: 8.1426 - val_loss: 8.1857 - val_mae: 31.4908 - val_mape: 8.1857 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1149 - mae: 34.4862 - mape: 8.1149 - val_loss: 8.1510 - val_mae: 31.8860 - val_mape: 8.1510 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1209 - mae: 34.4882 - mape: 8.1209 - val_loss: 8.1697 - val_mae: 31.6581 - val_mape: 8.1697 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1131 - mae: 34.4914 - mape: 8.1131 - val_loss: 8.1372 - val_mae: 31.4281 - val_mape: 8.1372 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1062 - mae: 34.0975 - mape: 8.1062 - val_loss: 8.1688 - val_mae: 31.2683 - val_mape: 8.1688 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1276 - mae: 33.7819 - mape: 8.1276 - val_loss: 8.1724 - val_mae: 31.6480 - val_mape: 8.1724 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1164 - mae: 34.5706 - mape: 8.1164 - val_loss: 8.1441 - val_mae: 31.7269 - val_mape: 8.1441 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1054 - mae: 34.2213 - mape: 8.1054 - val_loss: 8.1479 - val_mae: 31.5307 - val_mape: 8.1479 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1165 - mae: 34.3276 - mape: 8.1165 - val_loss: 8.1572 - val_mae: 31.4246 - val_mape: 8.1572 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1011 - mae: 34.1725 - mape: 8.1011 - val_loss: 8.1807 - val_mae: 31.7470 - val_mape: 8.1807 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.0970 - mae: 34.4989 - mape: 8.0970 - val_loss: 8.1336 - val_mae: 31.6464 - val_mape: 8.1336 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1177 - mae: 34.3712 - mape: 8.1177 - val_loss: 8.1395 - val_mae: 31.6277 - val_mape: 8.1395 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1037 - mae: 34.5478 - mape: 8.1037 - val_loss: 8.1715 - val_mae: 31.7929 - val_mape: 8.1715 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1076 - mae: 34.2730 - mape: 8.1076 - val_loss: 8.1641 - val_mae: 31.6105 - val_mape: 8.1641 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0964 - mae: 34.2320 - mape: 8.0964 - val_loss: 8.1407 - val_mae: 31.5160 - val_mape: 8.1407 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1221 - mae: 34.1163 - mape: 8.1221 - val_loss: 8.2014 - val_mae: 31.4056 - val_mape: 8.2014 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1121 - mae: 34.5029 - mape: 8.1121 - val_loss: 8.2139 - val_mae: 31.2113 - val_mape: 8.2139 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 8.0925 - mae: 31.3967 - mape: 8.0925\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1144 - mae: 34.1981 - mape: 8.1144 - val_loss: 8.1728 - val_mae: 31.3271 - val_mape: 8.1728 - lr: 3.0000e-04\n",
      "Epoch 61: early stopping\n",
      "Score for fold 2: loss of 8.010176658630371; mae of 33.24718475341797; mape of 8.010176658630371%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 3 ...\n",
      "Epoch 1/1000\n",
      "80/87 [==========================>...] - ETA: 0s - loss: 8.2986 - mae: 35.1228 - mape: 8.2986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_3\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_3\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 13ms/step - loss: 8.4204 - mae: 36.2478 - mape: 8.4204 - val_loss: 8.0594 - val_mae: 28.4610 - val_mape: 8.0594 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3653 - mae: 36.6576 - mape: 8.3653 - val_loss: 8.3256 - val_mae: 27.7364 - val_mape: 8.3256 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3665 - mae: 36.3985 - mape: 8.3665 - val_loss: 8.1911 - val_mae: 27.9375 - val_mape: 8.1911 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.4076 - mae: 36.8330 - mape: 8.4076 - val_loss: 8.1254 - val_mae: 28.4753 - val_mape: 8.1254 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3370 - mae: 36.0614 - mape: 8.3370 - val_loss: 8.1653 - val_mae: 28.3846 - val_mape: 8.1653 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3411 - mae: 36.7809 - mape: 8.3411 - val_loss: 8.3197 - val_mae: 28.5529 - val_mape: 8.3197 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3448 - mae: 35.8654 - mape: 8.3448 - val_loss: 8.2451 - val_mae: 28.8329 - val_mape: 8.2451 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3751 - mae: 36.6062 - mape: 8.3751 - val_loss: 8.2400 - val_mae: 27.5860 - val_mape: 8.2400 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3590 - mae: 36.3392 - mape: 8.3590 - val_loss: 8.1761 - val_mae: 27.9204 - val_mape: 8.1761 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3039 - mae: 36.5453 - mape: 8.3039 - val_loss: 8.2817 - val_mae: 27.5125 - val_mape: 8.2817 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3209 - mae: 36.3290 - mape: 8.3209 - val_loss: 8.1176 - val_mae: 27.3439 - val_mape: 8.1176 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3398 - mae: 35.6249 - mape: 8.3398 - val_loss: 8.2241 - val_mae: 27.9263 - val_mape: 8.2241 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3349 - mae: 35.6494 - mape: 8.3349 - val_loss: 8.1476 - val_mae: 28.3134 - val_mape: 8.1476 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3456 - mae: 37.2153 - mape: 8.3456 - val_loss: 8.3094 - val_mae: 27.7072 - val_mape: 8.3094 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3230 - mae: 36.0213 - mape: 8.3230 - val_loss: 8.1425 - val_mae: 27.7630 - val_mape: 8.1425 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3453 - mae: 35.7218 - mape: 8.3453 - val_loss: 8.4195 - val_mae: 29.6414 - val_mape: 8.4195 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2879 - mae: 36.7636 - mape: 8.2879 - val_loss: 8.3390 - val_mae: 28.9048 - val_mape: 8.3390 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3321 - mae: 36.6917 - mape: 8.3321 - val_loss: 8.3323 - val_mae: 27.8584 - val_mape: 8.3323 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2865 - mae: 36.0730 - mape: 8.2865 - val_loss: 8.2338 - val_mae: 27.8687 - val_mape: 8.2338 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2834 - mae: 36.5536 - mape: 8.2834 - val_loss: 8.3813 - val_mae: 27.9290 - val_mape: 8.3813 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3092 - mae: 36.0213 - mape: 8.3092 - val_loss: 8.2476 - val_mae: 27.6456 - val_mape: 8.2476 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2673 - mae: 36.4644 - mape: 8.2673 - val_loss: 8.2718 - val_mae: 28.4316 - val_mape: 8.2718 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2904 - mae: 35.4945 - mape: 8.2904 - val_loss: 8.2574 - val_mae: 29.4299 - val_mape: 8.2574 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2834 - mae: 36.6984 - mape: 8.2834 - val_loss: 8.3320 - val_mae: 27.6767 - val_mape: 8.3320 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2680 - mae: 35.4911 - mape: 8.2680 - val_loss: 8.3074 - val_mae: 27.3593 - val_mape: 8.3074 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2589 - mae: 35.5187 - mape: 8.2589 - val_loss: 8.2469 - val_mae: 28.4483 - val_mape: 8.2469 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2381 - mae: 36.1015 - mape: 8.2381 - val_loss: 8.4025 - val_mae: 28.1013 - val_mape: 8.4025 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3265 - mae: 36.3082 - mape: 8.3265 - val_loss: 8.2464 - val_mae: 28.0723 - val_mape: 8.2464 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2719 - mae: 35.9298 - mape: 8.2719 - val_loss: 8.1794 - val_mae: 28.1468 - val_mape: 8.1794 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2892 - mae: 36.0642 - mape: 8.2892 - val_loss: 8.2739 - val_mae: 27.6406 - val_mape: 8.2739 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 8.2293 - mae: 34.5392 - mape: 8.2293\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2457 - mae: 36.2394 - mape: 8.2457 - val_loss: 8.3373 - val_mae: 28.2027 - val_mape: 8.3373 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1491 - mae: 35.7384 - mape: 8.1491 - val_loss: 8.2239 - val_mae: 27.9560 - val_mape: 8.2239 - lr: 3.0000e-04\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1144 - mae: 35.7370 - mape: 8.1144 - val_loss: 8.2918 - val_mae: 28.0746 - val_mape: 8.2918 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1216 - mae: 35.5420 - mape: 8.1216 - val_loss: 8.2754 - val_mae: 28.0046 - val_mape: 8.2754 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1118 - mae: 35.6448 - mape: 8.1118 - val_loss: 8.2308 - val_mae: 27.9857 - val_mape: 8.2308 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1097 - mae: 35.5131 - mape: 8.1097 - val_loss: 8.2347 - val_mae: 27.7701 - val_mape: 8.2347 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1093 - mae: 35.6889 - mape: 8.1093 - val_loss: 8.3070 - val_mae: 27.8061 - val_mape: 8.3070 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1037 - mae: 35.4674 - mape: 8.1037 - val_loss: 8.2599 - val_mae: 28.3024 - val_mape: 8.2599 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1057 - mae: 35.7170 - mape: 8.1057 - val_loss: 8.2285 - val_mae: 27.8164 - val_mape: 8.2285 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1181 - mae: 35.4201 - mape: 8.1181 - val_loss: 8.2802 - val_mae: 27.9075 - val_mape: 8.2802 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0864 - mae: 35.2912 - mape: 8.0864 - val_loss: 8.2517 - val_mae: 28.0007 - val_mape: 8.2517 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1166 - mae: 35.9416 - mape: 8.1166 - val_loss: 8.2762 - val_mae: 27.8450 - val_mape: 8.2762 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1010 - mae: 35.7355 - mape: 8.1010 - val_loss: 8.2465 - val_mae: 27.8198 - val_mape: 8.2465 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0951 - mae: 35.4460 - mape: 8.0951 - val_loss: 8.2707 - val_mae: 27.7196 - val_mape: 8.2707 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0878 - mae: 35.1772 - mape: 8.0878 - val_loss: 8.2826 - val_mae: 28.2063 - val_mape: 8.2826 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0858 - mae: 35.3757 - mape: 8.0858 - val_loss: 8.2983 - val_mae: 28.1877 - val_mape: 8.2983 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0957 - mae: 35.5443 - mape: 8.0957 - val_loss: 8.2717 - val_mae: 27.6222 - val_mape: 8.2717 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0945 - mae: 35.4209 - mape: 8.0945 - val_loss: 8.2609 - val_mae: 27.9317 - val_mape: 8.2609 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0895 - mae: 35.5492 - mape: 8.0895 - val_loss: 8.2929 - val_mae: 28.1286 - val_mape: 8.2929 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1173 - mae: 35.8237 - mape: 8.1173 - val_loss: 8.2679 - val_mae: 27.8318 - val_mape: 8.2679 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0843 - mae: 35.3942 - mape: 8.0843 - val_loss: 8.2157 - val_mae: 28.1148 - val_mape: 8.2157 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0839 - mae: 35.4828 - mape: 8.0839 - val_loss: 8.2784 - val_mae: 27.9199 - val_mape: 8.2784 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0758 - mae: 35.4953 - mape: 8.0758 - val_loss: 8.3522 - val_mae: 27.7794 - val_mape: 8.3522 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1085 - mae: 35.8533 - mape: 8.1085 - val_loss: 8.3048 - val_mae: 28.0496 - val_mape: 8.3048 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0780 - mae: 35.6426 - mape: 8.0780 - val_loss: 8.3077 - val_mae: 28.0235 - val_mape: 8.3077 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0941 - mae: 35.6077 - mape: 8.0941 - val_loss: 8.3016 - val_mae: 27.8945 - val_mape: 8.3016 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0854 - mae: 35.5628 - mape: 8.0854 - val_loss: 8.3178 - val_mae: 27.8760 - val_mape: 8.3178 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1072 - mae: 35.7719 - mape: 8.1072 - val_loss: 8.2557 - val_mae: 27.7482 - val_mape: 8.2557 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1071 - mae: 35.3783 - mape: 8.1071 - val_loss: 8.2492 - val_mae: 27.7860 - val_mape: 8.2492 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0835 - mae: 35.2462 - mape: 8.0835 - val_loss: 8.2558 - val_mae: 27.8647 - val_mape: 8.2558 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 8.1002 - mae: 36.0005 - mape: 8.1002\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0749 - mae: 35.6341 - mape: 8.0749 - val_loss: 8.3130 - val_mae: 27.9148 - val_mape: 8.3130 - lr: 3.0000e-04\n",
      "Epoch 61: early stopping\n",
      "Score for fold 3: loss of 8.059365272521973; mae of 28.46101951599121; mape of 8.059365272521973%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 4 ...\n",
      "Epoch 1/1000\n",
      "78/87 [=========================>....] - ETA: 0s - loss: 8.2791 - mae: 30.5872 - mape: 8.2791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 2s 14ms/step - loss: 8.2890 - mae: 30.7924 - mape: 8.2890 - val_loss: 8.7280 - val_mae: 53.2243 - val_mape: 8.7280 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "85/87 [============================>.] - ETA: 0s - loss: 8.2870 - mae: 31.1713 - mape: 8.2870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 11ms/step - loss: 8.2790 - mae: 31.6956 - mape: 8.2790 - val_loss: 8.7207 - val_mae: 54.3648 - val_mape: 8.7207 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "86/87 [============================>.] - ETA: 0s - loss: 8.2146 - mae: 31.4393 - mape: 8.2146"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 11ms/step - loss: 8.2271 - mae: 31.2535 - mape: 8.2271 - val_loss: 8.6033 - val_mae: 50.3644 - val_mape: 8.6033 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "83/87 [===========================>..] - ETA: 0s - loss: 8.2214 - mae: 30.6622 - mape: 8.2214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_4\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_4\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 11ms/step - loss: 8.2219 - mae: 30.8087 - mape: 8.2219 - val_loss: 8.5786 - val_mae: 49.1202 - val_mape: 8.5786 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2741 - mae: 31.4131 - mape: 8.2741 - val_loss: 8.6592 - val_mae: 51.6855 - val_mape: 8.6592 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2381 - mae: 31.6409 - mape: 8.2381 - val_loss: 8.6112 - val_mae: 50.7421 - val_mape: 8.6112 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1930 - mae: 31.5114 - mape: 8.1930 - val_loss: 8.6899 - val_mae: 49.6111 - val_mape: 8.6899 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1993 - mae: 30.8346 - mape: 8.1993 - val_loss: 8.6684 - val_mae: 51.7651 - val_mape: 8.6684 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1898 - mae: 31.0784 - mape: 8.1898 - val_loss: 8.6430 - val_mae: 52.1965 - val_mape: 8.6430 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1790 - mae: 31.0569 - mape: 8.1790 - val_loss: 8.8034 - val_mae: 51.6959 - val_mape: 8.8034 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2064 - mae: 31.0192 - mape: 8.2064 - val_loss: 8.6381 - val_mae: 49.5734 - val_mape: 8.6381 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3147 - mae: 30.9862 - mape: 8.3147 - val_loss: 8.6956 - val_mae: 51.0945 - val_mape: 8.6956 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2268 - mae: 30.6739 - mape: 8.2268 - val_loss: 8.7627 - val_mae: 51.3504 - val_mape: 8.7627 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2050 - mae: 31.2571 - mape: 8.2050 - val_loss: 8.8506 - val_mae: 53.8251 - val_mape: 8.8506 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1549 - mae: 30.7752 - mape: 8.1549 - val_loss: 8.8268 - val_mae: 51.9104 - val_mape: 8.8268 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1596 - mae: 30.9810 - mape: 8.1596 - val_loss: 8.7618 - val_mae: 49.8739 - val_mape: 8.7618 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 1s 6ms/step - loss: 8.1734 - mae: 31.1100 - mape: 8.1734 - val_loss: 8.6417 - val_mae: 50.1533 - val_mape: 8.6417 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1710 - mae: 30.5864 - mape: 8.1710 - val_loss: 8.8347 - val_mae: 52.6767 - val_mape: 8.8347 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1523 - mae: 31.2629 - mape: 8.1523 - val_loss: 8.8884 - val_mae: 52.9124 - val_mape: 8.8884 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2396 - mae: 31.5998 - mape: 8.2396 - val_loss: 8.7254 - val_mae: 51.2723 - val_mape: 8.7254 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2047 - mae: 30.9066 - mape: 8.2047 - val_loss: 8.7905 - val_mae: 51.3555 - val_mape: 8.7905 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.1483 - mae: 30.8333 - mape: 8.1483 - val_loss: 8.7112 - val_mae: 50.6480 - val_mape: 8.7112 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1895 - mae: 30.6814 - mape: 8.1895 - val_loss: 8.7924 - val_mae: 54.1443 - val_mape: 8.7924 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1466 - mae: 30.7627 - mape: 8.1466 - val_loss: 8.8686 - val_mae: 51.9298 - val_mape: 8.8686 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1962 - mae: 30.8205 - mape: 8.1962 - val_loss: 8.7852 - val_mae: 54.0233 - val_mape: 8.7852 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1588 - mae: 31.0543 - mape: 8.1588 - val_loss: 8.6758 - val_mae: 52.6115 - val_mape: 8.6758 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1694 - mae: 30.5523 - mape: 8.1694 - val_loss: 8.7736 - val_mae: 51.6583 - val_mape: 8.7736 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1492 - mae: 30.8100 - mape: 8.1492 - val_loss: 8.7807 - val_mae: 52.8480 - val_mape: 8.7807 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1239 - mae: 30.9039 - mape: 8.1239 - val_loss: 8.7373 - val_mae: 51.7020 - val_mape: 8.7373 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1353 - mae: 30.6579 - mape: 8.1353 - val_loss: 8.8363 - val_mae: 50.1747 - val_mape: 8.8363 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1325 - mae: 30.8083 - mape: 8.1325 - val_loss: 8.7602 - val_mae: 50.9901 - val_mape: 8.7602 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0970 - mae: 30.9038 - mape: 8.0970 - val_loss: 8.7808 - val_mae: 54.0851 - val_mape: 8.7808 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1184 - mae: 30.6681 - mape: 8.1184 - val_loss: 8.7378 - val_mae: 53.3836 - val_mape: 8.7378 - lr: 0.0010\n",
      "Epoch 34/1000\n",
      "76/87 [=========================>....] - ETA: 0s - loss: 8.2830 - mae: 32.5521 - mape: 8.2830\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1497 - mae: 30.6619 - mape: 8.1497 - val_loss: 8.8236 - val_mae: 50.9134 - val_mape: 8.8236 - lr: 0.0010\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9951 - mae: 30.0185 - mape: 7.9951 - val_loss: 8.7275 - val_mae: 51.9464 - val_mape: 8.7275 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9802 - mae: 30.6193 - mape: 7.9802 - val_loss: 8.7199 - val_mae: 51.2971 - val_mape: 8.7199 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9827 - mae: 30.5978 - mape: 7.9827 - val_loss: 8.7044 - val_mae: 50.2732 - val_mape: 8.7044 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9581 - mae: 29.9232 - mape: 7.9581 - val_loss: 8.7876 - val_mae: 52.3281 - val_mape: 8.7876 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9614 - mae: 30.6828 - mape: 7.9614 - val_loss: 8.7951 - val_mae: 51.2572 - val_mape: 8.7951 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9779 - mae: 29.9168 - mape: 7.9779 - val_loss: 8.7310 - val_mae: 51.2854 - val_mape: 8.7310 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9650 - mae: 30.1095 - mape: 7.9650 - val_loss: 8.7351 - val_mae: 51.6749 - val_mape: 8.7351 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9508 - mae: 29.9223 - mape: 7.9508 - val_loss: 8.7709 - val_mae: 52.7529 - val_mape: 8.7709 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9647 - mae: 30.5816 - mape: 7.9647 - val_loss: 8.7086 - val_mae: 51.6371 - val_mape: 8.7086 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9651 - mae: 30.2311 - mape: 7.9651 - val_loss: 8.7369 - val_mae: 51.7093 - val_mape: 8.7369 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9642 - mae: 30.2661 - mape: 7.9642 - val_loss: 8.7649 - val_mae: 52.0911 - val_mape: 8.7649 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 7.9659 - mae: 30.1087 - mape: 7.9659 - val_loss: 8.7617 - val_mae: 50.9335 - val_mape: 8.7617 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9417 - mae: 30.0595 - mape: 7.9417 - val_loss: 8.7857 - val_mae: 51.4347 - val_mape: 8.7857 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9536 - mae: 30.6115 - mape: 7.9536 - val_loss: 8.7859 - val_mae: 50.8197 - val_mape: 8.7859 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9437 - mae: 30.0454 - mape: 7.9437 - val_loss: 8.7355 - val_mae: 50.7518 - val_mape: 8.7355 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9492 - mae: 29.9025 - mape: 7.9492 - val_loss: 8.7346 - val_mae: 51.3826 - val_mape: 8.7346 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9662 - mae: 30.1549 - mape: 7.9662 - val_loss: 8.7319 - val_mae: 51.0542 - val_mape: 8.7319 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9383 - mae: 29.9990 - mape: 7.9383 - val_loss: 8.7851 - val_mae: 51.1060 - val_mape: 8.7851 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9488 - mae: 30.0691 - mape: 7.9488 - val_loss: 8.7261 - val_mae: 50.8714 - val_mape: 8.7261 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9601 - mae: 30.0558 - mape: 7.9601 - val_loss: 8.7398 - val_mae: 50.6957 - val_mape: 8.7398 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9471 - mae: 30.0500 - mape: 7.9471 - val_loss: 8.7515 - val_mae: 52.5053 - val_mape: 8.7515 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9585 - mae: 30.3704 - mape: 7.9585 - val_loss: 8.7528 - val_mae: 51.8378 - val_mape: 8.7528 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9320 - mae: 30.0971 - mape: 7.9320 - val_loss: 8.7508 - val_mae: 50.8382 - val_mape: 8.7508 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9332 - mae: 29.9869 - mape: 7.9332 - val_loss: 8.7595 - val_mae: 51.1182 - val_mape: 8.7595 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9522 - mae: 30.2568 - mape: 7.9522 - val_loss: 8.7204 - val_mae: 51.3126 - val_mape: 8.7204 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9216 - mae: 29.8082 - mape: 7.9216 - val_loss: 8.7920 - val_mae: 51.9065 - val_mape: 8.7920 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9420 - mae: 30.2526 - mape: 7.9420 - val_loss: 8.7164 - val_mae: 50.8884 - val_mape: 8.7164 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9465 - mae: 29.9424 - mape: 7.9465 - val_loss: 8.8120 - val_mae: 52.0576 - val_mape: 8.8120 - lr: 3.0000e-04\n",
      "Epoch 63/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9440 - mae: 30.2237 - mape: 7.9440 - val_loss: 8.7528 - val_mae: 52.2090 - val_mape: 8.7528 - lr: 3.0000e-04\n",
      "Epoch 64/1000\n",
      "82/87 [===========================>..] - ETA: 0s - loss: 8.0046 - mae: 30.7525 - mape: 8.0046\n",
      "Epoch 64: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9324 - mae: 30.2886 - mape: 7.9324 - val_loss: 8.7839 - val_mae: 51.1516 - val_mape: 8.7839 - lr: 3.0000e-04\n",
      "Epoch 64: early stopping\n",
      "Score for fold 4: loss of 8.578596115112305; mae of 49.12015914916992; mape of 8.578596115112305%;\n",
      "------------------------------------------------------------------------\n",
      "Training for fold 5 ...\n",
      "Epoch 1/1000\n",
      "84/87 [===========================>..] - ETA: 0s - loss: 8.3396 - mae: 37.5785 - mape: 8.3396"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 13ms/step - loss: 8.3074 - mae: 36.5599 - mape: 8.3074 - val_loss: 8.4028 - val_mae: 27.1397 - val_mape: 8.4028 - lr: 0.0010\n",
      "Epoch 2/1000\n",
      "74/87 [========================>.....] - ETA: 0s - loss: 8.3041 - mae: 37.5328 - mape: 8.3041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) Input with unsupported characters which will be renamed to input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: crossvalidationmodels\\Baseline_single_layer_5\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 1s 11ms/step - loss: 8.2584 - mae: 36.2245 - mape: 8.2584 - val_loss: 8.3393 - val_mae: 27.2158 - val_mape: 8.3393 - lr: 0.0010\n",
      "Epoch 3/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2436 - mae: 36.3880 - mape: 8.2436 - val_loss: 8.4946 - val_mae: 27.3768 - val_mape: 8.4946 - lr: 0.0010\n",
      "Epoch 4/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.3206 - mae: 36.7574 - mape: 8.3206 - val_loss: 8.4235 - val_mae: 27.0345 - val_mape: 8.4235 - lr: 0.0010\n",
      "Epoch 5/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2665 - mae: 35.8703 - mape: 8.2665 - val_loss: 8.4096 - val_mae: 27.0255 - val_mape: 8.4096 - lr: 0.0010\n",
      "Epoch 6/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2891 - mae: 36.3179 - mape: 8.2891 - val_loss: 8.5029 - val_mae: 27.4559 - val_mape: 8.5029 - lr: 0.0010\n",
      "Epoch 7/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2793 - mae: 36.9859 - mape: 8.2793 - val_loss: 8.4809 - val_mae: 27.1868 - val_mape: 8.4809 - lr: 0.0010\n",
      "Epoch 8/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 8.2698 - mae: 35.4907 - mape: 8.2698 - val_loss: 8.5010 - val_mae: 27.5039 - val_mape: 8.5010 - lr: 0.0010\n",
      "Epoch 9/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2827 - mae: 36.4310 - mape: 8.2827 - val_loss: 8.6024 - val_mae: 27.6122 - val_mape: 8.6024 - lr: 0.0010\n",
      "Epoch 10/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2502 - mae: 35.8270 - mape: 8.2502 - val_loss: 8.4441 - val_mae: 27.4080 - val_mape: 8.4441 - lr: 0.0010\n",
      "Epoch 11/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2817 - mae: 36.4078 - mape: 8.2817 - val_loss: 8.5833 - val_mae: 27.3639 - val_mape: 8.5833 - lr: 0.0010\n",
      "Epoch 12/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2363 - mae: 36.9091 - mape: 8.2363 - val_loss: 8.5169 - val_mae: 26.8384 - val_mape: 8.5169 - lr: 0.0010\n",
      "Epoch 13/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2416 - mae: 36.2827 - mape: 8.2416 - val_loss: 8.4299 - val_mae: 27.1139 - val_mape: 8.4299 - lr: 0.0010\n",
      "Epoch 14/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2265 - mae: 36.3247 - mape: 8.2265 - val_loss: 8.5233 - val_mae: 27.0543 - val_mape: 8.5233 - lr: 0.0010\n",
      "Epoch 15/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2039 - mae: 35.7276 - mape: 8.2039 - val_loss: 8.5125 - val_mae: 26.9898 - val_mape: 8.5125 - lr: 0.0010\n",
      "Epoch 16/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2194 - mae: 35.7849 - mape: 8.2194 - val_loss: 8.8477 - val_mae: 27.3888 - val_mape: 8.8477 - lr: 0.0010\n",
      "Epoch 17/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2757 - mae: 36.4321 - mape: 8.2757 - val_loss: 8.4509 - val_mae: 27.0715 - val_mape: 8.4509 - lr: 0.0010\n",
      "Epoch 18/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1931 - mae: 36.0697 - mape: 8.1931 - val_loss: 8.5915 - val_mae: 27.3923 - val_mape: 8.5915 - lr: 0.0010\n",
      "Epoch 19/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2288 - mae: 36.2427 - mape: 8.2288 - val_loss: 8.4826 - val_mae: 27.1637 - val_mape: 8.4826 - lr: 0.0010\n",
      "Epoch 20/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2036 - mae: 35.5907 - mape: 8.2036 - val_loss: 8.6879 - val_mae: 27.6055 - val_mape: 8.6879 - lr: 0.0010\n",
      "Epoch 21/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2025 - mae: 36.4219 - mape: 8.2025 - val_loss: 8.5494 - val_mae: 27.5929 - val_mape: 8.5494 - lr: 0.0010\n",
      "Epoch 22/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1659 - mae: 35.2828 - mape: 8.1659 - val_loss: 8.4812 - val_mae: 27.3673 - val_mape: 8.4812 - lr: 0.0010\n",
      "Epoch 23/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2199 - mae: 35.4780 - mape: 8.2199 - val_loss: 8.4700 - val_mae: 27.4640 - val_mape: 8.4700 - lr: 0.0010\n",
      "Epoch 24/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1575 - mae: 36.2039 - mape: 8.1575 - val_loss: 8.5383 - val_mae: 27.2437 - val_mape: 8.5383 - lr: 0.0010\n",
      "Epoch 25/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1778 - mae: 35.8979 - mape: 8.1778 - val_loss: 8.5146 - val_mae: 27.0204 - val_mape: 8.5146 - lr: 0.0010\n",
      "Epoch 26/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2285 - mae: 36.0645 - mape: 8.2285 - val_loss: 8.5374 - val_mae: 27.3381 - val_mape: 8.5374 - lr: 0.0010\n",
      "Epoch 27/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2049 - mae: 35.7882 - mape: 8.2049 - val_loss: 8.5560 - val_mae: 27.5467 - val_mape: 8.5560 - lr: 0.0010\n",
      "Epoch 28/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1643 - mae: 36.0119 - mape: 8.1643 - val_loss: 8.6726 - val_mae: 27.5837 - val_mape: 8.6726 - lr: 0.0010\n",
      "Epoch 29/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.2006 - mae: 35.9799 - mape: 8.2006 - val_loss: 8.5815 - val_mae: 27.1428 - val_mape: 8.5815 - lr: 0.0010\n",
      "Epoch 30/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1831 - mae: 35.8980 - mape: 8.1831 - val_loss: 8.5399 - val_mae: 27.1555 - val_mape: 8.5399 - lr: 0.0010\n",
      "Epoch 31/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1865 - mae: 35.5954 - mape: 8.1865 - val_loss: 8.4571 - val_mae: 26.8457 - val_mape: 8.4571 - lr: 0.0010\n",
      "Epoch 32/1000\n",
      "75/87 [========================>.....] - ETA: 0s - loss: 8.0709 - mae: 36.1760 - mape: 8.0709\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.1625 - mae: 35.9449 - mape: 8.1625 - val_loss: 8.5632 - val_mae: 27.2527 - val_mape: 8.5632 - lr: 0.0010\n",
      "Epoch 33/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0557 - mae: 35.6248 - mape: 8.0557 - val_loss: 8.4941 - val_mae: 27.0308 - val_mape: 8.4941 - lr: 3.0000e-04\n",
      "Epoch 34/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0285 - mae: 35.3306 - mape: 8.0285 - val_loss: 8.4827 - val_mae: 26.9459 - val_mape: 8.4827 - lr: 3.0000e-04\n",
      "Epoch 35/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0181 - mae: 35.4956 - mape: 8.0181 - val_loss: 8.4753 - val_mae: 27.1800 - val_mape: 8.4753 - lr: 3.0000e-04\n",
      "Epoch 36/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0164 - mae: 35.2301 - mape: 8.0164 - val_loss: 8.4868 - val_mae: 27.1821 - val_mape: 8.4868 - lr: 3.0000e-04\n",
      "Epoch 37/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0123 - mae: 35.3910 - mape: 8.0123 - val_loss: 8.4722 - val_mae: 27.0501 - val_mape: 8.4722 - lr: 3.0000e-04\n",
      "Epoch 38/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0118 - mae: 35.5696 - mape: 8.0118 - val_loss: 8.4667 - val_mae: 26.9663 - val_mape: 8.4667 - lr: 3.0000e-04\n",
      "Epoch 39/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9972 - mae: 35.2673 - mape: 7.9972 - val_loss: 8.4796 - val_mae: 27.0725 - val_mape: 8.4796 - lr: 3.0000e-04\n",
      "Epoch 40/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0130 - mae: 35.2803 - mape: 8.0130 - val_loss: 8.4951 - val_mae: 27.1894 - val_mape: 8.4951 - lr: 3.0000e-04\n",
      "Epoch 41/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0061 - mae: 35.3733 - mape: 8.0061 - val_loss: 8.5285 - val_mae: 27.0879 - val_mape: 8.5285 - lr: 3.0000e-04\n",
      "Epoch 42/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0191 - mae: 35.1733 - mape: 8.0191 - val_loss: 8.5791 - val_mae: 27.1373 - val_mape: 8.5791 - lr: 3.0000e-04\n",
      "Epoch 43/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0067 - mae: 35.3874 - mape: 8.0067 - val_loss: 8.4699 - val_mae: 27.0031 - val_mape: 8.4699 - lr: 3.0000e-04\n",
      "Epoch 44/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0071 - mae: 35.3086 - mape: 8.0071 - val_loss: 8.4996 - val_mae: 27.0415 - val_mape: 8.4996 - lr: 3.0000e-04\n",
      "Epoch 45/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0016 - mae: 35.2823 - mape: 8.0016 - val_loss: 8.5331 - val_mae: 27.0256 - val_mape: 8.5331 - lr: 3.0000e-04\n",
      "Epoch 46/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9903 - mae: 35.3585 - mape: 7.9903 - val_loss: 8.4888 - val_mae: 27.1572 - val_mape: 8.4888 - lr: 3.0000e-04\n",
      "Epoch 47/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0020 - mae: 35.1283 - mape: 8.0020 - val_loss: 8.5311 - val_mae: 27.0650 - val_mape: 8.5311 - lr: 3.0000e-04\n",
      "Epoch 48/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0100 - mae: 35.0851 - mape: 8.0100 - val_loss: 8.5049 - val_mae: 27.1587 - val_mape: 8.5049 - lr: 3.0000e-04\n",
      "Epoch 49/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0096 - mae: 35.7622 - mape: 8.0096 - val_loss: 8.5038 - val_mae: 27.3655 - val_mape: 8.5038 - lr: 3.0000e-04\n",
      "Epoch 50/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0106 - mae: 35.3483 - mape: 8.0106 - val_loss: 8.4717 - val_mae: 27.1162 - val_mape: 8.4717 - lr: 3.0000e-04\n",
      "Epoch 51/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9965 - mae: 35.1364 - mape: 7.9965 - val_loss: 8.4844 - val_mae: 27.1137 - val_mape: 8.4844 - lr: 3.0000e-04\n",
      "Epoch 52/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0045 - mae: 35.4647 - mape: 8.0045 - val_loss: 8.5083 - val_mae: 27.0072 - val_mape: 8.5083 - lr: 3.0000e-04\n",
      "Epoch 53/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9877 - mae: 35.2449 - mape: 7.9877 - val_loss: 8.4947 - val_mae: 27.1669 - val_mape: 8.4947 - lr: 3.0000e-04\n",
      "Epoch 54/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9901 - mae: 35.4429 - mape: 7.9901 - val_loss: 8.5572 - val_mae: 27.0294 - val_mape: 8.5572 - lr: 3.0000e-04\n",
      "Epoch 55/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9906 - mae: 35.0272 - mape: 7.9906 - val_loss: 8.4931 - val_mae: 27.0993 - val_mape: 8.4931 - lr: 3.0000e-04\n",
      "Epoch 56/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9928 - mae: 35.4783 - mape: 7.9928 - val_loss: 8.5070 - val_mae: 27.1910 - val_mape: 8.5070 - lr: 3.0000e-04\n",
      "Epoch 57/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9911 - mae: 35.1013 - mape: 7.9911 - val_loss: 8.5145 - val_mae: 27.1259 - val_mape: 8.5145 - lr: 3.0000e-04\n",
      "Epoch 58/1000\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 7.9921 - mae: 35.5481 - mape: 7.9921 - val_loss: 8.5874 - val_mae: 27.0434 - val_mape: 8.5874 - lr: 3.0000e-04\n",
      "Epoch 59/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 8.0155 - mae: 35.1328 - mape: 8.0155 - val_loss: 8.5324 - val_mae: 26.9431 - val_mape: 8.5324 - lr: 3.0000e-04\n",
      "Epoch 60/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9900 - mae: 35.2839 - mape: 7.9900 - val_loss: 8.5281 - val_mae: 26.9228 - val_mape: 8.5281 - lr: 3.0000e-04\n",
      "Epoch 61/1000\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9726 - mae: 35.0920 - mape: 7.9726 - val_loss: 8.5365 - val_mae: 26.9183 - val_mape: 8.5365 - lr: 3.0000e-04\n",
      "Epoch 62/1000\n",
      "79/87 [==========================>...] - ETA: 0s - loss: 7.9558 - mae: 34.7584 - mape: 7.9558\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 7.9879 - mae: 34.9914 - mape: 7.9879 - val_loss: 8.4972 - val_mae: 26.9893 - val_mape: 8.4972 - lr: 3.0000e-04\n",
      "Epoch 62: early stopping\n",
      "Score for fold 5: loss of 8.33930778503418; mae of 27.215782165527344; mape of 8.33930778503418%;\n"
     ]
    }
   ],
   "source": [
    "#Baseline single layer\n",
    "model = keras.models.load_model(\"savedmodels/Baseline_single_layer/\")\n",
    "loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold = cross_validate(model, 'crossvalidationmodels/Baseline_single_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "Score per fold\n",
      "------------------------------------------------------------------------\n",
      "> Fold 1 - Loss: 8.394530296325684 - Mean average error: 35.270599365234375% - Mean percentage error: 8.394530296325684%\n",
      "    Score on unseen data: Loss: 10.917137145996094 - Mean average error: 77.03203582763672% - Mean percentage error: 10.917137145996094%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 2 - Loss: 8.010176658630371 - Mean average error: 33.24718475341797% - Mean percentage error: 8.010176658630371%\n",
      "    Score on unseen data: Loss: 10.75243854522705 - Mean average error: 83.67593383789062% - Mean percentage error: 10.75243854522705%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 3 - Loss: 8.059365272521973 - Mean average error: 28.46101951599121% - Mean percentage error: 8.059365272521973%\n",
      "    Score on unseen data: Loss: 10.739811897277832 - Mean average error: 81.40345001220703% - Mean percentage error: 10.739811897277832%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 4 - Loss: 8.578596115112305 - Mean average error: 49.12015914916992% - Mean percentage error: 8.578596115112305%\n",
      "    Score on unseen data: Loss: 10.810441017150879 - Mean average error: 77.5462417602539% - Mean percentage error: 10.810441017150879%\n",
      "------------------------------------------------------------------------\n",
      "------------------------------------------------------------------------\n",
      "> Fold 5 - Loss: 8.33930778503418 - Mean average error: 27.215782165527344% - Mean percentage error: 8.33930778503418%\n",
      "    Score on unseen data: Loss: 10.598382949829102 - Mean average error: 79.12207794189453% - Mean percentage error: 10.598382949829102%\n",
      "------------------------------------------------------------------------\n",
      "Average scores for all folds:\n",
      "> Loss: 8.276395225524903\n",
      "> Mean average error: 34.66294898986816\n",
      "> Mean percentage error: 8.276395225524903\n",
      "> Unseen Loss: 10.763642311096191\n",
      "> Unseen Mean average error: 79.75594787597656\n",
      "> Unseen Mean percentage error: 10.763642311096191\n",
      "------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print_scores(loss_per_fold, mae_per_fold, mape_per_fold, validation_per_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " normalization_7 (Normalizat  (None, 13)               27        \n",
      " ion)                                                            \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 72)                1008      \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 248)               18104     \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 8)                 1992      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,140\n",
      "Trainable params: 21,113\n",
      "Non-trainable params: 27\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"savedmodels/Baseline_thesis/\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_layer('dense_31')._name = 'Output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"architectures/baseline.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot mape\n",
    "plt.plot(model.history.history[\"mape\"], label='Train')\n",
    "plt.plot(model.history.history[\"val_mape\"], label='Validation')\n",
    "plt.legend()\n",
    "plt.title('model mean absolute percentage error')\n",
    "plt.ylabel('mape')\n",
    "plt.xlabel('epoch')\n",
    "#plt.ylim([35, 150])\n",
    "#plt.xlim([0, 250])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "objects = ('Baseline', 'Multi-input')\n",
    "y_pos = np.arange(len(objects))\n",
    "performance = [21.92,17.57]\n",
    "\n",
    "plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "plt.xticks(y_pos, objects)\n",
    "plt.ylabel('Mean absolute percentage error')\n",
    "plt.title('Model error rates (lower is better)')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfenvironment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d217d37ed9247659b2812203162b84cdb779e33cccd1fe199abf14cba0e180e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
